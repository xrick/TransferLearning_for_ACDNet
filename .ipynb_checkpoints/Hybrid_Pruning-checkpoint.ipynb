{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([(17,1),(18,2),(24,3),\n",
    "                             (51,4),(52,5),(53,6)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(\"./datasets/fold1_dataset.npz\", allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 64;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 10;#2000;\n",
    "    opt.LR = 0.01#0.1;\n",
    "    opt.schedule = [0.03, 0.06, 0.09]#[0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 6#50;\n",
    "    opt.nFolds = 1;#5;\n",
    "    opt.split = 1#[i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 16000#20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 5;\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  6 #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = 6\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=6, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 4;#2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 1 #determine the prunning algo\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.opt.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel()\n",
    "        self.net.load_state_dict(torch.load(\"./th/pruned_models/first_stage_pruning/acdnet_tl_weighted_pruning_model_202312271337_100epoch.pt\", map_location=self.opt.device)['weight']);\n",
    "        # self.net = models.GetACDNetModel().to(self.opt.device);\n",
    "        # state = torch.load(self.opt.model_path, map_location=self.opt.device);\n",
    "        # self.net.load_state_dict(state['weight']);\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(\"./datasets/fold1_test16000_65batch.npz\", allow_pickle=True);\n",
    "            self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "            self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = \"{}/th/pruned_models/second_stage_pruned_models/magnitude_pruning/{}.pt\";\n",
    "        old_model = fname.format(dir, self.opt.model_name.lower());\n",
    "        if os.path.isfile(old_model):\n",
    "            os.remove(old_model);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname.format(dir, self.opt.model_name.lower()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    opt.prune_ratio = 0.80\n",
    "    opt.prune_all = True;\n",
    "    # import torch;\n",
    "    opt.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.model_name = \"acdnet_tl_hybrid_pruning_magnitude_model_202312281149_test\"\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:65\n",
      "Start to pruning.....\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.308%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (6, 2, 4)      3,072       24,576\n",
      " BatchNorm2d-42         (6, 2, 4)         (6, 2, 4)         12            0\n",
      "        ReLu-43         (6, 2, 4)         (6, 2, 4)          0           48\n",
      "   AvgPool2d-44         (6, 2, 4)         (6, 1, 1)          0           48\n",
      "     Flatten-45         (6, 1, 1)            (1, 6)          0            0\n",
      "      Linear-46            (1, 6)            (1, 6)         42           42\n",
      "     Softmax-47            (1, 6)            (1, 6)          0            6\n",
      "==============================================================================\n",
      "Total Params: 4,710,254\n",
      "Total FLOPs : 544,238,560\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.97\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2030, Prunable: 2030, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (80%): 1623\n",
      "Total iterations required: 1623\n",
      "\n",
      "Iteration 1 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,710,212 (17.968 MB), Total: 18.08 MB, FLOPs: 483,670,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1625 finished in 0m06s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,710,170 (17.968 MB), Total: 18.08 MB, FLOPs: 483,305,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1625 finished in 0m06s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,710,128 (17.968 MB), Total: 18.08 MB, FLOPs: 478,773,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1625 finished in 0m06s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,710,086 (17.968 MB), Total: 18.08 MB, FLOPs: 478,407,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.308%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1625 finished in 0m06s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,710,044 (17.967 MB), Total: 18.08 MB, FLOPs: 465,673,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1625 finished in 0m05s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,710,002 (17.967 MB), Total: 18.08 MB, FLOPs: 465,307,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1625 finished in 0m06s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,709,960 (17.967 MB), Total: 18.08 MB, FLOPs: 460,775,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1625 finished in 0m05s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,709,918 (17.967 MB), Total: 18.08 MB, FLOPs: 460,409,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1625 finished in 0m05s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,709,876 (17.967 MB), Total: 18.08 MB, FLOPs: 431,731,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1625 finished in 0m05s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,709,834 (17.967 MB), Total: 18.08 MB, FLOPs: 431,366,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1625 finished in 0m05s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,709,792 (17.966 MB), Total: 18.08 MB, FLOPs: 426,834,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1625 finished in 0m05s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 1)]\n",
      "Input: 0.115 MB, Params: 4,709,205 (17.964 MB), Total: 18.08 MB, FLOPs: 425,623,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1625 finished in 0m05s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.115 MB, Params: 4,708,618 (17.962 MB), Total: 18.08 MB, FLOPs: 424,412,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1625 finished in 0m04s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 24)]\n",
      "Input: 0.115 MB, Params: 4,708,031 (17.960 MB), Total: 18.08 MB, FLOPs: 423,201,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1625 finished in 0m05s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 58)]\n",
      "Input: 0.115 MB, Params: 4,707,192 (17.957 MB), Total: 18.07 MB, FLOPs: 421,566,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1625 finished in 0m05s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,700,278 (17.930 MB), Total: 18.05 MB, FLOPs: 421,193,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1625 finished in 0m05s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 4,695,662 (17.913 MB), Total: 18.03 MB, FLOPs: 421,068,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1625 finished in 0m05s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 53)]\n",
      "Input: 0.115 MB, Params: 4,692,213 (17.899 MB), Total: 18.01 MB, FLOPs: 420,696,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1625 finished in 0m05s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.115 MB, Params: 4,691,635 (17.897 MB), Total: 18.01 MB, FLOPs: 419,503,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1625 finished in 0m05s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 15)]\n",
      "Input: 0.115 MB, Params: 4,691,057 (17.895 MB), Total: 18.01 MB, FLOPs: 418,309,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1625 finished in 0m05s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 110)]\n",
      "Input: 0.115 MB, Params: 4,687,608 (17.882 MB), Total: 18.00 MB, FLOPs: 417,937,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1625 finished in 0m05s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 9)]\n",
      "Input: 0.115 MB, Params: 4,687,030 (17.880 MB), Total: 17.99 MB, FLOPs: 416,743,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1625 finished in 0m05s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 469)]\n",
      "Input: 0.115 MB, Params: 4,680,134 (17.853 MB), Total: 17.97 MB, FLOPs: 416,557,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1625 finished in 0m04s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 4,673,238 (17.827 MB), Total: 17.94 MB, FLOPs: 416,371,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1625 finished in 0m05s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 4,666,342 (17.801 MB), Total: 17.92 MB, FLOPs: 416,185,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1625 finished in 0m05s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 4,659,446 (17.774 MB), Total: 17.89 MB, FLOPs: 415,999,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1625 finished in 0m05s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 4,652,550 (17.748 MB), Total: 17.86 MB, FLOPs: 415,812,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1625 finished in 0m05s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 4,645,654 (17.722 MB), Total: 17.84 MB, FLOPs: 415,626,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1625 finished in 0m05s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 155)]\n",
      "Input: 0.115 MB, Params: 4,642,205 (17.709 MB), Total: 17.82 MB, FLOPs: 415,254,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1625 finished in 0m05s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 505)]\n",
      "Input: 0.115 MB, Params: 4,635,309 (17.682 MB), Total: 17.80 MB, FLOPs: 415,068,231\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1625 finished in 0m05s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.115 MB, Params: 4,628,413 (17.656 MB), Total: 17.77 MB, FLOPs: 414,882,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1625 finished in 0m05s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 4,626,683 (17.649 MB), Total: 17.76 MB, FLOPs: 414,050,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1625 finished in 0m05s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 354)]\n",
      "Input: 0.115 MB, Params: 4,619,787 (17.623 MB), Total: 17.74 MB, FLOPs: 413,864,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1625 finished in 0m05s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 107)]\n",
      "Input: 0.115 MB, Params: 4,618,057 (17.616 MB), Total: 17.73 MB, FLOPs: 413,032,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1625 finished in 0m04s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 4,611,161 (17.590 MB), Total: 17.71 MB, FLOPs: 412,846,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1625 finished in 0m04s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 23)]\n",
      "Input: 0.115 MB, Params: 4,610,583 (17.588 MB), Total: 17.70 MB, FLOPs: 411,652,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1625 finished in 0m04s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 244)]\n",
      "Input: 0.115 MB, Params: 4,603,786 (17.562 MB), Total: 17.68 MB, FLOPs: 411,284,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1625 finished in 0m04s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 472)]\n",
      "Input: 0.115 MB, Params: 4,596,899 (17.536 MB), Total: 17.65 MB, FLOPs: 411,098,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1625 finished in 0m05s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 4,590,012 (17.510 MB), Total: 17.62 MB, FLOPs: 410,912,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1625 finished in 0m05s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 406)]\n",
      "Input: 0.115 MB, Params: 4,583,125 (17.483 MB), Total: 17.60 MB, FLOPs: 410,727,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1625 finished in 0m04s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 334)]\n",
      "Input: 0.115 MB, Params: 4,576,238 (17.457 MB), Total: 17.57 MB, FLOPs: 410,541,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1625 finished in 0m04s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 4,569,351 (17.431 MB), Total: 17.55 MB, FLOPs: 410,355,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1625 finished in 0m04s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 448)]\n",
      "Input: 0.115 MB, Params: 4,562,464 (17.404 MB), Total: 17.52 MB, FLOPs: 410,169,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1625 finished in 0m04s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.115 MB, Params: 4,555,577 (17.378 MB), Total: 17.49 MB, FLOPs: 409,983,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1625 finished in 0m04s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 4,548,690 (17.352 MB), Total: 17.47 MB, FLOPs: 409,797,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1625 finished in 0m04s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 201)]\n",
      "Input: 0.115 MB, Params: 4,541,965 (17.326 MB), Total: 17.44 MB, FLOPs: 409,431,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1625 finished in 0m04s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 4,535,087 (17.300 MB), Total: 17.42 MB, FLOPs: 409,245,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1625 finished in 0m05s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 179)]\n",
      "Input: 0.115 MB, Params: 4,531,656 (17.287 MB), Total: 17.40 MB, FLOPs: 408,875,171\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1625 finished in 0m05s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 4,528,225 (17.274 MB), Total: 17.39 MB, FLOPs: 408,504,731\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1625 finished in 0m04s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 405)]\n",
      "Input: 0.115 MB, Params: 4,521,347 (17.248 MB), Total: 17.36 MB, FLOPs: 408,319,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1625 finished in 0m04s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 4,514,469 (17.221 MB), Total: 17.34 MB, FLOPs: 408,133,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1625 finished in 0m04s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 4,511,038 (17.208 MB), Total: 17.32 MB, FLOPs: 407,762,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1625 finished in 0m04s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 4,504,160 (17.182 MB), Total: 17.30 MB, FLOPs: 407,577,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1625 finished in 0m04s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 4,497,282 (17.156 MB), Total: 17.27 MB, FLOPs: 407,391,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1625 finished in 0m05s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 4,490,629 (17.130 MB), Total: 17.25 MB, FLOPs: 407,029,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1625 finished in 0m05s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 4,483,760 (17.104 MB), Total: 17.22 MB, FLOPs: 406,844,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1625 finished in 0m05s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 4,476,891 (17.078 MB), Total: 17.19 MB, FLOPs: 406,658,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1625 finished in 0m05s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 4,470,022 (17.052 MB), Total: 17.17 MB, FLOPs: 406,473,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1625 finished in 0m05s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 342)]\n",
      "Input: 0.115 MB, Params: 4,463,153 (17.026 MB), Total: 17.14 MB, FLOPs: 406,287,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1625 finished in 0m05s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 4,461,423 (17.019 MB), Total: 17.13 MB, FLOPs: 405,456,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1625 finished in 0m05s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 4,457,050 (17.002 MB), Total: 17.12 MB, FLOPs: 405,338,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1625 finished in 0m05s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 4,452,677 (16.986 MB), Total: 17.10 MB, FLOPs: 405,220,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1625 finished in 0m05s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 4,445,826 (16.959 MB), Total: 17.07 MB, FLOPs: 405,035,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1625 finished in 0m05s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 4,438,975 (16.933 MB), Total: 17.05 MB, FLOPs: 404,850,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1625 finished in 0m05s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 4,435,553 (16.920 MB), Total: 17.04 MB, FLOPs: 404,480,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1625 finished in 0m05s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 4,428,702 (16.894 MB), Total: 17.01 MB, FLOPs: 404,295,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1625 finished in 0m05s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 467)]\n",
      "Input: 0.115 MB, Params: 4,424,356 (16.878 MB), Total: 16.99 MB, FLOPs: 404,178,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1625 finished in 0m05s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.115 MB, Params: 4,417,514 (16.851 MB), Total: 16.97 MB, FLOPs: 403,994,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1625 finished in 0m05s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 4,414,092 (16.838 MB), Total: 16.95 MB, FLOPs: 403,624,609\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1625 finished in 0m05s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 452)]\n",
      "Input: 0.115 MB, Params: 4,407,250 (16.812 MB), Total: 16.93 MB, FLOPs: 403,439,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1625 finished in 0m05s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 368)]\n",
      "Input: 0.115 MB, Params: 4,400,408 (16.786 MB), Total: 16.90 MB, FLOPs: 403,255,195\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1625 finished in 0m05s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 4,393,566 (16.760 MB), Total: 16.88 MB, FLOPs: 403,070,488\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1625 finished in 0m05s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 4,389,256 (16.744 MB), Total: 16.86 MB, FLOPs: 402,954,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1625 finished in 0m05s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 282)]\n",
      "Input: 0.115 MB, Params: 4,382,423 (16.718 MB), Total: 16.83 MB, FLOPs: 402,769,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1625 finished in 0m05s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 436)]\n",
      "Input: 0.115 MB, Params: 4,375,590 (16.692 MB), Total: 16.81 MB, FLOPs: 402,585,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1625 finished in 0m05s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 289)]\n",
      "Input: 0.115 MB, Params: 4,371,298 (16.675 MB), Total: 16.79 MB, FLOPs: 402,469,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1625 finished in 0m05s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 99)]\n",
      "Input: 0.115 MB, Params: 4,369,568 (16.669 MB), Total: 16.78 MB, FLOPs: 401,637,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1625 finished in 0m05s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 4,362,744 (16.643 MB), Total: 16.76 MB, FLOPs: 401,453,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1625 finished in 0m05s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 4,359,322 (16.629 MB), Total: 16.74 MB, FLOPs: 401,084,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1625 finished in 0m05s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.115 MB, Params: 4,355,039 (16.613 MB), Total: 16.73 MB, FLOPs: 400,968,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1625 finished in 0m05s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 463)]\n",
      "Input: 0.115 MB, Params: 4,348,224 (16.587 MB), Total: 16.70 MB, FLOPs: 400,784,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1625 finished in 0m05s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 50)]\n",
      "Input: 0.115 MB, Params: 4,347,421 (16.584 MB), Total: 16.70 MB, FLOPs: 399,220,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1625 finished in 0m05s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 4,340,606 (16.558 MB), Total: 16.67 MB, FLOPs: 399,036,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1625 finished in 0m05s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 4,333,791 (16.532 MB), Total: 16.65 MB, FLOPs: 398,852,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1625 finished in 0m05s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 174)]\n",
      "Input: 0.115 MB, Params: 4,330,369 (16.519 MB), Total: 16.63 MB, FLOPs: 398,483,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1625 finished in 0m05s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.115 MB, Params: 4,323,554 (16.493 MB), Total: 16.61 MB, FLOPs: 398,299,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1625 finished in 0m05s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 75)]\n",
      "Input: 0.115 MB, Params: 4,321,824 (16.486 MB), Total: 16.60 MB, FLOPs: 397,467,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1625 finished in 0m05s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 462)]\n",
      "Input: 0.115 MB, Params: 4,315,009 (16.460 MB), Total: 16.58 MB, FLOPs: 397,283,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1625 finished in 0m05s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 4,308,563 (16.436 MB), Total: 16.55 MB, FLOPs: 396,930,329\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1625 finished in 0m05s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 4,304,325 (16.420 MB), Total: 16.53 MB, FLOPs: 396,816,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1625 finished in 0m05s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 4,297,528 (16.394 MB), Total: 16.51 MB, FLOPs: 396,632,560\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1625 finished in 0m05s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.115 MB, Params: 4,290,731 (16.368 MB), Total: 16.48 MB, FLOPs: 396,449,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1625 finished in 0m05s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 4,283,934 (16.342 MB), Total: 16.46 MB, FLOPs: 396,265,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1625 finished in 0m05s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 440)]\n",
      "Input: 0.115 MB, Params: 4,277,137 (16.316 MB), Total: 16.43 MB, FLOPs: 396,082,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1625 finished in 0m05s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 4,270,340 (16.290 MB), Total: 16.41 MB, FLOPs: 395,898,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1625 finished in 0m05s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 456)]\n",
      "Input: 0.115 MB, Params: 4,263,543 (16.264 MB), Total: 16.38 MB, FLOPs: 395,715,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1625 finished in 0m05s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 4,257,151 (16.240 MB), Total: 16.36 MB, FLOPs: 395,363,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1625 finished in 0m05s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 388)]\n",
      "Input: 0.115 MB, Params: 4,250,363 (16.214 MB), Total: 16.33 MB, FLOPs: 395,179,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1625 finished in 0m05s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 4,243,575 (16.188 MB), Total: 16.30 MB, FLOPs: 394,996,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1625 finished in 0m05s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 4)]\n",
      "Input: 0.115 MB, Params: 4,242,772 (16.185 MB), Total: 16.30 MB, FLOPs: 393,432,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1625 finished in 0m05s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 223)]\n",
      "Input: 0.115 MB, Params: 4,236,398 (16.161 MB), Total: 16.28 MB, FLOPs: 393,081,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1625 finished in 0m05s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 233)]\n",
      "Input: 0.115 MB, Params: 4,229,619 (16.135 MB), Total: 16.25 MB, FLOPs: 392,898,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1625 finished in 0m05s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.115 MB, Params: 4,225,462 (16.119 MB), Total: 16.23 MB, FLOPs: 392,785,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1625 finished in 0m05s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 4,218,692 (16.093 MB), Total: 16.21 MB, FLOPs: 392,603,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1625 finished in 0m05s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 4,214,544 (16.077 MB), Total: 16.19 MB, FLOPs: 392,491,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1625 finished in 0m05s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 4,207,783 (16.051 MB), Total: 16.17 MB, FLOPs: 392,308,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1625 finished in 0m05s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 4,201,022 (16.026 MB), Total: 16.14 MB, FLOPs: 392,126,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1625 finished in 0m05s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 378)]\n",
      "Input: 0.115 MB, Params: 4,194,261 (16.000 MB), Total: 16.12 MB, FLOPs: 391,943,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1625 finished in 0m05s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 350)]\n",
      "Input: 0.115 MB, Params: 4,187,500 (15.974 MB), Total: 16.09 MB, FLOPs: 391,761,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1625 finished in 0m05s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 4,180,739 (15.948 MB), Total: 16.06 MB, FLOPs: 391,578,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1625 finished in 0m05s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.115 MB, Params: 4,173,978 (15.922 MB), Total: 16.04 MB, FLOPs: 391,396,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1625 finished in 0m05s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 4,169,884 (15.907 MB), Total: 16.02 MB, FLOPs: 391,285,813\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1625 finished in 0m05s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.115 MB, Params: 4,165,790 (15.891 MB), Total: 16.01 MB, FLOPs: 391,175,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1625 finished in 0m05s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 55)]\n",
      "Input: 0.115 MB, Params: 4,164,060 (15.885 MB), Total: 16.00 MB, FLOPs: 390,343,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1625 finished in 0m05s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 435)]\n",
      "Input: 0.115 MB, Params: 4,159,966 (15.869 MB), Total: 15.98 MB, FLOPs: 390,233,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1625 finished in 0m05s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 374)]\n",
      "Input: 0.115 MB, Params: 4,155,872 (15.853 MB), Total: 15.97 MB, FLOPs: 390,122,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1625 finished in 0m05s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 4,151,778 (15.838 MB), Total: 15.95 MB, FLOPs: 390,012,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1625 finished in 0m04s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 370)]\n",
      "Input: 0.115 MB, Params: 4,145,062 (15.812 MB), Total: 15.93 MB, FLOPs: 389,831,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1625 finished in 0m05s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.115 MB, Params: 4,138,769 (15.788 MB), Total: 15.90 MB, FLOPs: 389,481,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1625 finished in 0m05s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 432)]\n",
      "Input: 0.115 MB, Params: 4,134,684 (15.773 MB), Total: 15.89 MB, FLOPs: 389,371,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1625 finished in 0m04s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.115 MB, Params: 4,127,986 (15.747 MB), Total: 15.86 MB, FLOPs: 389,190,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1625 finished in 0m05s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 123)]\n",
      "Input: 0.115 MB, Params: 4,124,600 (15.734 MB), Total: 15.85 MB, FLOPs: 388,825,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1625 finished in 0m05s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 365)]\n",
      "Input: 0.115 MB, Params: 4,117,902 (15.709 MB), Total: 15.82 MB, FLOPs: 388,644,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1625 finished in 0m05s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 365)]\n",
      "Input: 0.115 MB, Params: 4,111,204 (15.683 MB), Total: 15.80 MB, FLOPs: 388,463,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1625 finished in 0m05s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 4,104,506 (15.657 MB), Total: 15.77 MB, FLOPs: 388,282,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1625 finished in 0m05s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 4,097,808 (15.632 MB), Total: 15.75 MB, FLOPs: 388,102,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1625 finished in 0m04s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 4,094,422 (15.619 MB), Total: 15.73 MB, FLOPs: 387,736,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1625 finished in 0m04s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 4,087,724 (15.593 MB), Total: 15.71 MB, FLOPs: 387,555,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1625 finished in 0m04s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 4,081,026 (15.568 MB), Total: 15.68 MB, FLOPs: 387,374,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1625 finished in 0m04s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 115)]\n",
      "Input: 0.115 MB, Params: 4,079,296 (15.561 MB), Total: 15.68 MB, FLOPs: 386,543,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1625 finished in 0m04s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 4,073,084 (15.538 MB), Total: 15.65 MB, FLOPs: 386,197,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1625 finished in 0m05s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 283)]\n",
      "Input: 0.115 MB, Params: 4,069,062 (15.522 MB), Total: 15.64 MB, FLOPs: 386,089,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1625 finished in 0m04s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 4,062,382 (15.497 MB), Total: 15.61 MB, FLOPs: 385,908,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1625 finished in 0m04s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 370)]\n",
      "Input: 0.115 MB, Params: 4,055,702 (15.471 MB), Total: 15.59 MB, FLOPs: 385,728,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1625 finished in 0m04s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 116)]\n",
      "Input: 0.115 MB, Params: 4,049,508 (15.448 MB), Total: 15.56 MB, FLOPs: 385,383,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1625 finished in 0m04s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 4,042,837 (15.422 MB), Total: 15.54 MB, FLOPs: 385,202,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1625 finished in 0m04s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 4,036,166 (15.397 MB), Total: 15.51 MB, FLOPs: 385,022,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1625 finished in 0m04s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 315)]\n",
      "Input: 0.115 MB, Params: 4,029,495 (15.371 MB), Total: 15.49 MB, FLOPs: 384,842,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1625 finished in 0m04s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 4,023,328 (15.348 MB), Total: 15.46 MB, FLOPs: 384,498,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1625 finished in 0m05s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.115 MB, Params: 4,019,351 (15.333 MB), Total: 15.45 MB, FLOPs: 384,391,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1625 finished in 0m04s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 4,012,698 (15.307 MB), Total: 15.42 MB, FLOPs: 384,211,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1625 finished in 0m04s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 358)]\n",
      "Input: 0.115 MB, Params: 4,008,730 (15.292 MB), Total: 15.41 MB, FLOPs: 384,104,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1625 finished in 0m04s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 4,002,086 (15.267 MB), Total: 15.38 MB, FLOPs: 383,925,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1625 finished in 0m04s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.115 MB, Params: 3,995,442 (15.241 MB), Total: 15.36 MB, FLOPs: 383,745,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1625 finished in 0m04s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 3,991,492 (15.226 MB), Total: 15.34 MB, FLOPs: 383,639,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1625 finished in 0m04s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 3,984,857 (15.201 MB), Total: 15.32 MB, FLOPs: 383,460,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1625 finished in 0m05s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 3,980,916 (15.186 MB), Total: 15.30 MB, FLOPs: 383,353,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1625 finished in 0m04s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 3,974,290 (15.161 MB), Total: 15.28 MB, FLOPs: 383,174,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1625 finished in 0m05s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.115 MB, Params: 3,967,664 (15.135 MB), Total: 15.25 MB, FLOPs: 382,996,072\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1625 finished in 0m04s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 259)]\n",
      "Input: 0.115 MB, Params: 3,961,038 (15.110 MB), Total: 15.23 MB, FLOPs: 382,817,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1625 finished in 0m04s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 440)]\n",
      "Input: 0.115 MB, Params: 3,957,124 (15.095 MB), Total: 15.21 MB, FLOPs: 382,711,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1625 finished in 0m04s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 327)]\n",
      "Input: 0.115 MB, Params: 3,950,507 (15.070 MB), Total: 15.19 MB, FLOPs: 382,533,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1625 finished in 0m04s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 3,948,777 (15.063 MB), Total: 15.18 MB, FLOPs: 381,701,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1625 finished in 0m04s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 268)]\n",
      "Input: 0.115 MB, Params: 3,942,160 (15.038 MB), Total: 15.15 MB, FLOPs: 381,522,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1625 finished in 0m04s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 3,935,543 (15.013 MB), Total: 15.13 MB, FLOPs: 381,344,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1625 finished in 0m04s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 3,928,926 (14.988 MB), Total: 15.10 MB, FLOPs: 381,165,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1625 finished in 0m04s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 477)]\n",
      "Input: 0.115 MB, Params: 3,925,048 (14.973 MB), Total: 15.09 MB, FLOPs: 381,060,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1625 finished in 0m04s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 3,918,440 (14.948 MB), Total: 15.06 MB, FLOPs: 380,882,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1625 finished in 0m04s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 3,911,832 (14.922 MB), Total: 15.04 MB, FLOPs: 380,704,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1625 finished in 0m04s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 171)]\n",
      "Input: 0.115 MB, Params: 3,908,473 (14.910 MB), Total: 15.02 MB, FLOPs: 380,341,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1625 finished in 0m04s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 3,904,613 (14.895 MB), Total: 15.01 MB, FLOPs: 380,237,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1625 finished in 0m04s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 380)]\n",
      "Input: 0.115 MB, Params: 3,898,014 (14.870 MB), Total: 14.99 MB, FLOPs: 380,059,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1625 finished in 0m04s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 178)]\n",
      "Input: 0.115 MB, Params: 3,891,415 (14.845 MB), Total: 14.96 MB, FLOPs: 379,881,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1625 finished in 0m04s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 79)]\n",
      "Input: 0.115 MB, Params: 3,889,685 (14.838 MB), Total: 14.95 MB, FLOPs: 379,049,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1625 finished in 0m04s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 320)]\n",
      "Input: 0.115 MB, Params: 3,883,086 (14.813 MB), Total: 14.93 MB, FLOPs: 378,871,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1625 finished in 0m04s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 3,879,253 (14.798 MB), Total: 14.91 MB, FLOPs: 378,767,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1625 finished in 0m04s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 411)]\n",
      "Input: 0.115 MB, Params: 3,875,420 (14.784 MB), Total: 14.90 MB, FLOPs: 378,664,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1625 finished in 0m04s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 3,868,839 (14.758 MB), Total: 14.87 MB, FLOPs: 378,486,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1625 finished in 0m04s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.115 MB, Params: 3,862,258 (14.733 MB), Total: 14.85 MB, FLOPs: 378,309,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1625 finished in 0m04s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 3,860,636 (14.727 MB), Total: 14.84 MB, FLOPs: 376,719,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1625 finished in 0m04s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.115 MB, Params: 3,854,055 (14.702 MB), Total: 14.82 MB, FLOPs: 376,542,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1625 finished in 0m04s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 3,847,474 (14.677 MB), Total: 14.79 MB, FLOPs: 376,364,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1625 finished in 0m04s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 3,843,677 (14.662 MB), Total: 14.78 MB, FLOPs: 376,262,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1625 finished in 0m04s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.115 MB, Params: 3,839,880 (14.648 MB), Total: 14.76 MB, FLOPs: 376,159,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1625 finished in 0m04s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.115 MB, Params: 3,833,317 (14.623 MB), Total: 14.74 MB, FLOPs: 375,982,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1625 finished in 0m04s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 483)]\n",
      "Input: 0.115 MB, Params: 3,829,529 (14.608 MB), Total: 14.72 MB, FLOPs: 375,880,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1625 finished in 0m04s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 279)]\n",
      "Input: 0.115 MB, Params: 3,822,975 (14.583 MB), Total: 14.70 MB, FLOPs: 375,703,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1625 finished in 0m04s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 3,816,421 (14.558 MB), Total: 14.67 MB, FLOPs: 375,526,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1625 finished in 0m04s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 230)]\n",
      "Input: 0.115 MB, Params: 3,809,867 (14.533 MB), Total: 14.65 MB, FLOPs: 375,349,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1625 finished in 0m05s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 482)]\n",
      "Input: 0.115 MB, Params: 3,806,106 (14.519 MB), Total: 14.63 MB, FLOPs: 375,248,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1625 finished in 0m04s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 3,799,561 (14.494 MB), Total: 14.61 MB, FLOPs: 375,071,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1625 finished in 0m04s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.115 MB, Params: 3,793,628 (14.472 MB), Total: 14.59 MB, FLOPs: 374,734,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1625 finished in 0m04s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.115 MB, Params: 3,787,092 (14.447 MB), Total: 14.56 MB, FLOPs: 374,557,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1625 finished in 0m04s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 221)]\n",
      "Input: 0.115 MB, Params: 3,781,168 (14.424 MB), Total: 14.54 MB, FLOPs: 374,220,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1625 finished in 0m04s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 480)]\n",
      "Input: 0.115 MB, Params: 3,777,425 (14.410 MB), Total: 14.53 MB, FLOPs: 374,119,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1625 finished in 0m04s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 3,770,907 (14.385 MB), Total: 14.50 MB, FLOPs: 373,943,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1625 finished in 0m04s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 3,767,173 (14.371 MB), Total: 14.49 MB, FLOPs: 373,842,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1625 finished in 0m04s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.115 MB, Params: 3,760,664 (14.346 MB), Total: 14.46 MB, FLOPs: 373,667,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1625 finished in 0m04s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 225)]\n",
      "Input: 0.115 MB, Params: 3,757,323 (14.333 MB), Total: 14.45 MB, FLOPs: 373,306,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1625 finished in 0m04s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 3,750,814 (14.308 MB), Total: 14.42 MB, FLOPs: 373,130,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1625 finished in 0m04s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 362)]\n",
      "Input: 0.115 MB, Params: 3,747,098 (14.294 MB), Total: 14.41 MB, FLOPs: 373,030,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1625 finished in 0m04s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 3,740,598 (14.269 MB), Total: 14.38 MB, FLOPs: 372,854,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1625 finished in 0m04s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 26)]\n",
      "Input: 0.115 MB, Params: 3,737,257 (14.257 MB), Total: 14.37 MB, FLOPs: 372,494,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1625 finished in 0m05s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 459)]\n",
      "Input: 0.115 MB, Params: 3,733,550 (14.242 MB), Total: 14.36 MB, FLOPs: 372,394,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1625 finished in 0m04s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 3,727,059 (14.218 MB), Total: 14.33 MB, FLOPs: 372,219,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1625 finished in 0m04s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 3,723,361 (14.203 MB), Total: 14.32 MB, FLOPs: 372,119,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1625 finished in 0m04s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 3,716,879 (14.179 MB), Total: 14.29 MB, FLOPs: 371,944,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1625 finished in 0m04s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 373)]\n",
      "Input: 0.115 MB, Params: 3,710,397 (14.154 MB), Total: 14.27 MB, FLOPs: 371,769,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1625 finished in 0m04s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 278)]\n",
      "Input: 0.115 MB, Params: 3,706,717 (14.140 MB), Total: 14.26 MB, FLOPs: 371,670,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1625 finished in 0m04s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 3,700,244 (14.115 MB), Total: 14.23 MB, FLOPs: 371,495,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1625 finished in 0m04s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 183)]\n",
      "Input: 0.115 MB, Params: 3,694,410 (14.093 MB), Total: 14.21 MB, FLOPs: 371,162,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1625 finished in 0m04s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 360)]\n",
      "Input: 0.115 MB, Params: 3,687,946 (14.068 MB), Total: 14.18 MB, FLOPs: 370,987,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1625 finished in 0m04s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 3,681,482 (14.044 MB), Total: 14.16 MB, FLOPs: 370,813,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1625 finished in 0m04s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 363)]\n",
      "Input: 0.115 MB, Params: 3,677,829 (14.030 MB), Total: 14.15 MB, FLOPs: 370,714,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1625 finished in 0m04s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.115 MB, Params: 3,671,374 (14.005 MB), Total: 14.12 MB, FLOPs: 370,540,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1625 finished in 0m04s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.115 MB, Params: 3,664,919 (13.981 MB), Total: 14.10 MB, FLOPs: 370,366,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1625 finished in 0m04s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 3,658,464 (13.956 MB), Total: 14.07 MB, FLOPs: 370,191,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1625 finished in 0m05s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 87)]\n",
      "Input: 0.115 MB, Params: 3,655,222 (13.944 MB), Total: 14.06 MB, FLOPs: 369,441,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1625 finished in 0m05s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 87)]\n",
      "Input: 0.115 MB, Params: 3,651,899 (13.931 MB), Total: 14.05 MB, FLOPs: 369,082,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1625 finished in 0m04s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 3,645,444 (13.906 MB), Total: 14.02 MB, FLOPs: 368,908,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1625 finished in 0m04s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.115 MB, Params: 3,641,827 (13.892 MB), Total: 14.01 MB, FLOPs: 368,810,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1625 finished in 0m04s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 461)]\n",
      "Input: 0.115 MB, Params: 3,638,210 (13.879 MB), Total: 13.99 MB, FLOPs: 368,713,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1625 finished in 0m04s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 337)]\n",
      "Input: 0.115 MB, Params: 3,634,593 (13.865 MB), Total: 13.98 MB, FLOPs: 368,615,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1625 finished in 0m04s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.115 MB, Params: 3,633,799 (13.862 MB), Total: 13.98 MB, FLOPs: 367,069,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1625 finished in 0m04s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 76)]\n",
      "Input: 0.115 MB, Params: 3,632,087 (13.855 MB), Total: 13.97 MB, FLOPs: 366,246,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1625 finished in 0m04s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.115 MB, Params: 3,630,483 (13.849 MB), Total: 13.96 MB, FLOPs: 364,678,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1625 finished in 0m04s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 310)]\n",
      "Input: 0.115 MB, Params: 3,624,055 (13.825 MB), Total: 13.94 MB, FLOPs: 364,505,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1625 finished in 0m04s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 164)]\n",
      "Input: 0.115 MB, Params: 3,620,732 (13.812 MB), Total: 13.93 MB, FLOPs: 364,146,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1625 finished in 0m04s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 3,617,124 (13.798 MB), Total: 13.91 MB, FLOPs: 364,049,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1625 finished in 0m04s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 3,613,516 (13.784 MB), Total: 13.90 MB, FLOPs: 363,952,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1625 finished in 0m05s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 3,609,908 (13.771 MB), Total: 13.89 MB, FLOPs: 363,854,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1625 finished in 0m04s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 460)]\n",
      "Input: 0.115 MB, Params: 3,606,300 (13.757 MB), Total: 13.87 MB, FLOPs: 363,757,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1625 finished in 0m04s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.115 MB, Params: 3,599,908 (13.733 MB), Total: 13.85 MB, FLOPs: 363,584,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1625 finished in 0m04s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 26)]\n",
      "Input: 0.115 MB, Params: 3,594,164 (13.711 MB), Total: 13.83 MB, FLOPs: 363,255,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1625 finished in 0m04s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 446)]\n",
      "Input: 0.115 MB, Params: 3,590,565 (13.697 MB), Total: 13.81 MB, FLOPs: 363,158,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1625 finished in 0m04s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 3,584,191 (13.673 MB), Total: 13.79 MB, FLOPs: 362,986,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1625 finished in 0m04s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.115 MB, Params: 3,577,817 (13.648 MB), Total: 13.76 MB, FLOPs: 362,814,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1625 finished in 0m04s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 149)]\n",
      "Input: 0.115 MB, Params: 3,574,503 (13.636 MB), Total: 13.75 MB, FLOPs: 362,456,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1625 finished in 0m04s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 3,568,129 (13.611 MB), Total: 13.73 MB, FLOPs: 362,284,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1625 finished in 0m04s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.115 MB, Params: 3,564,557 (13.598 MB), Total: 13.71 MB, FLOPs: 362,188,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1625 finished in 0m05s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.115 MB, Params: 3,558,192 (13.573 MB), Total: 13.69 MB, FLOPs: 362,016,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1625 finished in 0m04s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 3,551,827 (13.549 MB), Total: 13.66 MB, FLOPs: 361,844,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1625 finished in 0m04s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.115 MB, Params: 3,545,462 (13.525 MB), Total: 13.64 MB, FLOPs: 361,672,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1625 finished in 0m04s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 3,541,917 (13.511 MB), Total: 13.63 MB, FLOPs: 361,577,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1625 finished in 0m04s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 363)]\n",
      "Input: 0.115 MB, Params: 3,535,561 (13.487 MB), Total: 13.60 MB, FLOPs: 361,405,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1625 finished in 0m04s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 3,532,247 (13.474 MB), Total: 13.59 MB, FLOPs: 361,047,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1625 finished in 0m04s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 3,525,891 (13.450 MB), Total: 13.57 MB, FLOPs: 360,876,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1625 finished in 0m04s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.115 MB, Params: 3,522,364 (13.437 MB), Total: 13.55 MB, FLOPs: 360,781,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1625 finished in 0m04s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.115 MB, Params: 3,516,017 (13.413 MB), Total: 13.53 MB, FLOPs: 360,609,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1625 finished in 0m04s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 3,512,499 (13.399 MB), Total: 13.51 MB, FLOPs: 360,514,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1625 finished in 0m04s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 3,506,161 (13.375 MB), Total: 13.49 MB, FLOPs: 360,343,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1625 finished in 0m04s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 3,502,652 (13.362 MB), Total: 13.48 MB, FLOPs: 360,249,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1625 finished in 0m04s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 3,500,949 (13.355 MB), Total: 13.47 MB, FLOPs: 359,430,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1625 finished in 0m04s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.115 MB, Params: 3,494,620 (13.331 MB), Total: 13.45 MB, FLOPs: 359,259,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1625 finished in 0m04s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 199)]\n",
      "Input: 0.115 MB, Params: 3,491,306 (13.318 MB), Total: 13.43 MB, FLOPs: 358,901,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1625 finished in 0m04s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 320)]\n",
      "Input: 0.115 MB, Params: 3,487,806 (13.305 MB), Total: 13.42 MB, FLOPs: 358,807,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1625 finished in 0m04s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 292)]\n",
      "Input: 0.115 MB, Params: 3,481,486 (13.281 MB), Total: 13.40 MB, FLOPs: 358,636,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1625 finished in 0m04s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 3,475,166 (13.257 MB), Total: 13.37 MB, FLOPs: 358,466,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1625 finished in 0m04s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 172)]\n",
      "Input: 0.115 MB, Params: 3,471,852 (13.244 MB), Total: 13.36 MB, FLOPs: 358,108,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1625 finished in 0m04s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 3,465,532 (13.220 MB), Total: 13.34 MB, FLOPs: 357,937,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1625 finished in 0m04s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.115 MB, Params: 3,462,059 (13.207 MB), Total: 13.32 MB, FLOPs: 357,844,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1625 finished in 0m04s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 327)]\n",
      "Input: 0.115 MB, Params: 3,455,748 (13.183 MB), Total: 13.30 MB, FLOPs: 357,673,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1625 finished in 0m04s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 352)]\n",
      "Input: 0.115 MB, Params: 3,449,437 (13.159 MB), Total: 13.27 MB, FLOPs: 357,503,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1625 finished in 0m04s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 209)]\n",
      "Input: 0.115 MB, Params: 3,443,873 (13.137 MB), Total: 13.25 MB, FLOPs: 357,181,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1625 finished in 0m04s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 328)]\n",
      "Input: 0.115 MB, Params: 3,437,571 (13.113 MB), Total: 13.23 MB, FLOPs: 357,011,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1625 finished in 0m04s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 3,435,868 (13.107 MB), Total: 13.22 MB, FLOPs: 356,193,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1625 finished in 0m04s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 356)]\n",
      "Input: 0.115 MB, Params: 3,432,422 (13.094 MB), Total: 13.21 MB, FLOPs: 356,100,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1625 finished in 0m04s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 123)]\n",
      "Input: 0.115 MB, Params: 3,426,867 (13.072 MB), Total: 13.19 MB, FLOPs: 355,778,655\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1625 finished in 0m04s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 322)]\n",
      "Input: 0.115 MB, Params: 3,423,421 (13.059 MB), Total: 13.17 MB, FLOPs: 355,685,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1625 finished in 0m04s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 439)]\n",
      "Input: 0.115 MB, Params: 3,419,975 (13.046 MB), Total: 13.16 MB, FLOPs: 355,592,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1625 finished in 0m04s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 3,416,529 (13.033 MB), Total: 13.15 MB, FLOPs: 355,499,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1625 finished in 0m04s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 444)]\n",
      "Input: 0.115 MB, Params: 3,413,083 (13.020 MB), Total: 13.14 MB, FLOPs: 355,407,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1625 finished in 0m04s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 3,406,835 (12.996 MB), Total: 13.11 MB, FLOPs: 355,238,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1625 finished in 0m04s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.115 MB, Params: 3,403,398 (12.983 MB), Total: 13.10 MB, FLOPs: 355,145,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1625 finished in 0m04s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 3,399,961 (12.970 MB), Total: 13.09 MB, FLOPs: 355,053,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1625 finished in 0m04s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 3,396,524 (12.957 MB), Total: 13.07 MB, FLOPs: 354,960,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1625 finished in 0m04s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 203)]\n",
      "Input: 0.115 MB, Params: 3,393,228 (12.944 MB), Total: 13.06 MB, FLOPs: 354,604,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1625 finished in 0m04s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 3,389,791 (12.931 MB), Total: 13.05 MB, FLOPs: 354,511,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1625 finished in 0m04s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 3,383,579 (12.907 MB), Total: 13.02 MB, FLOPs: 354,344,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1625 finished in 0m04s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 92)]\n",
      "Input: 0.115 MB, Params: 3,381,876 (12.901 MB), Total: 13.02 MB, FLOPs: 353,525,595\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1625 finished in 0m04s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 375)]\n",
      "Input: 0.115 MB, Params: 3,378,448 (12.888 MB), Total: 13.00 MB, FLOPs: 353,433,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1625 finished in 0m04s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 152)]\n",
      "Input: 0.115 MB, Params: 3,372,920 (12.867 MB), Total: 12.98 MB, FLOPs: 353,113,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1625 finished in 0m04s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.115 MB, Params: 3,372,135 (12.864 MB), Total: 12.98 MB, FLOPs: 351,584,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1625 finished in 0m05s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.115 MB, Params: 3,368,707 (12.851 MB), Total: 12.97 MB, FLOPs: 351,491,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1625 finished in 0m04s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 3,365,279 (12.838 MB), Total: 12.95 MB, FLOPs: 351,399,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1625 finished in 0m15s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 3,359,103 (12.814 MB), Total: 12.93 MB, FLOPs: 351,232,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1625 finished in 0m04s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 3,355,684 (12.801 MB), Total: 12.92 MB, FLOPs: 351,140,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1625 finished in 0m04s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 363)]\n",
      "Input: 0.115 MB, Params: 3,352,265 (12.788 MB), Total: 12.90 MB, FLOPs: 351,048,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1625 finished in 0m04s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.115 MB, Params: 3,346,107 (12.764 MB), Total: 12.88 MB, FLOPs: 350,882,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1625 finished in 0m04s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 445)]\n",
      "Input: 0.115 MB, Params: 3,342,697 (12.751 MB), Total: 12.87 MB, FLOPs: 350,790,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1625 finished in 0m04s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 303)]\n",
      "Input: 0.115 MB, Params: 3,339,287 (12.738 MB), Total: 12.85 MB, FLOPs: 350,698,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1625 finished in 0m04s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 334)]\n",
      "Input: 0.115 MB, Params: 3,333,147 (12.715 MB), Total: 12.83 MB, FLOPs: 350,532,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1625 finished in 0m04s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 313)]\n",
      "Input: 0.115 MB, Params: 3,329,746 (12.702 MB), Total: 12.82 MB, FLOPs: 350,441,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1625 finished in 0m04s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.115 MB, Params: 3,323,615 (12.679 MB), Total: 12.79 MB, FLOPs: 350,275,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1625 finished in 0m04s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 193)]\n",
      "Input: 0.115 MB, Params: 3,320,328 (12.666 MB), Total: 12.78 MB, FLOPs: 349,920,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1625 finished in 0m04s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 107)]\n",
      "Input: 0.115 MB, Params: 3,314,197 (12.643 MB), Total: 12.76 MB, FLOPs: 349,755,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1625 finished in 0m04s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 3,308,066 (12.619 MB), Total: 12.73 MB, FLOPs: 349,589,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1625 finished in 0m04s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 114)]\n",
      "Input: 0.115 MB, Params: 3,306,363 (12.613 MB), Total: 12.73 MB, FLOPs: 348,770,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1625 finished in 0m04s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 3,302,989 (12.600 MB), Total: 12.72 MB, FLOPs: 348,679,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1625 finished in 0m04s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.115 MB, Params: 3,297,524 (12.579 MB), Total: 12.69 MB, FLOPs: 348,362,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1625 finished in 0m04s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 3,294,150 (12.566 MB), Total: 12.68 MB, FLOPs: 348,271,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1625 finished in 0m04s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 3,288,046 (12.543 MB), Total: 12.66 MB, FLOPs: 348,106,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1625 finished in 0m04s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.115 MB, Params: 3,281,942 (12.520 MB), Total: 12.63 MB, FLOPs: 347,941,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1625 finished in 0m04s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 288)]\n",
      "Input: 0.115 MB, Params: 3,278,586 (12.507 MB), Total: 12.62 MB, FLOPs: 347,851,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1625 finished in 0m04s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 3,272,491 (12.484 MB), Total: 12.60 MB, FLOPs: 347,686,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1625 finished in 0m04s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 3,269,144 (12.471 MB), Total: 12.59 MB, FLOPs: 347,596,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1625 finished in 0m04s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 3,263,058 (12.448 MB), Total: 12.56 MB, FLOPs: 347,432,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1625 finished in 0m04s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.115 MB, Params: 3,256,972 (12.424 MB), Total: 12.54 MB, FLOPs: 347,268,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1625 finished in 0m04s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 285)]\n",
      "Input: 0.115 MB, Params: 3,253,643 (12.412 MB), Total: 12.53 MB, FLOPs: 347,178,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1625 finished in 0m04s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 3,250,365 (12.399 MB), Total: 12.51 MB, FLOPs: 346,824,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1625 finished in 0m04s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 3,244,954 (12.379 MB), Total: 12.49 MB, FLOPs: 346,509,043\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1625 finished in 0m04s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 3,241,625 (12.366 MB), Total: 12.48 MB, FLOPs: 346,419,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1625 finished in 0m04s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 137)]\n",
      "Input: 0.115 MB, Params: 3,236,214 (12.345 MB), Total: 12.46 MB, FLOPs: 346,103,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1625 finished in 0m04s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.115 MB, Params: 3,230,803 (12.325 MB), Total: 12.44 MB, FLOPs: 345,788,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1625 finished in 0m04s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 3,224,762 (12.301 MB), Total: 12.42 MB, FLOPs: 345,625,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1625 finished in 0m04s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 3,218,721 (12.278 MB), Total: 12.39 MB, FLOPs: 345,462,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1625 finished in 0m04s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.115 MB, Params: 3,215,410 (12.266 MB), Total: 12.38 MB, FLOPs: 345,373,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1625 finished in 0m04s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 3,213,707 (12.259 MB), Total: 12.37 MB, FLOPs: 344,554,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1625 finished in 0m04s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 3,210,456 (12.247 MB), Total: 12.36 MB, FLOPs: 344,203,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1625 finished in 0m04s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 413)]\n",
      "Input: 0.115 MB, Params: 3,207,145 (12.234 MB), Total: 12.35 MB, FLOPs: 344,114,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1625 finished in 0m04s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 244)]\n",
      "Input: 0.115 MB, Params: 3,201,122 (12.211 MB), Total: 12.33 MB, FLOPs: 343,951,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1625 finished in 0m04s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 3,197,820 (12.199 MB), Total: 12.31 MB, FLOPs: 343,862,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1625 finished in 0m04s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 3,191,806 (12.176 MB), Total: 12.29 MB, FLOPs: 343,700,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1625 finished in 0m04s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 338)]\n",
      "Input: 0.115 MB, Params: 3,185,792 (12.153 MB), Total: 12.27 MB, FLOPs: 343,537,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1625 finished in 0m04s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 3,180,435 (12.132 MB), Total: 12.25 MB, FLOPs: 343,224,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1625 finished in 0m04s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 430)]\n",
      "Input: 0.115 MB, Params: 3,177,151 (12.120 MB), Total: 12.24 MB, FLOPs: 343,136,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1625 finished in 0m04s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 3,171,155 (12.097 MB), Total: 12.21 MB, FLOPs: 342,974,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1625 finished in 0m04s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 3,167,880 (12.085 MB), Total: 12.20 MB, FLOPs: 342,886,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1625 finished in 0m04s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 424)]\n",
      "Input: 0.115 MB, Params: 3,164,605 (12.072 MB), Total: 12.19 MB, FLOPs: 342,797,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1625 finished in 0m04s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.115 MB, Params: 3,161,363 (12.060 MB), Total: 12.17 MB, FLOPs: 342,447,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1625 finished in 0m04s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 361)]\n",
      "Input: 0.115 MB, Params: 3,155,385 (12.037 MB), Total: 12.15 MB, FLOPs: 342,286,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1625 finished in 0m04s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 95)]\n",
      "Input: 0.115 MB, Params: 3,152,143 (12.024 MB), Total: 12.14 MB, FLOPs: 341,936,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1625 finished in 0m04s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.115 MB, Params: 3,148,901 (12.012 MB), Total: 12.13 MB, FLOPs: 341,586,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1625 finished in 0m04s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 3,142,923 (11.989 MB), Total: 12.10 MB, FLOPs: 341,424,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1625 finished in 0m04s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.115 MB, Params: 3,141,220 (11.983 MB), Total: 12.10 MB, FLOPs: 340,606,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1625 finished in 0m04s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.115 MB, Params: 3,135,917 (11.963 MB), Total: 12.08 MB, FLOPs: 340,296,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1625 finished in 0m04s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 186)]\n",
      "Input: 0.115 MB, Params: 3,132,684 (11.950 MB), Total: 12.07 MB, FLOPs: 339,947,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1625 finished in 0m04s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.115 MB, Params: 3,126,715 (11.927 MB), Total: 12.04 MB, FLOPs: 339,786,529\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1625 finished in 0m04s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 3,123,467 (11.915 MB), Total: 12.03 MB, FLOPs: 339,698,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1625 finished in 0m04s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.115 MB, Params: 3,117,507 (11.892 MB), Total: 12.01 MB, FLOPs: 339,538,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1625 finished in 0m04s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 3,114,274 (11.880 MB), Total: 12.00 MB, FLOPs: 339,189,033\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1625 finished in 0m04s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 3,108,314 (11.857 MB), Total: 11.97 MB, FLOPs: 339,028,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1625 finished in 0m04s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 174)]\n",
      "Input: 0.115 MB, Params: 3,103,056 (11.837 MB), Total: 11.95 MB, FLOPs: 338,721,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1625 finished in 0m04s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.115 MB, Params: 3,097,105 (11.815 MB), Total: 11.93 MB, FLOPs: 338,560,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1625 finished in 0m04s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.115 MB, Params: 3,091,154 (11.792 MB), Total: 11.91 MB, FLOPs: 338,399,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1625 finished in 0m04s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 3,087,942 (11.780 MB), Total: 11.89 MB, FLOPs: 338,313,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1625 finished in 0m04s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 3,082,000 (11.757 MB), Total: 11.87 MB, FLOPs: 338,152,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1625 finished in 0m04s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 3,078,797 (11.745 MB), Total: 11.86 MB, FLOPs: 338,066,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1625 finished in 0m04s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 3,075,594 (11.732 MB), Total: 11.85 MB, FLOPs: 337,980,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1625 finished in 0m04s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 3,069,670 (11.710 MB), Total: 11.83 MB, FLOPs: 337,820,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1625 finished in 0m04s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 220)]\n",
      "Input: 0.115 MB, Params: 3,066,446 (11.698 MB), Total: 11.81 MB, FLOPs: 337,472,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1625 finished in 0m04s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 3,063,252 (11.685 MB), Total: 11.80 MB, FLOPs: 337,386,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1625 finished in 0m04s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.115 MB, Params: 3,061,549 (11.679 MB), Total: 11.79 MB, FLOPs: 336,567,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1625 finished in 0m04s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.115 MB, Params: 3,058,325 (11.667 MB), Total: 11.78 MB, FLOPs: 336,219,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1625 finished in 0m04s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 334)]\n",
      "Input: 0.115 MB, Params: 3,055,131 (11.654 MB), Total: 11.77 MB, FLOPs: 336,133,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1625 finished in 0m04s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 3,051,937 (11.642 MB), Total: 11.76 MB, FLOPs: 336,047,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1625 finished in 0m04s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 3,046,040 (11.620 MB), Total: 11.74 MB, FLOPs: 335,888,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1625 finished in 0m04s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 3,042,816 (11.607 MB), Total: 11.72 MB, FLOPs: 335,540,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1625 finished in 0m04s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 3,036,919 (11.585 MB), Total: 11.70 MB, FLOPs: 335,380,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1625 finished in 0m04s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 3,033,743 (11.573 MB), Total: 11.69 MB, FLOPs: 335,295,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1625 finished in 0m04s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 3,027,855 (11.550 MB), Total: 11.67 MB, FLOPs: 335,136,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1625 finished in 0m04s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 3,021,967 (11.528 MB), Total: 11.64 MB, FLOPs: 334,977,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1625 finished in 0m04s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 3,016,808 (11.508 MB), Total: 11.62 MB, FLOPs: 334,675,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1625 finished in 0m04s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 411)]\n",
      "Input: 0.115 MB, Params: 3,013,650 (11.496 MB), Total: 11.61 MB, FLOPs: 334,590,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1625 finished in 0m04s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 374)]\n",
      "Input: 0.115 MB, Params: 3,010,492 (11.484 MB), Total: 11.60 MB, FLOPs: 334,505,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1625 finished in 0m04s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.115 MB, Params: 3,007,334 (11.472 MB), Total: 11.59 MB, FLOPs: 334,419,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1625 finished in 0m04s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 3,001,482 (11.450 MB), Total: 11.57 MB, FLOPs: 334,261,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1625 finished in 0m04s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 415)]\n",
      "Input: 0.115 MB, Params: 2,998,333 (11.438 MB), Total: 11.55 MB, FLOPs: 334,177,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1625 finished in 0m04s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 2,992,490 (11.415 MB), Total: 11.53 MB, FLOPs: 334,019,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1625 finished in 0m04s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 2,986,647 (11.393 MB), Total: 11.51 MB, FLOPs: 333,861,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1625 finished in 0m04s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 2,980,804 (11.371 MB), Total: 11.49 MB, FLOPs: 333,703,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1625 finished in 0m04s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 2,977,682 (11.359 MB), Total: 11.47 MB, FLOPs: 333,619,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1625 finished in 0m04s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.115 MB, Params: 2,974,467 (11.347 MB), Total: 11.46 MB, FLOPs: 333,272,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1625 finished in 0m04s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 2,968,633 (11.324 MB), Total: 11.44 MB, FLOPs: 333,115,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1625 finished in 0m04s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.115 MB, Params: 2,962,799 (11.302 MB), Total: 11.42 MB, FLOPs: 332,957,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1625 finished in 0m04s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 2,959,695 (11.290 MB), Total: 11.41 MB, FLOPs: 332,874,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1625 finished in 0m04s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 261)]\n",
      "Input: 0.115 MB, Params: 2,953,870 (11.268 MB), Total: 11.38 MB, FLOPs: 332,716,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1625 finished in 0m04s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 2,950,775 (11.256 MB), Total: 11.37 MB, FLOPs: 332,633,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1625 finished in 0m04s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 161)]\n",
      "Input: 0.115 MB, Params: 2,947,560 (11.244 MB), Total: 11.36 MB, FLOPs: 332,286,225\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1625 finished in 0m04s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 2,941,744 (11.222 MB), Total: 11.34 MB, FLOPs: 332,129,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1625 finished in 0m04s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 2,935,928 (11.200 MB), Total: 11.31 MB, FLOPs: 331,972,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1625 finished in 0m04s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.115 MB, Params: 2,930,868 (11.180 MB), Total: 11.30 MB, FLOPs: 331,674,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1625 finished in 0m04s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 2,927,662 (11.168 MB), Total: 11.28 MB, FLOPs: 331,328,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1625 finished in 0m04s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.115 MB, Params: 2,921,855 (11.146 MB), Total: 11.26 MB, FLOPs: 331,171,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1625 finished in 0m04s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 383)]\n",
      "Input: 0.115 MB, Params: 2,918,787 (11.134 MB), Total: 11.25 MB, FLOPs: 331,088,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1625 finished in 0m04s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 2,912,989 (11.112 MB), Total: 11.23 MB, FLOPs: 330,932,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1625 finished in 0m04s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 374)]\n",
      "Input: 0.115 MB, Params: 2,909,930 (11.101 MB), Total: 11.22 MB, FLOPs: 330,849,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1625 finished in 0m04s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 2,904,141 (11.078 MB), Total: 11.19 MB, FLOPs: 330,693,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1625 finished in 0m04s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.115 MB, Params: 2,898,352 (11.056 MB), Total: 11.17 MB, FLOPs: 330,537,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1625 finished in 0m04s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 385)]\n",
      "Input: 0.115 MB, Params: 2,895,311 (11.045 MB), Total: 11.16 MB, FLOPs: 330,455,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1625 finished in 0m04s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 2,892,270 (11.033 MB), Total: 11.15 MB, FLOPs: 330,373,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1625 finished in 0m04s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 2,889,229 (11.022 MB), Total: 11.14 MB, FLOPs: 330,291,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1625 finished in 0m04s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.115 MB, Params: 2,883,467 (11.000 MB), Total: 11.11 MB, FLOPs: 330,135,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1625 finished in 0m04s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 319)]\n",
      "Input: 0.115 MB, Params: 2,880,435 (10.988 MB), Total: 11.10 MB, FLOPs: 330,054,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1625 finished in 0m04s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 278)]\n",
      "Input: 0.115 MB, Params: 2,874,682 (10.966 MB), Total: 11.08 MB, FLOPs: 329,898,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1625 finished in 0m04s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 2,871,659 (10.955 MB), Total: 11.07 MB, FLOPs: 329,817,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1625 finished in 0m04s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 2,868,453 (10.942 MB), Total: 11.06 MB, FLOPs: 329,471,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1625 finished in 0m04s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.115 MB, Params: 2,863,465 (10.923 MB), Total: 11.04 MB, FLOPs: 329,176,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1625 finished in 0m04s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 2,857,730 (10.901 MB), Total: 11.02 MB, FLOPs: 329,021,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1625 finished in 0m04s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 2,854,716 (10.890 MB), Total: 11.01 MB, FLOPs: 328,940,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1625 finished in 0m04s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 2,848,990 (10.868 MB), Total: 10.98 MB, FLOPs: 328,786,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1625 finished in 0m04s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.115 MB, Params: 2,845,985 (10.857 MB), Total: 10.97 MB, FLOPs: 328,705,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1625 finished in 0m04s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 178)]\n",
      "Input: 0.115 MB, Params: 2,840,268 (10.835 MB), Total: 10.95 MB, FLOPs: 328,550,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1625 finished in 0m04s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 403)]\n",
      "Input: 0.115 MB, Params: 2,837,272 (10.823 MB), Total: 10.94 MB, FLOPs: 328,469,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1625 finished in 0m04s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.115 MB, Params: 2,834,276 (10.812 MB), Total: 10.93 MB, FLOPs: 328,389,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1625 finished in 0m04s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 2,829,315 (10.793 MB), Total: 10.91 MB, FLOPs: 328,095,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1625 finished in 0m04s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.115 MB, Params: 2,823,625 (10.771 MB), Total: 10.89 MB, FLOPs: 327,941,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1625 finished in 0m04s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 231)]\n",
      "Input: 0.115 MB, Params: 2,820,638 (10.760 MB), Total: 10.88 MB, FLOPs: 327,861,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1625 finished in 0m04s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 2,815,686 (10.741 MB), Total: 10.86 MB, FLOPs: 327,567,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1625 finished in 0m04s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 2,812,699 (10.730 MB), Total: 10.84 MB, FLOPs: 327,487,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1625 finished in 0m04s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 255)]\n",
      "Input: 0.115 MB, Params: 2,809,712 (10.718 MB), Total: 10.83 MB, FLOPs: 327,406,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1625 finished in 0m04s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 2,804,058 (10.697 MB), Total: 10.81 MB, FLOPs: 327,254,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1625 finished in 0m04s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 2,798,404 (10.675 MB), Total: 10.79 MB, FLOPs: 327,101,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1625 finished in 0m04s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 342)]\n",
      "Input: 0.115 MB, Params: 2,795,435 (10.664 MB), Total: 10.78 MB, FLOPs: 327,021,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1625 finished in 0m04s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 2,789,790 (10.642 MB), Total: 10.76 MB, FLOPs: 326,869,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1625 finished in 0m04s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 318)]\n",
      "Input: 0.115 MB, Params: 2,786,830 (10.631 MB), Total: 10.75 MB, FLOPs: 326,789,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1625 finished in 0m04s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 93)]\n",
      "Input: 0.115 MB, Params: 2,781,905 (10.612 MB), Total: 10.73 MB, FLOPs: 326,496,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1625 finished in 0m04s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 2,778,735 (10.600 MB), Total: 10.72 MB, FLOPs: 326,154,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1625 finished in 0m04s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 2,775,775 (10.589 MB), Total: 10.70 MB, FLOPs: 326,074,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1625 finished in 0m04s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 2,772,815 (10.577 MB), Total: 10.69 MB, FLOPs: 325,994,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1625 finished in 0m04s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 2,769,855 (10.566 MB), Total: 10.68 MB, FLOPs: 325,915,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1625 finished in 0m04s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 2,766,895 (10.555 MB), Total: 10.67 MB, FLOPs: 325,835,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1625 finished in 0m04s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 2,761,304 (10.534 MB), Total: 10.65 MB, FLOPs: 325,684,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1625 finished in 0m04s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 2,758,353 (10.522 MB), Total: 10.64 MB, FLOPs: 325,604,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1625 finished in 0m04s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.115 MB, Params: 2,752,771 (10.501 MB), Total: 10.62 MB, FLOPs: 325,454,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1625 finished in 0m04s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 2,747,189 (10.480 MB), Total: 10.59 MB, FLOPs: 325,303,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1625 finished in 0m04s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 334)]\n",
      "Input: 0.115 MB, Params: 2,744,256 (10.469 MB), Total: 10.58 MB, FLOPs: 325,224,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1625 finished in 0m04s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 2,741,323 (10.457 MB), Total: 10.57 MB, FLOPs: 325,145,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1625 finished in 0m04s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 308)]\n",
      "Input: 0.115 MB, Params: 2,738,390 (10.446 MB), Total: 10.56 MB, FLOPs: 325,066,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1625 finished in 0m04s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.115 MB, Params: 2,732,835 (10.425 MB), Total: 10.54 MB, FLOPs: 324,916,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1625 finished in 0m04s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.115 MB, Params: 2,729,911 (10.414 MB), Total: 10.53 MB, FLOPs: 324,837,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1625 finished in 0m04s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 2,726,741 (10.402 MB), Total: 10.52 MB, FLOPs: 324,495,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1625 finished in 0m04s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 2,721,195 (10.381 MB), Total: 10.50 MB, FLOPs: 324,345,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1625 finished in 0m04s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 132)]\n",
      "Input: 0.115 MB, Params: 2,718,025 (10.368 MB), Total: 10.48 MB, FLOPs: 324,003,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1625 finished in 0m04s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 2,713,172 (10.350 MB), Total: 10.47 MB, FLOPs: 323,714,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1625 finished in 0m04s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 226)]\n",
      "Input: 0.115 MB, Params: 2,707,635 (10.329 MB), Total: 10.44 MB, FLOPs: 323,565,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1625 finished in 0m04s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 2,704,474 (10.317 MB), Total: 10.43 MB, FLOPs: 323,223,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1625 finished in 0m04s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.115 MB, Params: 2,698,937 (10.296 MB), Total: 10.41 MB, FLOPs: 323,074,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1625 finished in 0m04s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.115 MB, Params: 2,694,111 (10.277 MB), Total: 10.39 MB, FLOPs: 322,787,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1625 finished in 0m04s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 2,688,583 (10.256 MB), Total: 10.37 MB, FLOPs: 322,638,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1625 finished in 0m04s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 143)]\n",
      "Input: 0.115 MB, Params: 2,683,766 (10.238 MB), Total: 10.35 MB, FLOPs: 322,351,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1625 finished in 0m04s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 2,678,247 (10.217 MB), Total: 10.33 MB, FLOPs: 322,202,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1625 finished in 0m04s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 2,675,368 (10.206 MB), Total: 10.32 MB, FLOPs: 322,124,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1625 finished in 0m04s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 310)]\n",
      "Input: 0.115 MB, Params: 2,669,858 (10.185 MB), Total: 10.30 MB, FLOPs: 321,975,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1625 finished in 0m04s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 258)]\n",
      "Input: 0.115 MB, Params: 2,664,348 (10.164 MB), Total: 10.28 MB, FLOPs: 321,827,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1625 finished in 0m04s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 2,658,838 (10.143 MB), Total: 10.26 MB, FLOPs: 321,678,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1625 finished in 0m04s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 131)]\n",
      "Input: 0.115 MB, Params: 2,655,695 (10.131 MB), Total: 10.25 MB, FLOPs: 321,338,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1625 finished in 0m04s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 149)]\n",
      "Input: 0.115 MB, Params: 2,650,185 (10.110 MB), Total: 10.22 MB, FLOPs: 321,190,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1625 finished in 0m04s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.115 MB, Params: 2,644,675 (10.089 MB), Total: 10.20 MB, FLOPs: 321,041,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1625 finished in 0m04s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 2,641,841 (10.078 MB), Total: 10.19 MB, FLOPs: 320,965,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1625 finished in 0m04s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 2,640,138 (10.071 MB), Total: 10.19 MB, FLOPs: 320,146,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1625 finished in 0m04s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.115 MB, Params: 2,634,637 (10.050 MB), Total: 10.17 MB, FLOPs: 319,997,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1625 finished in 0m04s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.115 MB, Params: 2,629,892 (10.032 MB), Total: 10.15 MB, FLOPs: 319,713,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1625 finished in 0m04s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 2,624,400 (10.011 MB), Total: 10.13 MB, FLOPs: 319,565,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1625 finished in 0m04s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 2,622,697 (10.005 MB), Total: 10.12 MB, FLOPs: 318,746,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1625 finished in 0m04s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 2,617,205 (9.984 MB), Total: 10.10 MB, FLOPs: 318,598,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1625 finished in 0m04s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 2,612,478 (9.966 MB), Total: 10.08 MB, FLOPs: 318,314,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1625 finished in 0m04s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.115 MB, Params: 2,609,671 (9.955 MB), Total: 10.07 MB, FLOPs: 318,239,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1625 finished in 0m04s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 2,604,944 (9.937 MB), Total: 10.05 MB, FLOPs: 317,955,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1625 finished in 0m04s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 2,602,137 (9.926 MB), Total: 10.04 MB, FLOPs: 317,879,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1625 finished in 0m04s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 2,596,681 (9.906 MB), Total: 10.02 MB, FLOPs: 317,732,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1625 finished in 0m04s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 384)]\n",
      "Input: 0.115 MB, Params: 2,593,883 (9.895 MB), Total: 10.01 MB, FLOPs: 317,656,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1625 finished in 0m04s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 102)]\n",
      "Input: 0.115 MB, Params: 2,590,767 (9.883 MB), Total: 10.00 MB, FLOPs: 317,320,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1625 finished in 0m04s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.115 MB, Params: 2,585,320 (9.862 MB), Total: 9.98 MB, FLOPs: 317,173,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1625 finished in 0m04s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 381)]\n",
      "Input: 0.115 MB, Params: 2,582,531 (9.852 MB), Total: 9.97 MB, FLOPs: 317,098,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1625 finished in 0m04s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 2,579,742 (9.841 MB), Total: 9.96 MB, FLOPs: 317,023,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1625 finished in 0m04s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 201)]\n",
      "Input: 0.115 MB, Params: 2,576,953 (9.830 MB), Total: 9.95 MB, FLOPs: 316,948,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1625 finished in 0m04s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 2,571,533 (9.810 MB), Total: 9.92 MB, FLOPs: 316,801,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1625 finished in 0m04s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 2,568,753 (9.799 MB), Total: 9.91 MB, FLOPs: 316,726,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1625 finished in 0m04s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 2,565,637 (9.787 MB), Total: 9.90 MB, FLOPs: 316,390,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1625 finished in 0m04s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 2,560,226 (9.766 MB), Total: 9.88 MB, FLOPs: 316,244,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1625 finished in 0m04s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 331)]\n",
      "Input: 0.115 MB, Params: 2,557,455 (9.756 MB), Total: 9.87 MB, FLOPs: 316,169,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1625 finished in 0m04s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 2,554,684 (9.745 MB), Total: 9.86 MB, FLOPs: 316,094,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1625 finished in 0m04s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.115 MB, Params: 2,549,291 (9.725 MB), Total: 9.84 MB, FLOPs: 315,949,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1625 finished in 0m04s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 335)]\n",
      "Input: 0.115 MB, Params: 2,546,529 (9.714 MB), Total: 9.83 MB, FLOPs: 315,874,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1625 finished in 0m04s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 114)]\n",
      "Input: 0.115 MB, Params: 2,543,767 (9.704 MB), Total: 9.82 MB, FLOPs: 315,800,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1625 finished in 0m04s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.115 MB, Params: 2,538,392 (9.683 MB), Total: 9.80 MB, FLOPs: 315,655,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1625 finished in 0m04s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 2,533,017 (9.663 MB), Total: 9.78 MB, FLOPs: 315,510,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1625 finished in 0m04s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 2,530,273 (9.652 MB), Total: 9.77 MB, FLOPs: 315,436,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1625 finished in 0m04s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 2,527,529 (9.642 MB), Total: 9.76 MB, FLOPs: 315,362,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1625 finished in 0m04s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 2,524,413 (9.630 MB), Total: 9.75 MB, FLOPs: 315,026,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1625 finished in 0m04s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 2,519,056 (9.609 MB), Total: 9.72 MB, FLOPs: 314,881,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1625 finished in 0m04s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.115 MB, Params: 2,515,940 (9.598 MB), Total: 9.71 MB, FLOPs: 314,545,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1625 finished in 0m04s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 2,510,583 (9.577 MB), Total: 9.69 MB, FLOPs: 314,400,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1625 finished in 0m04s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 2,507,857 (9.567 MB), Total: 9.68 MB, FLOPs: 314,326,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1625 finished in 0m04s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 2,502,509 (9.546 MB), Total: 9.66 MB, FLOPs: 314,182,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1625 finished in 0m04s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 2,499,792 (9.536 MB), Total: 9.65 MB, FLOPs: 314,109,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1625 finished in 0m04s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 161)]\n",
      "Input: 0.115 MB, Params: 2,494,453 (9.516 MB), Total: 9.63 MB, FLOPs: 313,965,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1625 finished in 0m04s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 2,491,745 (9.505 MB), Total: 9.62 MB, FLOPs: 313,892,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1625 finished in 0m04s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.115 MB, Params: 2,490,960 (9.502 MB), Total: 9.62 MB, FLOPs: 312,363,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1625 finished in 0m04s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.115 MB, Params: 2,485,630 (9.482 MB), Total: 9.60 MB, FLOPs: 312,219,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1625 finished in 0m04s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 141)]\n",
      "Input: 0.115 MB, Params: 2,481,047 (9.464 MB), Total: 9.58 MB, FLOPs: 311,942,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1625 finished in 0m04s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 89)]\n",
      "Input: 0.115 MB, Params: 2,476,464 (9.447 MB), Total: 9.56 MB, FLOPs: 311,665,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1625 finished in 0m04s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 170)]\n",
      "Input: 0.115 MB, Params: 2,471,152 (9.427 MB), Total: 9.54 MB, FLOPs: 311,522,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1625 finished in 0m04s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 2,465,840 (9.406 MB), Total: 9.52 MB, FLOPs: 311,378,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1625 finished in 0m04s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 348)]\n",
      "Input: 0.115 MB, Params: 2,463,159 (9.396 MB), Total: 9.51 MB, FLOPs: 311,306,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1625 finished in 0m04s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 2,460,478 (9.386 MB), Total: 9.50 MB, FLOPs: 311,234,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1625 finished in 0m04s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 185)]\n",
      "Input: 0.115 MB, Params: 2,455,913 (9.369 MB), Total: 9.48 MB, FLOPs: 310,957,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1625 finished in 0m04s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 2,451,348 (9.351 MB), Total: 9.47 MB, FLOPs: 310,681,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1625 finished in 0m04s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 2,448,667 (9.341 MB), Total: 9.46 MB, FLOPs: 310,609,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1625 finished in 0m04s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 200)]\n",
      "Input: 0.115 MB, Params: 2,444,102 (9.324 MB), Total: 9.44 MB, FLOPs: 310,332,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1625 finished in 0m04s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 244)]\n",
      "Input: 0.115 MB, Params: 2,438,844 (9.303 MB), Total: 9.42 MB, FLOPs: 310,190,640\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1625 finished in 0m04s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 2,434,288 (9.286 MB), Total: 9.40 MB, FLOPs: 309,914,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1625 finished in 0m04s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 2,429,039 (9.266 MB), Total: 9.38 MB, FLOPs: 309,772,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1625 finished in 0m04s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 2,426,376 (9.256 MB), Total: 9.37 MB, FLOPs: 309,700,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1625 finished in 0m04s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 2,423,713 (9.246 MB), Total: 9.36 MB, FLOPs: 309,629,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1625 finished in 0m04s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 2,420,651 (9.234 MB), Total: 9.35 MB, FLOPs: 309,298,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1625 finished in 0m04s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.115 MB, Params: 2,417,589 (9.222 MB), Total: 9.34 MB, FLOPs: 308,968,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1625 finished in 0m04s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 2,414,926 (9.212 MB), Total: 9.33 MB, FLOPs: 308,896,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1625 finished in 0m04s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 2,412,263 (9.202 MB), Total: 9.32 MB, FLOPs: 308,824,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1625 finished in 0m04s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 2,407,050 (9.182 MB), Total: 9.30 MB, FLOPs: 308,683,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1625 finished in 0m04s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.115 MB, Params: 2,401,837 (9.162 MB), Total: 9.28 MB, FLOPs: 308,543,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1625 finished in 0m04s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 151)]\n",
      "Input: 0.115 MB, Params: 2,398,775 (9.151 MB), Total: 9.27 MB, FLOPs: 308,212,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1625 finished in 0m04s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 2,394,273 (9.133 MB), Total: 9.25 MB, FLOPs: 307,939,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1625 finished in 0m04s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 2,389,069 (9.114 MB), Total: 9.23 MB, FLOPs: 307,799,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.846%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1625 finished in 0m04s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 2,387,366 (9.107 MB), Total: 9.22 MB, FLOPs: 306,980,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1625 finished in 0m04s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 91)]\n",
      "Input: 0.115 MB, Params: 2,382,873 (9.090 MB), Total: 9.21 MB, FLOPs: 306,708,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1625 finished in 0m04s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.115 MB, Params: 2,379,829 (9.078 MB), Total: 9.19 MB, FLOPs: 306,379,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1625 finished in 0m04s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 52)]\n",
      "Input: 0.115 MB, Params: 2,379,787 (9.078 MB), Total: 9.19 MB, FLOPs: 306,024,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1625 finished in 0m04s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.115 MB, Params: 2,377,151 (9.068 MB), Total: 9.18 MB, FLOPs: 305,953,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1625 finished in 0m04s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.115 MB, Params: 2,371,965 (9.048 MB), Total: 9.16 MB, FLOPs: 305,813,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1625 finished in 0m04s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.115 MB, Params: 2,369,338 (9.038 MB), Total: 9.15 MB, FLOPs: 305,742,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1625 finished in 0m04s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 2,364,161 (9.019 MB), Total: 9.13 MB, FLOPs: 305,603,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1625 finished in 0m04s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 2,361,543 (9.009 MB), Total: 9.12 MB, FLOPs: 305,532,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1625 finished in 0m04s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 2,356,375 (8.989 MB), Total: 9.10 MB, FLOPs: 305,393,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1625 finished in 0m04s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 163)]\n",
      "Input: 0.115 MB, Params: 2,353,331 (8.977 MB), Total: 9.09 MB, FLOPs: 305,064,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1625 finished in 0m04s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.115 MB, Params: 2,348,163 (8.958 MB), Total: 9.07 MB, FLOPs: 304,924,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1625 finished in 0m04s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 56)]\n",
      "Input: 0.115 MB, Params: 2,346,460 (8.951 MB), Total: 9.07 MB, FLOPs: 304,106,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1625 finished in 0m04s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 2,341,292 (8.931 MB), Total: 9.05 MB, FLOPs: 303,966,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1625 finished in 0m04s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 2,338,701 (8.921 MB), Total: 9.04 MB, FLOPs: 303,896,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1625 finished in 0m04s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.115 MB, Params: 2,333,542 (8.902 MB), Total: 9.02 MB, FLOPs: 303,757,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1625 finished in 0m04s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 2,330,960 (8.892 MB), Total: 9.01 MB, FLOPs: 303,688,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1625 finished in 0m04s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 2,327,916 (8.880 MB), Total: 9.00 MB, FLOPs: 303,359,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1625 finished in 0m04s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 2,322,766 (8.861 MB), Total: 8.98 MB, FLOPs: 303,220,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1625 finished in 0m04s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 197)]\n",
      "Input: 0.115 MB, Params: 2,320,193 (8.851 MB), Total: 8.97 MB, FLOPs: 303,151,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1625 finished in 0m04s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 2,317,620 (8.841 MB), Total: 8.96 MB, FLOPs: 303,081,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1625 finished in 0m04s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 96)]\n",
      "Input: 0.115 MB, Params: 2,314,576 (8.829 MB), Total: 8.94 MB, FLOPs: 302,753,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1625 finished in 0m04s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 2,309,444 (8.810 MB), Total: 8.93 MB, FLOPs: 302,614,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1625 finished in 0m04s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.115 MB, Params: 2,306,880 (8.800 MB), Total: 8.92 MB, FLOPs: 302,545,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1625 finished in 0m04s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.115 MB, Params: 2,304,316 (8.790 MB), Total: 8.91 MB, FLOPs: 302,476,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1625 finished in 0m04s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.115 MB, Params: 2,299,202 (8.771 MB), Total: 8.89 MB, FLOPs: 302,338,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1625 finished in 0m04s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 274)]\n",
      "Input: 0.115 MB, Params: 2,296,647 (8.761 MB), Total: 8.88 MB, FLOPs: 302,269,609\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1625 finished in 0m04s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 2,292,271 (8.744 MB), Total: 8.86 MB, FLOPs: 302,003,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1625 finished in 0m04s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 2,287,175 (8.725 MB), Total: 8.84 MB, FLOPs: 301,865,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1625 finished in 0m04s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 326)]\n",
      "Input: 0.115 MB, Params: 2,284,629 (8.715 MB), Total: 8.83 MB, FLOPs: 301,797,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1625 finished in 0m04s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 2,282,083 (8.705 MB), Total: 8.82 MB, FLOPs: 301,728,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1625 finished in 0m04s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 274)]\n",
      "Input: 0.115 MB, Params: 2,279,537 (8.696 MB), Total: 8.81 MB, FLOPs: 301,659,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1625 finished in 0m04s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 2,276,502 (8.684 MB), Total: 8.80 MB, FLOPs: 301,332,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1625 finished in 0m04s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.115 MB, Params: 2,271,433 (8.665 MB), Total: 8.78 MB, FLOPs: 301,195,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1625 finished in 0m04s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.115 MB, Params: 2,268,896 (8.655 MB), Total: 8.77 MB, FLOPs: 301,127,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1625 finished in 0m04s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 282)]\n",
      "Input: 0.115 MB, Params: 2,266,359 (8.645 MB), Total: 8.76 MB, FLOPs: 301,058,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1625 finished in 0m04s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.115 MB, Params: 2,263,822 (8.636 MB), Total: 8.75 MB, FLOPs: 300,990,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1625 finished in 0m04s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 2,258,780 (8.617 MB), Total: 8.73 MB, FLOPs: 300,854,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1625 finished in 0m04s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.115 MB, Params: 2,256,252 (8.607 MB), Total: 8.72 MB, FLOPs: 300,786,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1625 finished in 0m04s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 193)]\n",
      "Input: 0.115 MB, Params: 2,251,912 (8.590 MB), Total: 8.71 MB, FLOPs: 300,521,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1625 finished in 0m04s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 88)]\n",
      "Input: 0.115 MB, Params: 2,247,572 (8.574 MB), Total: 8.69 MB, FLOPs: 300,256,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1625 finished in 0m04s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.115 MB, Params: 2,242,557 (8.555 MB), Total: 8.67 MB, FLOPs: 300,121,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1625 finished in 0m04s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.115 MB, Params: 2,237,542 (8.536 MB), Total: 8.65 MB, FLOPs: 299,986,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1625 finished in 0m04s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 268)]\n",
      "Input: 0.115 MB, Params: 2,235,032 (8.526 MB), Total: 8.64 MB, FLOPs: 299,918,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1625 finished in 0m04s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 2,233,329 (8.519 MB), Total: 8.63 MB, FLOPs: 299,099,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1625 finished in 0m04s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 2,228,323 (8.500 MB), Total: 8.62 MB, FLOPs: 298,964,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1625 finished in 0m04s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 2,225,822 (8.491 MB), Total: 8.61 MB, FLOPs: 298,897,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1625 finished in 0m04s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 2,220,825 (8.472 MB), Total: 8.59 MB, FLOPs: 298,762,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1625 finished in 0m04s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 2,218,333 (8.462 MB), Total: 8.58 MB, FLOPs: 298,695,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1625 finished in 0m04s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 2,213,345 (8.443 MB), Total: 8.56 MB, FLOPs: 298,560,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1625 finished in 0m04s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 2,210,862 (8.434 MB), Total: 8.55 MB, FLOPs: 298,493,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1625 finished in 0m04s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 2,208,379 (8.424 MB), Total: 8.54 MB, FLOPs: 298,426,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1625 finished in 0m04s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 2,205,896 (8.415 MB), Total: 8.53 MB, FLOPs: 298,360,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1625 finished in 0m04s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.115 MB, Params: 2,200,935 (8.396 MB), Total: 8.51 MB, FLOPs: 298,226,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1625 finished in 0m04s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 322)]\n",
      "Input: 0.115 MB, Params: 2,198,461 (8.386 MB), Total: 8.50 MB, FLOPs: 298,159,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1625 finished in 0m04s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 194)]\n",
      "Input: 0.115 MB, Params: 2,194,175 (8.370 MB), Total: 8.49 MB, FLOPs: 297,896,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1625 finished in 0m04s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.115 MB, Params: 2,189,889 (8.354 MB), Total: 8.47 MB, FLOPs: 297,633,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1625 finished in 0m04s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 2,184,955 (8.335 MB), Total: 8.45 MB, FLOPs: 297,500,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1625 finished in 0m04s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 2,182,490 (8.326 MB), Total: 8.44 MB, FLOPs: 297,433,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1625 finished in 0m04s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 300)]\n",
      "Input: 0.115 MB, Params: 2,180,025 (8.316 MB), Total: 8.43 MB, FLOPs: 297,367,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1625 finished in 0m04s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 96)]\n",
      "Input: 0.115 MB, Params: 2,177,026 (8.305 MB), Total: 8.42 MB, FLOPs: 297,043,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1625 finished in 0m04s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 2,172,758 (8.288 MB), Total: 8.40 MB, FLOPs: 296,781,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1625 finished in 0m04s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 63)]\n",
      "Input: 0.115 MB, Params: 2,171,055 (8.282 MB), Total: 8.40 MB, FLOPs: 295,962,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1625 finished in 0m04s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 100)]\n",
      "Input: 0.115 MB, Params: 2,169,352 (8.275 MB), Total: 8.39 MB, FLOPs: 295,144,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1625 finished in 0m04s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 203)]\n",
      "Input: 0.115 MB, Params: 2,166,887 (8.266 MB), Total: 8.38 MB, FLOPs: 295,077,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1625 finished in 0m04s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 174)]\n",
      "Input: 0.115 MB, Params: 2,162,619 (8.250 MB), Total: 8.37 MB, FLOPs: 294,815,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1625 finished in 0m04s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 2,160,154 (8.240 MB), Total: 8.36 MB, FLOPs: 294,749,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1625 finished in 0m04s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 2,157,689 (8.231 MB), Total: 8.35 MB, FLOPs: 294,683,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1625 finished in 0m04s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.115 MB, Params: 2,152,818 (8.212 MB), Total: 8.33 MB, FLOPs: 294,551,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1625 finished in 0m04s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 2,150,362 (8.203 MB), Total: 8.32 MB, FLOPs: 294,485,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1625 finished in 0m04s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 2,147,906 (8.194 MB), Total: 8.31 MB, FLOPs: 294,419,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1625 finished in 0m04s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 2,144,925 (8.182 MB), Total: 8.30 MB, FLOPs: 294,097,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1625 finished in 0m04s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 2,140,072 (8.164 MB), Total: 8.28 MB, FLOPs: 293,966,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1625 finished in 0m04s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.115 MB, Params: 2,137,091 (8.152 MB), Total: 8.27 MB, FLOPs: 293,644,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1625 finished in 0m04s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 2,132,238 (8.134 MB), Total: 8.25 MB, FLOPs: 293,513,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.308%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1625 finished in 0m04s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 2,129,800 (8.125 MB), Total: 8.24 MB, FLOPs: 293,447,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1625 finished in 0m04s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 2,124,956 (8.106 MB), Total: 8.22 MB, FLOPs: 293,317,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1625 finished in 0m04s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.115 MB, Params: 2,122,227 (8.096 MB), Total: 8.21 MB, FLOPs: 292,672,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1625 finished in 0m04s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 2,117,383 (8.077 MB), Total: 8.19 MB, FLOPs: 292,541,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1625 finished in 0m04s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 2,114,963 (8.068 MB), Total: 8.18 MB, FLOPs: 292,476,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1625 finished in 0m04s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.115 MB, Params: 2,111,991 (8.057 MB), Total: 8.17 MB, FLOPs: 292,155,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1625 finished in 0m04s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.115 MB, Params: 2,107,795 (8.041 MB), Total: 8.16 MB, FLOPs: 291,897,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1625 finished in 0m04s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 2,102,969 (8.022 MB), Total: 8.14 MB, FLOPs: 291,767,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1625 finished in 0m04s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 297)]\n",
      "Input: 0.115 MB, Params: 2,100,558 (8.013 MB), Total: 8.13 MB, FLOPs: 291,702,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1625 finished in 0m04s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 2,095,741 (7.995 MB), Total: 8.11 MB, FLOPs: 291,572,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1625 finished in 0m04s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 213)]\n",
      "Input: 0.115 MB, Params: 2,093,339 (7.985 MB), Total: 8.10 MB, FLOPs: 291,507,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1625 finished in 0m04s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 2,090,376 (7.974 MB), Total: 8.09 MB, FLOPs: 291,188,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1625 finished in 0m04s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 2,087,974 (7.965 MB), Total: 8.08 MB, FLOPs: 291,123,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1625 finished in 0m04s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 253)]\n",
      "Input: 0.115 MB, Params: 2,085,572 (7.956 MB), Total: 8.07 MB, FLOPs: 291,058,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1625 finished in 0m04s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.115 MB, Params: 2,082,609 (7.945 MB), Total: 8.06 MB, FLOPs: 290,738,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1625 finished in 0m04s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 230)]\n",
      "Input: 0.115 MB, Params: 2,077,819 (7.926 MB), Total: 8.04 MB, FLOPs: 290,609,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1625 finished in 0m04s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 2,073,029 (7.908 MB), Total: 8.02 MB, FLOPs: 290,480,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1625 finished in 0m04s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 2,070,645 (7.899 MB), Total: 8.01 MB, FLOPs: 290,415,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1625 finished in 0m04s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.115 MB, Params: 2,068,261 (7.890 MB), Total: 8.01 MB, FLOPs: 290,351,731\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1625 finished in 0m04s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.115 MB, Params: 2,065,877 (7.881 MB), Total: 8.00 MB, FLOPs: 290,287,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1625 finished in 0m04s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.115 MB, Params: 2,061,114 (7.863 MB), Total: 7.98 MB, FLOPs: 290,158,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1625 finished in 0m04s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,058,739 (7.853 MB), Total: 7.97 MB, FLOPs: 290,094,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1625 finished in 0m04s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 2,053,985 (7.835 MB), Total: 7.95 MB, FLOPs: 289,966,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1625 finished in 0m04s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.115 MB, Params: 2,051,619 (7.826 MB), Total: 7.94 MB, FLOPs: 289,902,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1625 finished in 0m04s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 2,049,925 (7.820 MB), Total: 7.94 MB, FLOPs: 289,088,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1625 finished in 0m04s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 2,045,801 (7.804 MB), Total: 7.92 MB, FLOPs: 288,834,171\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1625 finished in 0m04s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.115 MB, Params: 2,041,065 (7.786 MB), Total: 7.90 MB, FLOPs: 288,706,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1625 finished in 0m04s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 2,038,708 (7.777 MB), Total: 7.89 MB, FLOPs: 288,642,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1625 finished in 0m04s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.115 MB, Params: 2,036,351 (7.768 MB), Total: 7.88 MB, FLOPs: 288,579,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1625 finished in 0m04s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 205)]\n",
      "Input: 0.115 MB, Params: 2,031,633 (7.750 MB), Total: 7.87 MB, FLOPs: 288,451,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1625 finished in 0m04s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 2,029,285 (7.741 MB), Total: 7.86 MB, FLOPs: 288,388,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1625 finished in 0m04s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.115 MB, Params: 2,027,591 (7.735 MB), Total: 7.85 MB, FLOPs: 287,574,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1625 finished in 0m04s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 2,022,882 (7.717 MB), Total: 7.83 MB, FLOPs: 287,447,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1625 finished in 0m04s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.115 MB, Params: 2,018,785 (7.701 MB), Total: 7.82 MB, FLOPs: 287,193,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1625 finished in 0m04s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 2,014,085 (7.683 MB), Total: 7.80 MB, FLOPs: 287,066,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1625 finished in 0m04s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 240)]\n",
      "Input: 0.115 MB, Params: 2,009,385 (7.665 MB), Total: 7.78 MB, FLOPs: 286,939,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1625 finished in 0m04s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 2,007,064 (7.656 MB), Total: 7.77 MB, FLOPs: 286,877,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1625 finished in 0m04s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.115 MB, Params: 2,002,373 (7.638 MB), Total: 7.75 MB, FLOPs: 286,750,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1625 finished in 0m04s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 2,000,061 (7.630 MB), Total: 7.74 MB, FLOPs: 286,688,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1625 finished in 0m04s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 1,997,749 (7.621 MB), Total: 7.74 MB, FLOPs: 286,626,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1625 finished in 0m04s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 1,993,076 (7.603 MB), Total: 7.72 MB, FLOPs: 286,500,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1625 finished in 0m04s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 1,988,403 (7.585 MB), Total: 7.70 MB, FLOPs: 286,373,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1625 finished in 0m04s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 275)]\n",
      "Input: 0.115 MB, Params: 1,986,109 (7.576 MB), Total: 7.69 MB, FLOPs: 286,312,105\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1625 finished in 0m04s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.115 MB, Params: 1,983,815 (7.568 MB), Total: 7.68 MB, FLOPs: 286,250,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1625 finished in 0m04s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 170)]\n",
      "Input: 0.115 MB, Params: 1,980,870 (7.556 MB), Total: 7.67 MB, FLOPs: 285,932,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1625 finished in 0m04s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 1,978,576 (7.548 MB), Total: 7.66 MB, FLOPs: 285,870,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1625 finished in 0m04s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 1,973,930 (7.530 MB), Total: 7.65 MB, FLOPs: 285,745,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1625 finished in 0m04s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 262)]\n",
      "Input: 0.115 MB, Params: 1,971,645 (7.521 MB), Total: 7.64 MB, FLOPs: 285,683,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1625 finished in 0m04s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 276)]\n",
      "Input: 0.115 MB, Params: 1,969,360 (7.513 MB), Total: 7.63 MB, FLOPs: 285,622,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1625 finished in 0m04s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 161)]\n",
      "Input: 0.115 MB, Params: 1,966,415 (7.501 MB), Total: 7.62 MB, FLOPs: 285,304,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1625 finished in 0m04s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 1,961,787 (7.484 MB), Total: 7.60 MB, FLOPs: 285,179,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1625 finished in 0m04s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.115 MB, Params: 1,959,511 (7.475 MB), Total: 7.59 MB, FLOPs: 285,117,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1625 finished in 0m04s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 33)]\n",
      "Input: 0.115 MB, Params: 1,958,726 (7.472 MB), Total: 7.59 MB, FLOPs: 283,589,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1625 finished in 0m04s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 186)]\n",
      "Input: 0.115 MB, Params: 1,954,107 (7.454 MB), Total: 7.57 MB, FLOPs: 283,464,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1625 finished in 0m04s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 176)]\n",
      "Input: 0.115 MB, Params: 1,951,162 (7.443 MB), Total: 7.56 MB, FLOPs: 283,146,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1625 finished in 0m04s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 1,946,543 (7.425 MB), Total: 7.54 MB, FLOPs: 283,021,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1625 finished in 0m04s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 1,943,598 (7.414 MB), Total: 7.53 MB, FLOPs: 282,703,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1625 finished in 0m04s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.115 MB, Params: 1,938,979 (7.397 MB), Total: 7.51 MB, FLOPs: 282,579,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1625 finished in 0m04s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.115 MB, Params: 1,936,034 (7.385 MB), Total: 7.50 MB, FLOPs: 282,261,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1625 finished in 0m04s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 133)]\n",
      "Input: 0.115 MB, Params: 1,932,072 (7.370 MB), Total: 7.49 MB, FLOPs: 282,014,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1625 finished in 0m04s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.115 MB, Params: 1,927,462 (7.353 MB), Total: 7.47 MB, FLOPs: 281,890,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1625 finished in 0m04s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 1,925,222 (7.344 MB), Total: 7.46 MB, FLOPs: 281,830,021\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1625 finished in 0m04s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 1,920,621 (7.327 MB), Total: 7.44 MB, FLOPs: 281,705,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1625 finished in 0m04s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 1,918,390 (7.318 MB), Total: 7.43 MB, FLOPs: 281,645,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1625 finished in 0m04s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 1,916,159 (7.310 MB), Total: 7.42 MB, FLOPs: 281,585,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1625 finished in 0m04s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 45)]\n",
      "Input: 0.115 MB, Params: 1,914,465 (7.303 MB), Total: 7.42 MB, FLOPs: 280,771,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1625 finished in 0m04s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 1,911,529 (7.292 MB), Total: 7.41 MB, FLOPs: 280,454,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1625 finished in 0m04s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 106)]\n",
      "Input: 0.115 MB, Params: 1,908,908 (7.282 MB), Total: 7.40 MB, FLOPs: 279,831,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1625 finished in 0m04s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 1,904,325 (7.264 MB), Total: 7.38 MB, FLOPs: 279,707,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1625 finished in 0m04s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.115 MB, Params: 1,902,103 (7.256 MB), Total: 7.37 MB, FLOPs: 279,647,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1625 finished in 0m04s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 1,899,881 (7.247 MB), Total: 7.36 MB, FLOPs: 279,588,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1625 finished in 0m04s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.115 MB, Params: 1,895,316 (7.230 MB), Total: 7.35 MB, FLOPs: 279,464,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1625 finished in 0m04s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.115 MB, Params: 1,893,103 (7.222 MB), Total: 7.34 MB, FLOPs: 279,405,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1625 finished in 0m04s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 1,890,890 (7.213 MB), Total: 7.33 MB, FLOPs: 279,345,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1625 finished in 0m04s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 136)]\n",
      "Input: 0.115 MB, Params: 1,887,963 (7.202 MB), Total: 7.32 MB, FLOPs: 279,029,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1625 finished in 0m04s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 2)]\n",
      "Input: 0.115 MB, Params: 1,885,351 (7.192 MB), Total: 7.31 MB, FLOPs: 278,407,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1625 finished in 0m04s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 1,882,433 (7.181 MB), Total: 7.30 MB, FLOPs: 278,092,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1625 finished in 0m04s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 1,880,220 (7.172 MB), Total: 7.29 MB, FLOPs: 278,033,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1625 finished in 0m04s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 1,878,007 (7.164 MB), Total: 7.28 MB, FLOPs: 277,973,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1625 finished in 0m04s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.115 MB, Params: 1,873,478 (7.147 MB), Total: 7.26 MB, FLOPs: 277,851,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1625 finished in 0m04s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.115 MB, Params: 1,871,274 (7.138 MB), Total: 7.25 MB, FLOPs: 277,791,961\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1625 finished in 0m04s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 97)]\n",
      "Input: 0.115 MB, Params: 1,869,598 (7.132 MB), Total: 7.25 MB, FLOPs: 276,986,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1625 finished in 0m04s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 1,867,394 (7.124 MB), Total: 7.24 MB, FLOPs: 276,926,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1625 finished in 0m04s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 1,863,504 (7.109 MB), Total: 7.22 MB, FLOPs: 276,684,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1625 finished in 0m04s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 102)]\n",
      "Input: 0.115 MB, Params: 1,859,614 (7.094 MB), Total: 7.21 MB, FLOPs: 276,442,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1625 finished in 0m04s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 1,855,121 (7.077 MB), Total: 7.19 MB, FLOPs: 276,321,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1625 finished in 0m04s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 1,852,926 (7.068 MB), Total: 7.18 MB, FLOPs: 276,262,039\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1625 finished in 0m04s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 1,850,731 (7.060 MB), Total: 7.18 MB, FLOPs: 276,202,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1625 finished in 0m04s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.115 MB, Params: 1,849,055 (7.054 MB), Total: 7.17 MB, FLOPs: 275,397,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1625 finished in 0m04s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 102)]\n",
      "Input: 0.115 MB, Params: 1,846,470 (7.044 MB), Total: 7.16 MB, FLOPs: 274,785,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1625 finished in 0m04s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 1,844,275 (7.035 MB), Total: 7.15 MB, FLOPs: 274,725,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1625 finished in 0m04s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.115 MB, Params: 1,839,809 (7.018 MB), Total: 7.13 MB, FLOPs: 274,605,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1625 finished in 0m04s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 237)]\n",
      "Input: 0.115 MB, Params: 1,837,623 (7.010 MB), Total: 7.13 MB, FLOPs: 274,546,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1625 finished in 0m04s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 1,833,166 (6.993 MB), Total: 7.11 MB, FLOPs: 274,426,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1625 finished in 0m04s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 1,830,989 (6.985 MB), Total: 7.10 MB, FLOPs: 274,367,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1625 finished in 0m04s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 1,828,098 (6.974 MB), Total: 7.09 MB, FLOPs: 274,055,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1625 finished in 0m04s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 1,823,650 (6.957 MB), Total: 7.07 MB, FLOPs: 273,935,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1625 finished in 0m04s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,821,482 (6.948 MB), Total: 7.06 MB, FLOPs: 273,876,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1625 finished in 0m04s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 238)]\n",
      "Input: 0.115 MB, Params: 1,819,314 (6.940 MB), Total: 7.06 MB, FLOPs: 273,818,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1625 finished in 0m04s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.115 MB, Params: 1,816,423 (6.929 MB), Total: 7.04 MB, FLOPs: 273,506,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1625 finished in 0m04s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 1,811,993 (6.912 MB), Total: 7.03 MB, FLOPs: 273,386,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1625 finished in 0m04s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 1,809,834 (6.904 MB), Total: 7.02 MB, FLOPs: 273,328,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1625 finished in 0m04s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.115 MB, Params: 1,806,007 (6.889 MB), Total: 7.00 MB, FLOPs: 273,089,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1625 finished in 0m04s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.115 MB, Params: 1,801,595 (6.873 MB), Total: 6.99 MB, FLOPs: 272,970,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1625 finished in 0m04s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 1,797,777 (6.858 MB), Total: 6.97 MB, FLOPs: 272,731,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1625 finished in 0m04s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 39)]\n",
      "Input: 0.115 MB, Params: 1,796,992 (6.855 MB), Total: 6.97 MB, FLOPs: 271,202,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1625 finished in 0m04s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 169)]\n",
      "Input: 0.115 MB, Params: 1,794,119 (6.844 MB), Total: 6.96 MB, FLOPs: 270,892,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1625 finished in 0m04s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 171)]\n",
      "Input: 0.115 MB, Params: 1,790,310 (6.829 MB), Total: 6.94 MB, FLOPs: 270,654,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1625 finished in 0m04s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 182)]\n",
      "Input: 0.115 MB, Params: 1,785,916 (6.813 MB), Total: 6.93 MB, FLOPs: 270,536,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1625 finished in 0m04s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 1,783,775 (6.805 MB), Total: 6.92 MB, FLOPs: 270,478,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1625 finished in 0m04s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 1,782,108 (6.798 MB), Total: 6.91 MB, FLOPs: 269,677,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1625 finished in 0m04s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.115 MB, Params: 1,779,967 (6.790 MB), Total: 6.91 MB, FLOPs: 269,619,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1625 finished in 0m04s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.115 MB, Params: 1,776,167 (6.776 MB), Total: 6.89 MB, FLOPs: 269,381,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1625 finished in 0m04s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 1,771,800 (6.759 MB), Total: 6.87 MB, FLOPs: 269,264,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1625 finished in 0m04s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 1,769,668 (6.751 MB), Total: 6.87 MB, FLOPs: 269,206,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1625 finished in 0m04s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.115 MB, Params: 1,767,536 (6.743 MB), Total: 6.86 MB, FLOPs: 269,149,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1625 finished in 0m04s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.115 MB, Params: 1,764,681 (6.732 MB), Total: 6.85 MB, FLOPs: 268,841,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1625 finished in 0m04s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 1,760,899 (6.717 MB), Total: 6.83 MB, FLOPs: 268,604,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1625 finished in 0m04s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 1,756,559 (6.701 MB), Total: 6.82 MB, FLOPs: 268,487,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1625 finished in 0m04s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 262)]\n",
      "Input: 0.115 MB, Params: 1,754,436 (6.693 MB), Total: 6.81 MB, FLOPs: 268,430,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1625 finished in 0m04s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 1,752,313 (6.685 MB), Total: 6.80 MB, FLOPs: 268,373,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1625 finished in 0m04s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.115 MB, Params: 1,747,991 (6.668 MB), Total: 6.78 MB, FLOPs: 268,256,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1625 finished in 0m04s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 1,745,877 (6.660 MB), Total: 6.78 MB, FLOPs: 268,199,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1625 finished in 0m04s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 175)]\n",
      "Input: 0.115 MB, Params: 1,743,031 (6.649 MB), Total: 6.76 MB, FLOPs: 267,892,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1625 finished in 0m04s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 1,738,718 (6.633 MB), Total: 6.75 MB, FLOPs: 267,775,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1625 finished in 0m04s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.115 MB, Params: 1,736,613 (6.625 MB), Total: 6.74 MB, FLOPs: 267,719,143\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1625 finished in 0m04s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.115 MB, Params: 1,732,309 (6.608 MB), Total: 6.72 MB, FLOPs: 267,602,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1625 finished in 0m04s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 1,730,213 (6.600 MB), Total: 6.72 MB, FLOPs: 267,546,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1625 finished in 0m04s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 1,727,367 (6.589 MB), Total: 6.70 MB, FLOPs: 267,239,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1625 finished in 0m04s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 78)]\n",
      "Input: 0.115 MB, Params: 1,725,700 (6.583 MB), Total: 6.70 MB, FLOPs: 266,437,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1625 finished in 0m04s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 1,721,405 (6.567 MB), Total: 6.68 MB, FLOPs: 266,321,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1625 finished in 0m04s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 1,719,318 (6.559 MB), Total: 6.67 MB, FLOPs: 266,265,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1625 finished in 0m04s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 1,715,032 (6.542 MB), Total: 6.66 MB, FLOPs: 266,150,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1625 finished in 0m04s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 1,712,954 (6.534 MB), Total: 6.65 MB, FLOPs: 266,094,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1625 finished in 0m04s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.115 MB, Params: 1,708,677 (6.518 MB), Total: 6.63 MB, FLOPs: 265,978,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1625 finished in 0m04s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.115 MB, Params: 1,706,608 (6.510 MB), Total: 6.63 MB, FLOPs: 265,922,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1625 finished in 0m04s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 106)]\n",
      "Input: 0.115 MB, Params: 1,702,907 (6.496 MB), Total: 6.61 MB, FLOPs: 265,690,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1625 finished in 0m04s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 1,698,648 (6.480 MB), Total: 6.60 MB, FLOPs: 265,575,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1625 finished in 0m04s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 1,696,588 (6.472 MB), Total: 6.59 MB, FLOPs: 265,519,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1625 finished in 0m04s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 1,692,338 (6.456 MB), Total: 6.57 MB, FLOPs: 265,405,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1625 finished in 0m04s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 1,690,287 (6.448 MB), Total: 6.56 MB, FLOPs: 265,349,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1625 finished in 0m04s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 1,688,236 (6.440 MB), Total: 6.56 MB, FLOPs: 265,294,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1625 finished in 0m04s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 1,685,723 (6.431 MB), Total: 6.55 MB, FLOPs: 264,696,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1625 finished in 0m04s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 9)]\n",
      "Input: 0.115 MB, Params: 1,682,040 (6.416 MB), Total: 6.53 MB, FLOPs: 264,464,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1625 finished in 0m04s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 1,677,817 (6.400 MB), Total: 6.52 MB, FLOPs: 264,350,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1625 finished in 0m04s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 1,675,775 (6.393 MB), Total: 6.51 MB, FLOPs: 264,295,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1625 finished in 0m04s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 1,671,561 (6.376 MB), Total: 6.49 MB, FLOPs: 264,181,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1625 finished in 0m04s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 187)]\n",
      "Input: 0.115 MB, Params: 1,667,896 (6.363 MB), Total: 6.48 MB, FLOPs: 263,950,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1625 finished in 0m04s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 1,663,691 (6.346 MB), Total: 6.46 MB, FLOPs: 263,836,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1625 finished in 0m04s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 1,661,667 (6.339 MB), Total: 6.45 MB, FLOPs: 263,782,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1625 finished in 0m04s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 1,657,471 (6.323 MB), Total: 6.44 MB, FLOPs: 263,668,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1625 finished in 0m04s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 1,653,824 (6.309 MB), Total: 6.42 MB, FLOPs: 263,437,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1625 finished in 0m04s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 183)]\n",
      "Input: 0.115 MB, Params: 1,649,637 (6.293 MB), Total: 6.41 MB, FLOPs: 263,324,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1625 finished in 0m04s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 1,645,450 (6.277 MB), Total: 6.39 MB, FLOPs: 263,211,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1625 finished in 0m04s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 1,641,821 (6.263 MB), Total: 6.38 MB, FLOPs: 262,980,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1625 finished in 0m04s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 154)]\n",
      "Input: 0.115 MB, Params: 1,639,029 (6.252 MB), Total: 6.37 MB, FLOPs: 262,679,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1625 finished in 0m04s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 92)]\n",
      "Input: 0.115 MB, Params: 1,637,371 (6.246 MB), Total: 6.36 MB, FLOPs: 261,882,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1625 finished in 0m04s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 44)]\n",
      "Input: 0.115 MB, Params: 1,636,001 (6.241 MB), Total: 6.36 MB, FLOPs: 260,479,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1625 finished in 0m04s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 95)]\n",
      "Input: 0.115 MB, Params: 1,633,209 (6.230 MB), Total: 6.35 MB, FLOPs: 260,178,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1625 finished in 0m04s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 1,631,212 (6.223 MB), Total: 6.34 MB, FLOPs: 260,124,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1625 finished in 0m04s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.115 MB, Params: 1,629,215 (6.215 MB), Total: 6.33 MB, FLOPs: 260,070,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1625 finished in 0m04s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 1,625,055 (6.199 MB), Total: 6.31 MB, FLOPs: 259,958,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1625 finished in 0m04s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 1,622,263 (6.188 MB), Total: 6.30 MB, FLOPs: 259,657,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1625 finished in 0m04s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 1,619,786 (6.179 MB), Total: 6.29 MB, FLOPs: 259,066,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1625 finished in 0m04s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 1,615,626 (6.163 MB), Total: 6.28 MB, FLOPs: 258,954,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1625 finished in 0m04s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.115 MB, Params: 1,613,647 (6.156 MB), Total: 6.27 MB, FLOPs: 258,901,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1625 finished in 0m04s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.115 MB, Params: 1,610,063 (6.142 MB), Total: 6.26 MB, FLOPs: 258,673,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1625 finished in 0m04s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 170)]\n",
      "Input: 0.115 MB, Params: 1,605,921 (6.126 MB), Total: 6.24 MB, FLOPs: 258,561,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1625 finished in 0m04s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 1,601,779 (6.110 MB), Total: 6.23 MB, FLOPs: 258,450,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1625 finished in 0m04s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 51)]\n",
      "Input: 0.115 MB, Params: 1,599,302 (6.101 MB), Total: 6.22 MB, FLOPs: 257,859,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1625 finished in 0m04s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 1,595,160 (6.085 MB), Total: 6.20 MB, FLOPs: 257,747,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1625 finished in 0m04s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,593,208 (6.078 MB), Total: 6.19 MB, FLOPs: 257,695,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1625 finished in 0m04s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 89)]\n",
      "Input: 0.115 MB, Params: 1,590,443 (6.067 MB), Total: 6.18 MB, FLOPs: 257,396,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1625 finished in 0m04s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 1,588,491 (6.060 MB), Total: 6.17 MB, FLOPs: 257,344,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1625 finished in 0m04s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 1,584,367 (6.044 MB), Total: 6.16 MB, FLOPs: 257,232,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1625 finished in 0m04s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 1,582,424 (6.036 MB), Total: 6.15 MB, FLOPs: 257,180,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1625 finished in 0m04s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 1,580,481 (6.029 MB), Total: 6.14 MB, FLOPs: 257,128,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1625 finished in 0m04s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 204)]\n",
      "Input: 0.115 MB, Params: 1,576,375 (6.013 MB), Total: 6.13 MB, FLOPs: 257,017,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1625 finished in 0m04s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.115 MB, Params: 1,574,441 (6.006 MB), Total: 6.12 MB, FLOPs: 256,965,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1625 finished in 0m04s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 1,570,911 (5.993 MB), Total: 6.11 MB, FLOPs: 256,740,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1625 finished in 0m04s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 149)]\n",
      "Input: 0.115 MB, Params: 1,566,823 (5.977 MB), Total: 6.09 MB, FLOPs: 256,629,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1625 finished in 0m04s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 1,564,355 (5.968 MB), Total: 6.08 MB, FLOPs: 256,040,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1625 finished in 0m04s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 1,560,834 (5.954 MB), Total: 6.07 MB, FLOPs: 255,815,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1625 finished in 0m04s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 1,556,755 (5.939 MB), Total: 6.05 MB, FLOPs: 255,705,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1625 finished in 0m04s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,554,839 (5.931 MB), Total: 6.05 MB, FLOPs: 255,653,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1625 finished in 0m04s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 1,552,923 (5.924 MB), Total: 6.04 MB, FLOPs: 255,601,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1625 finished in 0m04s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 1,551,007 (5.917 MB), Total: 6.03 MB, FLOPs: 255,550,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1625 finished in 0m04s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 97)]\n",
      "Input: 0.115 MB, Params: 1,548,539 (5.907 MB), Total: 6.02 MB, FLOPs: 254,960,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1625 finished in 0m04s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 181)]\n",
      "Input: 0.115 MB, Params: 1,545,027 (5.894 MB), Total: 6.01 MB, FLOPs: 254,736,135\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1625 finished in 0m04s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 156)]\n",
      "Input: 0.115 MB, Params: 1,540,984 (5.878 MB), Total: 5.99 MB, FLOPs: 254,627,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1625 finished in 0m04s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 1,536,941 (5.863 MB), Total: 5.98 MB, FLOPs: 254,517,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1625 finished in 0m04s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 1,535,043 (5.856 MB), Total: 5.97 MB, FLOPs: 254,466,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1625 finished in 0m04s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 1,533,145 (5.848 MB), Total: 5.96 MB, FLOPs: 254,415,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1625 finished in 0m04s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 243)]\n",
      "Input: 0.115 MB, Params: 1,531,247 (5.841 MB), Total: 5.96 MB, FLOPs: 254,364,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1625 finished in 0m04s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 1,527,753 (5.828 MB), Total: 5.94 MB, FLOPs: 254,140,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1625 finished in 0m04s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 1,523,746 (5.813 MB), Total: 5.93 MB, FLOPs: 254,032,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1625 finished in 0m04s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.115 MB, Params: 1,521,857 (5.805 MB), Total: 5.92 MB, FLOPs: 253,981,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1625 finished in 0m04s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 1,519,146 (5.795 MB), Total: 5.91 MB, FLOPs: 253,688,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1625 finished in 0m04s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 40)]\n",
      "Input: 0.115 MB, Params: 1,517,533 (5.789 MB), Total: 5.90 MB, FLOPs: 252,913,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1625 finished in 0m04s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 1,513,535 (5.774 MB), Total: 5.89 MB, FLOPs: 252,805,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1625 finished in 0m04s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.115 MB, Params: 1,510,824 (5.763 MB), Total: 5.88 MB, FLOPs: 252,512,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1625 finished in 0m04s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 1,509,463 (5.758 MB), Total: 5.87 MB, FLOPs: 251,114,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1625 finished in 0m04s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,507,583 (5.751 MB), Total: 5.87 MB, FLOPs: 251,064,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1625 finished in 0m04s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 1,503,594 (5.736 MB), Total: 5.85 MB, FLOPs: 250,956,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1625 finished in 0m04s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 127)]\n",
      "Input: 0.115 MB, Params: 1,501,723 (5.729 MB), Total: 5.84 MB, FLOPs: 250,906,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1625 finished in 0m04s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.115 MB, Params: 1,500,119 (5.722 MB), Total: 5.84 MB, FLOPs: 250,135,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1625 finished in 0m04s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.115 MB, Params: 1,497,687 (5.713 MB), Total: 5.83 MB, FLOPs: 249,556,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1625 finished in 0m04s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 1,494,985 (5.703 MB), Total: 5.82 MB, FLOPs: 249,264,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1625 finished in 0m04s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.115 MB, Params: 1,491,545 (5.690 MB), Total: 5.81 MB, FLOPs: 249,043,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1625 finished in 0m04s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 1,487,574 (5.675 MB), Total: 5.79 MB, FLOPs: 248,936,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1625 finished in 0m04s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 1,483,603 (5.659 MB), Total: 5.77 MB, FLOPs: 248,829,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1625 finished in 0m04s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 1,481,750 (5.652 MB), Total: 5.77 MB, FLOPs: 248,779,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1625 finished in 0m04s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 1,480,155 (5.646 MB), Total: 5.76 MB, FLOPs: 248,012,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1625 finished in 0m04s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 1,478,302 (5.639 MB), Total: 5.75 MB, FLOPs: 247,962,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1625 finished in 0m04s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.115 MB, Params: 1,474,349 (5.624 MB), Total: 5.74 MB, FLOPs: 247,856,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1625 finished in 0m04s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.115 MB, Params: 1,472,505 (5.617 MB), Total: 5.73 MB, FLOPs: 247,806,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1625 finished in 0m04s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.115 MB, Params: 1,469,092 (5.604 MB), Total: 5.72 MB, FLOPs: 247,586,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1625 finished in 0m04s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 1,466,408 (5.594 MB), Total: 5.71 MB, FLOPs: 247,296,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1625 finished in 0m04s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 1,464,564 (5.587 MB), Total: 5.70 MB, FLOPs: 247,247,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1625 finished in 0m04s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 1,461,880 (5.577 MB), Total: 5.69 MB, FLOPs: 246,957,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1625 finished in 0m04s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,460,036 (5.570 MB), Total: 5.68 MB, FLOPs: 246,907,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1625 finished in 0m04s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 1,457,352 (5.559 MB), Total: 5.67 MB, FLOPs: 246,618,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1625 finished in 0m04s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.115 MB, Params: 1,454,965 (5.550 MB), Total: 5.67 MB, FLOPs: 246,047,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1625 finished in 0m04s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 1,452,290 (5.540 MB), Total: 5.66 MB, FLOPs: 245,758,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1625 finished in 0m04s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.115 MB, Params: 1,448,913 (5.527 MB), Total: 5.64 MB, FLOPs: 245,542,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1625 finished in 0m04s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 1,445,005 (5.512 MB), Total: 5.63 MB, FLOPs: 245,437,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1625 finished in 0m04s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 1,443,170 (5.505 MB), Total: 5.62 MB, FLOPs: 245,387,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1625 finished in 0m04s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 1,441,335 (5.498 MB), Total: 5.61 MB, FLOPs: 245,338,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1625 finished in 0m04s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.115 MB, Params: 1,439,992 (5.493 MB), Total: 5.61 MB, FLOPs: 243,949,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1625 finished in 0m04s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 1,437,326 (5.483 MB), Total: 5.60 MB, FLOPs: 243,661,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1625 finished in 0m04s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 1,433,967 (5.470 MB), Total: 5.59 MB, FLOPs: 243,446,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1625 finished in 0m04s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 1,430,086 (5.455 MB), Total: 5.57 MB, FLOPs: 243,341,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1625 finished in 0m04s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 1,428,260 (5.448 MB), Total: 5.56 MB, FLOPs: 243,292,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1625 finished in 0m04s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.115 MB, Params: 1,425,603 (5.438 MB), Total: 5.55 MB, FLOPs: 243,005,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1625 finished in 0m04s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 1,423,777 (5.431 MB), Total: 5.55 MB, FLOPs: 242,956,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1625 finished in 0m04s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 1,419,914 (5.417 MB), Total: 5.53 MB, FLOPs: 242,852,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1625 finished in 0m04s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.115 MB, Params: 1,418,097 (5.410 MB), Total: 5.52 MB, FLOPs: 242,803,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1625 finished in 0m04s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.115 MB, Params: 1,416,280 (5.403 MB), Total: 5.52 MB, FLOPs: 242,754,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1625 finished in 0m04s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.115 MB, Params: 1,412,435 (5.388 MB), Total: 5.50 MB, FLOPs: 242,650,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1625 finished in 0m04s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 1,410,627 (5.381 MB), Total: 5.50 MB, FLOPs: 242,602,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1625 finished in 0m04s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.115 MB, Params: 1,406,791 (5.366 MB), Total: 5.48 MB, FLOPs: 242,498,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1625 finished in 0m04s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 1,404,992 (5.360 MB), Total: 5.47 MB, FLOPs: 242,450,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1625 finished in 0m04s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.115 MB, Params: 1,401,165 (5.345 MB), Total: 5.46 MB, FLOPs: 242,346,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1625 finished in 0m04s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 1,398,508 (5.335 MB), Total: 5.45 MB, FLOPs: 242,059,900\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1625 finished in 0m04s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 1,395,212 (5.322 MB), Total: 5.44 MB, FLOPs: 241,848,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1625 finished in 0m04s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.115 MB, Params: 1,391,916 (5.310 MB), Total: 5.43 MB, FLOPs: 241,636,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1625 finished in 0m04s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 1,388,107 (5.295 MB), Total: 5.41 MB, FLOPs: 241,533,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1625 finished in 0m04s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 132)]\n",
      "Input: 0.115 MB, Params: 1,386,326 (5.288 MB), Total: 5.40 MB, FLOPs: 241,485,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1625 finished in 0m04s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 1,384,545 (5.282 MB), Total: 5.40 MB, FLOPs: 241,437,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1625 finished in 0m04s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 1,382,764 (5.275 MB), Total: 5.39 MB, FLOPs: 241,390,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1625 finished in 0m04s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 1,380,983 (5.268 MB), Total: 5.38 MB, FLOPs: 241,342,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1625 finished in 0m04s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 1,378,632 (5.259 MB), Total: 5.37 MB, FLOPs: 240,775,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1625 finished in 0m04s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.115 MB, Params: 1,374,859 (5.245 MB), Total: 5.36 MB, FLOPs: 240,673,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1625 finished in 0m04s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 1,373,087 (5.238 MB), Total: 5.35 MB, FLOPs: 240,625,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1625 finished in 0m04s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 213)]\n",
      "Input: 0.115 MB, Params: 1,371,315 (5.231 MB), Total: 5.35 MB, FLOPs: 240,578,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1625 finished in 0m04s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 1,367,560 (5.217 MB), Total: 5.33 MB, FLOPs: 240,476,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1625 finished in 0m04s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 95)]\n",
      "Input: 0.115 MB, Params: 1,365,209 (5.208 MB), Total: 5.32 MB, FLOPs: 239,909,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1625 finished in 0m04s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 87)]\n",
      "Input: 0.115 MB, Params: 1,362,588 (5.198 MB), Total: 5.31 MB, FLOPs: 239,626,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1625 finished in 0m04s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.115 MB, Params: 1,359,328 (5.185 MB), Total: 5.30 MB, FLOPs: 239,416,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1625 finished in 0m04s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 1,355,582 (5.171 MB), Total: 5.29 MB, FLOPs: 239,315,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1625 finished in 0m04s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 1,353,828 (5.164 MB), Total: 5.28 MB, FLOPs: 239,268,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1625 finished in 0m04s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 1,350,091 (5.150 MB), Total: 5.27 MB, FLOPs: 239,167,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1625 finished in 0m04s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 1,348,346 (5.144 MB), Total: 5.26 MB, FLOPs: 239,120,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1625 finished in 0m04s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 1,344,618 (5.129 MB), Total: 5.24 MB, FLOPs: 239,020,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1625 finished in 0m04s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 1,342,882 (5.123 MB), Total: 5.24 MB, FLOPs: 238,973,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1625 finished in 0m04s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 1,339,163 (5.109 MB), Total: 5.22 MB, FLOPs: 238,873,091\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1625 finished in 0m04s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 1,337,436 (5.102 MB), Total: 5.22 MB, FLOPs: 238,826,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1625 finished in 0m04s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 102)]\n",
      "Input: 0.115 MB, Params: 1,334,212 (5.090 MB), Total: 5.20 MB, FLOPs: 238,617,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1625 finished in 0m04s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.115 MB, Params: 1,330,511 (5.075 MB), Total: 5.19 MB, FLOPs: 238,517,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1625 finished in 0m04s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.115 MB, Params: 1,328,793 (5.069 MB), Total: 5.18 MB, FLOPs: 238,471,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1625 finished in 0m04s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 1,327,075 (5.062 MB), Total: 5.18 MB, FLOPs: 238,425,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1625 finished in 0m04s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 231)]\n",
      "Input: 0.115 MB, Params: 1,325,357 (5.056 MB), Total: 5.17 MB, FLOPs: 238,379,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1625 finished in 0m04s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 81)]\n",
      "Input: 0.115 MB, Params: 1,323,798 (5.050 MB), Total: 5.17 MB, FLOPs: 237,629,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1625 finished in 0m04s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 157)]\n",
      "Input: 0.115 MB, Params: 1,321,195 (5.040 MB), Total: 5.16 MB, FLOPs: 237,348,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1625 finished in 0m04s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 1,317,989 (5.028 MB), Total: 5.14 MB, FLOPs: 237,140,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1625 finished in 0m04s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.115 MB, Params: 1,314,783 (5.015 MB), Total: 5.13 MB, FLOPs: 236,933,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1625 finished in 0m04s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.115 MB, Params: 1,313,065 (5.009 MB), Total: 5.12 MB, FLOPs: 236,886,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1625 finished in 0m04s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.115 MB, Params: 1,310,480 (4.999 MB), Total: 5.11 MB, FLOPs: 236,607,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1625 finished in 0m04s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 2)]\n",
      "Input: 0.115 MB, Params: 1,308,165 (4.990 MB), Total: 5.11 MB, FLOPs: 236,048,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1625 finished in 0m04s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.115 MB, Params: 1,305,589 (4.980 MB), Total: 5.10 MB, FLOPs: 235,770,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1625 finished in 0m04s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 160)]\n",
      "Input: 0.115 MB, Params: 1,302,401 (4.968 MB), Total: 5.08 MB, FLOPs: 235,564,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1625 finished in 0m04s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 91)]\n",
      "Input: 0.115 MB, Params: 1,299,213 (4.956 MB), Total: 5.07 MB, FLOPs: 235,358,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1625 finished in 0m04s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.115 MB, Params: 1,297,495 (4.950 MB), Total: 5.06 MB, FLOPs: 235,312,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1625 finished in 0m04s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 1,295,777 (4.943 MB), Total: 5.06 MB, FLOPs: 235,266,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1625 finished in 0m04s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 39)]\n",
      "Input: 0.115 MB, Params: 1,293,471 (4.934 MB), Total: 5.05 MB, FLOPs: 234,707,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1625 finished in 0m04s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 1,291,930 (4.928 MB), Total: 5.04 MB, FLOPs: 233,966,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1625 finished in 0m04s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 107)]\n",
      "Input: 0.115 MB, Params: 1,289,633 (4.920 MB), Total: 5.03 MB, FLOPs: 233,412,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1625 finished in 0m04s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 1,287,093 (4.910 MB), Total: 5.03 MB, FLOPs: 233,138,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1625 finished in 0m04s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.115 MB, Params: 1,283,914 (4.898 MB), Total: 5.01 MB, FLOPs: 232,933,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1625 finished in 0m04s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.115 MB, Params: 1,280,312 (4.884 MB), Total: 5.00 MB, FLOPs: 232,836,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1625 finished in 0m04s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 1,278,603 (4.877 MB), Total: 4.99 MB, FLOPs: 232,790,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1625 finished in 0m04s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 1,276,894 (4.871 MB), Total: 4.99 MB, FLOPs: 232,744,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1625 finished in 0m04s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.115 MB, Params: 1,273,310 (4.857 MB), Total: 4.97 MB, FLOPs: 232,647,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1625 finished in 0m04s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 1,270,149 (4.845 MB), Total: 4.96 MB, FLOPs: 232,443,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1625 finished in 0m04s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 1,266,574 (4.832 MB), Total: 4.95 MB, FLOPs: 232,346,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1625 finished in 0m04s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 1,264,883 (4.825 MB), Total: 4.94 MB, FLOPs: 232,301,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1625 finished in 0m04s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 1,261,731 (4.813 MB), Total: 4.93 MB, FLOPs: 232,097,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1625 finished in 0m04s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 152)]\n",
      "Input: 0.115 MB, Params: 1,258,579 (4.801 MB), Total: 4.92 MB, FLOPs: 231,893,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1625 finished in 0m04s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 1,255,031 (4.788 MB), Total: 4.90 MB, FLOPs: 231,797,249\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1625 finished in 0m04s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 1,253,349 (4.781 MB), Total: 4.90 MB, FLOPs: 231,751,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1625 finished in 0m04s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 1,251,667 (4.775 MB), Total: 4.89 MB, FLOPs: 231,706,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1625 finished in 0m04s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 1,249,985 (4.768 MB), Total: 4.88 MB, FLOPs: 231,661,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1625 finished in 0m04s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 1,248,303 (4.762 MB), Total: 4.88 MB, FLOPs: 231,616,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1625 finished in 0m04s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 1,245,160 (4.750 MB), Total: 4.87 MB, FLOPs: 231,412,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1625 finished in 0m04s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 1,241,657 (4.737 MB), Total: 4.85 MB, FLOPs: 231,317,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1625 finished in 0m04s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 1,239,984 (4.730 MB), Total: 4.85 MB, FLOPs: 231,272,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1625 finished in 0m04s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 1,238,452 (4.724 MB), Total: 4.84 MB, FLOPs: 230,536,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1625 finished in 0m04s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 74)]\n",
      "Input: 0.115 MB, Params: 1,235,318 (4.712 MB), Total: 4.83 MB, FLOPs: 230,332,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1625 finished in 0m04s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 1,231,833 (4.699 MB), Total: 4.81 MB, FLOPs: 230,238,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1625 finished in 0m04s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 1,230,169 (4.693 MB), Total: 4.81 MB, FLOPs: 230,193,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1625 finished in 0m04s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 1,228,505 (4.686 MB), Total: 4.80 MB, FLOPs: 230,149,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1625 finished in 0m04s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.115 MB, Params: 1,226,019 (4.677 MB), Total: 4.79 MB, FLOPs: 229,880,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1625 finished in 0m04s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 1,224,487 (4.671 MB), Total: 4.79 MB, FLOPs: 229,144,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1625 finished in 0m04s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 1,221,020 (4.658 MB), Total: 4.77 MB, FLOPs: 229,050,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1625 finished in 0m04s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.115 MB, Params: 1,218,534 (4.648 MB), Total: 4.76 MB, FLOPs: 228,782,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1625 finished in 0m04s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 111)]\n",
      "Input: 0.115 MB, Params: 1,215,436 (4.637 MB), Total: 4.75 MB, FLOPs: 228,581,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1625 finished in 0m04s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.115 MB, Params: 1,211,978 (4.623 MB), Total: 4.74 MB, FLOPs: 228,487,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1625 finished in 0m04s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 1,208,520 (4.610 MB), Total: 4.73 MB, FLOPs: 228,394,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1625 finished in 0m04s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.115 MB, Params: 1,206,883 (4.604 MB), Total: 4.72 MB, FLOPs: 228,350,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1625 finished in 0m04s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 1,205,246 (4.598 MB), Total: 4.71 MB, FLOPs: 228,306,411\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1625 finished in 0m04s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 1,203,609 (4.591 MB), Total: 4.71 MB, FLOPs: 228,262,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1625 finished in 0m04s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 1,201,132 (4.582 MB), Total: 4.70 MB, FLOPs: 227,994,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1625 finished in 0m04s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 1,198,061 (4.570 MB), Total: 4.69 MB, FLOPs: 227,795,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1625 finished in 0m04s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 1,194,639 (4.557 MB), Total: 4.67 MB, FLOPs: 227,702,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1625 finished in 0m04s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.115 MB, Params: 1,193,011 (4.551 MB), Total: 4.67 MB, FLOPs: 227,659,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1625 finished in 0m04s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.115 MB, Params: 1,190,543 (4.542 MB), Total: 4.66 MB, FLOPs: 227,392,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1625 finished in 0m04s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 1,188,309 (4.533 MB), Total: 4.65 MB, FLOPs: 226,851,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1625 finished in 0m04s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 113)]\n",
      "Input: 0.115 MB, Params: 1,185,850 (4.524 MB), Total: 4.64 MB, FLOPs: 226,586,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1625 finished in 0m04s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 115)]\n",
      "Input: 0.115 MB, Params: 1,182,806 (4.512 MB), Total: 4.63 MB, FLOPs: 226,388,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1625 finished in 0m04s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.115 MB, Params: 1,179,402 (4.499 MB), Total: 4.61 MB, FLOPs: 226,297,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1625 finished in 0m04s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 1,177,783 (4.493 MB), Total: 4.61 MB, FLOPs: 226,253,441\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1625 finished in 0m04s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 111)]\n",
      "Input: 0.115 MB, Params: 1,175,333 (4.484 MB), Total: 4.60 MB, FLOPs: 225,988,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1625 finished in 0m04s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 205)]\n",
      "Input: 0.115 MB, Params: 1,173,714 (4.477 MB), Total: 4.59 MB, FLOPs: 225,945,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1625 finished in 0m04s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.115 MB, Params: 1,171,264 (4.468 MB), Total: 4.58 MB, FLOPs: 225,680,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1625 finished in 0m04s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 112)]\n",
      "Input: 0.115 MB, Params: 1,168,814 (4.459 MB), Total: 4.57 MB, FLOPs: 225,416,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1625 finished in 0m04s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 62)]\n",
      "Input: 0.115 MB, Params: 1,167,291 (4.453 MB), Total: 4.57 MB, FLOPs: 224,684,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1625 finished in 0m04s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 1,165,672 (4.447 MB), Total: 4.56 MB, FLOPs: 224,640,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1625 finished in 0m04s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 95)]\n",
      "Input: 0.115 MB, Params: 1,163,483 (4.438 MB), Total: 4.55 MB, FLOPs: 224,108,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1625 finished in 0m04s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.115 MB, Params: 1,160,475 (4.427 MB), Total: 4.54 MB, FLOPs: 223,913,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1625 finished in 0m04s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 1,157,107 (4.414 MB), Total: 4.53 MB, FLOPs: 223,822,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1625 finished in 0m04s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 127)]\n",
      "Input: 0.115 MB, Params: 1,154,675 (4.405 MB), Total: 4.52 MB, FLOPs: 223,560,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1625 finished in 0m04s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.115 MB, Params: 1,151,685 (4.393 MB), Total: 4.51 MB, FLOPs: 223,367,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1625 finished in 0m04s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 1,150,075 (4.387 MB), Total: 4.50 MB, FLOPs: 223,323,921\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1625 finished in 0m04s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 1,146,725 (4.374 MB), Total: 4.49 MB, FLOPs: 223,233,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1625 finished in 0m04s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.115 MB, Params: 1,145,124 (4.368 MB), Total: 4.48 MB, FLOPs: 223,190,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1625 finished in 0m04s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 1,143,523 (4.362 MB), Total: 4.48 MB, FLOPs: 223,147,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1625 finished in 0m04s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.115 MB, Params: 1,140,542 (4.351 MB), Total: 4.47 MB, FLOPs: 222,954,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1625 finished in 0m04s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 1,137,219 (4.338 MB), Total: 4.45 MB, FLOPs: 222,864,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1625 finished in 0m04s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.115 MB, Params: 1,134,805 (4.329 MB), Total: 4.44 MB, FLOPs: 222,604,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1625 finished in 0m04s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 1,131,842 (4.318 MB), Total: 4.43 MB, FLOPs: 222,412,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1625 finished in 0m04s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 71)]\n",
      "Input: 0.115 MB, Params: 1,129,671 (4.309 MB), Total: 4.42 MB, FLOPs: 221,881,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1625 finished in 0m04s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.115 MB, Params: 1,126,357 (4.297 MB), Total: 4.41 MB, FLOPs: 221,792,397\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1625 finished in 0m04s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 1,124,774 (4.291 MB), Total: 4.41 MB, FLOPs: 221,749,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1625 finished in 0m04s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 1,123,191 (4.285 MB), Total: 4.40 MB, FLOPs: 221,707,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1625 finished in 0m04s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 1,119,895 (4.272 MB), Total: 4.39 MB, FLOPs: 221,618,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1625 finished in 0m04s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 1,118,390 (4.266 MB), Total: 4.38 MB, FLOPs: 220,894,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1625 finished in 0m04s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.115 MB, Params: 1,116,816 (4.260 MB), Total: 4.38 MB, FLOPs: 220,852,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1625 finished in 0m04s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.115 MB, Params: 1,113,871 (4.249 MB), Total: 4.36 MB, FLOPs: 220,661,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1625 finished in 0m04s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 1,110,593 (4.237 MB), Total: 4.35 MB, FLOPs: 220,572,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1625 finished in 0m04s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 1,109,028 (4.231 MB), Total: 4.35 MB, FLOPs: 220,530,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1625 finished in 0m04s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 1,106,866 (4.222 MB), Total: 4.34 MB, FLOPs: 220,004,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1625 finished in 0m04s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.115 MB, Params: 1,103,597 (4.210 MB), Total: 4.33 MB, FLOPs: 219,916,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1625 finished in 0m04s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 1,102,041 (4.204 MB), Total: 4.32 MB, FLOPs: 219,874,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1625 finished in 0m04s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 137)]\n",
      "Input: 0.115 MB, Params: 1,099,114 (4.193 MB), Total: 4.31 MB, FLOPs: 219,683,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1625 finished in 0m04s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 120)]\n",
      "Input: 0.115 MB, Params: 1,096,745 (4.184 MB), Total: 4.30 MB, FLOPs: 219,427,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1625 finished in 0m04s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 1,095,249 (4.178 MB), Total: 4.29 MB, FLOPs: 218,708,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1625 finished in 0m04s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 1,091,998 (4.166 MB), Total: 4.28 MB, FLOPs: 218,621,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1625 finished in 0m04s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,090,451 (4.160 MB), Total: 4.28 MB, FLOPs: 218,579,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1625 finished in 0m04s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 1,088,082 (4.151 MB), Total: 4.27 MB, FLOPs: 218,323,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1625 finished in 0m04s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.115 MB, Params: 1,086,586 (4.145 MB), Total: 4.26 MB, FLOPs: 217,604,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1625 finished in 0m04s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 1,083,686 (4.134 MB), Total: 4.25 MB, FLOPs: 217,416,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1625 finished in 0m04s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 1,080,453 (4.122 MB), Total: 4.24 MB, FLOPs: 217,328,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1625 finished in 0m04s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 1,077,220 (4.109 MB), Total: 4.22 MB, FLOPs: 217,241,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1625 finished in 0m04s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.115 MB, Params: 1,075,691 (4.103 MB), Total: 4.22 MB, FLOPs: 217,200,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1625 finished in 0m04s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 1,074,162 (4.098 MB), Total: 4.21 MB, FLOPs: 217,159,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1625 finished in 0m04s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.115 MB, Params: 1,070,947 (4.085 MB), Total: 4.20 MB, FLOPs: 217,072,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1625 finished in 0m04s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 1,069,427 (4.080 MB), Total: 4.19 MB, FLOPs: 217,031,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1625 finished in 0m04s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 1,067,067 (4.071 MB), Total: 4.19 MB, FLOPs: 216,776,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1625 finished in 0m04s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 1,065,547 (4.065 MB), Total: 4.18 MB, FLOPs: 216,735,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1625 finished in 0m04s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,064,027 (4.059 MB), Total: 4.17 MB, FLOPs: 216,694,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1625 finished in 0m04s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 146)]\n",
      "Input: 0.115 MB, Params: 1,061,667 (4.050 MB), Total: 4.17 MB, FLOPs: 216,440,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1625 finished in 0m04s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.115 MB, Params: 1,058,479 (4.038 MB), Total: 4.15 MB, FLOPs: 216,354,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1625 finished in 0m04s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.115 MB, Params: 1,056,968 (4.032 MB), Total: 4.15 MB, FLOPs: 216,313,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1625 finished in 0m04s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.115 MB, Params: 1,055,472 (4.026 MB), Total: 4.14 MB, FLOPs: 215,594,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1625 finished in 0m04s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 1,053,976 (4.021 MB), Total: 4.14 MB, FLOPs: 214,875,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1625 finished in 0m04s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 81)]\n",
      "Input: 0.115 MB, Params: 1,051,886 (4.013 MB), Total: 4.13 MB, FLOPs: 214,370,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1625 finished in 0m04s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 1,049,040 (4.002 MB), Total: 4.12 MB, FLOPs: 214,184,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1625 finished in 0m04s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.115 MB, Params: 1,045,870 (3.990 MB), Total: 4.10 MB, FLOPs: 214,099,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1625 finished in 0m04s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.115 MB, Params: 1,044,368 (3.984 MB), Total: 4.10 MB, FLOPs: 214,058,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1625 finished in 0m04s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 1,042,866 (3.978 MB), Total: 4.09 MB, FLOPs: 214,018,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1625 finished in 0m04s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 1,039,714 (3.966 MB), Total: 4.08 MB, FLOPs: 213,933,207\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1625 finished in 0m04s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 1,038,221 (3.960 MB), Total: 4.08 MB, FLOPs: 213,893,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1625 finished in 0m04s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 1,036,728 (3.955 MB), Total: 4.07 MB, FLOPs: 213,852,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1625 finished in 0m04s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 1,033,900 (3.944 MB), Total: 4.06 MB, FLOPs: 213,667,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1625 finished in 0m04s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 1,030,775 (3.932 MB), Total: 4.05 MB, FLOPs: 213,583,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1625 finished in 0m04s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 1,029,291 (3.926 MB), Total: 4.04 MB, FLOPs: 213,543,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1625 finished in 0m04s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 1,026,472 (3.916 MB), Total: 4.03 MB, FLOPs: 213,358,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1625 finished in 0m04s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.115 MB, Params: 1,024,148 (3.907 MB), Total: 4.02 MB, FLOPs: 213,107,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1625 finished in 0m04s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 1,021,338 (3.896 MB), Total: 4.01 MB, FLOPs: 212,923,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1625 finished in 0m04s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 1,019,023 (3.887 MB), Total: 4.00 MB, FLOPs: 212,673,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1625 finished in 0m04s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 127)]\n",
      "Input: 0.115 MB, Params: 1,017,539 (3.882 MB), Total: 4.00 MB, FLOPs: 212,633,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1625 finished in 0m04s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 1,014,450 (3.870 MB), Total: 3.99 MB, FLOPs: 212,550,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1625 finished in 0m04s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.115 MB, Params: 1,012,975 (3.864 MB), Total: 3.98 MB, FLOPs: 212,510,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1625 finished in 0m04s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,011,500 (3.859 MB), Total: 3.97 MB, FLOPs: 212,471,214\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1625 finished in 0m04s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 1,010,025 (3.853 MB), Total: 3.97 MB, FLOPs: 212,431,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1625 finished in 0m04s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 1,006,963 (3.841 MB), Total: 3.96 MB, FLOPs: 212,348,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1625 finished in 0m04s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,005,497 (3.836 MB), Total: 3.95 MB, FLOPs: 212,309,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1625 finished in 0m04s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,004,031 (3.830 MB), Total: 3.95 MB, FLOPs: 212,270,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1625 finished in 0m04s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.115 MB, Params: 1,002,544 (3.824 MB), Total: 3.94 MB, FLOPs: 211,555,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1625 finished in 0m04s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 1,000,229 (3.816 MB), Total: 3.93 MB, FLOPs: 211,305,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1625 finished in 0m04s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 998,763 (3.810 MB), Total: 3.93 MB, FLOPs: 211,265,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1625 finished in 0m04s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 995,728 (3.798 MB), Total: 3.91 MB, FLOPs: 211,183,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1625 finished in 0m04s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 145)]\n",
      "Input: 0.115 MB, Params: 994,271 (3.793 MB), Total: 3.91 MB, FLOPs: 211,144,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1625 finished in 0m04s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 34)]\n",
      "Input: 0.115 MB, Params: 992,217 (3.785 MB), Total: 3.90 MB, FLOPs: 210,647,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1625 finished in 0m04s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 111)]\n",
      "Input: 0.115 MB, Params: 989,911 (3.776 MB), Total: 3.89 MB, FLOPs: 210,398,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1625 finished in 0m04s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.115 MB, Params: 988,433 (3.771 MB), Total: 3.89 MB, FLOPs: 209,687,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1625 finished in 0m04s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.115 MB, Params: 986,397 (3.763 MB), Total: 3.88 MB, FLOPs: 209,195,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.538%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1625 finished in 0m04s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 984,940 (3.757 MB), Total: 3.87 MB, FLOPs: 209,155,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1625 finished in 0m04s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 59)]\n",
      "Input: 0.115 MB, Params: 983,471 (3.752 MB), Total: 3.87 MB, FLOPs: 208,449,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1625 finished in 0m04s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.115 MB, Params: 981,444 (3.744 MB), Total: 3.86 MB, FLOPs: 207,961,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.115 MB, Params: 978,688 (3.733 MB), Total: 3.85 MB, FLOPs: 207,781,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.115 MB, Params: 975,680 (3.722 MB), Total: 3.84 MB, FLOPs: 207,700,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 974,232 (3.716 MB), Total: 3.83 MB, FLOPs: 207,661,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 971,485 (3.706 MB), Total: 3.82 MB, FLOPs: 207,481,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 968,495 (3.695 MB), Total: 3.81 MB, FLOPs: 207,400,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 967,056 (3.689 MB), Total: 3.80 MB, FLOPs: 207,361,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 35)]\n",
      "Input: 0.115 MB, Params: 965,596 (3.683 MB), Total: 3.80 MB, FLOPs: 206,660,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 95)]\n",
      "Input: 0.115 MB, Params: 963,578 (3.676 MB), Total: 3.79 MB, FLOPs: 206,176,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.115 MB, Params: 961,317 (3.667 MB), Total: 3.78 MB, FLOPs: 205,932,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 958,588 (3.657 MB), Total: 3.77 MB, FLOPs: 205,753,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 955,616 (3.645 MB), Total: 3.76 MB, FLOPs: 205,673,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 954,186 (3.640 MB), Total: 3.76 MB, FLOPs: 205,634,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 951,934 (3.631 MB), Total: 3.75 MB, FLOPs: 205,391,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 120)]\n",
      "Input: 0.115 MB, Params: 949,223 (3.621 MB), Total: 3.74 MB, FLOPs: 205,213,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 946,269 (3.610 MB), Total: 3.73 MB, FLOPs: 205,134,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.115 MB, Params: 944,848 (3.604 MB), Total: 3.72 MB, FLOPs: 205,095,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 943,427 (3.599 MB), Total: 3.71 MB, FLOPs: 205,057,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 940,491 (3.588 MB), Total: 3.70 MB, FLOPs: 204,978,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 131)]\n",
      "Input: 0.115 MB, Params: 937,555 (3.576 MB), Total: 3.69 MB, FLOPs: 204,899,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 936,152 (3.571 MB), Total: 3.69 MB, FLOPs: 204,861,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 934,749 (3.566 MB), Total: 3.68 MB, FLOPs: 204,823,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.115 MB, Params: 933,298 (3.560 MB), Total: 3.68 MB, FLOPs: 204,126,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 930,614 (3.550 MB), Total: 3.67 MB, FLOPs: 203,949,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.115 MB, Params: 928,380 (3.541 MB), Total: 3.66 MB, FLOPs: 203,708,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 49)]\n",
      "Input: 0.115 MB, Params: 927,172 (3.537 MB), Total: 3.65 MB, FLOPs: 202,383,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 924,938 (3.528 MB), Total: 3.64 MB, FLOPs: 202,142,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 46)]\n",
      "Input: 0.115 MB, Params: 922,965 (3.521 MB), Total: 3.64 MB, FLOPs: 201,667,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 920,740 (3.512 MB), Total: 3.63 MB, FLOPs: 201,426,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 918,083 (3.502 MB), Total: 3.62 MB, FLOPs: 201,252,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 915,426 (3.492 MB), Total: 3.61 MB, FLOPs: 201,079,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 47)]\n",
      "Input: 0.115 MB, Params: 912,769 (3.482 MB), Total: 3.60 MB, FLOPs: 200,905,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 909,887 (3.471 MB), Total: 3.59 MB, FLOPs: 200,827,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 0)]\n",
      "Input: 0.115 MB, Params: 909,845 (3.471 MB), Total: 3.59 MB, FLOPs: 193,173,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.115 MB, Params: 908,637 (3.466 MB), Total: 3.58 MB, FLOPs: 191,913,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 905,755 (3.455 MB), Total: 3.57 MB, FLOPs: 191,835,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 904,370 (3.450 MB), Total: 3.57 MB, FLOPs: 191,798,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 902,985 (3.445 MB), Total: 3.56 MB, FLOPs: 191,761,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 900,787 (3.436 MB), Total: 3.55 MB, FLOPs: 191,523,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 898,157 (3.426 MB), Total: 3.54 MB, FLOPs: 191,351,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.115 MB, Params: 895,302 (3.415 MB), Total: 3.53 MB, FLOPs: 191,274,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 892,681 (3.405 MB), Total: 3.52 MB, FLOPs: 191,102,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 889,835 (3.394 MB), Total: 3.51 MB, FLOPs: 191,025,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.115 MB, Params: 887,880 (3.387 MB), Total: 3.50 MB, FLOPs: 190,577,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.115 MB, Params: 885,925 (3.380 MB), Total: 3.49 MB, FLOPs: 190,129,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 125)]\n",
      "Input: 0.115 MB, Params: 883,313 (3.370 MB), Total: 3.48 MB, FLOPs: 189,957,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 46)]\n",
      "Input: 0.115 MB, Params: 882,573 (3.367 MB), Total: 3.48 MB, FLOPs: 188,572,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 22)]\n",
      "Input: 0.115 MB, Params: 880,618 (3.359 MB), Total: 3.47 MB, FLOPs: 188,124,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 879,251 (3.354 MB), Total: 3.47 MB, FLOPs: 188,087,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 877,296 (3.347 MB), Total: 3.46 MB, FLOPs: 187,640,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 874,468 (3.336 MB), Total: 3.45 MB, FLOPs: 187,563,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 873,110 (3.331 MB), Total: 3.45 MB, FLOPs: 187,527,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 870,507 (3.321 MB), Total: 3.44 MB, FLOPs: 187,355,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 867,697 (3.310 MB), Total: 3.43 MB, FLOPs: 187,279,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 866,348 (3.305 MB), Total: 3.42 MB, FLOPs: 187,243,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.115 MB, Params: 864,960 (3.300 MB), Total: 3.41 MB, FLOPs: 186,627,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.115 MB, Params: 862,366 (3.290 MB), Total: 3.40 MB, FLOPs: 186,456,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.115 MB, Params: 859,574 (3.279 MB), Total: 3.39 MB, FLOPs: 186,380,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 858,234 (3.274 MB), Total: 3.39 MB, FLOPs: 186,344,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 855,451 (3.263 MB), Total: 3.38 MB, FLOPs: 186,269,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 854,120 (3.258 MB), Total: 3.37 MB, FLOPs: 186,233,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 131)]\n",
      "Input: 0.115 MB, Params: 851,346 (3.248 MB), Total: 3.36 MB, FLOPs: 186,158,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 850,024 (3.243 MB), Total: 3.36 MB, FLOPs: 186,123,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 848,702 (3.238 MB), Total: 3.35 MB, FLOPs: 186,087,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 845,946 (3.227 MB), Total: 3.34 MB, FLOPs: 186,013,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.115 MB, Params: 844,633 (3.222 MB), Total: 3.34 MB, FLOPs: 185,978,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 843,320 (3.217 MB), Total: 3.33 MB, FLOPs: 185,942,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 842,007 (3.212 MB), Total: 3.33 MB, FLOPs: 185,907,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 839,278 (3.202 MB), Total: 3.32 MB, FLOPs: 185,833,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 837,161 (3.194 MB), Total: 3.31 MB, FLOPs: 185,605,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 835,773 (3.188 MB), Total: 3.30 MB, FLOPs: 184,989,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 833,656 (3.180 MB), Total: 3.30 MB, FLOPs: 184,760,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 831,125 (3.170 MB), Total: 3.29 MB, FLOPs: 184,592,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 829,821 (3.166 MB), Total: 3.28 MB, FLOPs: 184,557,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.115 MB, Params: 827,713 (3.157 MB), Total: 3.27 MB, FLOPs: 184,329,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 825,191 (3.148 MB), Total: 3.26 MB, FLOPs: 184,162,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 822,669 (3.138 MB), Total: 3.25 MB, FLOPs: 183,995,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 11)]\n",
      "Input: 0.115 MB, Params: 821,488 (3.134 MB), Total: 3.25 MB, FLOPs: 182,759,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.115 MB, Params: 819,398 (3.126 MB), Total: 3.24 MB, FLOPs: 182,534,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 52)]\n",
      "Input: 0.115 MB, Params: 818,667 (3.123 MB), Total: 3.24 MB, FLOPs: 181,165,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 815,974 (3.113 MB), Total: 3.23 MB, FLOPs: 181,092,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 814,679 (3.108 MB), Total: 3.22 MB, FLOPs: 181,057,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.115 MB, Params: 812,589 (3.100 MB), Total: 3.22 MB, FLOPs: 180,832,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.115 MB, Params: 810,094 (3.090 MB), Total: 3.21 MB, FLOPs: 180,667,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 807,419 (3.080 MB), Total: 3.20 MB, FLOPs: 180,594,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 806,133 (3.075 MB), Total: 3.19 MB, FLOPs: 180,560,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 803,647 (3.066 MB), Total: 3.18 MB, FLOPs: 180,395,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 800,990 (3.056 MB), Total: 3.17 MB, FLOPs: 180,323,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 799,713 (3.051 MB), Total: 3.17 MB, FLOPs: 180,289,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 798,436 (3.046 MB), Total: 3.16 MB, FLOPs: 180,254,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 797,159 (3.041 MB), Total: 3.16 MB, FLOPs: 180,220,595\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 795,882 (3.036 MB), Total: 3.15 MB, FLOPs: 180,186,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 794,605 (3.031 MB), Total: 3.15 MB, FLOPs: 180,151,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 792,533 (3.023 MB), Total: 3.14 MB, FLOPs: 179,928,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 790,065 (3.014 MB), Total: 3.13 MB, FLOPs: 179,764,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 787,462 (3.004 MB), Total: 3.12 MB, FLOPs: 179,694,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.115 MB, Params: 785,579 (2.997 MB), Total: 3.11 MB, FLOPs: 179,260,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 120)]\n",
      "Input: 0.115 MB, Params: 783,525 (2.989 MB), Total: 3.10 MB, FLOPs: 179,038,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 127)]\n",
      "Input: 0.115 MB, Params: 781,075 (2.980 MB), Total: 3.09 MB, FLOPs: 178,876,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 778,481 (2.970 MB), Total: 3.08 MB, FLOPs: 178,806,135\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 777,222 (2.965 MB), Total: 3.08 MB, FLOPs: 178,772,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.115 MB, Params: 775,852 (2.960 MB), Total: 3.07 MB, FLOPs: 178,164,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.115 MB, Params: 773,411 (2.950 MB), Total: 3.07 MB, FLOPs: 178,002,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 770,835 (2.941 MB), Total: 3.06 MB, FLOPs: 177,932,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.115 MB, Params: 768,259 (2.931 MB), Total: 3.05 MB, FLOPs: 177,863,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.115 MB, Params: 765,683 (2.921 MB), Total: 3.04 MB, FLOPs: 177,793,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.115 MB, Params: 764,451 (2.916 MB), Total: 3.03 MB, FLOPs: 177,760,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 763,219 (2.911 MB), Total: 3.03 MB, FLOPs: 177,727,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 51)]\n",
      "Input: 0.115 MB, Params: 762,056 (2.907 MB), Total: 3.02 MB, FLOPs: 176,512,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.115 MB, Params: 760,191 (2.900 MB), Total: 3.02 MB, FLOPs: 176,083,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.115 MB, Params: 757,777 (2.891 MB), Total: 3.01 MB, FLOPs: 175,922,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 4)]\n",
      "Input: 0.115 MB, Params: 757,735 (2.891 MB), Total: 3.01 MB, FLOPs: 175,567,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 755,321 (2.881 MB), Total: 3.00 MB, FLOPs: 175,405,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 37)]\n",
      "Input: 0.115 MB, Params: 754,599 (2.879 MB), Total: 2.99 MB, FLOPs: 174,053,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 18)]\n",
      "Input: 0.115 MB, Params: 754,557 (2.878 MB), Total: 2.99 MB, FLOPs: 170,821,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 130)]\n",
      "Input: 0.115 MB, Params: 752,548 (2.871 MB), Total: 2.99 MB, FLOPs: 170,604,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 751,316 (2.866 MB), Total: 2.98 MB, FLOPs: 170,571,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 748,911 (2.857 MB), Total: 2.97 MB, FLOPs: 170,410,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.115 MB, Params: 747,679 (2.852 MB), Total: 2.97 MB, FLOPs: 170,377,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.115 MB, Params: 745,679 (2.845 MB), Total: 2.96 MB, FLOPs: 170,161,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 744,447 (2.840 MB), Total: 2.96 MB, FLOPs: 170,128,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 61)]\n",
      "Input: 0.115 MB, Params: 743,095 (2.835 MB), Total: 2.95 MB, FLOPs: 169,528,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 740,591 (2.825 MB), Total: 2.94 MB, FLOPs: 169,461,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 739,368 (2.820 MB), Total: 2.94 MB, FLOPs: 169,428,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 123)]\n",
      "Input: 0.115 MB, Params: 737,368 (2.813 MB), Total: 2.93 MB, FLOPs: 169,212,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 34)]\n",
      "Input: 0.115 MB, Params: 736,646 (2.810 MB), Total: 2.93 MB, FLOPs: 167,914,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 36)]\n",
      "Input: 0.115 MB, Params: 735,510 (2.806 MB), Total: 2.92 MB, FLOPs: 166,772,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 89)]\n",
      "Input: 0.115 MB, Params: 733,681 (2.799 MB), Total: 2.91 MB, FLOPs: 166,350,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 731,186 (2.789 MB), Total: 2.90 MB, FLOPs: 166,283,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 728,817 (2.780 MB), Total: 2.90 MB, FLOPs: 166,125,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 726,331 (2.771 MB), Total: 2.89 MB, FLOPs: 166,058,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 725,126 (2.766 MB), Total: 2.88 MB, FLOPs: 166,025,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 723,921 (2.762 MB), Total: 2.88 MB, FLOPs: 165,993,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.115 MB, Params: 722,092 (2.755 MB), Total: 2.87 MB, FLOPs: 165,571,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.115 MB, Params: 719,624 (2.745 MB), Total: 2.86 MB, FLOPs: 165,505,033\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 718,428 (2.741 MB), Total: 2.86 MB, FLOPs: 165,472,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 717,232 (2.736 MB), Total: 2.85 MB, FLOPs: 165,440,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 716,036 (2.731 MB), Total: 2.85 MB, FLOPs: 165,408,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 713,595 (2.722 MB), Total: 2.84 MB, FLOPs: 165,342,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.115 MB, Params: 712,408 (2.718 MB), Total: 2.83 MB, FLOPs: 165,310,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.115 MB, Params: 710,579 (2.711 MB), Total: 2.83 MB, FLOPs: 164,888,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.115 MB, Params: 708,237 (2.702 MB), Total: 2.82 MB, FLOPs: 164,731,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 705,814 (2.692 MB), Total: 2.81 MB, FLOPs: 164,666,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.115 MB, Params: 704,636 (2.688 MB), Total: 2.80 MB, FLOPs: 164,634,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 703,458 (2.683 MB), Total: 2.80 MB, FLOPs: 164,602,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 701,503 (2.676 MB), Total: 2.79 MB, FLOPs: 164,391,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.115 MB, Params: 699,179 (2.667 MB), Total: 2.78 MB, FLOPs: 164,235,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 80)]\n",
      "Input: 0.115 MB, Params: 697,359 (2.660 MB), Total: 2.78 MB, FLOPs: 163,814,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 696,181 (2.656 MB), Total: 2.77 MB, FLOPs: 163,782,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 693,794 (2.647 MB), Total: 2.76 MB, FLOPs: 163,718,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 691,479 (2.638 MB), Total: 2.75 MB, FLOPs: 163,562,403\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 689,101 (2.629 MB), Total: 2.74 MB, FLOPs: 163,498,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 687,794 (2.624 MB), Total: 2.74 MB, FLOPs: 162,918,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 66)]\n",
      "Input: 0.115 MB, Params: 685,983 (2.617 MB), Total: 2.73 MB, FLOPs: 162,501,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.115 MB, Params: 684,064 (2.609 MB), Total: 2.72 MB, FLOPs: 162,294,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 681,686 (2.600 MB), Total: 2.72 MB, FLOPs: 162,230,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 680,535 (2.596 MB), Total: 2.71 MB, FLOPs: 162,199,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 679,237 (2.591 MB), Total: 2.71 MB, FLOPs: 161,623,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 678,086 (2.587 MB), Total: 2.70 MB, FLOPs: 161,592,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 675,798 (2.578 MB), Total: 2.69 MB, FLOPs: 161,437,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 673,447 (2.569 MB), Total: 2.68 MB, FLOPs: 161,374,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 671,096 (2.560 MB), Total: 2.68 MB, FLOPs: 161,310,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.115 MB, Params: 668,826 (2.551 MB), Total: 2.67 MB, FLOPs: 161,156,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 666,484 (2.542 MB), Total: 2.66 MB, FLOPs: 161,093,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.115 MB, Params: 665,360 (2.538 MB), Total: 2.65 MB, FLOPs: 161,063,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.115 MB, Params: 663,567 (2.531 MB), Total: 2.65 MB, FLOPs: 160,651,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.115 MB, Params: 662,278 (2.526 MB), Total: 2.64 MB, FLOPs: 160,079,547\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 69)]\n",
      "Input: 0.115 MB, Params: 660,494 (2.520 MB), Total: 2.63 MB, FLOPs: 159,671,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 659,370 (2.515 MB), Total: 2.63 MB, FLOPs: 159,641,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 657,046 (2.506 MB), Total: 2.62 MB, FLOPs: 159,578,591\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 655,163 (2.499 MB), Total: 2.61 MB, FLOPs: 159,375,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 652,920 (2.491 MB), Total: 2.61 MB, FLOPs: 159,222,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 650,605 (2.482 MB), Total: 2.60 MB, FLOPs: 159,160,280\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 648,290 (2.473 MB), Total: 2.59 MB, FLOPs: 159,097,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.115 MB, Params: 647,193 (2.469 MB), Total: 2.58 MB, FLOPs: 159,068,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.115 MB, Params: 644,887 (2.460 MB), Total: 2.58 MB, FLOPs: 159,006,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 643,799 (2.456 MB), Total: 2.57 MB, FLOPs: 158,976,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 642,711 (2.452 MB), Total: 2.57 MB, FLOPs: 158,947,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 640,495 (2.443 MB), Total: 2.56 MB, FLOPs: 158,795,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.115 MB, Params: 638,630 (2.436 MB), Total: 2.55 MB, FLOPs: 158,594,483\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 105)]\n",
      "Input: 0.115 MB, Params: 636,423 (2.428 MB), Total: 2.54 MB, FLOPs: 158,443,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 19)]\n",
      "Input: 0.115 MB, Params: 634,657 (2.421 MB), Total: 2.54 MB, FLOPs: 158,037,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 632,387 (2.412 MB), Total: 2.53 MB, FLOPs: 157,976,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.115 MB, Params: 631,278 (2.408 MB), Total: 2.52 MB, FLOPs: 156,846,560\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 630,199 (2.404 MB), Total: 2.52 MB, FLOPs: 156,817,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1184/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1184\n",
      "\n",
      "Iteration 1185 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 628,001 (2.396 MB), Total: 2.51 MB, FLOPs: 156,666,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1185/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1185\n",
      "\n",
      "Iteration 1186 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 625,749 (2.387 MB), Total: 2.50 MB, FLOPs: 156,606,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1186/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1186\n",
      "\n",
      "Iteration 1187 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 623,911 (2.380 MB), Total: 2.50 MB, FLOPs: 156,407,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1187/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1187\n",
      "\n",
      "Iteration 1188 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 621,731 (2.372 MB), Total: 2.49 MB, FLOPs: 156,258,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1188/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1188\n",
      "\n",
      "Iteration 1189 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 619,488 (2.363 MB), Total: 2.48 MB, FLOPs: 156,197,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1189/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1189\n",
      "\n",
      "Iteration 1190 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 618,427 (2.359 MB), Total: 2.47 MB, FLOPs: 156,169,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1190/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1190\n",
      "\n",
      "Iteration 1191 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.115 MB, Params: 617,366 (2.355 MB), Total: 2.47 MB, FLOPs: 156,140,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1191/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1191\n",
      "\n",
      "Iteration 1192 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 616,305 (2.351 MB), Total: 2.47 MB, FLOPs: 156,112,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1192/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1192\n",
      "\n",
      "Iteration 1193 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.115 MB, Params: 614,548 (2.344 MB), Total: 2.46 MB, FLOPs: 155,707,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1193/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1193\n",
      "\n",
      "Iteration 1194 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 612,728 (2.337 MB), Total: 2.45 MB, FLOPs: 155,510,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1194/1625 finished in 0m04s\n",
      "Total channels prunned so far: 1194\n",
      "\n",
      "Iteration 1195 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 612,686 (2.337 MB), Total: 2.45 MB, FLOPs: 155,155,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1195/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1195\n",
      "\n",
      "Iteration 1196 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 611,625 (2.333 MB), Total: 2.45 MB, FLOPs: 155,127,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1196/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1196\n",
      "\n",
      "Iteration 1197 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 609,463 (2.325 MB), Total: 2.44 MB, FLOPs: 154,979,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1197/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1197\n",
      "\n",
      "Iteration 1198 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 607,265 (2.317 MB), Total: 2.43 MB, FLOPs: 154,919,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1198/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1198\n",
      "\n",
      "Iteration 1199 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 605,112 (2.308 MB), Total: 2.42 MB, FLOPs: 154,771,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1199/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1199\n",
      "\n",
      "Iteration 1200 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 603,310 (2.301 MB), Total: 2.42 MB, FLOPs: 154,577,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1200/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1200\n",
      "\n",
      "Iteration 1201 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.115 MB, Params: 601,166 (2.293 MB), Total: 2.41 MB, FLOPs: 154,430,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1201/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1201\n",
      "\n",
      "Iteration 1202 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 598,986 (2.285 MB), Total: 2.40 MB, FLOPs: 154,371,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1202/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1202\n",
      "\n",
      "Iteration 1203 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.115 MB, Params: 596,851 (2.277 MB), Total: 2.39 MB, FLOPs: 154,224,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1203/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1203\n",
      "\n",
      "Iteration 1204 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 595,067 (2.270 MB), Total: 2.39 MB, FLOPs: 154,032,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1204/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1204\n",
      "\n",
      "Iteration 1205 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 592,941 (2.262 MB), Total: 2.38 MB, FLOPs: 153,886,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1205/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1205\n",
      "\n",
      "Iteration 1206 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.115 MB, Params: 591,688 (2.257 MB), Total: 2.37 MB, FLOPs: 153,330,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1206/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1206\n",
      "\n",
      "Iteration 1207 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 589,526 (2.249 MB), Total: 2.36 MB, FLOPs: 153,272,153\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1207/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1207\n",
      "\n",
      "Iteration 1208 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 41)]\n",
      "Input: 0.115 MB, Params: 589,484 (2.249 MB), Total: 2.36 MB, FLOPs: 140,815,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1208/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1208\n",
      "\n",
      "Iteration 1209 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 587,709 (2.242 MB), Total: 2.36 MB, FLOPs: 140,656,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1209/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1209\n",
      "\n",
      "Iteration 1210 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 586,675 (2.238 MB), Total: 2.35 MB, FLOPs: 140,637,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1210/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1210\n",
      "\n",
      "Iteration 1211 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 84)]\n",
      "Input: 0.115 MB, Params: 584,900 (2.231 MB), Total: 2.35 MB, FLOPs: 140,478,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1211/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1211\n",
      "\n",
      "Iteration 1212 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.115 MB, Params: 582,801 (2.223 MB), Total: 2.34 MB, FLOPs: 140,363,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1212/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1212\n",
      "\n",
      "Iteration 1213 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.115 MB, Params: 581,098 (2.217 MB), Total: 2.33 MB, FLOPs: 140,009,561\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1213/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1213\n",
      "\n",
      "Iteration 1214 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 579,341 (2.210 MB), Total: 2.33 MB, FLOPs: 139,851,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1214/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1214\n",
      "\n",
      "Iteration 1215 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 88)]\n",
      "Input: 0.115 MB, Params: 577,251 (2.202 MB), Total: 2.32 MB, FLOPs: 139,737,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1215/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1215\n",
      "\n",
      "Iteration 1216 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 575,116 (2.194 MB), Total: 2.31 MB, FLOPs: 139,698,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1216/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1216\n",
      "\n",
      "Iteration 1217 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.115 MB, Params: 574,091 (2.190 MB), Total: 2.31 MB, FLOPs: 139,680,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1217/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1217\n",
      "\n",
      "Iteration 1218 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 26)]\n",
      "Input: 0.115 MB, Params: 573,387 (2.187 MB), Total: 2.30 MB, FLOPs: 138,467,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1218/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1218\n",
      "\n",
      "Iteration 1219 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.115 MB, Params: 571,693 (2.181 MB), Total: 2.30 MB, FLOPs: 138,115,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1219/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1219\n",
      "\n",
      "Iteration 1220 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 569,954 (2.174 MB), Total: 2.29 MB, FLOPs: 137,958,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1220/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1220\n",
      "\n",
      "Iteration 1221 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.115 MB, Params: 568,215 (2.168 MB), Total: 2.28 MB, FLOPs: 137,802,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1221/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1221\n",
      "\n",
      "Iteration 1222 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.115 MB, Params: 566,152 (2.160 MB), Total: 2.27 MB, FLOPs: 137,689,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1222/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1222\n",
      "\n",
      "Iteration 1223 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.115 MB, Params: 564,035 (2.152 MB), Total: 2.27 MB, FLOPs: 137,651,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1223/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1223\n",
      "\n",
      "Iteration 1224 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.115 MB, Params: 561,918 (2.144 MB), Total: 2.26 MB, FLOPs: 137,613,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1224/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1224\n",
      "\n",
      "Iteration 1225 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 560,911 (2.140 MB), Total: 2.26 MB, FLOPs: 137,595,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1225/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1225\n",
      "\n",
      "Iteration 1226 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 559,904 (2.136 MB), Total: 2.25 MB, FLOPs: 137,577,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1226/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1226\n",
      "\n",
      "Iteration 1227 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 75)]\n",
      "Input: 0.115 MB, Params: 558,228 (2.129 MB), Total: 2.24 MB, FLOPs: 137,226,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1227/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1227\n",
      "\n",
      "Iteration 1228 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 556,507 (2.123 MB), Total: 2.24 MB, FLOPs: 137,071,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1228/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1228\n",
      "\n",
      "Iteration 1229 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.115 MB, Params: 554,471 (2.115 MB), Total: 2.23 MB, FLOPs: 136,960,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1229/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1229\n",
      "\n",
      "Iteration 1230 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 552,759 (2.109 MB), Total: 2.22 MB, FLOPs: 136,806,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1230/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1230\n",
      "\n",
      "Iteration 1231 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 552,717 (2.108 MB), Total: 2.22 MB, FLOPs: 136,451,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1231/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1231\n",
      "\n",
      "Iteration 1232 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 78)]\n",
      "Input: 0.115 MB, Params: 551,059 (2.102 MB), Total: 2.22 MB, FLOPs: 136,101,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1232/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1232\n",
      "\n",
      "Iteration 1233 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.115 MB, Params: 549,356 (2.096 MB), Total: 2.21 MB, FLOPs: 135,948,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1233/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1233\n",
      "\n",
      "Iteration 1234 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 548,349 (2.092 MB), Total: 2.21 MB, FLOPs: 135,930,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1234/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1234\n",
      "\n",
      "Iteration 1235 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.115 MB, Params: 546,700 (2.085 MB), Total: 2.20 MB, FLOPs: 135,581,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1235/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1235\n",
      "\n",
      "Iteration 1236 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 545,006 (2.079 MB), Total: 2.19 MB, FLOPs: 135,429,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1236/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1236\n",
      "\n",
      "Iteration 1237 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 542,925 (2.071 MB), Total: 2.19 MB, FLOPs: 135,392,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1237/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1237\n",
      "\n",
      "Iteration 1238 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 541,927 (2.067 MB), Total: 2.18 MB, FLOPs: 135,374,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1238/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1238\n",
      "\n",
      "Iteration 1239 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 540,929 (2.063 MB), Total: 2.18 MB, FLOPs: 135,356,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1239/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1239\n",
      "\n",
      "Iteration 1240 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 539,721 (2.059 MB), Total: 2.17 MB, FLOPs: 134,865,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1240/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1240\n",
      "\n",
      "Iteration 1241 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.115 MB, Params: 538,090 (2.053 MB), Total: 2.17 MB, FLOPs: 134,520,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1241/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1241\n",
      "\n",
      "Iteration 1242 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.115 MB, Params: 536,090 (2.045 MB), Total: 2.16 MB, FLOPs: 134,412,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1242/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1242\n",
      "\n",
      "Iteration 1243 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 534,036 (2.037 MB), Total: 2.15 MB, FLOPs: 134,375,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1243/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1243\n",
      "\n",
      "Iteration 1244 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.115 MB, Params: 533,332 (2.035 MB), Total: 2.15 MB, FLOPs: 133,162,561\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1244/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1244\n",
      "\n",
      "Iteration 1245 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.115 MB, Params: 532,133 (2.030 MB), Total: 2.15 MB, FLOPs: 132,674,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1245/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1245\n",
      "\n",
      "Iteration 1246 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.115 MB, Params: 530,142 (2.022 MB), Total: 2.14 MB, FLOPs: 132,566,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1246/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1246\n",
      "\n",
      "Iteration 1247 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 528,097 (2.015 MB), Total: 2.13 MB, FLOPs: 132,529,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1247/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1247\n",
      "\n",
      "Iteration 1248 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 526,898 (2.010 MB), Total: 2.13 MB, FLOPs: 132,042,057\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1248/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1248\n",
      "\n",
      "Iteration 1249 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 525,918 (2.006 MB), Total: 2.12 MB, FLOPs: 132,024,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1249/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1249\n",
      "\n",
      "Iteration 1250 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 523,882 (1.998 MB), Total: 2.11 MB, FLOPs: 131,987,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1250/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1250\n",
      "\n",
      "Iteration 1251 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 9)]\n",
      "Input: 0.115 MB, Params: 523,178 (1.996 MB), Total: 2.11 MB, FLOPs: 130,775,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1251/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1251\n",
      "\n",
      "Iteration 1252 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 521,511 (1.989 MB), Total: 2.10 MB, FLOPs: 130,625,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1252/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1252\n",
      "\n",
      "Iteration 1253 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 519,547 (1.982 MB), Total: 2.10 MB, FLOPs: 130,517,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1253/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1253\n",
      "\n",
      "Iteration 1254 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 517,583 (1.974 MB), Total: 2.09 MB, FLOPs: 130,410,446\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1254/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1254\n",
      "\n",
      "Iteration 1255 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.115 MB, Params: 515,934 (1.968 MB), Total: 2.08 MB, FLOPs: 130,262,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1255/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1255\n",
      "\n",
      "Iteration 1256 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 514,963 (1.964 MB), Total: 2.08 MB, FLOPs: 130,244,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1256/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1256\n",
      "\n",
      "Iteration 1257 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 513,368 (1.958 MB), Total: 2.07 MB, FLOPs: 129,909,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1257/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1257\n",
      "\n",
      "Iteration 1258 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 511,728 (1.952 MB), Total: 2.07 MB, FLOPs: 129,761,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1258/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1258\n",
      "\n",
      "Iteration 1259 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 509,782 (1.945 MB), Total: 2.06 MB, FLOPs: 129,656,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1259/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1259\n",
      "\n",
      "Iteration 1260 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.115 MB, Params: 508,151 (1.938 MB), Total: 2.05 MB, FLOPs: 129,509,450\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1260/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1260\n",
      "\n",
      "Iteration 1261 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 507,180 (1.935 MB), Total: 2.05 MB, FLOPs: 129,492,058\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1261/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1261\n",
      "\n",
      "Iteration 1262 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 106)]\n",
      "Input: 0.115 MB, Params: 505,549 (1.929 MB), Total: 2.04 MB, FLOPs: 129,345,358\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss 0.217  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1262/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1262\n",
      "\n",
      "Iteration 1263 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.115 MB, Params: 503,981 (1.923 MB), Total: 2.04 MB, FLOPs: 129,012,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1263/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1263\n",
      "\n",
      "Iteration 1264 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.115 MB, Params: 502,359 (1.916 MB), Total: 2.03 MB, FLOPs: 128,866,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1264/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1264\n",
      "\n",
      "Iteration 1265 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 500,368 (1.909 MB), Total: 2.02 MB, FLOPs: 128,830,790\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 53.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1265/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1265\n",
      "\n",
      "Iteration 1266 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 499,406 (1.905 MB), Total: 2.02 MB, FLOPs: 128,813,560\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1266/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1266\n",
      "\n",
      "Iteration 1267 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 498,444 (1.901 MB), Total: 2.02 MB, FLOPs: 128,796,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1267/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1267\n",
      "\n",
      "Iteration 1268 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 497,263 (1.897 MB), Total: 2.01 MB, FLOPs: 128,316,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.846%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1268/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1268\n",
      "\n",
      "Iteration 1269 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 495,713 (1.891 MB), Total: 2.01 MB, FLOPs: 127,987,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1269/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1269\n",
      "\n",
      "Iteration 1270 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 494,100 (1.885 MB), Total: 2.00 MB, FLOPs: 127,842,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1270/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1270\n",
      "\n",
      "Iteration 1271 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 74)]\n",
      "Input: 0.115 MB, Params: 492,199 (1.878 MB), Total: 1.99 MB, FLOPs: 127,740,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1271/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1271\n",
      "\n",
      "Iteration 1272 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 491,237 (1.874 MB), Total: 1.99 MB, FLOPs: 127,722,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1272/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1272\n",
      "\n",
      "Iteration 1273 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 489,696 (1.868 MB), Total: 1.98 MB, FLOPs: 127,395,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1273/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1273\n",
      "\n",
      "Iteration 1274 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.115 MB, Params: 487,741 (1.861 MB), Total: 1.98 MB, FLOPs: 127,360,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1274/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1274\n",
      "\n",
      "Iteration 1275 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 486,788 (1.857 MB), Total: 1.97 MB, FLOPs: 127,343,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1275/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1275\n",
      "\n",
      "Iteration 1276 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 485,835 (1.853 MB), Total: 1.97 MB, FLOPs: 127,326,108\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1276/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1276\n",
      "\n",
      "Iteration 1277 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 483,898 (1.846 MB), Total: 1.96 MB, FLOPs: 127,291,260\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1277/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1277\n",
      "\n",
      "Iteration 1278 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.115 MB, Params: 482,303 (1.840 MB), Total: 1.96 MB, FLOPs: 127,147,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1278/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1278\n",
      "\n",
      "Iteration 1279 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 480,429 (1.833 MB), Total: 1.95 MB, FLOPs: 127,046,550\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1279/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1279\n",
      "\n",
      "Iteration 1280 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 478,501 (1.825 MB), Total: 1.94 MB, FLOPs: 127,011,864\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1280/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1280\n",
      "\n",
      "Iteration 1281 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.115 MB, Params: 476,573 (1.818 MB), Total: 1.93 MB, FLOPs: 126,977,178\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1281/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1281\n",
      "\n",
      "Iteration 1282 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 475,647 (1.814 MB), Total: 1.93 MB, FLOPs: 126,960,596\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1282/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1282\n",
      "\n",
      "Iteration 1283 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 474,115 (1.809 MB), Total: 1.92 MB, FLOPs: 126,633,831\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1283/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1283\n",
      "\n",
      "Iteration 1284 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 49)]\n",
      "Input: 0.115 MB, Params: 473,078 (1.805 MB), Total: 1.92 MB, FLOPs: 125,627,995\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1284/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1284\n",
      "\n",
      "Iteration 1285 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 471,501 (1.799 MB), Total: 1.91 MB, FLOPs: 125,486,155\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1285/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1285\n",
      "\n",
      "Iteration 1286 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 470,575 (1.795 MB), Total: 1.91 MB, FLOPs: 125,469,573\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1286/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1286\n",
      "\n",
      "Iteration 1287 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.115 MB, Params: 468,728 (1.788 MB), Total: 1.90 MB, FLOPs: 125,369,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1287/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1287\n",
      "\n",
      "Iteration 1288 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 466,827 (1.781 MB), Total: 1.90 MB, FLOPs: 125,335,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1288/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1288\n",
      "\n",
      "Iteration 1289 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 465,910 (1.777 MB), Total: 1.89 MB, FLOPs: 125,318,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1289/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1289\n",
      "\n",
      "Iteration 1290 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 464,993 (1.774 MB), Total: 1.89 MB, FLOPs: 125,302,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1290/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1290\n",
      "\n",
      "Iteration 1291 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 464,076 (1.770 MB), Total: 1.89 MB, FLOPs: 125,285,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1291/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1291\n",
      "\n",
      "Iteration 1292 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 462,202 (1.763 MB), Total: 1.88 MB, FLOPs: 125,252,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1292/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1292\n",
      "\n",
      "Iteration 1293 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 68)]\n",
      "Input: 0.115 MB, Params: 461,294 (1.760 MB), Total: 1.87 MB, FLOPs: 125,236,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1293/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1293\n",
      "\n",
      "Iteration 1294 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.115 MB, Params: 459,771 (1.754 MB), Total: 1.87 MB, FLOPs: 124,910,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1294/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1294\n",
      "\n",
      "Iteration 1295 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.115 MB, Params: 458,212 (1.748 MB), Total: 1.86 MB, FLOPs: 124,769,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1295/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1295\n",
      "\n",
      "Iteration 1296 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.115 MB, Params: 456,347 (1.741 MB), Total: 1.86 MB, FLOPs: 124,736,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1296/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1296\n",
      "\n",
      "Iteration 1297 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 455,448 (1.737 MB), Total: 1.85 MB, FLOPs: 124,720,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1297/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1297\n",
      "\n",
      "Iteration 1298 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 454,549 (1.734 MB), Total: 1.85 MB, FLOPs: 124,704,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1298/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1298\n",
      "\n",
      "Iteration 1299 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 453,650 (1.731 MB), Total: 1.85 MB, FLOPs: 124,688,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1299/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1299\n",
      "\n",
      "Iteration 1300 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 451,839 (1.724 MB), Total: 1.84 MB, FLOPs: 124,589,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1300/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1300\n",
      "\n",
      "Iteration 1301 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.115 MB, Params: 450,703 (1.719 MB), Total: 1.83 MB, FLOPs: 124,127,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1301/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1301\n",
      "\n",
      "Iteration 1302 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.115 MB, Params: 449,198 (1.714 MB), Total: 1.83 MB, FLOPs: 123,805,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1302/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1302\n",
      "\n",
      "Iteration 1303 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.115 MB, Params: 448,071 (1.709 MB), Total: 1.82 MB, FLOPs: 123,347,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1303/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1303\n",
      "\n",
      "Iteration 1304 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.115 MB, Params: 447,376 (1.707 MB), Total: 1.82 MB, FLOPs: 122,150,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1304/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1304\n",
      "\n",
      "Iteration 1305 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 446,477 (1.703 MB), Total: 1.82 MB, FLOPs: 122,134,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1305/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1305\n",
      "\n",
      "Iteration 1306 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 43)]\n",
      "Input: 0.115 MB, Params: 444,981 (1.697 MB), Total: 1.81 MB, FLOPs: 121,816,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1306/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1306\n",
      "\n",
      "Iteration 1307 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 443,449 (1.692 MB), Total: 1.81 MB, FLOPs: 121,678,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1307/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1307\n",
      "\n",
      "Iteration 1308 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.115 MB, Params: 441,647 (1.685 MB), Total: 1.80 MB, FLOPs: 121,580,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1308/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1308\n",
      "\n",
      "Iteration 1309 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.115 MB, Params: 439,845 (1.678 MB), Total: 1.79 MB, FLOPs: 121,482,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1309/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1309\n",
      "\n",
      "Iteration 1310 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 438,835 (1.674 MB), Total: 1.79 MB, FLOPs: 120,499,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1310/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1310\n",
      "\n",
      "Iteration 1311 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.115 MB, Params: 437,726 (1.670 MB), Total: 1.79 MB, FLOPs: 120,048,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1311/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1311\n",
      "\n",
      "Iteration 1312 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.115 MB, Params: 437,040 (1.667 MB), Total: 1.78 MB, FLOPs: 118,867,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1312/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1312\n",
      "\n",
      "Iteration 1313 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.115 MB, Params: 436,048 (1.663 MB), Total: 1.78 MB, FLOPs: 117,903,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1313/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1313\n",
      "\n",
      "Iteration 1314 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 434,534 (1.658 MB), Total: 1.77 MB, FLOPs: 117,767,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1314/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1314\n",
      "\n",
      "Iteration 1315 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 432,741 (1.651 MB), Total: 1.77 MB, FLOPs: 117,669,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1315/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1315\n",
      "\n",
      "Iteration 1316 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 431,842 (1.647 MB), Total: 1.76 MB, FLOPs: 117,653,777\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1316/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1316\n",
      "\n",
      "Iteration 1317 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 21)]\n",
      "Input: 0.115 MB, Params: 431,408 (1.646 MB), Total: 1.76 MB, FLOPs: 116,847,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1317/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1317\n",
      "\n",
      "Iteration 1318 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.115 MB, Params: 430,740 (1.643 MB), Total: 1.76 MB, FLOPs: 115,697,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1318/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1318\n",
      "\n",
      "Iteration 1319 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 428,956 (1.636 MB), Total: 1.75 MB, FLOPs: 115,665,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1319/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1319\n",
      "\n",
      "Iteration 1320 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 428,066 (1.633 MB), Total: 1.75 MB, FLOPs: 115,649,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1320/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1320\n",
      "\n",
      "Iteration 1321 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.115 MB, Params: 426,966 (1.629 MB), Total: 1.74 MB, FLOPs: 115,201,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1321/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1321\n",
      "\n",
      "Iteration 1322 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 425,182 (1.622 MB), Total: 1.74 MB, FLOPs: 115,104,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1322/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1322\n",
      "\n",
      "Iteration 1323 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.115 MB, Params: 423,416 (1.615 MB), Total: 1.73 MB, FLOPs: 115,073,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1323/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1323\n",
      "\n",
      "Iteration 1324 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.115 MB, Params: 421,956 (1.610 MB), Total: 1.72 MB, FLOPs: 114,764,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1324/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1324\n",
      "\n",
      "Iteration 1325 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.115 MB, Params: 420,469 (1.604 MB), Total: 1.72 MB, FLOPs: 114,630,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1325/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1325\n",
      "\n",
      "Iteration 1326 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.115 MB, Params: 418,703 (1.597 MB), Total: 1.71 MB, FLOPs: 114,534,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1326/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1326\n",
      "\n",
      "Iteration 1327 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.115 MB, Params: 416,946 (1.591 MB), Total: 1.71 MB, FLOPs: 114,502,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1327/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1327\n",
      "\n",
      "Iteration 1328 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 48)]\n",
      "Input: 0.115 MB, Params: 415,855 (1.586 MB), Total: 1.70 MB, FLOPs: 114,059,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1328/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1328\n",
      "\n",
      "Iteration 1329 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 70)]\n",
      "Input: 0.115 MB, Params: 414,377 (1.581 MB), Total: 1.70 MB, FLOPs: 113,926,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1329/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1329\n",
      "\n",
      "Iteration 1330 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 412,629 (1.574 MB), Total: 1.69 MB, FLOPs: 113,831,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1330/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1330\n",
      "\n",
      "Iteration 1331 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 411,160 (1.568 MB), Total: 1.68 MB, FLOPs: 113,698,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1331/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1331\n",
      "\n",
      "Iteration 1332 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.115 MB, Params: 409,421 (1.562 MB), Total: 1.68 MB, FLOPs: 113,604,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1332/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1332\n",
      "\n",
      "Iteration 1333 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.115 MB, Params: 407,682 (1.555 MB), Total: 1.67 MB, FLOPs: 113,573,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1333/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1333\n",
      "\n",
      "Iteration 1334 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 27)]\n",
      "Input: 0.115 MB, Params: 406,591 (1.551 MB), Total: 1.67 MB, FLOPs: 113,129,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1334/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1334\n",
      "\n",
      "Iteration 1335 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 91)]\n",
      "Input: 0.115 MB, Params: 405,131 (1.545 MB), Total: 1.66 MB, FLOPs: 112,998,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.615%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1335/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1335\n",
      "\n",
      "Iteration 1336 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.115 MB, Params: 405,089 (1.545 MB), Total: 1.66 MB, FLOPs: 110,332,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1336/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1336\n",
      "\n",
      "Iteration 1337 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 404,226 (1.542 MB), Total: 1.66 MB, FLOPs: 110,317,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1337/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1337\n",
      "\n",
      "Iteration 1338 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.115 MB, Params: 402,820 (1.537 MB), Total: 1.65 MB, FLOPs: 110,019,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1338/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1338\n",
      "\n",
      "Iteration 1339 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.115 MB, Params: 401,369 (1.531 MB), Total: 1.65 MB, FLOPs: 109,888,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1339/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1339\n",
      "\n",
      "Iteration 1340 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 84)]\n",
      "Input: 0.115 MB, Params: 399,918 (1.526 MB), Total: 1.64 MB, FLOPs: 109,758,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1340/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1340\n",
      "\n",
      "Iteration 1341 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.115 MB, Params: 398,215 (1.519 MB), Total: 1.63 MB, FLOPs: 109,666,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1341/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1341\n",
      "\n",
      "Iteration 1342 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 396,494 (1.513 MB), Total: 1.63 MB, FLOPs: 109,635,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1342/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1342\n",
      "\n",
      "Iteration 1343 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 394,773 (1.506 MB), Total: 1.62 MB, FLOPs: 109,604,539\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1343/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1343\n",
      "\n",
      "Iteration 1344 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 393,928 (1.503 MB), Total: 1.62 MB, FLOPs: 109,589,415\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1344/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1344\n",
      "\n",
      "Iteration 1345 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 393,083 (1.499 MB), Total: 1.61 MB, FLOPs: 109,574,291\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1345/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1345\n",
      "\n",
      "Iteration 1346 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 392,238 (1.496 MB), Total: 1.61 MB, FLOPs: 109,559,167\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1346/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1346\n",
      "\n",
      "Iteration 1347 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.115 MB, Params: 390,796 (1.491 MB), Total: 1.61 MB, FLOPs: 109,429,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1347/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1347\n",
      "\n",
      "Iteration 1348 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.115 MB, Params: 389,951 (1.488 MB), Total: 1.60 MB, FLOPs: 109,414,353\n",
      "Current Testing Performance - Val: Loss 1.646  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.572  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.671  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1348/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1348\n",
      "\n",
      "Iteration 1349 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 44)]\n",
      "Input: 0.115 MB, Params: 389,909 (1.487 MB), Total: 1.60 MB, FLOPs: 109,060,890\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1349/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1349\n",
      "\n",
      "Iteration 1350 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.115 MB, Params: 388,827 (1.483 MB), Total: 1.60 MB, FLOPs: 108,620,923\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1350/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1350\n",
      "\n",
      "Iteration 1351 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.115 MB, Params: 387,142 (1.477 MB), Total: 1.59 MB, FLOPs: 108,590,611\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.745  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.646  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1351/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1351\n",
      "\n",
      "Iteration 1352 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.115 MB, Params: 385,700 (1.471 MB), Total: 1.59 MB, FLOPs: 108,460,921\n",
      "Current Testing Performance - Val: Loss 1.409  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.483  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1352/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1352\n",
      "\n",
      "Iteration 1353 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 384,618 (1.467 MB), Total: 1.58 MB, FLOPs: 108,020,954\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1353/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1353\n",
      "\n",
      "Iteration 1354 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.115 MB, Params: 383,176 (1.462 MB), Total: 1.58 MB, FLOPs: 107,891,264\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1354/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1354\n",
      "\n",
      "Iteration 1355 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 381,527 (1.455 MB), Total: 1.57 MB, FLOPs: 107,802,488\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1355/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1355\n",
      "\n",
      "Iteration 1356 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 379,851 (1.449 MB), Total: 1.56 MB, FLOPs: 107,772,338\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1356/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1356\n",
      "\n",
      "Iteration 1357 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 379,024 (1.446 MB), Total: 1.56 MB, FLOPs: 107,757,538\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1357/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1357\n",
      "\n",
      "Iteration 1358 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 378,197 (1.443 MB), Total: 1.56 MB, FLOPs: 107,742,738\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1358/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1358\n",
      "\n",
      "Iteration 1359 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 377,370 (1.440 MB), Total: 1.55 MB, FLOPs: 107,727,938\n",
      "Current Testing Performance - Val: Loss 1.582  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.604  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.604  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1359/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1359\n",
      "\n",
      "Iteration 1360 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.115 MB, Params: 375,730 (1.433 MB), Total: 1.55 MB, FLOPs: 107,639,324\n",
      "Current Testing Performance - Val: Loss 1.465  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.465  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss 1.465  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1360/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1360\n",
      "\n",
      "Iteration 1361 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 374,090 (1.427 MB), Total: 1.54 MB, FLOPs: 107,609,822\n",
      "Current Testing Performance - Val: Loss 1.465  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1361/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1361\n",
      "\n",
      "Iteration 1362 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.115 MB, Params: 373,272 (1.424 MB), Total: 1.54 MB, FLOPs: 107,595,184\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1362/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1362\n",
      "\n",
      "Iteration 1363 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 372,454 (1.421 MB), Total: 1.54 MB, FLOPs: 107,580,546\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1363/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1363\n",
      "\n",
      "Iteration 1364 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 40)]\n",
      "Input: 0.115 MB, Params: 371,786 (1.418 MB), Total: 1.53 MB, FLOPs: 106,479,996\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1364/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1364\n",
      "\n",
      "Iteration 1365 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 370,704 (1.414 MB), Total: 1.53 MB, FLOPs: 106,040,029\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1365/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1365\n",
      "\n",
      "Iteration 1366 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.115 MB, Params: 369,370 (1.409 MB), Total: 1.52 MB, FLOPs: 105,756,761\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1366/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1366\n",
      "\n",
      "Iteration 1367 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 367,955 (1.404 MB), Total: 1.52 MB, FLOPs: 105,629,501\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.579  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.579  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1367/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1367\n",
      "\n",
      "Iteration 1368 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 366,540 (1.398 MB), Total: 1.51 MB, FLOPs: 105,502,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1368/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1368\n",
      "\n",
      "Iteration 1369 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 365,125 (1.393 MB), Total: 1.51 MB, FLOPs: 105,374,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1369/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1369\n",
      "\n",
      "Iteration 1370 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 363,503 (1.387 MB), Total: 1.50 MB, FLOPs: 105,345,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1370/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1370\n",
      "\n",
      "Iteration 1371 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 361,908 (1.381 MB), Total: 1.50 MB, FLOPs: 105,259,943\n",
      "Current Testing Performance - Val: Loss 1.452  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.501  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1371/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1371\n",
      "\n",
      "Iteration 1372 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 360,295 (1.374 MB), Total: 1.49 MB, FLOPs: 105,230,927\n",
      "Current Testing Performance - Val: Loss 1.402  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1372/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1372\n",
      "\n",
      "Iteration 1373 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 359,495 (1.371 MB), Total: 1.49 MB, FLOPs: 105,216,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1373/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1373\n",
      "\n",
      "Iteration 1374 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 358,695 (1.368 MB), Total: 1.48 MB, FLOPs: 105,202,299\n",
      "Current Testing Performance - Val: Loss 1.501  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.501  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1374/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1374\n",
      "\n",
      "Iteration 1375 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 358,027 (1.366 MB), Total: 1.48 MB, FLOPs: 104,101,749\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1375/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1375\n",
      "\n",
      "Iteration 1376 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 45)]\n",
      "Input: 0.115 MB, Params: 357,116 (1.362 MB), Total: 1.48 MB, FLOPs: 103,236,280\n",
      "Current Testing Performance - Val: Loss 1.625  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.529  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1376/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1376\n",
      "\n",
      "Iteration 1377 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 355,809 (1.357 MB), Total: 1.47 MB, FLOPs: 102,955,442\n",
      "Current Testing Performance - Val: Loss 1.561  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.561  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 1.561  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1377/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1377\n",
      "\n",
      "Iteration 1378 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 354,412 (1.352 MB), Total: 1.47 MB, FLOPs: 102,829,802\n",
      "Current Testing Performance - Val: Loss 1.660  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.660  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1378/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1378\n",
      "\n",
      "Iteration 1379 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.115 MB, Params: 353,015 (1.347 MB), Total: 1.46 MB, FLOPs: 102,704,162\n",
      "Current Testing Performance - Val: Loss 1.540  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1379/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1379\n",
      "\n",
      "Iteration 1380 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.115 MB, Params: 351,447 (1.341 MB), Total: 1.46 MB, FLOPs: 102,620,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1380/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1380\n",
      "\n",
      "Iteration 1381 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 349,861 (1.335 MB), Total: 1.45 MB, FLOPs: 102,591,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1381/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1381\n",
      "\n",
      "Iteration 1382 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.115 MB, Params: 348,806 (1.331 MB), Total: 1.45 MB, FLOPs: 102,162,576\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1382/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1382\n",
      "\n",
      "Iteration 1383 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.115 MB, Params: 347,526 (1.326 MB), Total: 1.44 MB, FLOPs: 101,887,021\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1383/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1383\n",
      "\n",
      "Iteration 1384 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.115 MB, Params: 346,867 (1.323 MB), Total: 1.44 MB, FLOPs: 100,801,321\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1384/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1384\n",
      "\n",
      "Iteration 1385 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 346,076 (1.320 MB), Total: 1.44 MB, FLOPs: 100,787,169\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1385/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1385\n",
      "\n",
      "Iteration 1386 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 65)]\n",
      "Input: 0.115 MB, Params: 344,796 (1.315 MB), Total: 1.43 MB, FLOPs: 100,511,614\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Finished fine tuning.\n",
      "Iteration 1386/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1386\n",
      "\n",
      "Iteration 1387 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 68)]\n",
      "Input: 0.115 MB, Params: 343,426 (1.310 MB), Total: 1.43 MB, FLOPs: 100,388,404\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1387/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1387\n",
      "\n",
      "Iteration 1388 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 341,876 (1.304 MB), Total: 1.42 MB, FLOPs: 100,305,298\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1388/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1388\n",
      "\n",
      "Iteration 1389 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 340,308 (1.298 MB), Total: 1.41 MB, FLOPs: 100,277,092\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 41.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1389/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1389\n",
      "\n",
      "Iteration 1390 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.115 MB, Params: 339,526 (1.295 MB), Total: 1.41 MB, FLOPs: 100,263,102\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1390/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1390\n",
      "\n",
      "Iteration 1391 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.115 MB, Params: 339,484 (1.295 MB), Total: 1.41 MB, FLOPs: 95,620,428\n",
      "Current Testing Performance - Val: Loss 1.101  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.928  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1391/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1391\n",
      "\n",
      "Iteration 1392 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 337,943 (1.289 MB), Total: 1.40 MB, FLOPs: 95,537,484\n",
      "Current Testing Performance - Val: Loss 0.928  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1392/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1392\n",
      "\n",
      "Iteration 1393 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 337,050 (1.286 MB), Total: 1.40 MB, FLOPs: 94,738,424\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 40.000%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1393/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1393\n",
      "\n",
      "Iteration 1394 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 335,698 (1.281 MB), Total: 1.40 MB, FLOPs: 94,616,834\n",
      "Current Testing Performance - Val: Loss 0.928  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.681  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1394/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1394\n",
      "\n",
      "Iteration 1395 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 334,166 (1.275 MB), Total: 1.39 MB, FLOPs: 94,534,700\n",
      "Current Testing Performance - Val: Loss 0.681  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.730  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1395/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1395\n",
      "\n",
      "Iteration 1396 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.115 MB, Params: 332,625 (1.269 MB), Total: 1.38 MB, FLOPs: 94,506,980\n",
      "Current Testing Performance - Val: Loss 0.928  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1396/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1396\n",
      "\n",
      "Iteration 1397 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 331,852 (1.266 MB), Total: 1.38 MB, FLOPs: 94,493,152\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1397/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1397\n",
      "\n",
      "Iteration 1398 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 330,329 (1.260 MB), Total: 1.38 MB, FLOPs: 94,411,180\n",
      "Current Testing Performance - Val: Loss 0.836  Acc(top1) 41.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.836  Acc(top1) 41.538%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1398/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1398\n",
      "\n",
      "Iteration 1399 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.115 MB, Params: 328,806 (1.254 MB), Total: 1.37 MB, FLOPs: 94,383,784\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss 0.829  Acc(top1) 38.462%\n",
      "Finished fine tuning.\n",
      "Iteration 1399/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1399\n",
      "\n",
      "Iteration 1400 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 327,283 (1.248 MB), Total: 1.36 MB, FLOPs: 94,356,388\n",
      "Current Testing Performance - Val: Loss 0.928  Acc(top1) 38.462%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.027  Acc(top1) 38.462%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1400/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1400\n",
      "\n",
      "Iteration 1401 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 326,528 (1.246 MB), Total: 1.36 MB, FLOPs: 94,342,884\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.098  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss 1.045  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1401/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1401\n",
      "\n",
      "Iteration 1402 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 325,773 (1.243 MB), Total: 1.36 MB, FLOPs: 94,329,380\n",
      "Current Testing Performance - Val: Loss 1.243  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.420  Acc(top1) 36.923%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1402/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1402\n",
      "\n",
      "Iteration 1403 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.115 MB, Params: 324,511 (1.238 MB), Total: 1.35 MB, FLOPs: 94,074,130\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1403/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1403\n",
      "\n",
      "Iteration 1404 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 323,186 (1.233 MB), Total: 1.35 MB, FLOPs: 93,954,970\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 36.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1404/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1404\n",
      "\n",
      "Iteration 1405 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 321,681 (1.227 MB), Total: 1.34 MB, FLOPs: 93,927,898\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1405/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1405\n",
      "\n",
      "Iteration 1406 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 320,935 (1.224 MB), Total: 1.34 MB, FLOPs: 93,914,556\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1406/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1406\n",
      "\n",
      "Iteration 1407 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 51)]\n",
      "Input: 0.115 MB, Params: 319,682 (1.219 MB), Total: 1.33 MB, FLOPs: 93,660,116\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Finished fine tuning.\n",
      "Iteration 1407/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1407\n",
      "\n",
      "Iteration 1408 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 318,366 (1.214 MB), Total: 1.33 MB, FLOPs: 93,541,766\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1408/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1408\n",
      "\n",
      "Iteration 1409 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 40)]\n",
      "Input: 0.115 MB, Params: 317,716 (1.212 MB), Total: 1.33 MB, FLOPs: 92,519,591\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 35.385%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1409/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1409\n",
      "\n",
      "Iteration 1410 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 19)]\n",
      "Input: 0.115 MB, Params: 317,674 (1.212 MB), Total: 1.33 MB, FLOPs: 92,166,128\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1410/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1410\n",
      "\n",
      "Iteration 1411 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.115 MB, Params: 317,024 (1.209 MB), Total: 1.32 MB, FLOPs: 91,143,953\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1411/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1411\n",
      "\n",
      "Iteration 1412 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.115 MB, Params: 316,149 (1.206 MB), Total: 1.32 MB, FLOPs: 90,373,243\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1412/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1412\n",
      "\n",
      "Iteration 1413 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.115 MB, Params: 315,148 (1.202 MB), Total: 1.32 MB, FLOPs: 90,003,243\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1413/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1413\n",
      "\n",
      "Iteration 1414 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 313,670 (1.197 MB), Total: 1.31 MB, FLOPs: 89,923,377\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1414/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1414\n",
      "\n",
      "Iteration 1415 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 313,628 (1.196 MB), Total: 1.31 MB, FLOPs: 87,591,189\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1415/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1415\n",
      "\n",
      "Iteration 1416 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.115 MB, Params: 312,393 (1.192 MB), Total: 1.31 MB, FLOPs: 87,340,889\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1416/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1416\n",
      "\n",
      "Iteration 1417 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.115 MB, Params: 311,095 (1.187 MB), Total: 1.30 MB, FLOPs: 87,224,159\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1417/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1417\n",
      "\n",
      "Iteration 1418 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.115 MB, Params: 309,626 (1.181 MB), Total: 1.30 MB, FLOPs: 87,145,103\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1418/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1418\n",
      "\n",
      "Iteration 1419 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 308,157 (1.176 MB), Total: 1.29 MB, FLOPs: 87,066,047\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1419/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1419\n",
      "\n",
      "Iteration 1420 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 307,411 (1.173 MB), Total: 1.29 MB, FLOPs: 87,052,705\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1420/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1420\n",
      "\n",
      "Iteration 1421 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.115 MB, Params: 305,951 (1.167 MB), Total: 1.28 MB, FLOPs: 87,026,443\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1421/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1421\n",
      "\n",
      "Iteration 1422 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 305,214 (1.164 MB), Total: 1.28 MB, FLOPs: 87,013,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1422/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1422\n",
      "\n",
      "Iteration 1423 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 39)]\n",
      "Input: 0.115 MB, Params: 304,573 (1.162 MB), Total: 1.28 MB, FLOPs: 86,053,263\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1423/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1423\n",
      "\n",
      "Iteration 1424 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 12)]\n",
      "Input: 0.115 MB, Params: 303,716 (1.159 MB), Total: 1.27 MB, FLOPs: 85,327,133\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 21.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1424/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1424\n",
      "\n",
      "Iteration 1425 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 45)]\n",
      "Input: 0.115 MB, Params: 302,490 (1.154 MB), Total: 1.27 MB, FLOPs: 85,077,643\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 20.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.552  Acc(top1) 20.000%\n",
      "Current Testing Performance - Val: Loss 2.354  Acc(top1) 21.538%\n",
      "Finished fine tuning.\n",
      "Iteration 1425/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1425\n",
      "\n",
      "Iteration 1426 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 301,219 (1.149 MB), Total: 1.26 MB, FLOPs: 84,963,343\n",
      "Current Testing Performance - Val: Loss 2.478  Acc(top1) 20.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.403  Acc(top1) 20.000%\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1426/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1426\n",
      "\n",
      "Iteration 1427 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 300,482 (1.146 MB), Total: 1.26 MB, FLOPs: 84,950,163\n",
      "Current Testing Performance - Val: Loss 1.190  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.413  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.908  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1427/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1427\n",
      "\n",
      "Iteration 1428 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 36)]\n",
      "Input: 0.115 MB, Params: 299,850 (1.144 MB), Total: 1.26 MB, FLOPs: 84,003,663\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.908  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss 2.106  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1428/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1428\n",
      "\n",
      "Iteration 1429 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 298,876 (1.140 MB), Total: 1.26 MB, FLOPs: 83,643,653\n",
      "Current Testing Performance - Val: Loss 1.834  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.859  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss 2.082  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1429/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1429\n",
      "\n",
      "Iteration 1430 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 297,425 (1.135 MB), Total: 1.25 MB, FLOPs: 83,565,569\n",
      "Current Testing Performance - Val: Loss 1.859  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.760  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss 1.760  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1430/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1430\n",
      "\n",
      "Iteration 1431 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 9)]\n",
      "Input: 0.115 MB, Params: 296,793 (1.132 MB), Total: 1.25 MB, FLOPs: 82,619,069\n",
      "Current Testing Performance - Val: Loss 1.760  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.760  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss 1.859  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1431/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1431\n",
      "\n",
      "Iteration 1432 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.115 MB, Params: 295,531 (1.127 MB), Total: 1.24 MB, FLOPs: 82,505,579\n",
      "Current Testing Performance - Val: Loss 2.329  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.329  Acc(top1) 23.077%\n",
      "Current Testing Performance - Val: Loss 2.329  Acc(top1) 23.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1432/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1432\n",
      "\n",
      "Iteration 1433 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 294,557 (1.124 MB), Total: 1.24 MB, FLOPs: 82,145,569\n",
      "Current Testing Performance - Val: Loss 2.156  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1433/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1433\n",
      "\n",
      "Iteration 1434 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.115 MB, Params: 293,367 (1.119 MB), Total: 1.23 MB, FLOPs: 81,904,359\n",
      "Current Testing Performance - Val: Loss 1.264  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.438  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss 1.215  Acc(top1) 33.846%\n",
      "Finished fine tuning.\n",
      "Iteration 1434/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1434\n",
      "\n",
      "Iteration 1435 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 40)]\n",
      "Input: 0.115 MB, Params: 292,546 (1.116 MB), Total: 1.23 MB, FLOPs: 81,211,889\n",
      "Current Testing Performance - Val: Loss 1.834  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.834  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.661  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1435/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1435\n",
      "\n",
      "Iteration 1436 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 291,113 (1.111 MB), Total: 1.23 MB, FLOPs: 81,186,113\n",
      "Current Testing Performance - Val: Loss 1.264  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.413  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss 1.784  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1436/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1436\n",
      "\n",
      "Iteration 1437 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 290,385 (1.108 MB), Total: 1.22 MB, FLOPs: 81,173,095\n",
      "Current Testing Performance - Val: Loss 1.190  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.264  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss 1.463  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1437/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1437\n",
      "\n",
      "Iteration 1438 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 289,657 (1.105 MB), Total: 1.22 MB, FLOPs: 81,160,077\n",
      "Current Testing Performance - Val: Loss 1.141  Acc(top1) 33.846%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.264  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss 1.438  Acc(top1) 32.308%\n",
      "Finished fine tuning.\n",
      "Iteration 1438/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1438\n",
      "\n",
      "Iteration 1439 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 289,615 (1.105 MB), Total: 1.22 MB, FLOPs: 80,806,614\n",
      "Current Testing Performance - Val: Loss 1.091  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.091  Acc(top1) 29.231%\n",
      "Current Testing Performance - Val: Loss 1.339  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1439/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1439\n",
      "\n",
      "Iteration 1440 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 288,887 (1.102 MB), Total: 1.22 MB, FLOPs: 80,793,596\n",
      "Current Testing Performance - Val: Loss 1.512  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.463  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.586  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1440/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1440\n",
      "\n",
      "Iteration 1441 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 287,481 (1.097 MB), Total: 1.21 MB, FLOPs: 80,768,306\n",
      "Current Testing Performance - Val: Loss 1.240  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.091  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1441/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1441\n",
      "\n",
      "Iteration 1442 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 286,762 (1.094 MB), Total: 1.21 MB, FLOPs: 80,755,450\n",
      "Current Testing Performance - Val: Loss 1.289  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.289  Acc(top1) 30.769%\n",
      "Current Testing Performance - Val: Loss 1.314  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1442/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1442\n",
      "\n",
      "Iteration 1443 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 285,509 (1.089 MB), Total: 1.20 MB, FLOPs: 80,642,770\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.710  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.784  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1443/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1443\n",
      "\n",
      "Iteration 1444 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 284,112 (1.084 MB), Total: 1.20 MB, FLOPs: 80,617,642\n",
      "Current Testing Performance - Val: Loss 1.685  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.784  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.908  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1444/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1444\n",
      "\n",
      "Iteration 1445 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 283,402 (1.081 MB), Total: 1.20 MB, FLOPs: 80,604,948\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss 2.032  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1445/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1445\n",
      "\n",
      "Iteration 1446 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.115 MB, Params: 282,779 (1.079 MB), Total: 1.19 MB, FLOPs: 79,671,948\n",
      "Current Testing Performance - Val: Loss 1.735  Acc(top1) 29.231%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 29.231%\n",
      "Current Testing Performance - Val: Loss 1.983  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1446/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1446\n",
      "\n",
      "Iteration 1447 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 282,069 (1.076 MB), Total: 1.19 MB, FLOPs: 79,659,254\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.586  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1447/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1447\n",
      "\n",
      "Iteration 1448 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 280,663 (1.071 MB), Total: 1.19 MB, FLOPs: 79,583,276\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.908  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss 1.710  Acc(top1) 26.154%\n",
      "Finished fine tuning.\n",
      "Iteration 1448/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1448\n",
      "\n",
      "Iteration 1449 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 279,419 (1.066 MB), Total: 1.18 MB, FLOPs: 79,471,406\n",
      "Current Testing Performance - Val: Loss 2.156  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.933  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss 1.859  Acc(top1) 23.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1449/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1449\n",
      "\n",
      "Iteration 1450 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.115 MB, Params: 278,022 (1.061 MB), Total: 1.18 MB, FLOPs: 79,396,238\n",
      "Current Testing Performance - Val: Loss 1.735  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.958  Acc(top1) 23.077%\n",
      "Current Testing Performance - Val: Loss 1.834  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1450/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1450\n",
      "\n",
      "Iteration 1451 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 276,661 (1.055 MB), Total: 1.17 MB, FLOPs: 79,371,758\n",
      "Current Testing Performance - Val: Loss 1.636  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.859  Acc(top1) 23.077%\n",
      "Current Testing Performance - Val: Loss 1.487  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1451/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1451\n",
      "\n",
      "Iteration 1452 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 275,960 (1.053 MB), Total: 1.17 MB, FLOPs: 79,359,226\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 32.308%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 0.621  Acc(top1) 32.308%\n",
      "Current Testing Performance - Val: Loss 0.967  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1452/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1452\n",
      "\n",
      "Iteration 1453 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.115 MB, Params: 274,725 (1.048 MB), Total: 1.16 MB, FLOPs: 79,248,166\n",
      "Current Testing Performance - Val: Loss 0.868  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.165  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.141  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1453/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1453\n",
      "\n",
      "Iteration 1454 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.115 MB, Params: 273,346 (1.043 MB), Total: 1.16 MB, FLOPs: 79,173,970\n",
      "Current Testing Performance - Val: Loss 1.643  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.544  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.643  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1454/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1454\n",
      "\n",
      "Iteration 1455 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 272,003 (1.038 MB), Total: 1.15 MB, FLOPs: 79,149,814\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 26.154%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 27.692%\n",
      "Finished fine tuning.\n",
      "Iteration 1455/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1455\n",
      "\n",
      "Iteration 1456 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 271,311 (1.035 MB), Total: 1.15 MB, FLOPs: 79,137,444\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1456/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1456\n",
      "\n",
      "Iteration 1457 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 270,619 (1.032 MB), Total: 1.15 MB, FLOPs: 79,125,074\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1457/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1457\n",
      "\n",
      "Iteration 1458 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.115 MB, Params: 270,275 (1.031 MB), Total: 1.15 MB, FLOPs: 78,559,174\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 23.077%\n",
      "Current Testing Performance - Val: Loss 2.181  Acc(top1) 23.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1458/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1458\n",
      "\n",
      "Iteration 1459 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 269,049 (1.026 MB), Total: 1.14 MB, FLOPs: 78,448,924\n",
      "Current Testing Performance - Val: Loss 2.085  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.209  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss 2.209  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1459/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1459\n",
      "\n",
      "Iteration 1460 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 267,688 (1.021 MB), Total: 1.14 MB, FLOPs: 78,375,700\n",
      "Current Testing Performance - Val: Loss 2.258  Acc(top1) 24.615%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 2.258  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss 2.159  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1460/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1460\n",
      "\n",
      "Iteration 1461 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.115 MB, Params: 266,534 (1.017 MB), Total: 1.13 MB, FLOPs: 78,137,730\n",
      "Current Testing Performance - Val: Loss 1.714  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.689  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1461/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1461\n",
      "\n",
      "Iteration 1462 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 265,173 (1.012 MB), Total: 1.13 MB, FLOPs: 78,064,506\n",
      "Current Testing Performance - Val: Loss 1.590  Acc(top1) 27.692%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.516  Acc(top1) 27.692%\n",
      "Current Testing Performance - Val: Loss 1.809  Acc(top1) 23.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1462/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1462\n",
      "\n",
      "Iteration 1463 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 263,866 (1.007 MB), Total: 1.12 MB, FLOPs: 78,040,998\n",
      "Current Testing Performance - Val: Loss 1.809  Acc(top1) 23.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss 1.689  Acc(top1) 24.615%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 24.615%\n",
      "Finished fine tuning.\n",
      "Iteration 1463/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1463\n",
      "\n",
      "Iteration 1464 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 19)]\n",
      "Input: 0.115 MB, Params: 263,824 (1.006 MB), Total: 1.12 MB, FLOPs: 72,490,775\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 29.231%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 30.769%\n",
      "Finished fine tuning.\n",
      "Iteration 1464/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1464\n",
      "\n",
      "Iteration 1465 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 17)]\n",
      "Input: 0.115 MB, Params: 263,012 (1.003 MB), Total: 1.12 MB, FLOPs: 71,854,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.769%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 29.231%\n",
      "Current Testing Performance - Val: Loss inf  Acc(top1) 29.231%\n",
      "Finished fine tuning.\n",
      "Iteration 1465/1625 finished in 0m03s\n",
      "Total channels prunned so far: 1465\n",
      "\n",
      "Iteration 1466 of 1623 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 261,858 (0.999 MB), Total: 1.11 MB, FLOPs: 71,646,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.154%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
