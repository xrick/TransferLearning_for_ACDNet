{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15eb05a5-0216-4c21-9226-27bca5bb4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import random;\n",
    "import time;\n",
    "import torch\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "886f8b70-1961-4c4f-823f-55393ff9c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import th.resources.train_generator as train_generator;\n",
    "import th.resources.pruning_tools.weight_pruning as weight_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd58c73b-11bf-48dc-895b-0959625f38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb31f54-0d24-4942-ad4c-f498900e61d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f626e5-5ed6-4aef-908f-2a39342bb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([(17,1),(18,2),(24,3),\n",
    "                             (51,4),(52,5),(53,6)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d298ee4-f3f7-4001-8224-54b8817a2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;\n",
    "###########################################\n",
    "\n",
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  6 #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = 6\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=6, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d0fab78-4fcd-4cd2-88c8-032daf68fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acdnet_model = GetCustomedACDNetModel()\n",
    "# pretrain_weight= torch.load('./th/resources/pretrained_models/acdnet_20khz_trained_model_fold4_91.00.pt', map_location=torch.device('cpu'))['weight']\n",
    "# model_state = acdnet_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2c8d8d4-86db-4d94-9910-b970ac6434d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acdnet_model)\n",
    "# print(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22423f68-d925-450f-a24b-567422ef736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 5;#64;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 10;#2000;\n",
    "    opt.LR = 0.01#0.1;\n",
    "    opt.schedule = [0.03, 0.06, 0.09]#[0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 6#50;\n",
    "    opt.nFolds = 1;#5;\n",
    "    opt.split = 1#[i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 16000#20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 5;\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48a4c5d5-e2b4-4775-b7f6-4de0c5147e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(\"./datasets/fold1_dataset.npz\", allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec8011c4-e99c-4675-b692-204ee0cfd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        #Conditional compression settings\n",
    "        self.opt.LR = 0.01;\n",
    "        self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "        self.opt.warmup = 0;\n",
    "        self.opt.prune_ratio = 0.95;\n",
    "        self.opt.prune_algo = 'l0norm';\n",
    "        self.opt.prune_interval = 1;\n",
    "        self.opt.nEpochs = 20;\n",
    "\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.start_time = time.time();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        self.load_test_data();\n",
    "        print(self.device);\n",
    "        loss_func = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "\n",
    "        #Load saved model dict\n",
    "        net = GetCustomedACDNetModel()\n",
    "        net.load_state_dict(torch.load(\"./th/trained_models/tlacdnet_torch_model_20231226.pt\", map_location=self.device)['weight']);\n",
    "        # dir = os.getcwd();\n",
    "        # net = models.GetACDNetModel().to(self.device);\n",
    "        # file_paths = glob.glob(self.opt.model_path);\n",
    "        # if len(file_paths)>0 and os.path.isfile(file_paths[0]):\n",
    "        #     net.load_state_dict(torch.load(file_paths[0], map_location=self.device)['weight']);\n",
    "        #     print('Model Loaded from: {}'.format(file_paths[0]));\n",
    "        # else:\n",
    "        #     print('Model is not found at: {}'.format(net_path));\n",
    "        #     exit();\n",
    "\n",
    "        calc.summary(net, (1,1,self.opt.inputLength))\n",
    "        net.eval();\n",
    "        val_acc, val_loss = self.__validate(net, loss_func);\n",
    "        print('Testing - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(val_loss, val_acc));\n",
    "        net.train();\n",
    "\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True)\n",
    "\n",
    "        weight_name = [\"weight\"]# if not self.opt.factorize else [\"weightA\", \"weightB\", \"weightC\"]\n",
    "        layers_n = weight_pruner.layers_n(net, param_name=[\"weight\"])[1];\n",
    "        all_num = sum(layers_n.values());\n",
    "        print(\"\\t TOTAL PRUNABLE PARAMS: {}\".format(all_num));\n",
    "        print(\"\\t PRUNE RATIO :{}\".format(self.opt.prune_ratio));\n",
    "        sparse_factor = int(all_num * (1-self.opt.prune_ratio));\n",
    "        print(\"\\t SPARSE FACTOR: {}\".format(sparse_factor));\n",
    "        model_size = (sparse_factor * 4)/1024**2;\n",
    "        print(\"\\t MODEL SIZE: {:.2f} MB\".format(model_size));\n",
    "        prune_algo = getattr(weight_pruner, self.opt.prune_algo);\n",
    "        prune_func = lambda m: prune_algo(m, sparse_factor, param_name=weight_name);\n",
    "\n",
    "        for epoch_idx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epoch_idx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            net.train();\n",
    "            for batch_idx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batch_idx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.device);\n",
    "                y = torch.tensor(y).to(self.device);\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(x);\n",
    "                running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                loss = loss_func(outputs.log(), y);\n",
    "\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    prune_func(net);\n",
    "\n",
    "            prune_func(net)\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, loss_func);\n",
    "            #Save best model\n",
    "            self.__save_model(val_acc, epoch_idx, net);\n",
    "\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epoch_idx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - self.start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(\"./datasets/fold1_test16000_65batch.npz\", allow_pickle=True);\n",
    "            self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "            self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                scores = net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, epoch_start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - epoch_start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        total_time = time.time() - self.start_time;\n",
    "        line = '{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            U.to_hms(total_time), epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def __save_model(self, acc, epochIdx, net):\n",
    "        if acc > self.bestAcc:\n",
    "            dir = os.getcwd();\n",
    "            fname = \"{}/th/pruned_models/{}.pt\";\n",
    "            old_model = fname.format(dir, self.opt.model_name.lower());\n",
    "            if os.path.isfile(old_model):\n",
    "                os.remove(old_model);\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname.format(dir, self.opt.model_name.lower()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb69075-8799-469d-b9c1-a545cee964d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9fd15f0-cbdf-4b2f-b3c9-96f694eb4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    opt.sr = 16000#20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    opt.prune_ratio = 0.95\n",
    "    # import torch;\n",
    "    opt.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.model_name = \"acdnet_tl_pruning_model\"\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8780ef94-ad0c-46bc-abb9-a5573b8b3480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:65\n",
      "Start to pruning.....\n",
      "cpu\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (6, 2, 4)      3,072       24,576\n",
      " BatchNorm2d-42         (6, 2, 4)         (6, 2, 4)         12            0\n",
      "        ReLu-43         (6, 2, 4)         (6, 2, 4)          0           48\n",
      "   AvgPool2d-44         (6, 2, 4)         (6, 1, 1)          0           48\n",
      "     Flatten-45         (6, 1, 1)            (1, 6)          0            0\n",
      "      Linear-46            (1, 6)            (1, 6)         42           42\n",
      "     Softmax-47            (1, 6)            (1, 6)          0            6\n",
      "==============================================================================\n",
      "Total Params: 4,710,254\n",
      "Total FLOPs : 544,238,560\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.97\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Testing - Val: Loss nan  Acc(top1) 32.308%\n",
      "\t TOTAL PRUNABLE PARAMS: 4706188\n",
      "\t PRUNE RATIO :0.95\n",
      "\t SPARSE FACTOR: 235309\n",
      "\t MODEL SIZE: 0.90 MB\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.3233005  0.67669946 0.         0.         0.        ]\n",
      " [0.         0.6020187  0.         0.39798126 0.         0.        ]\n",
      " [0.75880736 0.         0.         0.         0.         0.24119264]\n",
      " [0.         0.         0.         0.10221028 0.8977897  0.        ]\n",
      " [0.         0.         0.9211998  0.         0.0788002  0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.9852215  0.         0.         0.         0.         0.01477848]\n",
      " [0.79049295 0.20950703 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.26994783 0.         0.         0.7300522 ]\n",
      " [0.         0.         0.         0.         0.1949542  0.8050458 ]\n",
      " [0.         0.         0.21262655 0.         0.         0.7873735 ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.7372584  0.2627416  0.         0.        ]\n",
      " [0.         0.8471587  0.         0.         0.         0.15284131]\n",
      " [0.         0.         0.1392203  0.8607797  0.         0.        ]\n",
      " [0.         0.         0.15815775 0.         0.84184223 0.        ]\n",
      " [0.         0.         0.         0.7015552  0.29844478 0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.32415605 0.         0.         0.         0.         0.67584395]\n",
      " [0.08565345 0.         0.         0.         0.9143466  0.        ]\n",
      " [0.         0.7349434  0.26505664 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.3989923  0.         0.6010077 ]\n",
      " [0.06402589 0.         0.         0.9359741  0.         0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.5141561  0.         0.         0.         0.48584387]\n",
      " [0.         0.         0.         0.78461945 0.         0.21538058]\n",
      " [0.         0.5329753  0.         0.         0.         0.46702465]\n",
      " [0.53628576 0.         0.         0.         0.46371424 0.        ]\n",
      " [0.         0.         0.         0.         0.90209126 0.09790873]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.5186416  0.4813584  0.         0.         0.        ]\n",
      " [0.         0.28524923 0.         0.         0.         0.71475077]\n",
      " [0.         0.         0.         0.7357372  0.         0.26426283]\n",
      " [0.         0.84256727 0.         0.         0.15743273 0.        ]\n",
      " [0.         0.         0.40377554 0.         0.         0.5962244 ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.4772173  0.         0.52278274 0.        ]\n",
      " [0.         0.         0.         0.         0.54277545 0.45722458]\n",
      " [0.         0.06674062 0.         0.93325937 0.         0.        ]\n",
      " [0.6974829  0.         0.         0.         0.30251715 0.        ]\n",
      " [0.         0.         0.26446593 0.         0.7355341  0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.         0.         0.31250286 0.68749714]\n",
      " [0.         0.9964543  0.         0.         0.00354569 0.        ]\n",
      " [0.         0.         0.         0.         0.0096697  0.9903303 ]\n",
      " [0.         0.8725545  0.         0.         0.         0.12744552]\n",
      " [0.21988375 0.         0.78011626 0.         0.         0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.8814162  0.         0.         0.         0.         0.1185838 ]\n",
      " [0.6174583  0.         0.         0.         0.38254172 0.        ]\n",
      " [0.         0.         0.         0.22292355 0.         0.7770764 ]\n",
      " [0.35114613 0.         0.         0.         0.6488539  0.        ]\n",
      " [0.         0.9617428  0.         0.         0.0382572  0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.2547225  0.         0.         0.         0.74527746 0.        ]\n",
      " [0.         0.         0.6231554  0.         0.         0.37684458]\n",
      " [0.         0.5544125  0.         0.         0.44558752 0.        ]\n",
      " [0.30387494 0.         0.         0.         0.         0.69612503]\n",
      " [0.         0.         0.         0.34114924 0.6588507  0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.1934371  0.         0.         0.8065629  0.        ]\n",
      " [0.         0.         0.45541617 0.         0.54458386 0.        ]\n",
      " [0.10734017 0.         0.         0.         0.         0.89265984]\n",
      " [0.         0.         0.24919827 0.75080174 0.         0.        ]\n",
      " [0.         0.4045477  0.         0.5954523  0.         0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.         0.23418632 0.         0.7658137 ]\n",
      " [0.         0.         0.31970957 0.         0.68029046 0.        ]\n",
      " [0.         0.4148679  0.         0.         0.         0.5851321 ]\n",
      " [0.14326797 0.         0.         0.856732   0.         0.        ]\n",
      " [0.853448   0.         0.         0.14655206 0.         0.        ]]\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "sound length after U.mix is 30225\n",
      "sound length after U.random_gain is 30225\n",
      "labels in generate_batch is:\n",
      "[[0.38885722 0.         0.         0.         0.         0.6111428 ]\n",
      " [0.02696645 0.         0.         0.         0.         0.97303355]\n",
      " [0.         0.05028464 0.9497154  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.74772847 0.         0.25227153]\n",
      " [0.9496117  0.         0.         0.         0.         0.05038827]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /home/ai/RLRepo/Works/Projects/TransferLearning_for_ACDNet/torch/pruned_models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m PruningTrainer(opt)\u001b[38;5;66;03m#TLTrainer(opt)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to pruning.....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPruneAndTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 99\u001b[0m, in \u001b[0;36mPruningTrainer.PruneAndTrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__validate(net, loss_func);\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#Save best model\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_epoch_end(epoch_start_time, epoch_train_time, epoch_idx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n\u001b[1;32m    103\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m;\n",
      "Cell \u001b[0;32mIn[54], line 167\u001b[0m, in \u001b[0;36mPruningTrainer.__save_model\u001b[0;34m(self, acc, epochIdx, net)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbestAcc \u001b[38;5;241m=\u001b[39m acc;\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbestAccEpoch \u001b[38;5;241m=\u001b[39m epochIdx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m;\n\u001b[0;32m--> 167\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mch_config\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    619\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/serialization.py:492\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/serialization.py:463\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /home/ai/RLRepo/Works/Projects/TransferLearning_for_ACDNet/torch/pruned_models does not exist."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae31fa-cf50-449c-88b3-fdca70c66228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
