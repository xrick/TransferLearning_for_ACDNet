{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from refine_codes.SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36995275-4419-4d02-a744-3d37ef85e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genDataTimeStr():\n",
    "#     return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([(52,1),(99,2)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/forOneClassModel_alarm/train_test_npz/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=2, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 2 #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        self.opt.device = 'mps'#at home use apple m2\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel();\n",
    "        self.net.load_state_dict(torch.load(\"../retrained_models_after_first_stage_pruning/pruning_time_2024021123_prunratio0.7/retrained_model_after_first_pruning_0.7ratio_acc97.7272720336914_11th_epoch_20240211230408.pt\", map_location=\"mps\")['weight']);\n",
    "        self.net = self.net.to('mps');#at home use apple m2\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        print(f\"pruning algorithm is {self.pruner}\");\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);#in office, use cuda(better) or cpu\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # if self.opt.device == \"mps\":\n",
    "            #     y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                label = label.cpu() #use apple m2, in office use cuda\n",
    "                output = output.cpu() #use apple m2, in office use cuda\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # if self.opt.device == \"mps\":\n",
    "                #     x = torch.tensor(x)\n",
    "                #     x = x.type(torch.FloatTensor) # use apple mp2\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 32;\n",
    "    # opt.LR = 0.01;\n",
    "    # opt.momentum = 0.09;\n",
    "    # opt.weightDecay = 5e-3;\n",
    "    # opt.nEpochs = 1000;#2000;\n",
    "    # opt.schedule = [0.03, 0.06, 0.09]\n",
    "    # opt.warmup = 10;\n",
    "    #set train and validation sets\n",
    "    opt.trainSet = \"../../datasets/CurrentUse/forOneClassModel_alarm/train/trainSet_20240119002902.npz\"\n",
    "    opt.valSet = \"../../datasets/CurrentUse/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz\"\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.nClasses = 2\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    \n",
    "    # import torch;\n",
    "    # opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use cuda or cpu\n",
    "    opt.device = 'mps' #at home use apple m2\n",
    "    # tlopts.display_info(opt)\n",
    "    save_dir = \"../../th/pruned_models/second_stage_pruned_models/pruning_time_{}_prunratio{}/\".format(getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    model_name = \"model_second_stage_prun_{}.pt\".format(genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:325\n",
      "Start to pruning.....\n",
      "pruning algorithm is <th.resources.pruning_tools.filter_pruning.Taylor object at 0x28a6e5e90>\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (2, 2, 4)      1,024        8,192\n",
      " BatchNorm2d-42         (2, 2, 4)         (2, 2, 4)          4            0\n",
      "        ReLu-43         (2, 2, 4)         (2, 2, 4)          0           16\n",
      "   AvgPool2d-44         (2, 2, 4)         (2, 1, 1)          0           16\n",
      "     Flatten-45         (2, 1, 1)            (1, 2)          0            0\n",
      "      Linear-46            (1, 2)            (1, 2)          6            6\n",
      "     Softmax-47            (1, 2)            (1, 2)          0            2\n",
      "==============================================================================\n",
      "Total Params: 4,708,162\n",
      "Total FLOPs : 544,222,072\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2026, Prunable: 2026, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1721\n",
      "Total iterations required: 1721\n",
      "\n",
      "Iteration 1 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,708,120 (17.960 MB), Total: 18.08 MB, FLOPs: 483,662,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,708,078 (17.960 MB), Total: 18.08 MB, FLOPs: 483,296,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1723 finished in 0m08s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,708,036 (17.960 MB), Total: 18.08 MB, FLOPs: 478,764,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.636%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1723 finished in 0m08s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,994 (17.960 MB), Total: 18.07 MB, FLOPs: 478,399,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1723 finished in 0m08s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,952 (17.959 MB), Total: 18.07 MB, FLOPs: 465,664,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1723 finished in 0m09s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,707,910 (17.959 MB), Total: 18.07 MB, FLOPs: 465,299,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1723 finished in 0m08s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,868 (17.959 MB), Total: 18.07 MB, FLOPs: 460,767,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1723 finished in 0m08s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,826 (17.959 MB), Total: 18.07 MB, FLOPs: 460,401,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1723 finished in 0m08s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,707,784 (17.959 MB), Total: 18.07 MB, FLOPs: 431,723,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1723 finished in 0m09s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,707,742 (17.959 MB), Total: 18.07 MB, FLOPs: 431,357,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1723 finished in 0m08s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,707,700 (17.958 MB), Total: 18.07 MB, FLOPs: 426,825,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1723 finished in 0m08s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 26)]\n",
      "Input: 0.115 MB, Params: 4,707,113 (17.956 MB), Total: 18.07 MB, FLOPs: 425,614,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1723 finished in 0m08s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,700,199 (17.930 MB), Total: 18.05 MB, FLOPs: 425,241,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1723 finished in 0m07s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 4,693,294 (17.903 MB), Total: 18.02 MB, FLOPs: 425,054,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1723 finished in 0m07s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 493)]\n",
      "Input: 0.115 MB, Params: 4,688,691 (17.886 MB), Total: 18.00 MB, FLOPs: 424,930,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1723 finished in 0m07s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.115 MB, Params: 4,685,233 (17.873 MB), Total: 17.99 MB, FLOPs: 424,126,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1723 finished in 0m07s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 454)]\n",
      "Input: 0.115 MB, Params: 4,678,337 (17.846 MB), Total: 17.96 MB, FLOPs: 423,940,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1723 finished in 0m07s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 345)]\n",
      "Input: 0.115 MB, Params: 4,673,743 (17.829 MB), Total: 17.94 MB, FLOPs: 423,816,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1723 finished in 0m07s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 405)]\n",
      "Input: 0.115 MB, Params: 4,669,149 (17.811 MB), Total: 17.93 MB, FLOPs: 423,692,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1723 finished in 0m07s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.115 MB, Params: 4,664,555 (17.794 MB), Total: 17.91 MB, FLOPs: 423,568,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1723 finished in 0m07s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 4,659,961 (17.776 MB), Total: 17.89 MB, FLOPs: 423,444,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1723 finished in 0m07s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 4,653,101 (17.750 MB), Total: 17.87 MB, FLOPs: 423,259,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1723 finished in 0m07s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 4,646,241 (17.724 MB), Total: 17.84 MB, FLOPs: 423,074,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1723 finished in 0m07s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 4,641,665 (17.707 MB), Total: 17.82 MB, FLOPs: 422,950,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1723 finished in 0m07s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 178)]\n",
      "Input: 0.115 MB, Params: 4,634,787 (17.680 MB), Total: 17.80 MB, FLOPs: 422,578,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1723 finished in 0m08s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 154)]\n",
      "Input: 0.115 MB, Params: 4,627,945 (17.654 MB), Total: 17.77 MB, FLOPs: 422,393,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1723 finished in 0m07s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 138)]\n",
      "Input: 0.115 MB, Params: 4,621,076 (17.628 MB), Total: 17.74 MB, FLOPs: 422,021,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1723 finished in 0m07s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 4,616,509 (17.611 MB), Total: 17.73 MB, FLOPs: 421,898,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1723 finished in 0m08s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 231)]\n",
      "Input: 0.115 MB, Params: 4,609,640 (17.584 MB), Total: 17.70 MB, FLOPs: 421,525,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1723 finished in 0m07s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 4,605,073 (17.567 MB), Total: 17.68 MB, FLOPs: 421,402,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1723 finished in 0m08s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.115 MB, Params: 4,600,506 (17.550 MB), Total: 17.66 MB, FLOPs: 421,279,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1723 finished in 0m08s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 475)]\n",
      "Input: 0.115 MB, Params: 4,595,939 (17.532 MB), Total: 17.65 MB, FLOPs: 421,156,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1723 finished in 0m08s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 410)]\n",
      "Input: 0.115 MB, Params: 4,591,372 (17.515 MB), Total: 17.63 MB, FLOPs: 421,032,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1723 finished in 0m08s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 428)]\n",
      "Input: 0.115 MB, Params: 4,586,805 (17.497 MB), Total: 17.61 MB, FLOPs: 420,909,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1723 finished in 0m08s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 4,580,035 (17.471 MB), Total: 17.59 MB, FLOPs: 420,726,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1723 finished in 0m07s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.115 MB, Params: 4,579,993 (17.471 MB), Total: 17.59 MB, FLOPs: 420,362,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1723 finished in 0m07s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 4,575,435 (17.454 MB), Total: 17.57 MB, FLOPs: 420,239,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1723 finished in 0m08s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 388)]\n",
      "Input: 0.115 MB, Params: 4,570,877 (17.437 MB), Total: 17.55 MB, FLOPs: 420,116,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1723 finished in 0m08s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 4,566,319 (17.419 MB), Total: 17.53 MB, FLOPs: 419,993,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1723 finished in 0m08s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 362)]\n",
      "Input: 0.115 MB, Params: 4,561,761 (17.402 MB), Total: 17.52 MB, FLOPs: 419,870,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1723 finished in 0m08s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.115 MB, Params: 4,558,348 (17.389 MB), Total: 17.50 MB, FLOPs: 419,502,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1723 finished in 0m07s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 206)]\n",
      "Input: 0.115 MB, Params: 4,551,497 (17.363 MB), Total: 17.48 MB, FLOPs: 419,131,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1723 finished in 0m07s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 4,546,939 (17.345 MB), Total: 17.46 MB, FLOPs: 419,008,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1723 finished in 0m08s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.115 MB, Params: 4,545,218 (17.339 MB), Total: 17.45 MB, FLOPs: 418,180,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1723 finished in 0m07s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 448)]\n",
      "Input: 0.115 MB, Params: 4,538,502 (17.313 MB), Total: 17.43 MB, FLOPs: 417,999,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1723 finished in 0m07s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 51)]\n",
      "Input: 0.115 MB, Params: 4,535,062 (17.300 MB), Total: 17.42 MB, FLOPs: 417,201,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1723 finished in 0m07s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 413)]\n",
      "Input: 0.115 MB, Params: 4,528,346 (17.274 MB), Total: 17.39 MB, FLOPs: 417,019,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1723 finished in 0m07s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 4,523,806 (17.257 MB), Total: 17.37 MB, FLOPs: 416,897,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1723 finished in 0m07s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 354)]\n",
      "Input: 0.115 MB, Params: 4,519,266 (17.240 MB), Total: 17.35 MB, FLOPs: 416,774,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1723 finished in 0m08s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 4,514,726 (17.222 MB), Total: 17.34 MB, FLOPs: 416,652,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1723 finished in 0m08s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 137)]\n",
      "Input: 0.115 MB, Params: 4,510,186 (17.205 MB), Total: 17.32 MB, FLOPs: 416,529,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1723 finished in 0m08s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 4,503,506 (17.180 MB), Total: 17.29 MB, FLOPs: 416,349,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1723 finished in 0m07s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 433)]\n",
      "Input: 0.115 MB, Params: 4,498,975 (17.162 MB), Total: 17.28 MB, FLOPs: 416,227,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1723 finished in 0m07s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.115 MB, Params: 4,495,580 (17.149 MB), Total: 17.26 MB, FLOPs: 415,860,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1723 finished in 0m07s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 389)]\n",
      "Input: 0.115 MB, Params: 4,491,049 (17.132 MB), Total: 17.25 MB, FLOPs: 415,738,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1723 finished in 0m07s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 234)]\n",
      "Input: 0.115 MB, Params: 4,484,234 (17.106 MB), Total: 17.22 MB, FLOPs: 415,368,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1723 finished in 0m07s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 266)]\n",
      "Input: 0.115 MB, Params: 4,479,703 (17.089 MB), Total: 17.20 MB, FLOPs: 415,246,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1723 finished in 0m07s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 4,475,172 (17.071 MB), Total: 17.19 MB, FLOPs: 415,124,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1723 finished in 0m07s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 4,470,641 (17.054 MB), Total: 17.17 MB, FLOPs: 415,002,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1723 finished in 0m07s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 4,466,110 (17.037 MB), Total: 17.15 MB, FLOPs: 414,879,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1723 finished in 0m07s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.115 MB, Params: 4,464,389 (17.030 MB), Total: 17.15 MB, FLOPs: 413,202,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1723 finished in 0m07s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.115 MB, Params: 4,457,772 (17.005 MB), Total: 17.12 MB, FLOPs: 413,024,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1723 finished in 0m07s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 4,451,155 (16.980 MB), Total: 17.10 MB, FLOPs: 412,845,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1723 finished in 0m07s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 241)]\n",
      "Input: 0.115 MB, Params: 4,444,358 (16.954 MB), Total: 17.07 MB, FLOPs: 412,476,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1723 finished in 0m07s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 458)]\n",
      "Input: 0.115 MB, Params: 4,439,845 (16.937 MB), Total: 17.05 MB, FLOPs: 412,355,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1723 finished in 0m08s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 373)]\n",
      "Input: 0.115 MB, Params: 4,433,246 (16.911 MB), Total: 17.03 MB, FLOPs: 412,176,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1723 finished in 0m07s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 394)]\n",
      "Input: 0.115 MB, Params: 4,428,742 (16.894 MB), Total: 17.01 MB, FLOPs: 412,055,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1723 finished in 0m07s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 51)]\n",
      "Input: 0.115 MB, Params: 4,422,152 (16.869 MB), Total: 16.98 MB, FLOPs: 411,877,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1723 finished in 0m07s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 219)]\n",
      "Input: 0.115 MB, Params: 4,415,373 (16.843 MB), Total: 16.96 MB, FLOPs: 411,509,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1723 finished in 0m07s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.115 MB, Params: 4,408,792 (16.818 MB), Total: 16.93 MB, FLOPs: 411,331,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1723 finished in 0m07s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 4,402,211 (16.793 MB), Total: 16.91 MB, FLOPs: 411,153,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1723 finished in 0m07s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 4,397,734 (16.776 MB), Total: 16.89 MB, FLOPs: 411,032,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1723 finished in 0m07s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 4,394,366 (16.763 MB), Total: 16.88 MB, FLOPs: 410,669,341\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1723 finished in 0m07s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 4,387,794 (16.738 MB), Total: 16.85 MB, FLOPs: 410,491,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1723 finished in 0m07s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 4,387,752 (16.738 MB), Total: 16.85 MB, FLOPs: 398,036,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1723 finished in 0m10s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 4,383,284 (16.721 MB), Total: 16.84 MB, FLOPs: 397,916,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1723 finished in 0m08s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 4,378,816 (16.704 MB), Total: 16.82 MB, FLOPs: 397,795,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1723 finished in 0m08s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 421)]\n",
      "Input: 0.115 MB, Params: 4,372,262 (16.679 MB), Total: 16.79 MB, FLOPs: 397,618,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1723 finished in 0m07s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.115 MB, Params: 4,365,528 (16.653 MB), Total: 16.77 MB, FLOPs: 397,252,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1723 finished in 0m07s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 197)]\n",
      "Input: 0.115 MB, Params: 4,358,983 (16.628 MB), Total: 16.74 MB, FLOPs: 397,075,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1723 finished in 0m07s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 4,354,533 (16.611 MB), Total: 16.73 MB, FLOPs: 396,955,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1723 finished in 0m08s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 4,347,997 (16.586 MB), Total: 16.70 MB, FLOPs: 396,778,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1723 finished in 0m07s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 4,341,461 (16.561 MB), Total: 16.68 MB, FLOPs: 396,602,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1723 finished in 0m07s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 404)]\n",
      "Input: 0.115 MB, Params: 4,334,925 (16.536 MB), Total: 16.65 MB, FLOPs: 396,425,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1723 finished in 0m07s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 464)]\n",
      "Input: 0.115 MB, Params: 4,330,502 (16.520 MB), Total: 16.63 MB, FLOPs: 396,306,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1723 finished in 0m08s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 232)]\n",
      "Input: 0.115 MB, Params: 4,326,079 (16.503 MB), Total: 16.62 MB, FLOPs: 396,187,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1723 finished in 0m08s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 4,319,381 (16.477 MB), Total: 16.59 MB, FLOPs: 395,821,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1723 finished in 0m08s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 457)]\n",
      "Input: 0.115 MB, Params: 4,312,872 (16.452 MB), Total: 16.57 MB, FLOPs: 395,646,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1723 finished in 0m07s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 378)]\n",
      "Input: 0.115 MB, Params: 4,306,363 (16.427 MB), Total: 16.54 MB, FLOPs: 395,470,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1723 finished in 0m07s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.115 MB, Params: 4,301,958 (16.411 MB), Total: 16.53 MB, FLOPs: 395,351,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1723 finished in 0m07s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 4,295,458 (16.386 MB), Total: 16.50 MB, FLOPs: 395,176,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1723 finished in 0m07s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 4,291,062 (16.369 MB), Total: 16.48 MB, FLOPs: 395,057,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1723 finished in 0m07s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 4,286,666 (16.352 MB), Total: 16.47 MB, FLOPs: 394,938,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1723 finished in 0m08s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.115 MB, Params: 4,282,270 (16.336 MB), Total: 16.45 MB, FLOPs: 394,820,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1723 finished in 0m08s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.115 MB, Params: 4,275,599 (16.310 MB), Total: 16.43 MB, FLOPs: 394,455,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1723 finished in 0m08s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.115 MB, Params: 4,273,878 (16.304 MB), Total: 16.42 MB, FLOPs: 392,864,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1723 finished in 0m08s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 431)]\n",
      "Input: 0.115 MB, Params: 4,269,482 (16.287 MB), Total: 16.40 MB, FLOPs: 392,745,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1723 finished in 0m08s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 4,265,086 (16.270 MB), Total: 16.39 MB, FLOPs: 392,626,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1723 finished in 0m08s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 4,260,690 (16.253 MB), Total: 16.37 MB, FLOPs: 392,508,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1723 finished in 0m08s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 422)]\n",
      "Input: 0.115 MB, Params: 4,256,294 (16.236 MB), Total: 16.35 MB, FLOPs: 392,389,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1723 finished in 0m08s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 227)]\n",
      "Input: 0.115 MB, Params: 4,249,866 (16.212 MB), Total: 16.33 MB, FLOPs: 392,216,171\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1723 finished in 0m07s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 374)]\n",
      "Input: 0.115 MB, Params: 4,243,438 (16.187 MB), Total: 16.30 MB, FLOPs: 392,042,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1723 finished in 0m07s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 4,241,744 (16.181 MB), Total: 16.30 MB, FLOPs: 391,290,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1723 finished in 0m07s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 471)]\n",
      "Input: 0.115 MB, Params: 4,235,316 (16.156 MB), Total: 16.27 MB, FLOPs: 391,117,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1723 finished in 0m07s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 4,230,947 (16.140 MB), Total: 16.26 MB, FLOPs: 390,999,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1723 finished in 0m07s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.115 MB, Params: 4,224,528 (16.115 MB), Total: 16.23 MB, FLOPs: 390,826,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1723 finished in 0m07s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 473)]\n",
      "Input: 0.115 MB, Params: 4,218,109 (16.091 MB), Total: 16.21 MB, FLOPs: 390,652,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1723 finished in 0m07s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.115 MB, Params: 4,213,758 (16.074 MB), Total: 16.19 MB, FLOPs: 390,535,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1723 finished in 0m07s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 415)]\n",
      "Input: 0.115 MB, Params: 4,209,407 (16.058 MB), Total: 16.17 MB, FLOPs: 390,418,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1723 finished in 0m08s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 4,205,056 (16.041 MB), Total: 16.16 MB, FLOPs: 390,300,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1723 finished in 0m08s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 372)]\n",
      "Input: 0.115 MB, Params: 4,200,705 (16.024 MB), Total: 16.14 MB, FLOPs: 390,183,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1723 finished in 0m08s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 4,196,354 (16.008 MB), Total: 16.12 MB, FLOPs: 390,065,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1723 finished in 0m08s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 119)]\n",
      "Input: 0.115 MB, Params: 4,192,941 (15.995 MB), Total: 16.11 MB, FLOPs: 389,315,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1723 finished in 0m08s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 21)]\n",
      "Input: 0.115 MB, Params: 4,191,229 (15.988 MB), Total: 16.10 MB, FLOPs: 387,728,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1723 finished in 0m08s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 362)]\n",
      "Input: 0.115 MB, Params: 4,186,878 (15.972 MB), Total: 16.09 MB, FLOPs: 387,610,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1723 finished in 0m08s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 4,182,527 (15.955 MB), Total: 16.07 MB, FLOPs: 387,493,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1723 finished in 0m08s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.115 MB, Params: 4,176,171 (15.931 MB), Total: 16.05 MB, FLOPs: 387,321,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1723 finished in 0m07s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 340)]\n",
      "Input: 0.115 MB, Params: 4,169,815 (15.907 MB), Total: 16.02 MB, FLOPs: 387,150,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1723 finished in 0m07s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 4,165,482 (15.890 MB), Total: 16.01 MB, FLOPs: 387,033,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1723 finished in 0m07s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 4,159,135 (15.866 MB), Total: 15.98 MB, FLOPs: 386,862,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1723 finished in 0m07s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 329)]\n",
      "Input: 0.115 MB, Params: 4,154,811 (15.849 MB), Total: 15.96 MB, FLOPs: 386,745,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1723 finished in 0m07s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 170)]\n",
      "Input: 0.115 MB, Params: 4,148,212 (15.824 MB), Total: 15.94 MB, FLOPs: 386,382,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1723 finished in 0m08s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 4,143,888 (15.808 MB), Total: 15.92 MB, FLOPs: 386,265,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1723 finished in 0m08s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 446)]\n",
      "Input: 0.115 MB, Params: 4,139,564 (15.791 MB), Total: 15.91 MB, FLOPs: 386,149,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1723 finished in 0m08s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 188)]\n",
      "Input: 0.115 MB, Params: 4,136,241 (15.779 MB), Total: 15.89 MB, FLOPs: 385,790,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1723 finished in 0m07s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 442)]\n",
      "Input: 0.115 MB, Params: 4,129,930 (15.754 MB), Total: 15.87 MB, FLOPs: 385,620,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1723 finished in 0m07s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 132)]\n",
      "Input: 0.115 MB, Params: 4,126,607 (15.742 MB), Total: 15.86 MB, FLOPs: 385,261,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1723 finished in 0m07s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 4,120,296 (15.718 MB), Total: 15.83 MB, FLOPs: 385,090,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1723 finished in 0m07s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 4,113,985 (15.694 MB), Total: 15.81 MB, FLOPs: 384,920,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1723 finished in 0m07s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.115 MB, Params: 4,109,688 (15.677 MB), Total: 15.79 MB, FLOPs: 384,804,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1723 finished in 0m07s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 169)]\n",
      "Input: 0.115 MB, Params: 4,103,134 (15.652 MB), Total: 15.77 MB, FLOPs: 384,444,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1723 finished in 0m08s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 329)]\n",
      "Input: 0.115 MB, Params: 4,098,837 (15.636 MB), Total: 15.75 MB, FLOPs: 384,328,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1723 finished in 0m08s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 4,094,540 (15.619 MB), Total: 15.73 MB, FLOPs: 384,212,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1723 finished in 0m08s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 4,090,243 (15.603 MB), Total: 15.72 MB, FLOPs: 384,096,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1723 finished in 0m08s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 353)]\n",
      "Input: 0.115 MB, Params: 4,085,946 (15.587 MB), Total: 15.70 MB, FLOPs: 383,980,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1723 finished in 0m08s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 362)]\n",
      "Input: 0.115 MB, Params: 4,081,649 (15.570 MB), Total: 15.69 MB, FLOPs: 383,864,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1723 finished in 0m08s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 4,077,352 (15.554 MB), Total: 15.67 MB, FLOPs: 383,748,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1723 finished in 0m08s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.115 MB, Params: 4,073,055 (15.537 MB), Total: 15.65 MB, FLOPs: 383,632,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1723 finished in 0m08s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 346)]\n",
      "Input: 0.115 MB, Params: 4,066,825 (15.514 MB), Total: 15.63 MB, FLOPs: 383,464,637\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1723 finished in 0m07s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 4,063,511 (15.501 MB), Total: 15.62 MB, FLOPs: 383,106,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1723 finished in 0m07s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 153)]\n",
      "Input: 0.115 MB, Params: 4,056,975 (15.476 MB), Total: 15.59 MB, FLOPs: 382,747,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1723 finished in 0m07s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 312)]\n",
      "Input: 0.115 MB, Params: 4,050,754 (15.452 MB), Total: 15.57 MB, FLOPs: 382,580,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1723 finished in 0m07s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 4,044,533 (15.429 MB), Total: 15.54 MB, FLOPs: 382,412,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1723 finished in 0m07s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 4,040,263 (15.412 MB), Total: 15.53 MB, FLOPs: 382,296,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1723 finished in 0m08s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 393)]\n",
      "Input: 0.115 MB, Params: 4,035,993 (15.396 MB), Total: 15.51 MB, FLOPs: 382,181,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1723 finished in 0m08s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 4,029,790 (15.372 MB), Total: 15.49 MB, FLOPs: 382,014,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1723 finished in 0m07s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 104)]\n",
      "Input: 0.115 MB, Params: 4,026,485 (15.360 MB), Total: 15.48 MB, FLOPs: 381,657,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1723 finished in 0m07s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 162)]\n",
      "Input: 0.115 MB, Params: 4,020,282 (15.336 MB), Total: 15.45 MB, FLOPs: 381,489,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1723 finished in 0m07s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 304)]\n",
      "Input: 0.115 MB, Params: 4,016,030 (15.320 MB), Total: 15.44 MB, FLOPs: 381,375,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1723 finished in 0m07s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 352)]\n",
      "Input: 0.115 MB, Params: 4,011,778 (15.304 MB), Total: 15.42 MB, FLOPs: 381,260,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1723 finished in 0m08s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 413)]\n",
      "Input: 0.115 MB, Params: 4,005,593 (15.280 MB), Total: 15.40 MB, FLOPs: 381,093,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1723 finished in 0m07s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 330)]\n",
      "Input: 0.115 MB, Params: 3,999,408 (15.257 MB), Total: 15.37 MB, FLOPs: 380,926,433\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1723 finished in 0m07s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 3,992,935 (15.232 MB), Total: 15.35 MB, FLOPs: 380,569,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1723 finished in 0m08s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 3,986,759 (15.208 MB), Total: 15.32 MB, FLOPs: 380,403,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1723 finished in 0m07s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 113)]\n",
      "Input: 0.115 MB, Params: 3,985,083 (15.202 MB), Total: 15.32 MB, FLOPs: 379,659,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1723 finished in 0m07s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 309)]\n",
      "Input: 0.115 MB, Params: 3,980,858 (15.186 MB), Total: 15.30 MB, FLOPs: 379,545,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1723 finished in 0m08s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 3,974,691 (15.162 MB), Total: 15.28 MB, FLOPs: 379,379,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1723 finished in 0m07s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.115 MB, Params: 3,973,015 (15.156 MB), Total: 15.27 MB, FLOPs: 378,635,354\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1723 finished in 0m08s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 127)]\n",
      "Input: 0.115 MB, Params: 3,966,560 (15.131 MB), Total: 15.25 MB, FLOPs: 378,279,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1723 finished in 0m08s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.115 MB, Params: 3,960,402 (15.108 MB), Total: 15.22 MB, FLOPs: 378,113,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1723 finished in 0m07s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 247)]\n",
      "Input: 0.115 MB, Params: 3,957,115 (15.095 MB), Total: 15.21 MB, FLOPs: 377,758,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1723 finished in 0m07s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 392)]\n",
      "Input: 0.115 MB, Params: 3,952,908 (15.079 MB), Total: 15.19 MB, FLOPs: 377,644,727\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1723 finished in 0m08s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 418)]\n",
      "Input: 0.115 MB, Params: 3,946,759 (15.056 MB), Total: 15.17 MB, FLOPs: 377,478,731\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1723 finished in 0m07s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 162)]\n",
      "Input: 0.115 MB, Params: 3,940,331 (15.031 MB), Total: 15.15 MB, FLOPs: 377,124,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1723 finished in 0m08s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.115 MB, Params: 3,936,133 (15.015 MB), Total: 15.13 MB, FLOPs: 377,010,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1723 finished in 0m08s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 276)]\n",
      "Input: 0.115 MB, Params: 3,930,002 (14.992 MB), Total: 15.11 MB, FLOPs: 376,845,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1723 finished in 0m07s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 199)]\n",
      "Input: 0.115 MB, Params: 3,925,813 (14.976 MB), Total: 15.09 MB, FLOPs: 376,732,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1723 finished in 0m08s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.115 MB, Params: 3,921,624 (14.960 MB), Total: 15.08 MB, FLOPs: 376,619,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1723 finished in 0m08s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 3,917,435 (14.944 MB), Total: 15.06 MB, FLOPs: 376,506,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1723 finished in 0m08s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.115 MB, Params: 3,914,085 (14.931 MB), Total: 15.05 MB, FLOPs: 375,768,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1723 finished in 0m07s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.115 MB, Params: 3,910,735 (14.918 MB), Total: 15.03 MB, FLOPs: 375,031,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1723 finished in 0m08s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.115 MB, Params: 3,909,077 (14.912 MB), Total: 15.03 MB, FLOPs: 374,295,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1723 finished in 0m07s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 3,904,888 (14.896 MB), Total: 15.01 MB, FLOPs: 374,182,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1723 finished in 0m08s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.115 MB, Params: 3,900,699 (14.880 MB), Total: 15.00 MB, FLOPs: 374,069,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1723 finished in 0m08s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 3,894,613 (14.857 MB), Total: 14.97 MB, FLOPs: 373,905,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1723 finished in 0m07s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 3,891,353 (14.844 MB), Total: 14.96 MB, FLOPs: 373,553,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1723 finished in 0m07s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 272)]\n",
      "Input: 0.115 MB, Params: 3,887,173 (14.828 MB), Total: 14.94 MB, FLOPs: 373,440,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1723 finished in 0m08s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 3,882,993 (14.812 MB), Total: 14.93 MB, FLOPs: 373,327,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1723 finished in 0m08s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 224)]\n",
      "Input: 0.115 MB, Params: 3,879,733 (14.800 MB), Total: 14.92 MB, FLOPs: 372,975,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1723 finished in 0m07s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 350)]\n",
      "Input: 0.115 MB, Params: 3,875,553 (14.784 MB), Total: 14.90 MB, FLOPs: 372,862,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1723 finished in 0m08s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 58)]\n",
      "Input: 0.115 MB, Params: 3,873,868 (14.778 MB), Total: 14.89 MB, FLOPs: 371,287,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1723 finished in 0m08s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 3,867,476 (14.753 MB), Total: 14.87 MB, FLOPs: 370,935,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1723 finished in 0m08s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 3,861,426 (14.730 MB), Total: 14.85 MB, FLOPs: 370,772,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1723 finished in 0m07s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 237)]\n",
      "Input: 0.115 MB, Params: 3,857,255 (14.714 MB), Total: 14.83 MB, FLOPs: 370,659,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1723 finished in 0m08s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 3,857,213 (14.714 MB), Total: 14.83 MB, FLOPs: 370,295,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1723 finished in 0m09s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 121)]\n",
      "Input: 0.115 MB, Params: 3,853,890 (14.701 MB), Total: 14.82 MB, FLOPs: 369,564,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1723 finished in 0m08s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 3,849,719 (14.686 MB), Total: 14.80 MB, FLOPs: 369,451,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1723 finished in 0m08s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 3,845,548 (14.670 MB), Total: 14.78 MB, FLOPs: 369,339,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1723 finished in 0m08s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 3,841,377 (14.654 MB), Total: 14.77 MB, FLOPs: 369,226,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1723 finished in 0m08s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 3,837,206 (14.638 MB), Total: 14.75 MB, FLOPs: 369,114,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1723 finished in 0m08s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 3,831,201 (14.615 MB), Total: 14.73 MB, FLOPs: 368,951,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1723 finished in 0m07s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.115 MB, Params: 3,824,827 (14.591 MB), Total: 14.71 MB, FLOPs: 368,600,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1723 finished in 0m08s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 3,820,665 (14.575 MB), Total: 14.69 MB, FLOPs: 368,488,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1723 finished in 0m09s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 3,816,503 (14.559 MB), Total: 14.67 MB, FLOPs: 368,375,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1723 finished in 0m09s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 447)]\n",
      "Input: 0.115 MB, Params: 3,810,525 (14.536 MB), Total: 14.65 MB, FLOPs: 368,214,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1723 finished in 0m07s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 71)]\n",
      "Input: 0.115 MB, Params: 3,807,202 (14.523 MB), Total: 14.64 MB, FLOPs: 367,482,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1723 finished in 0m08s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 289)]\n",
      "Input: 0.115 MB, Params: 3,803,049 (14.507 MB), Total: 14.62 MB, FLOPs: 367,370,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1723 finished in 0m08s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 3,798,896 (14.492 MB), Total: 14.61 MB, FLOPs: 367,258,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1723 finished in 0m09s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 3,794,743 (14.476 MB), Total: 14.59 MB, FLOPs: 367,146,640\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1723 finished in 0m09s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.115 MB, Params: 3,790,590 (14.460 MB), Total: 14.58 MB, FLOPs: 367,034,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1723 finished in 0m09s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 3,784,648 (14.437 MB), Total: 14.55 MB, FLOPs: 366,874,159\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1723 finished in 0m07s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.115 MB, Params: 3,781,424 (14.425 MB), Total: 14.54 MB, FLOPs: 366,526,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1723 finished in 0m07s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 307)]\n",
      "Input: 0.115 MB, Params: 3,775,482 (14.402 MB), Total: 14.52 MB, FLOPs: 366,365,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1723 finished in 0m07s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 3,771,347 (14.387 MB), Total: 14.50 MB, FLOPs: 366,254,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1723 finished in 0m08s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 3,767,212 (14.371 MB), Total: 14.49 MB, FLOPs: 366,142,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1723 finished in 0m09s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 3,761,288 (14.348 MB), Total: 14.46 MB, FLOPs: 365,982,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1723 finished in 0m08s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 3,755,364 (14.326 MB), Total: 14.44 MB, FLOPs: 365,822,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1723 finished in 0m07s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.115 MB, Params: 3,753,733 (14.319 MB), Total: 14.43 MB, FLOPs: 365,098,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1723 finished in 0m07s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 325)]\n",
      "Input: 0.115 MB, Params: 3,747,809 (14.297 MB), Total: 14.41 MB, FLOPs: 364,939,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1723 finished in 0m07s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 3,741,885 (14.274 MB), Total: 14.39 MB, FLOPs: 364,779,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1723 finished in 0m07s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 224)]\n",
      "Input: 0.115 MB, Params: 3,735,583 (14.250 MB), Total: 14.37 MB, FLOPs: 364,430,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1723 finished in 0m08s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 231)]\n",
      "Input: 0.115 MB, Params: 3,731,484 (14.234 MB), Total: 14.35 MB, FLOPs: 364,319,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1723 finished in 0m09s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 402)]\n",
      "Input: 0.115 MB, Params: 3,725,578 (14.212 MB), Total: 14.33 MB, FLOPs: 364,160,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1723 finished in 0m07s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 3,722,363 (14.200 MB), Total: 14.31 MB, FLOPs: 363,813,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1723 finished in 0m07s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.115 MB, Params: 3,718,273 (14.184 MB), Total: 14.30 MB, FLOPs: 363,702,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1723 finished in 0m08s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.115 MB, Params: 3,714,183 (14.168 MB), Total: 14.28 MB, FLOPs: 363,592,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1723 finished in 0m09s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 3,710,093 (14.153 MB), Total: 14.27 MB, FLOPs: 363,481,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1723 finished in 0m09s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 302)]\n",
      "Input: 0.115 MB, Params: 3,704,214 (14.130 MB), Total: 14.25 MB, FLOPs: 363,323,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1723 finished in 0m08s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.115 MB, Params: 3,698,335 (14.108 MB), Total: 14.22 MB, FLOPs: 363,164,473\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1723 finished in 0m07s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.115 MB, Params: 3,692,069 (14.084 MB), Total: 14.20 MB, FLOPs: 362,817,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1723 finished in 0m08s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 445)]\n",
      "Input: 0.115 MB, Params: 3,686,199 (14.062 MB), Total: 14.18 MB, FLOPs: 362,658,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1723 finished in 0m08s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.115 MB, Params: 3,682,136 (14.046 MB), Total: 14.16 MB, FLOPs: 362,549,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1723 finished in 0m08s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 300)]\n",
      "Input: 0.115 MB, Params: 3,678,073 (14.031 MB), Total: 14.15 MB, FLOPs: 362,439,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1723 finished in 0m09s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.115 MB, Params: 3,672,221 (14.008 MB), Total: 14.12 MB, FLOPs: 362,281,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1723 finished in 0m08s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 151)]\n",
      "Input: 0.115 MB, Params: 3,669,015 (13.996 MB), Total: 14.11 MB, FLOPs: 361,935,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1723 finished in 0m07s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 3,664,961 (13.981 MB), Total: 14.10 MB, FLOPs: 361,825,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1723 finished in 0m09s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 191)]\n",
      "Input: 0.115 MB, Params: 3,660,907 (13.965 MB), Total: 14.08 MB, FLOPs: 361,716,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1723 finished in 0m09s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 232)]\n",
      "Input: 0.115 MB, Params: 3,654,668 (13.941 MB), Total: 14.06 MB, FLOPs: 361,370,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1723 finished in 0m09s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.115 MB, Params: 3,650,614 (13.926 MB), Total: 14.04 MB, FLOPs: 361,261,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1723 finished in 0m09s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 377)]\n",
      "Input: 0.115 MB, Params: 3,646,560 (13.911 MB), Total: 14.03 MB, FLOPs: 361,152,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1723 finished in 0m09s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 180)]\n",
      "Input: 0.115 MB, Params: 3,640,321 (13.887 MB), Total: 14.00 MB, FLOPs: 360,806,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1723 finished in 0m09s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 117)]\n",
      "Input: 0.115 MB, Params: 3,637,034 (13.874 MB), Total: 13.99 MB, FLOPs: 360,081,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1723 finished in 0m09s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 85)]\n",
      "Input: 0.115 MB, Params: 3,633,747 (13.862 MB), Total: 13.98 MB, FLOPs: 359,357,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1723 finished in 0m09s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 169)]\n",
      "Input: 0.115 MB, Params: 3,630,577 (13.850 MB), Total: 13.96 MB, FLOPs: 359,014,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1723 finished in 0m08s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 3,626,523 (13.834 MB), Total: 13.95 MB, FLOPs: 358,905,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1723 finished in 0m09s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 3,620,734 (13.812 MB), Total: 13.93 MB, FLOPs: 358,749,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1723 finished in 0m08s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 114)]\n",
      "Input: 0.115 MB, Params: 3,616,689 (13.797 MB), Total: 13.91 MB, FLOPs: 358,640,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1723 finished in 0m09s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 3,610,468 (13.773 MB), Total: 13.89 MB, FLOPs: 358,295,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1723 finished in 0m09s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 144)]\n",
      "Input: 0.115 MB, Params: 3,604,247 (13.749 MB), Total: 13.86 MB, FLOPs: 357,950,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1723 finished in 0m09s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.115 MB, Params: 3,600,202 (13.734 MB), Total: 13.85 MB, FLOPs: 357,841,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1723 finished in 0m09s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 3,596,157 (13.718 MB), Total: 13.83 MB, FLOPs: 357,732,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1723 finished in 0m09s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 242)]\n",
      "Input: 0.115 MB, Params: 3,592,112 (13.703 MB), Total: 13.82 MB, FLOPs: 357,623,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1723 finished in 0m09s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 210)]\n",
      "Input: 0.115 MB, Params: 3,585,891 (13.679 MB), Total: 13.79 MB, FLOPs: 357,278,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1723 finished in 0m09s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.115 MB, Params: 3,579,670 (13.655 MB), Total: 13.77 MB, FLOPs: 356,934,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1723 finished in 0m09s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 3,573,953 (13.634 MB), Total: 13.75 MB, FLOPs: 356,780,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1723 finished in 0m08s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.115 MB, Params: 3,568,236 (13.612 MB), Total: 13.73 MB, FLOPs: 356,625,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1723 finished in 0m07s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.115 MB, Params: 3,564,209 (13.596 MB), Total: 13.71 MB, FLOPs: 356,517,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1723 finished in 0m09s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 3,560,182 (13.581 MB), Total: 13.70 MB, FLOPs: 356,408,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1723 finished in 0m09s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 340)]\n",
      "Input: 0.115 MB, Params: 3,556,155 (13.566 MB), Total: 13.68 MB, FLOPs: 356,299,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1723 finished in 0m09s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 3,550,465 (13.544 MB), Total: 13.66 MB, FLOPs: 356,146,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1723 finished in 0m08s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 3,544,271 (13.520 MB), Total: 13.64 MB, FLOPs: 355,802,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1723 finished in 0m08s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 384)]\n",
      "Input: 0.115 MB, Params: 3,540,253 (13.505 MB), Total: 13.62 MB, FLOPs: 355,693,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1723 finished in 0m09s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.115 MB, Params: 3,538,640 (13.499 MB), Total: 13.61 MB, FLOPs: 354,978,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1723 finished in 0m08s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.115 MB, Params: 3,532,968 (13.477 MB), Total: 13.59 MB, FLOPs: 354,824,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1723 finished in 0m07s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 102)]\n",
      "Input: 0.115 MB, Params: 3,529,699 (13.465 MB), Total: 13.58 MB, FLOPs: 354,105,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1723 finished in 0m08s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 3,524,027 (13.443 MB), Total: 13.56 MB, FLOPs: 353,952,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1723 finished in 0m08s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.115 MB, Params: 3,523,206 (13.440 MB), Total: 13.56 MB, FLOPs: 352,414,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1723 finished in 0m07s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 368)]\n",
      "Input: 0.115 MB, Params: 3,517,534 (13.418 MB), Total: 13.53 MB, FLOPs: 352,261,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1723 finished in 0m07s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 234)]\n",
      "Input: 0.115 MB, Params: 3,514,418 (13.406 MB), Total: 13.52 MB, FLOPs: 351,925,195\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1723 finished in 0m07s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.115 MB, Params: 3,512,814 (13.400 MB), Total: 13.52 MB, FLOPs: 351,213,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1723 finished in 0m07s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.115 MB, Params: 3,507,142 (13.379 MB), Total: 13.49 MB, FLOPs: 351,060,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1723 finished in 0m07s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.115 MB, Params: 3,503,160 (13.363 MB), Total: 13.48 MB, FLOPs: 350,952,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1723 finished in 0m09s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 3,497,011 (13.340 MB), Total: 13.46 MB, FLOPs: 350,611,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1723 finished in 0m09s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 3,493,029 (13.325 MB), Total: 13.44 MB, FLOPs: 350,503,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1723 finished in 0m09s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 159)]\n",
      "Input: 0.115 MB, Params: 3,486,880 (13.301 MB), Total: 13.42 MB, FLOPs: 350,161,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1723 finished in 0m09s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 3,482,898 (13.286 MB), Total: 13.40 MB, FLOPs: 350,054,227\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1723 finished in 0m09s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 3,478,916 (13.271 MB), Total: 13.39 MB, FLOPs: 349,946,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1723 finished in 0m09s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,473,298 (13.250 MB), Total: 13.36 MB, FLOPs: 349,795,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1723 finished in 0m08s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 141)]\n",
      "Input: 0.115 MB, Params: 3,469,325 (13.234 MB), Total: 13.35 MB, FLOPs: 349,687,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1723 finished in 0m09s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 3,463,716 (13.213 MB), Total: 13.33 MB, FLOPs: 349,536,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1723 finished in 0m08s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 3,458,107 (13.192 MB), Total: 13.31 MB, FLOPs: 349,385,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1723 finished in 0m07s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 410)]\n",
      "Input: 0.115 MB, Params: 3,452,498 (13.170 MB), Total: 13.29 MB, FLOPs: 349,233,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1723 finished in 0m07s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 3,448,552 (13.155 MB), Total: 13.27 MB, FLOPs: 349,127,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1723 finished in 0m09s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 3,445,454 (13.143 MB), Total: 13.26 MB, FLOPs: 348,792,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1723 finished in 0m08s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 107)]\n",
      "Input: 0.115 MB, Params: 3,443,850 (13.137 MB), Total: 13.25 MB, FLOPs: 348,080,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1723 finished in 0m07s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 3,442,246 (13.131 MB), Total: 13.25 MB, FLOPs: 347,369,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1723 finished in 0m07s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.115 MB, Params: 3,438,300 (13.116 MB), Total: 13.23 MB, FLOPs: 347,262,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1723 finished in 0m09s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.115 MB, Params: 3,436,696 (13.110 MB), Total: 13.23 MB, FLOPs: 346,551,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1723 finished in 0m09s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 104)]\n",
      "Input: 0.115 MB, Params: 3,433,481 (13.098 MB), Total: 13.21 MB, FLOPs: 345,849,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1723 finished in 0m08s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 253)]\n",
      "Input: 0.115 MB, Params: 3,429,535 (13.083 MB), Total: 13.20 MB, FLOPs: 345,742,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1723 finished in 0m08s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.115 MB, Params: 3,423,953 (13.061 MB), Total: 13.18 MB, FLOPs: 345,592,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1723 finished in 0m08s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.115 MB, Params: 3,417,858 (13.038 MB), Total: 13.15 MB, FLOPs: 345,252,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1723 finished in 0m08s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 26)]\n",
      "Input: 0.115 MB, Params: 3,411,763 (13.015 MB), Total: 13.13 MB, FLOPs: 344,912,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1723 finished in 0m09s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 3,405,668 (12.992 MB), Total: 13.11 MB, FLOPs: 344,573,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1723 finished in 0m09s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 3,401,731 (12.977 MB), Total: 13.09 MB, FLOPs: 344,466,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1723 finished in 0m09s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 37)]\n",
      "Input: 0.115 MB, Params: 3,401,689 (12.976 MB), Total: 13.09 MB, FLOPs: 340,214,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1723 finished in 0m12s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 3,397,752 (12.961 MB), Total: 13.08 MB, FLOPs: 340,108,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1723 finished in 0m10s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.115 MB, Params: 3,392,215 (12.940 MB), Total: 13.06 MB, FLOPs: 339,958,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1723 finished in 0m08s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.115 MB, Params: 3,386,678 (12.919 MB), Total: 13.03 MB, FLOPs: 339,809,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1723 finished in 0m07s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 213)]\n",
      "Input: 0.115 MB, Params: 3,380,601 (12.896 MB), Total: 13.01 MB, FLOPs: 339,470,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1723 finished in 0m08s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 350)]\n",
      "Input: 0.115 MB, Params: 3,376,682 (12.881 MB), Total: 13.00 MB, FLOPs: 339,364,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1723 finished in 0m09s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 3,372,763 (12.866 MB), Total: 12.98 MB, FLOPs: 339,258,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1723 finished in 0m09s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 3,366,686 (12.843 MB), Total: 12.96 MB, FLOPs: 338,919,411\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1723 finished in 0m09s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 102)]\n",
      "Input: 0.115 MB, Params: 3,363,471 (12.831 MB), Total: 12.95 MB, FLOPs: 338,217,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1723 finished in 0m09s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 168)]\n",
      "Input: 0.115 MB, Params: 3,357,394 (12.807 MB), Total: 12.92 MB, FLOPs: 337,878,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1723 finished in 0m09s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 259)]\n",
      "Input: 0.115 MB, Params: 3,351,902 (12.786 MB), Total: 12.90 MB, FLOPs: 337,730,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1723 finished in 0m08s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 165)]\n",
      "Input: 0.115 MB, Params: 3,345,834 (12.763 MB), Total: 12.88 MB, FLOPs: 337,391,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1723 finished in 0m08s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 16)]\n",
      "Input: 0.115 MB, Params: 3,344,212 (12.757 MB), Total: 12.87 MB, FLOPs: 335,899,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1723 finished in 0m09s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 195)]\n",
      "Input: 0.115 MB, Params: 3,341,195 (12.746 MB), Total: 12.86 MB, FLOPs: 335,573,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1723 finished in 0m07s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 3,335,712 (12.725 MB), Total: 12.84 MB, FLOPs: 335,425,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1723 finished in 0m07s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 374)]\n",
      "Input: 0.115 MB, Params: 3,331,811 (12.710 MB), Total: 12.83 MB, FLOPs: 335,320,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1723 finished in 0m09s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 3,326,337 (12.689 MB), Total: 12.80 MB, FLOPs: 335,172,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1723 finished in 0m08s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 3,320,296 (12.666 MB), Total: 12.78 MB, FLOPs: 334,835,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1723 finished in 0m08s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 3,314,831 (12.645 MB), Total: 12.76 MB, FLOPs: 334,687,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1723 finished in 0m08s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 218)]\n",
      "Input: 0.115 MB, Params: 3,311,823 (12.634 MB), Total: 12.75 MB, FLOPs: 334,363,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1723 finished in 0m07s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.115 MB, Params: 3,306,358 (12.613 MB), Total: 12.73 MB, FLOPs: 334,215,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1723 finished in 0m07s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 3,302,484 (12.598 MB), Total: 12.71 MB, FLOPs: 334,110,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1723 finished in 0m09s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 176)]\n",
      "Input: 0.115 MB, Params: 3,299,476 (12.587 MB), Total: 12.70 MB, FLOPs: 333,786,207\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1723 finished in 0m08s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 3,294,020 (12.566 MB), Total: 12.68 MB, FLOPs: 333,638,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1723 finished in 0m07s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 3,288,024 (12.543 MB), Total: 12.66 MB, FLOPs: 333,304,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1723 finished in 0m08s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 206)]\n",
      "Input: 0.115 MB, Params: 3,285,025 (12.531 MB), Total: 12.65 MB, FLOPs: 332,980,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1723 finished in 0m08s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 352)]\n",
      "Input: 0.115 MB, Params: 3,279,578 (12.511 MB), Total: 12.63 MB, FLOPs: 332,833,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1723 finished in 0m07s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 184)]\n",
      "Input: 0.115 MB, Params: 3,274,131 (12.490 MB), Total: 12.61 MB, FLOPs: 332,686,227\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1723 finished in 0m07s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.115 MB, Params: 3,268,684 (12.469 MB), Total: 12.58 MB, FLOPs: 332,539,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1723 finished in 0m07s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 164)]\n",
      "Input: 0.115 MB, Params: 3,265,685 (12.458 MB), Total: 12.57 MB, FLOPs: 332,215,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1723 finished in 0m07s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 102)]\n",
      "Input: 0.115 MB, Params: 3,264,108 (12.452 MB), Total: 12.57 MB, FLOPs: 331,515,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1723 finished in 0m07s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 215)]\n",
      "Input: 0.115 MB, Params: 3,260,270 (12.437 MB), Total: 12.55 MB, FLOPs: 331,412,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1723 finished in 0m09s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 3,254,832 (12.416 MB), Total: 12.53 MB, FLOPs: 331,265,289\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1723 finished in 0m08s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.115 MB, Params: 3,248,890 (12.394 MB), Total: 12.51 MB, FLOPs: 330,933,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1723 finished in 0m08s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 379)]\n",
      "Input: 0.115 MB, Params: 3,245,061 (12.379 MB), Total: 12.49 MB, FLOPs: 330,830,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1723 finished in 0m09s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 184)]\n",
      "Input: 0.115 MB, Params: 3,239,119 (12.356 MB), Total: 12.47 MB, FLOPs: 330,498,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1723 finished in 0m09s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 325)]\n",
      "Input: 0.115 MB, Params: 3,235,290 (12.342 MB), Total: 12.46 MB, FLOPs: 330,394,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1723 finished in 0m09s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 3,229,348 (12.319 MB), Total: 12.43 MB, FLOPs: 330,062,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1723 finished in 0m09s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 3,225,519 (12.304 MB), Total: 12.42 MB, FLOPs: 329,959,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1723 finished in 0m09s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.115 MB, Params: 3,223,942 (12.298 MB), Total: 12.41 MB, FLOPs: 329,259,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1723 finished in 0m09s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 3,218,558 (12.278 MB), Total: 12.39 MB, FLOPs: 329,114,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1723 finished in 0m08s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.115 MB, Params: 3,213,174 (12.257 MB), Total: 12.37 MB, FLOPs: 328,969,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1723 finished in 0m07s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 3,210,202 (12.246 MB), Total: 12.36 MB, FLOPs: 328,648,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1723 finished in 0m07s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 244)]\n",
      "Input: 0.115 MB, Params: 3,206,391 (12.231 MB), Total: 12.35 MB, FLOPs: 328,545,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1723 finished in 0m09s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 3,203,419 (12.220 MB), Total: 12.34 MB, FLOPs: 328,224,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1723 finished in 0m08s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.115 MB, Params: 3,200,447 (12.209 MB), Total: 12.32 MB, FLOPs: 327,903,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1723 finished in 0m07s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 3,195,072 (12.188 MB), Total: 12.30 MB, FLOPs: 327,758,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1723 finished in 0m07s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 3,189,697 (12.168 MB), Total: 12.28 MB, FLOPs: 327,613,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1723 finished in 0m07s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 278)]\n",
      "Input: 0.115 MB, Params: 3,184,322 (12.147 MB), Total: 12.26 MB, FLOPs: 327,468,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1723 finished in 0m07s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 3,178,452 (12.125 MB), Total: 12.24 MB, FLOPs: 327,140,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1723 finished in 0m09s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 3,172,582 (12.102 MB), Total: 12.22 MB, FLOPs: 326,812,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1723 finished in 0m10s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 3,167,225 (12.082 MB), Total: 12.20 MB, FLOPs: 326,668,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1723 finished in 0m08s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 3,164,271 (12.071 MB), Total: 12.19 MB, FLOPs: 326,349,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1723 finished in 0m07s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 3,160,496 (12.056 MB), Total: 12.17 MB, FLOPs: 326,247,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1723 finished in 0m10s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 3,155,148 (12.036 MB), Total: 12.15 MB, FLOPs: 326,103,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1723 finished in 0m09s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.115 MB, Params: 3,151,382 (12.022 MB), Total: 12.14 MB, FLOPs: 326,001,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1723 finished in 0m10s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 382)]\n",
      "Input: 0.115 MB, Params: 3,146,043 (12.001 MB), Total: 12.12 MB, FLOPs: 325,857,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1723 finished in 0m08s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 3,142,286 (11.987 MB), Total: 12.10 MB, FLOPs: 325,755,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1723 finished in 0m10s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.115 MB, Params: 3,138,529 (11.973 MB), Total: 12.09 MB, FLOPs: 325,654,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1723 finished in 0m10s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 22)]\n",
      "Input: 0.115 MB, Params: 3,135,413 (11.961 MB), Total: 12.08 MB, FLOPs: 324,969,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1723 finished in 0m09s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 56)]\n",
      "Input: 0.115 MB, Params: 3,132,297 (11.949 MB), Total: 12.06 MB, FLOPs: 324,284,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1723 finished in 0m09s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 3,129,361 (11.938 MB), Total: 12.05 MB, FLOPs: 323,967,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1723 finished in 0m09s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 45)]\n",
      "Input: 0.115 MB, Params: 3,128,549 (11.934 MB), Total: 12.05 MB, FLOPs: 322,507,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1723 finished in 0m09s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.115 MB, Params: 3,125,442 (11.923 MB), Total: 12.04 MB, FLOPs: 321,823,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1723 finished in 0m10s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 3,122,335 (11.911 MB), Total: 12.03 MB, FLOPs: 321,139,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1723 finished in 0m10s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 322)]\n",
      "Input: 0.115 MB, Params: 3,118,578 (11.896 MB), Total: 12.01 MB, FLOPs: 321,038,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1723 finished in 0m10s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.115 MB, Params: 3,117,766 (11.893 MB), Total: 12.01 MB, FLOPs: 319,578,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1723 finished in 0m09s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 3,114,009 (11.879 MB), Total: 11.99 MB, FLOPs: 319,477,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1723 finished in 0m10s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 3,110,252 (11.865 MB), Total: 11.98 MB, FLOPs: 319,375,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1723 finished in 0m10s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 3,104,958 (11.844 MB), Total: 11.96 MB, FLOPs: 319,233,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1723 finished in 0m08s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 100)]\n",
      "Input: 0.115 MB, Params: 3,103,417 (11.839 MB), Total: 11.95 MB, FLOPs: 318,549,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1723 finished in 0m08s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.115 MB, Params: 3,099,669 (11.824 MB), Total: 11.94 MB, FLOPs: 318,448,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1723 finished in 0m10s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 325)]\n",
      "Input: 0.115 MB, Params: 3,094,384 (11.804 MB), Total: 11.92 MB, FLOPs: 318,305,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1723 finished in 0m09s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.115 MB, Params: 3,088,577 (11.782 MB), Total: 11.90 MB, FLOPs: 317,980,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1723 finished in 0m09s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 3,084,838 (11.768 MB), Total: 11.88 MB, FLOPs: 317,879,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1723 finished in 0m10s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 289)]\n",
      "Input: 0.115 MB, Params: 3,079,571 (11.748 MB), Total: 11.86 MB, FLOPs: 317,737,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1723 finished in 0m08s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.115 MB, Params: 3,075,841 (11.733 MB), Total: 11.85 MB, FLOPs: 317,637,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1723 finished in 0m10s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 335)]\n",
      "Input: 0.115 MB, Params: 3,070,583 (11.713 MB), Total: 11.83 MB, FLOPs: 317,495,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1723 finished in 0m08s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 320)]\n",
      "Input: 0.115 MB, Params: 3,065,325 (11.693 MB), Total: 11.81 MB, FLOPs: 317,353,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1723 finished in 0m08s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 3,060,067 (11.673 MB), Total: 11.79 MB, FLOPs: 317,211,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1723 finished in 0m08s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 174)]\n",
      "Input: 0.115 MB, Params: 3,057,158 (11.662 MB), Total: 11.78 MB, FLOPs: 316,897,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1723 finished in 0m08s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 3,051,900 (11.642 MB), Total: 11.76 MB, FLOPs: 316,755,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1723 finished in 0m08s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.115 MB, Params: 3,048,991 (11.631 MB), Total: 11.75 MB, FLOPs: 316,441,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1723 finished in 0m08s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 49)]\n",
      "Input: 0.115 MB, Params: 3,048,179 (11.628 MB), Total: 11.74 MB, FLOPs: 314,981,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1723 finished in 0m08s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 3,044,485 (11.614 MB), Total: 11.73 MB, FLOPs: 314,881,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1723 finished in 0m10s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 304)]\n",
      "Input: 0.115 MB, Params: 3,040,791 (11.600 MB), Total: 11.71 MB, FLOPs: 314,782,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1723 finished in 0m11s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.115 MB, Params: 3,037,882 (11.589 MB), Total: 11.70 MB, FLOPs: 314,468,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1723 finished in 0m09s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 107)]\n",
      "Input: 0.115 MB, Params: 3,036,341 (11.583 MB), Total: 11.70 MB, FLOPs: 313,784,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1723 finished in 0m08s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 91)]\n",
      "Input: 0.115 MB, Params: 3,033,279 (11.571 MB), Total: 11.69 MB, FLOPs: 313,111,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1723 finished in 0m09s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.115 MB, Params: 3,031,747 (11.565 MB), Total: 11.68 MB, FLOPs: 312,431,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1723 finished in 0m09s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 331)]\n",
      "Input: 0.115 MB, Params: 3,028,053 (11.551 MB), Total: 11.67 MB, FLOPs: 312,331,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1723 finished in 0m10s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.115 MB, Params: 3,024,359 (11.537 MB), Total: 11.65 MB, FLOPs: 312,232,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1723 finished in 0m11s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 3,019,137 (11.517 MB), Total: 11.63 MB, FLOPs: 312,091,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1723 finished in 0m09s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 367)]\n",
      "Input: 0.115 MB, Params: 3,015,452 (11.503 MB), Total: 11.62 MB, FLOPs: 311,991,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1723 finished in 0m10s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 3,011,767 (11.489 MB), Total: 11.60 MB, FLOPs: 311,892,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1723 finished in 0m11s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 113)]\n",
      "Input: 0.115 MB, Params: 3,008,082 (11.475 MB), Total: 11.59 MB, FLOPs: 311,792,817\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1723 finished in 0m11s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 3,002,887 (11.455 MB), Total: 11.57 MB, FLOPs: 311,652,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1723 finished in 0m09s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 250)]\n",
      "Input: 0.115 MB, Params: 2,999,211 (11.441 MB), Total: 11.56 MB, FLOPs: 311,553,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1723 finished in 0m10s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 2,993,494 (11.419 MB), Total: 11.53 MB, FLOPs: 311,233,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1723 finished in 0m10s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 101)]\n",
      "Input: 0.115 MB, Params: 2,991,962 (11.413 MB), Total: 11.53 MB, FLOPs: 310,553,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1723 finished in 0m09s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 357)]\n",
      "Input: 0.115 MB, Params: 2,986,785 (11.394 MB), Total: 11.51 MB, FLOPs: 310,413,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1723 finished in 0m08s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 394)]\n",
      "Input: 0.115 MB, Params: 2,981,608 (11.374 MB), Total: 11.49 MB, FLOPs: 310,274,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1723 finished in 0m08s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 344)]\n",
      "Input: 0.115 MB, Params: 2,977,950 (11.360 MB), Total: 11.48 MB, FLOPs: 310,175,403\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1723 finished in 0m10s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 2,975,059 (11.349 MB), Total: 11.46 MB, FLOPs: 309,863,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1723 finished in 0m08s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 183)]\n",
      "Input: 0.115 MB, Params: 2,969,891 (11.329 MB), Total: 11.44 MB, FLOPs: 309,723,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1723 finished in 0m08s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.115 MB, Params: 2,964,723 (11.310 MB), Total: 11.42 MB, FLOPs: 309,584,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1723 finished in 0m08s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 4)]\n",
      "Input: 0.115 MB, Params: 2,964,467 (11.309 MB), Total: 11.42 MB, FLOPs: 307,582,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.000%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1723 finished in 0m09s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 127)]\n",
      "Input: 0.115 MB, Params: 2,958,795 (11.287 MB), Total: 11.40 MB, FLOPs: 307,264,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1723 finished in 0m10s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 312)]\n",
      "Input: 0.115 MB, Params: 2,953,636 (11.267 MB), Total: 11.38 MB, FLOPs: 307,125,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1723 finished in 0m09s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 2,950,754 (11.256 MB), Total: 11.37 MB, FLOPs: 306,814,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1723 finished in 0m08s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 2,947,123 (11.242 MB), Total: 11.36 MB, FLOPs: 306,716,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1723 finished in 0m10s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 2,943,492 (11.229 MB), Total: 11.34 MB, FLOPs: 306,618,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1723 finished in 0m11s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 266)]\n",
      "Input: 0.115 MB, Params: 2,939,861 (11.215 MB), Total: 11.33 MB, FLOPs: 306,520,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1723 finished in 0m11s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 22)]\n",
      "Input: 0.115 MB, Params: 2,939,049 (11.212 MB), Total: 11.33 MB, FLOPs: 305,060,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1723 finished in 0m08s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,935,418 (11.198 MB), Total: 11.31 MB, FLOPs: 304,962,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1723 finished in 0m10s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 2,932,536 (11.187 MB), Total: 11.30 MB, FLOPs: 304,651,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1723 finished in 0m09s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 2,929,654 (11.176 MB), Total: 11.29 MB, FLOPs: 304,340,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1723 finished in 0m08s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 9)]\n",
      "Input: 0.115 MB, Params: 2,924,018 (11.154 MB), Total: 11.27 MB, FLOPs: 304,025,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1723 finished in 0m10s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 2,918,904 (11.135 MB), Total: 11.25 MB, FLOPs: 303,887,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1723 finished in 0m09s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 2,915,282 (11.121 MB), Total: 11.24 MB, FLOPs: 303,789,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1723 finished in 0m10s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 2,911,660 (11.107 MB), Total: 11.22 MB, FLOPs: 303,691,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1723 finished in 0m11s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 2,906,564 (11.088 MB), Total: 11.20 MB, FLOPs: 303,554,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1723 finished in 0m09s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 2,901,468 (11.068 MB), Total: 11.18 MB, FLOPs: 303,416,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1723 finished in 0m08s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 2,896,372 (11.049 MB), Total: 11.16 MB, FLOPs: 303,279,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1723 finished in 0m08s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 197)]\n",
      "Input: 0.115 MB, Params: 2,891,276 (11.029 MB), Total: 11.14 MB, FLOPs: 303,141,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1723 finished in 0m08s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 200)]\n",
      "Input: 0.115 MB, Params: 2,885,685 (11.008 MB), Total: 11.12 MB, FLOPs: 302,827,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1723 finished in 0m10s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.115 MB, Params: 2,880,094 (10.987 MB), Total: 11.10 MB, FLOPs: 302,514,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1723 finished in 0m10s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 2,876,508 (10.973 MB), Total: 11.09 MB, FLOPs: 302,417,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1723 finished in 0m11s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,872,922 (10.959 MB), Total: 11.07 MB, FLOPs: 302,320,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1723 finished in 0m11s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 2,869,336 (10.946 MB), Total: 11.06 MB, FLOPs: 302,223,847\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1723 finished in 0m11s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 2,869,299 (10.946 MB), Total: 11.06 MB, FLOPs: 301,897,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1723 finished in 0m11s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 150)]\n",
      "Input: 0.115 MB, Params: 2,863,708 (10.924 MB), Total: 11.04 MB, FLOPs: 301,583,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1723 finished in 0m11s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.115 MB, Params: 2,860,122 (10.910 MB), Total: 11.03 MB, FLOPs: 301,487,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1723 finished in 0m11s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 2,856,536 (10.897 MB), Total: 11.01 MB, FLOPs: 301,390,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1723 finished in 0m11s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 2,852,950 (10.883 MB), Total: 11.00 MB, FLOPs: 301,293,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1723 finished in 0m11s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.115 MB, Params: 2,849,364 (10.869 MB), Total: 10.98 MB, FLOPs: 301,196,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1723 finished in 0m11s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.115 MB, Params: 2,845,778 (10.856 MB), Total: 10.97 MB, FLOPs: 301,100,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1723 finished in 0m11s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,842,192 (10.842 MB), Total: 10.96 MB, FLOPs: 301,003,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1723 finished in 0m11s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 2,837,204 (10.823 MB), Total: 10.94 MB, FLOPs: 300,868,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1723 finished in 0m09s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.115 MB, Params: 2,831,622 (10.802 MB), Total: 10.92 MB, FLOPs: 300,555,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1723 finished in 0m10s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.115 MB, Params: 2,826,040 (10.780 MB), Total: 10.90 MB, FLOPs: 300,241,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1723 finished in 0m11s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 2,822,463 (10.767 MB), Total: 10.88 MB, FLOPs: 300,145,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1723 finished in 0m11s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 202)]\n",
      "Input: 0.115 MB, Params: 2,819,635 (10.756 MB), Total: 10.87 MB, FLOPs: 299,839,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1723 finished in 0m09s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 2,816,807 (10.745 MB), Total: 10.86 MB, FLOPs: 299,534,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1723 finished in 0m08s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 2,811,846 (10.726 MB), Total: 10.84 MB, FLOPs: 299,400,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1723 finished in 0m08s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 336)]\n",
      "Input: 0.115 MB, Params: 2,808,278 (10.713 MB), Total: 10.83 MB, FLOPs: 299,304,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1723 finished in 0m10s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 2,803,326 (10.694 MB), Total: 10.81 MB, FLOPs: 299,170,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1723 finished in 0m09s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 2,799,767 (10.680 MB), Total: 10.80 MB, FLOPs: 299,074,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1723 finished in 0m10s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.115 MB, Params: 2,796,208 (10.667 MB), Total: 10.78 MB, FLOPs: 298,978,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1723 finished in 0m11s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.115 MB, Params: 2,791,274 (10.648 MB), Total: 10.76 MB, FLOPs: 298,845,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1723 finished in 0m09s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 2,787,724 (10.634 MB), Total: 10.75 MB, FLOPs: 298,749,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1723 finished in 0m10s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 177)]\n",
      "Input: 0.115 MB, Params: 2,784,896 (10.624 MB), Total: 10.74 MB, FLOPs: 298,444,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1723 finished in 0m09s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 2,779,971 (10.605 MB), Total: 10.72 MB, FLOPs: 298,311,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1723 finished in 0m08s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 2,774,452 (10.584 MB), Total: 10.70 MB, FLOPs: 298,001,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1723 finished in 0m10s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 378)]\n",
      "Input: 0.115 MB, Params: 2,769,536 (10.565 MB), Total: 10.68 MB, FLOPs: 297,869,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1723 finished in 0m09s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 56)]\n",
      "Input: 0.115 MB, Params: 2,768,004 (10.559 MB), Total: 10.67 MB, FLOPs: 297,189,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1723 finished in 0m09s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.115 MB, Params: 2,763,088 (10.540 MB), Total: 10.66 MB, FLOPs: 297,056,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1723 finished in 0m09s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 2,759,565 (10.527 MB), Total: 10.64 MB, FLOPs: 296,961,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1723 finished in 0m10s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 197)]\n",
      "Input: 0.115 MB, Params: 2,756,746 (10.516 MB), Total: 10.63 MB, FLOPs: 296,657,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1723 finished in 0m09s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 2,751,839 (10.497 MB), Total: 10.61 MB, FLOPs: 296,524,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1723 finished in 0m08s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 39)]\n",
      "Input: 0.115 MB, Params: 2,750,316 (10.492 MB), Total: 10.61 MB, FLOPs: 295,125,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1723 finished in 0m09s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 2,745,409 (10.473 MB), Total: 10.59 MB, FLOPs: 294,993,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1723 finished in 0m08s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 301)]\n",
      "Input: 0.115 MB, Params: 2,740,502 (10.454 MB), Total: 10.57 MB, FLOPs: 294,860,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1723 finished in 0m08s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 2,735,595 (10.435 MB), Total: 10.55 MB, FLOPs: 294,728,497\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1723 finished in 0m08s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.115 MB, Params: 2,732,108 (10.422 MB), Total: 10.54 MB, FLOPs: 294,634,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1723 finished in 0m10s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 46)]\n",
      "Input: 0.115 MB, Params: 2,730,585 (10.416 MB), Total: 10.53 MB, FLOPs: 293,235,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1723 finished in 0m10s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 2,725,687 (10.398 MB), Total: 10.51 MB, FLOPs: 293,103,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1723 finished in 0m08s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 2,720,789 (10.379 MB), Total: 10.49 MB, FLOPs: 292,971,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1723 finished in 0m08s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.115 MB, Params: 2,717,320 (10.366 MB), Total: 10.48 MB, FLOPs: 292,877,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1723 finished in 0m10s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 2,714,501 (10.355 MB), Total: 10.47 MB, FLOPs: 292,573,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1723 finished in 0m09s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.115 MB, Params: 2,711,682 (10.344 MB), Total: 10.46 MB, FLOPs: 292,268,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1723 finished in 0m08s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 167)]\n",
      "Input: 0.115 MB, Params: 2,708,213 (10.331 MB), Total: 10.45 MB, FLOPs: 292,175,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1723 finished in 0m10s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 242)]\n",
      "Input: 0.115 MB, Params: 2,703,333 (10.312 MB), Total: 10.43 MB, FLOPs: 292,043,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1723 finished in 0m09s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 2,699,873 (10.299 MB), Total: 10.41 MB, FLOPs: 291,950,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1723 finished in 0m10s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.115 MB, Params: 2,696,413 (10.286 MB), Total: 10.40 MB, FLOPs: 291,856,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1723 finished in 0m11s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 2,692,953 (10.273 MB), Total: 10.39 MB, FLOPs: 291,763,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1723 finished in 0m11s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 76)]\n",
      "Input: 0.115 MB, Params: 2,690,134 (10.262 MB), Total: 10.38 MB, FLOPs: 291,458,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1723 finished in 0m09s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 202)]\n",
      "Input: 0.115 MB, Params: 2,687,315 (10.251 MB), Total: 10.37 MB, FLOPs: 291,154,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1723 finished in 0m08s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.115 MB, Params: 2,685,801 (10.246 MB), Total: 10.36 MB, FLOPs: 290,482,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1723 finished in 0m10s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.115 MB, Params: 2,685,007 (10.242 MB), Total: 10.36 MB, FLOPs: 289,055,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1723 finished in 0m09s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 192)]\n",
      "Input: 0.115 MB, Params: 2,682,188 (10.232 MB), Total: 10.35 MB, FLOPs: 288,751,105\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1723 finished in 0m08s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.115 MB, Params: 2,678,728 (10.219 MB), Total: 10.33 MB, FLOPs: 288,657,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1723 finished in 0m10s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.115 MB, Params: 2,677,934 (10.216 MB), Total: 10.33 MB, FLOPs: 287,230,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1723 finished in 0m09s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 2,674,474 (10.202 MB), Total: 10.32 MB, FLOPs: 287,136,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1723 finished in 0m10s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.115 MB, Params: 2,672,978 (10.197 MB), Total: 10.31 MB, FLOPs: 285,774,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1723 finished in 0m10s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 36)]\n",
      "Input: 0.115 MB, Params: 2,672,941 (10.196 MB), Total: 10.31 MB, FLOPs: 248,421,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1723 finished in 0m25s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 2,668,106 (10.178 MB), Total: 10.29 MB, FLOPs: 248,334,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1723 finished in 0m11s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 158)]\n",
      "Input: 0.115 MB, Params: 2,662,731 (10.158 MB), Total: 10.27 MB, FLOPs: 248,099,329\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1723 finished in 0m10s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 271)]\n",
      "Input: 0.115 MB, Params: 2,657,905 (10.139 MB), Total: 10.25 MB, FLOPs: 248,012,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1723 finished in 0m10s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.115 MB, Params: 2,653,079 (10.121 MB), Total: 10.24 MB, FLOPs: 247,925,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1723 finished in 0m09s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.115 MB, Params: 2,651,574 (10.115 MB), Total: 10.23 MB, FLOPs: 247,313,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1723 finished in 0m10s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 270)]\n",
      "Input: 0.115 MB, Params: 2,648,141 (10.102 MB), Total: 10.22 MB, FLOPs: 247,251,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1723 finished in 0m11s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 91)]\n",
      "Input: 0.115 MB, Params: 2,646,636 (10.096 MB), Total: 10.21 MB, FLOPs: 246,639,609\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1723 finished in 0m10s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 67)]\n",
      "Input: 0.115 MB, Params: 2,645,131 (10.090 MB), Total: 10.21 MB, FLOPs: 246,027,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1723 finished in 0m11s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 194)]\n",
      "Input: 0.115 MB, Params: 2,642,321 (10.080 MB), Total: 10.19 MB, FLOPs: 245,774,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1723 finished in 0m10s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 56)]\n",
      "Input: 0.115 MB, Params: 2,640,816 (10.074 MB), Total: 10.19 MB, FLOPs: 245,162,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1723 finished in 0m10s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.115 MB, Params: 2,637,383 (10.061 MB), Total: 10.18 MB, FLOPs: 245,100,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1723 finished in 0m11s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 2,633,950 (10.048 MB), Total: 10.16 MB, FLOPs: 245,039,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1723 finished in 0m11s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 194)]\n",
      "Input: 0.115 MB, Params: 2,631,140 (10.037 MB), Total: 10.15 MB, FLOPs: 244,786,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1723 finished in 0m10s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 2,625,801 (10.017 MB), Total: 10.13 MB, FLOPs: 244,552,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1723 finished in 0m10s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 2,622,946 (10.006 MB), Total: 10.12 MB, FLOPs: 243,995,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1723 finished in 0m10s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 2,619,513 (9.993 MB), Total: 10.11 MB, FLOPs: 243,933,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1723 finished in 0m11s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 329)]\n",
      "Input: 0.115 MB, Params: 2,616,080 (9.980 MB), Total: 10.09 MB, FLOPs: 243,871,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1723 finished in 0m11s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 105)]\n",
      "Input: 0.115 MB, Params: 2,610,741 (9.959 MB), Total: 10.07 MB, FLOPs: 243,638,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1723 finished in 0m11s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 2,605,978 (9.941 MB), Total: 10.06 MB, FLOPs: 243,552,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1723 finished in 0m10s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 2,602,554 (9.928 MB), Total: 10.04 MB, FLOPs: 243,491,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1723 finished in 0m11s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 187)]\n",
      "Input: 0.115 MB, Params: 2,597,224 (9.908 MB), Total: 10.02 MB, FLOPs: 243,257,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1723 finished in 0m11s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 273)]\n",
      "Input: 0.115 MB, Params: 2,592,479 (9.890 MB), Total: 10.00 MB, FLOPs: 243,172,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1723 finished in 0m10s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 182)]\n",
      "Input: 0.115 MB, Params: 2,587,158 (9.869 MB), Total: 9.98 MB, FLOPs: 242,938,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1723 finished in 0m10s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 79)]\n",
      "Input: 0.115 MB, Params: 2,584,393 (9.859 MB), Total: 9.97 MB, FLOPs: 242,690,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1723 finished in 0m10s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 2,580,978 (9.846 MB), Total: 9.96 MB, FLOPs: 242,628,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1723 finished in 0m11s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 277)]\n",
      "Input: 0.115 MB, Params: 2,577,563 (9.833 MB), Total: 9.95 MB, FLOPs: 242,567,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1723 finished in 0m11s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.115 MB, Params: 2,572,845 (9.815 MB), Total: 9.93 MB, FLOPs: 242,482,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1723 finished in 0m10s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 326)]\n",
      "Input: 0.115 MB, Params: 2,569,439 (9.802 MB), Total: 9.92 MB, FLOPs: 242,421,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1723 finished in 0m11s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 318)]\n",
      "Input: 0.115 MB, Params: 2,564,730 (9.784 MB), Total: 9.90 MB, FLOPs: 242,336,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1723 finished in 0m10s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 2,561,333 (9.771 MB), Total: 9.89 MB, FLOPs: 242,275,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1723 finished in 0m11s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 2,557,936 (9.758 MB), Total: 9.87 MB, FLOPs: 242,214,135\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1723 finished in 0m11s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 2,553,245 (9.740 MB), Total: 9.86 MB, FLOPs: 242,129,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1723 finished in 0m10s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 2,549,857 (9.727 MB), Total: 9.84 MB, FLOPs: 242,068,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1723 finished in 0m11s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.115 MB, Params: 2,548,361 (9.721 MB), Total: 9.84 MB, FLOPs: 241,460,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1723 finished in 0m11s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 2,543,679 (9.703 MB), Total: 9.82 MB, FLOPs: 241,376,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1723 finished in 0m10s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 314)]\n",
      "Input: 0.115 MB, Params: 2,538,997 (9.686 MB), Total: 9.80 MB, FLOPs: 241,291,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1723 finished in 0m10s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 196)]\n",
      "Input: 0.115 MB, Params: 2,533,730 (9.665 MB), Total: 9.78 MB, FLOPs: 241,060,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1723 finished in 0m10s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 2,530,360 (9.653 MB), Total: 9.77 MB, FLOPs: 240,999,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1723 finished in 0m11s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 2,525,696 (9.635 MB), Total: 9.75 MB, FLOPs: 240,915,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1723 finished in 0m10s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 166)]\n",
      "Input: 0.115 MB, Params: 2,522,940 (9.624 MB), Total: 9.74 MB, FLOPs: 240,667,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1723 finished in 0m09s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 316)]\n",
      "Input: 0.115 MB, Params: 2,518,276 (9.606 MB), Total: 9.72 MB, FLOPs: 240,583,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1723 finished in 0m09s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 271)]\n",
      "Input: 0.115 MB, Params: 2,513,612 (9.589 MB), Total: 9.70 MB, FLOPs: 240,499,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1723 finished in 0m09s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,510,269 (9.576 MB), Total: 9.69 MB, FLOPs: 240,439,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1723 finished in 0m11s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.115 MB, Params: 2,505,614 (9.558 MB), Total: 9.67 MB, FLOPs: 240,355,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1723 finished in 0m10s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 2,500,959 (9.540 MB), Total: 9.66 MB, FLOPs: 240,272,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1723 finished in 0m09s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.115 MB, Params: 2,496,304 (9.523 MB), Total: 9.64 MB, FLOPs: 240,188,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1723 finished in 0m09s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 136)]\n",
      "Input: 0.115 MB, Params: 2,491,100 (9.503 MB), Total: 9.62 MB, FLOPs: 239,958,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1723 finished in 0m10s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 2,487,784 (9.490 MB), Total: 9.61 MB, FLOPs: 239,898,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1723 finished in 0m11s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 200)]\n",
      "Input: 0.115 MB, Params: 2,483,147 (9.472 MB), Total: 9.59 MB, FLOPs: 239,815,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1723 finished in 0m10s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 115)]\n",
      "Input: 0.115 MB, Params: 2,477,952 (9.453 MB), Total: 9.57 MB, FLOPs: 239,585,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1723 finished in 0m10s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 185)]\n",
      "Input: 0.115 MB, Params: 2,473,324 (9.435 MB), Total: 9.55 MB, FLOPs: 239,502,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1723 finished in 0m10s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 290)]\n",
      "Input: 0.115 MB, Params: 2,468,696 (9.417 MB), Total: 9.53 MB, FLOPs: 239,419,006\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1723 finished in 0m09s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 2,464,068 (9.400 MB), Total: 9.51 MB, FLOPs: 239,335,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1723 finished in 0m09s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 2,459,440 (9.382 MB), Total: 9.50 MB, FLOPs: 239,252,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1723 finished in 0m09s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.115 MB, Params: 2,456,169 (9.370 MB), Total: 9.48 MB, FLOPs: 239,193,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1723 finished in 0m11s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 2,451,550 (9.352 MB), Total: 9.47 MB, FLOPs: 239,110,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1723 finished in 0m10s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 2,450,054 (9.346 MB), Total: 9.46 MB, FLOPs: 238,501,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1723 finished in 0m10s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 2,445,435 (9.329 MB), Total: 9.44 MB, FLOPs: 238,418,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1723 finished in 0m10s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 2,442,182 (9.316 MB), Total: 9.43 MB, FLOPs: 238,360,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1723 finished in 0m11s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 2,437,572 (9.299 MB), Total: 9.41 MB, FLOPs: 238,277,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1723 finished in 0m10s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 2,434,834 (9.288 MB), Total: 9.40 MB, FLOPs: 238,031,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1723 finished in 0m10s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.115 MB, Params: 2,430,224 (9.271 MB), Total: 9.39 MB, FLOPs: 237,948,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1723 finished in 0m09s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.115 MB, Params: 2,427,486 (9.260 MB), Total: 9.38 MB, FLOPs: 237,701,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1723 finished in 0m09s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 2,426,962 (9.258 MB), Total: 9.37 MB, FLOPs: 236,738,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1723 finished in 0m10s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 354)]\n",
      "Input: 0.115 MB, Params: 2,422,352 (9.241 MB), Total: 9.36 MB, FLOPs: 236,656,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1723 finished in 0m10s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 2,417,256 (9.221 MB), Total: 9.34 MB, FLOPs: 236,429,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1723 finished in 0m10s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 2,416,732 (9.219 MB), Total: 9.33 MB, FLOPs: 235,466,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1723 finished in 0m11s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.115 MB, Params: 2,413,506 (9.207 MB), Total: 9.32 MB, FLOPs: 235,408,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1723 finished in 0m12s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 37)]\n",
      "Input: 0.115 MB, Params: 2,412,739 (9.204 MB), Total: 9.32 MB, FLOPs: 234,087,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1723 finished in 0m09s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.115 MB, Params: 2,408,147 (9.186 MB), Total: 9.30 MB, FLOPs: 234,004,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1723 finished in 0m09s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.115 MB, Params: 2,405,418 (9.176 MB), Total: 9.29 MB, FLOPs: 233,759,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1723 finished in 0m09s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 2,400,826 (9.158 MB), Total: 9.27 MB, FLOPs: 233,676,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1723 finished in 0m09s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 95)]\n",
      "Input: 0.115 MB, Params: 2,399,330 (9.153 MB), Total: 9.27 MB, FLOPs: 233,067,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1723 finished in 0m10s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 2,396,122 (9.140 MB), Total: 9.26 MB, FLOPs: 233,010,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1723 finished in 0m12s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 66)]\n",
      "Input: 0.115 MB, Params: 2,394,626 (9.135 MB), Total: 9.25 MB, FLOPs: 232,401,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1723 finished in 0m11s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.115 MB, Params: 2,390,043 (9.117 MB), Total: 9.23 MB, FLOPs: 232,319,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1723 finished in 0m10s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 2,387,314 (9.107 MB), Total: 9.22 MB, FLOPs: 232,073,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1723 finished in 0m09s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 221)]\n",
      "Input: 0.115 MB, Params: 2,384,115 (9.095 MB), Total: 9.21 MB, FLOPs: 232,016,199\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1723 finished in 0m11s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 330)]\n",
      "Input: 0.115 MB, Params: 2,379,541 (9.077 MB), Total: 9.19 MB, FLOPs: 231,933,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1723 finished in 0m10s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 265)]\n",
      "Input: 0.115 MB, Params: 2,374,967 (9.060 MB), Total: 9.18 MB, FLOPs: 231,851,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1723 finished in 0m10s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.115 MB, Params: 2,372,202 (9.049 MB), Total: 9.16 MB, FLOPs: 231,313,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1723 finished in 0m09s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.115 MB, Params: 2,369,482 (9.039 MB), Total: 9.15 MB, FLOPs: 231,069,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1723 finished in 0m09s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 2,364,908 (9.021 MB), Total: 9.14 MB, FLOPs: 230,986,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1723 finished in 0m10s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 2,361,736 (9.009 MB), Total: 9.12 MB, FLOPs: 230,929,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1723 finished in 0m11s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 328)]\n",
      "Input: 0.115 MB, Params: 2,357,171 (8.992 MB), Total: 9.11 MB, FLOPs: 230,847,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1723 finished in 0m10s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.115 MB, Params: 2,352,606 (8.974 MB), Total: 9.09 MB, FLOPs: 230,765,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1723 finished in 0m09s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 160)]\n",
      "Input: 0.115 MB, Params: 2,347,609 (8.955 MB), Total: 9.07 MB, FLOPs: 230,542,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1723 finished in 0m11s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.115 MB, Params: 2,343,053 (8.938 MB), Total: 9.05 MB, FLOPs: 230,460,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1723 finished in 0m11s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 2,338,497 (8.921 MB), Total: 9.04 MB, FLOPs: 230,378,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1723 finished in 0m10s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 2,333,518 (8.902 MB), Total: 9.02 MB, FLOPs: 230,156,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1723 finished in 0m11s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.115 MB, Params: 2,328,971 (8.884 MB), Total: 9.00 MB, FLOPs: 230,074,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1723 finished in 0m10s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.115 MB, Params: 2,324,424 (8.867 MB), Total: 8.98 MB, FLOPs: 229,992,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1723 finished in 0m10s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 2,319,877 (8.850 MB), Total: 8.96 MB, FLOPs: 229,910,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1723 finished in 0m10s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 2,315,330 (8.832 MB), Total: 8.95 MB, FLOPs: 229,828,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1723 finished in 0m10s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 26)]\n",
      "Input: 0.115 MB, Params: 2,315,293 (8.832 MB), Total: 8.95 MB, FLOPs: 229,505,547\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1723 finished in 0m12s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 2,310,746 (8.815 MB), Total: 8.93 MB, FLOPs: 229,423,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1723 finished in 0m11s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.115 MB, Params: 2,306,199 (8.797 MB), Total: 8.91 MB, FLOPs: 229,341,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1723 finished in 0m10s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 307)]\n",
      "Input: 0.115 MB, Params: 2,303,117 (8.786 MB), Total: 8.90 MB, FLOPs: 229,286,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1723 finished in 0m11s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 2,298,579 (8.768 MB), Total: 8.88 MB, FLOPs: 229,204,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1723 finished in 0m11s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 174)]\n",
      "Input: 0.115 MB, Params: 2,295,877 (8.758 MB), Total: 8.87 MB, FLOPs: 228,961,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1723 finished in 0m10s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 2,293,175 (8.748 MB), Total: 8.86 MB, FLOPs: 228,718,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1723 finished in 0m10s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.115 MB, Params: 2,288,637 (8.730 MB), Total: 8.85 MB, FLOPs: 228,636,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1723 finished in 0m10s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.115 MB, Params: 2,285,935 (8.720 MB), Total: 8.84 MB, FLOPs: 228,393,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1723 finished in 0m08s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.115 MB, Params: 2,284,448 (8.714 MB), Total: 8.83 MB, FLOPs: 227,789,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1723 finished in 0m10s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 182)]\n",
      "Input: 0.115 MB, Params: 2,279,910 (8.697 MB), Total: 8.81 MB, FLOPs: 227,707,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1723 finished in 0m10s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 27)]\n",
      "Input: 0.115 MB, Params: 2,278,504 (8.692 MB), Total: 8.81 MB, FLOPs: 226,468,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1723 finished in 0m10s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 2,275,449 (8.680 MB), Total: 8.80 MB, FLOPs: 226,413,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1723 finished in 0m12s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 2,272,394 (8.668 MB), Total: 8.78 MB, FLOPs: 226,358,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1723 finished in 0m12s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 2,270,916 (8.663 MB), Total: 8.78 MB, FLOPs: 225,757,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1723 finished in 0m11s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 242)]\n",
      "Input: 0.115 MB, Params: 2,267,861 (8.651 MB), Total: 8.77 MB, FLOPs: 225,702,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1723 finished in 0m12s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 167)]\n",
      "Input: 0.115 MB, Params: 2,264,806 (8.640 MB), Total: 8.75 MB, FLOPs: 225,647,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1723 finished in 0m13s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 2,262,104 (8.629 MB), Total: 8.74 MB, FLOPs: 225,404,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1723 finished in 0m09s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 195)]\n",
      "Input: 0.115 MB, Params: 2,259,402 (8.619 MB), Total: 8.73 MB, FLOPs: 225,161,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1723 finished in 0m09s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.115 MB, Params: 2,256,700 (8.609 MB), Total: 8.72 MB, FLOPs: 224,918,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1723 finished in 0m08s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 2,253,645 (8.597 MB), Total: 8.71 MB, FLOPs: 224,863,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1723 finished in 0m11s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.115 MB, Params: 2,249,152 (8.580 MB), Total: 8.70 MB, FLOPs: 224,782,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1723 finished in 0m11s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 182)]\n",
      "Input: 0.115 MB, Params: 2,244,317 (8.561 MB), Total: 8.68 MB, FLOPs: 224,566,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1723 finished in 0m11s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 318)]\n",
      "Input: 0.115 MB, Params: 2,239,833 (8.544 MB), Total: 8.66 MB, FLOPs: 224,485,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1723 finished in 0m11s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 273)]\n",
      "Input: 0.115 MB, Params: 2,235,349 (8.527 MB), Total: 8.64 MB, FLOPs: 224,404,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 98.864%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1723 finished in 0m10s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 2,232,656 (8.517 MB), Total: 8.63 MB, FLOPs: 224,162,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 98.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1723 finished in 0m09s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 2,227,848 (8.499 MB), Total: 8.61 MB, FLOPs: 223,947,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1723 finished in 0m11s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 86)]\n",
      "Input: 0.115 MB, Params: 2,225,173 (8.488 MB), Total: 8.60 MB, FLOPs: 223,423,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1723 finished in 0m10s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 174)]\n",
      "Input: 0.115 MB, Params: 2,220,365 (8.470 MB), Total: 8.59 MB, FLOPs: 223,208,749\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1723 finished in 0m11s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 2,217,337 (8.458 MB), Total: 8.57 MB, FLOPs: 223,154,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1723 finished in 0m13s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.115 MB, Params: 2,214,662 (8.448 MB), Total: 8.56 MB, FLOPs: 222,630,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1723 finished in 0m10s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 2,210,205 (8.431 MB), Total: 8.55 MB, FLOPs: 222,550,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1723 finished in 0m08s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 2,205,748 (8.414 MB), Total: 8.53 MB, FLOPs: 222,470,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1723 finished in 0m08s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.115 MB, Params: 2,204,288 (8.409 MB), Total: 8.52 MB, FLOPs: 221,876,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1723 finished in 0m10s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 103)]\n",
      "Input: 0.115 MB, Params: 2,201,622 (8.399 MB), Total: 8.51 MB, FLOPs: 221,356,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1723 finished in 0m10s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 2,198,612 (8.387 MB), Total: 8.50 MB, FLOPs: 221,301,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1723 finished in 0m12s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 2,193,822 (8.369 MB), Total: 8.48 MB, FLOPs: 221,087,341\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1723 finished in 0m12s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 2,190,812 (8.357 MB), Total: 8.47 MB, FLOPs: 221,033,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1723 finished in 0m13s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 27)]\n",
      "Input: 0.115 MB, Params: 2,189,424 (8.352 MB), Total: 8.47 MB, FLOPs: 219,801,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1723 finished in 0m11s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 2,184,634 (8.334 MB), Total: 8.45 MB, FLOPs: 219,586,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1723 finished in 0m11s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.115 MB, Params: 2,182,004 (8.324 MB), Total: 8.44 MB, FLOPs: 219,350,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1723 finished in 0m09s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 2,178,994 (8.312 MB), Total: 8.43 MB, FLOPs: 219,296,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1723 finished in 0m11s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 331)]\n",
      "Input: 0.115 MB, Params: 2,174,582 (8.295 MB), Total: 8.41 MB, FLOPs: 219,216,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1723 finished in 0m09s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.115 MB, Params: 2,171,952 (8.285 MB), Total: 8.40 MB, FLOPs: 218,980,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1723 finished in 0m09s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 88)]\n",
      "Input: 0.115 MB, Params: 2,170,510 (8.280 MB), Total: 8.40 MB, FLOPs: 218,393,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1723 finished in 0m11s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 161)]\n",
      "Input: 0.115 MB, Params: 2,165,747 (8.262 MB), Total: 8.38 MB, FLOPs: 218,180,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1723 finished in 0m12s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 2,161,344 (8.245 MB), Total: 8.36 MB, FLOPs: 218,101,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1723 finished in 0m10s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 2,156,941 (8.228 MB), Total: 8.34 MB, FLOPs: 218,022,219\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1723 finished in 0m08s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.115 MB, Params: 2,156,192 (8.225 MB), Total: 8.34 MB, FLOPs: 216,731,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1723 finished in 0m09s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 291)]\n",
      "Input: 0.115 MB, Params: 2,153,209 (8.214 MB), Total: 8.33 MB, FLOPs: 216,678,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1723 finished in 0m11s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 309)]\n",
      "Input: 0.115 MB, Params: 2,148,815 (8.197 MB), Total: 8.31 MB, FLOPs: 216,599,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1723 finished in 0m10s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 2,145,841 (8.186 MB), Total: 8.30 MB, FLOPs: 216,545,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1723 finished in 0m11s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 135)]\n",
      "Input: 0.115 MB, Params: 2,143,220 (8.176 MB), Total: 8.29 MB, FLOPs: 216,309,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1723 finished in 0m10s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 35)]\n",
      "Input: 0.115 MB, Params: 2,138,493 (8.158 MB), Total: 8.27 MB, FLOPs: 216,098,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1723 finished in 0m11s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 2,137,123 (8.152 MB), Total: 8.27 MB, FLOPs: 214,885,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1723 finished in 0m11s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 73)]\n",
      "Input: 0.115 MB, Params: 2,134,493 (8.142 MB), Total: 8.26 MB, FLOPs: 214,371,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1723 finished in 0m09s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 20)]\n",
      "Input: 0.115 MB, Params: 2,134,456 (8.142 MB), Total: 8.26 MB, FLOPs: 210,987,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1723 finished in 0m15s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.115 MB, Params: 2,129,729 (8.124 MB), Total: 8.24 MB, FLOPs: 210,775,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1723 finished in 0m13s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 130)]\n",
      "Input: 0.115 MB, Params: 2,125,002 (8.106 MB), Total: 8.22 MB, FLOPs: 210,564,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1723 finished in 0m12s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 2,120,644 (8.090 MB), Total: 8.20 MB, FLOPs: 210,485,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1723 finished in 0m10s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 2,115,926 (8.072 MB), Total: 8.19 MB, FLOPs: 210,274,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1723 finished in 0m11s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 2,112,961 (8.060 MB), Total: 8.18 MB, FLOPs: 210,221,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1723 finished in 0m13s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 2,110,331 (8.050 MB), Total: 8.17 MB, FLOPs: 209,707,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1723 finished in 0m11s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 2,107,366 (8.039 MB), Total: 8.15 MB, FLOPs: 209,653,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1723 finished in 0m12s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 270)]\n",
      "Input: 0.115 MB, Params: 2,103,035 (8.022 MB), Total: 8.14 MB, FLOPs: 209,575,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1723 finished in 0m10s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 2,098,326 (8.004 MB), Total: 8.12 MB, FLOPs: 209,364,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1723 finished in 0m11s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.115 MB, Params: 2,093,617 (7.987 MB), Total: 8.10 MB, FLOPs: 209,153,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1723 finished in 0m12s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 2,090,661 (7.975 MB), Total: 8.09 MB, FLOPs: 209,100,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1723 finished in 0m12s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 36)]\n",
      "Input: 0.115 MB, Params: 2,089,291 (7.970 MB), Total: 8.09 MB, FLOPs: 207,924,801\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1723 finished in 0m11s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 64)]\n",
      "Input: 0.115 MB, Params: 2,084,582 (7.952 MB), Total: 8.07 MB, FLOPs: 207,713,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1723 finished in 0m12s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 2,081,626 (7.941 MB), Total: 8.06 MB, FLOPs: 207,660,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1723 finished in 0m13s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 162)]\n",
      "Input: 0.115 MB, Params: 2,076,917 (7.923 MB), Total: 8.04 MB, FLOPs: 207,449,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1723 finished in 0m12s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.115 MB, Params: 2,072,640 (7.906 MB), Total: 8.02 MB, FLOPs: 207,372,159\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1723 finished in 0m10s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 2,069,693 (7.895 MB), Total: 8.01 MB, FLOPs: 207,319,143\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1723 finished in 0m12s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.115 MB, Params: 2,068,287 (7.890 MB), Total: 8.01 MB, FLOPs: 206,747,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1723 finished in 0m12s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 170)]\n",
      "Input: 0.115 MB, Params: 2,063,587 (7.872 MB), Total: 7.99 MB, FLOPs: 206,536,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1723 finished in 0m12s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 2,060,640 (7.861 MB), Total: 7.98 MB, FLOPs: 206,483,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1723 finished in 0m13s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.115 MB, Params: 2,055,940 (7.843 MB), Total: 7.96 MB, FLOPs: 206,272,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1723 finished in 0m12s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 2,051,699 (7.827 MB), Total: 7.94 MB, FLOPs: 206,195,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1723 finished in 0m10s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 2,047,458 (7.810 MB), Total: 7.93 MB, FLOPs: 206,119,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1723 finished in 0m09s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 2,044,945 (7.801 MB), Total: 7.92 MB, FLOPs: 205,893,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1723 finished in 0m09s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 2,040,704 (7.785 MB), Total: 7.90 MB, FLOPs: 205,817,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1723 finished in 0m09s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.115 MB, Params: 2,038,191 (7.775 MB), Total: 7.89 MB, FLOPs: 205,591,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1723 finished in 0m09s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.115 MB, Params: 2,033,950 (7.759 MB), Total: 7.87 MB, FLOPs: 205,514,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1723 finished in 0m09s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 2,031,039 (7.748 MB), Total: 7.86 MB, FLOPs: 205,462,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1723 finished in 0m12s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 2,026,807 (7.732 MB), Total: 7.85 MB, FLOPs: 205,386,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1723 finished in 0m10s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 18)]\n",
      "Input: 0.115 MB, Params: 2,026,301 (7.730 MB), Total: 7.85 MB, FLOPs: 204,494,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1723 finished in 0m11s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 138)]\n",
      "Input: 0.115 MB, Params: 2,021,664 (7.712 MB), Total: 7.83 MB, FLOPs: 204,286,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1723 finished in 0m13s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 2,017,027 (7.694 MB), Total: 7.81 MB, FLOPs: 204,077,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1723 finished in 0m13s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 2,014,125 (7.683 MB), Total: 7.80 MB, FLOPs: 204,025,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1723 finished in 0m13s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.115 MB, Params: 2,012,719 (7.678 MB), Total: 7.79 MB, FLOPs: 203,453,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1723 finished in 0m12s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 89)]\n",
      "Input: 0.115 MB, Params: 2,010,125 (7.668 MB), Total: 7.78 MB, FLOPs: 202,948,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1723 finished in 0m11s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 26)]\n",
      "Input: 0.115 MB, Params: 2,009,403 (7.665 MB), Total: 7.78 MB, FLOPs: 201,758,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1723 finished in 0m10s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.115 MB, Params: 2,006,501 (7.654 MB), Total: 7.77 MB, FLOPs: 201,706,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1723 finished in 0m12s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 69)]\n",
      "Input: 0.115 MB, Params: 2,003,907 (7.644 MB), Total: 7.76 MB, FLOPs: 201,201,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1723 finished in 0m11s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 1,999,711 (7.628 MB), Total: 7.74 MB, FLOPs: 201,125,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1723 finished in 0m09s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 1,996,818 (7.617 MB), Total: 7.73 MB, FLOPs: 201,073,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1723 finished in 0m12s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 304)]\n",
      "Input: 0.115 MB, Params: 1,992,631 (7.601 MB), Total: 7.72 MB, FLOPs: 200,998,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1723 finished in 0m10s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.115 MB, Params: 1,990,154 (7.592 MB), Total: 7.71 MB, FLOPs: 200,775,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1723 finished in 0m09s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 1,987,270 (7.581 MB), Total: 7.70 MB, FLOPs: 200,723,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1723 finished in 0m12s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.115 MB, Params: 1,984,386 (7.570 MB), Total: 7.69 MB, FLOPs: 200,671,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1723 finished in 0m13s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 1,980,217 (7.554 MB), Total: 7.67 MB, FLOPs: 200,596,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1723 finished in 0m10s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 122)]\n",
      "Input: 0.115 MB, Params: 1,977,740 (7.544 MB), Total: 7.66 MB, FLOPs: 200,374,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1723 finished in 0m09s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 1,974,865 (7.534 MB), Total: 7.65 MB, FLOPs: 200,322,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1723 finished in 0m12s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 1,971,990 (7.523 MB), Total: 7.64 MB, FLOPs: 200,270,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1723 finished in 0m13s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 112)]\n",
      "Input: 0.115 MB, Params: 1,969,513 (7.513 MB), Total: 7.63 MB, FLOPs: 200,047,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1723 finished in 0m10s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,966,638 (7.502 MB), Total: 7.62 MB, FLOPs: 199,996,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1723 finished in 0m12s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.115 MB, Params: 1,962,496 (7.486 MB), Total: 7.60 MB, FLOPs: 199,921,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1723 finished in 0m10s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 1,957,922 (7.469 MB), Total: 7.58 MB, FLOPs: 199,715,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1723 finished in 0m11s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 42)]\n",
      "Input: 0.115 MB, Params: 1,957,200 (7.466 MB), Total: 7.58 MB, FLOPs: 198,526,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1723 finished in 0m10s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.115 MB, Params: 1,952,626 (7.449 MB), Total: 7.56 MB, FLOPs: 198,320,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1723 finished in 0m12s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 39)]\n",
      "Input: 0.115 MB, Params: 1,951,904 (7.446 MB), Total: 7.56 MB, FLOPs: 197,131,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1723 finished in 0m10s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 95)]\n",
      "Input: 0.115 MB, Params: 1,947,330 (7.428 MB), Total: 7.54 MB, FLOPs: 196,925,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1723 finished in 0m11s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 1,944,464 (7.418 MB), Total: 7.53 MB, FLOPs: 196,873,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1723 finished in 0m14s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 1,943,076 (7.412 MB), Total: 7.53 MB, FLOPs: 196,309,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1723 finished in 0m12s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 284)]\n",
      "Input: 0.115 MB, Params: 1,940,210 (7.401 MB), Total: 7.52 MB, FLOPs: 196,257,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1723 finished in 0m13s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 137)]\n",
      "Input: 0.115 MB, Params: 1,937,344 (7.390 MB), Total: 7.51 MB, FLOPs: 196,206,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1723 finished in 0m13s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.115 MB, Params: 1,934,478 (7.379 MB), Total: 7.49 MB, FLOPs: 196,154,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1723 finished in 0m13s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.115 MB, Params: 1,931,612 (7.369 MB), Total: 7.48 MB, FLOPs: 196,103,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1723 finished in 0m13s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 1,928,746 (7.358 MB), Total: 7.47 MB, FLOPs: 196,051,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1723 finished in 0m13s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.115 MB, Params: 1,927,358 (7.352 MB), Total: 7.47 MB, FLOPs: 195,487,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1723 finished in 0m12s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 1,924,492 (7.341 MB), Total: 7.46 MB, FLOPs: 195,435,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1723 finished in 0m13s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 1,922,042 (7.332 MB), Total: 7.45 MB, FLOPs: 195,215,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1723 finished in 0m10s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 15)]\n",
      "Input: 0.115 MB, Params: 1,919,502 (7.322 MB), Total: 7.44 MB, FLOPs: 194,720,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1723 finished in 0m09s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 62)]\n",
      "Input: 0.115 MB, Params: 1,918,123 (7.317 MB), Total: 7.43 MB, FLOPs: 194,159,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1723 finished in 0m11s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 1,915,257 (7.306 MB), Total: 7.42 MB, FLOPs: 194,108,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1723 finished in 0m13s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 1,914,778 (7.304 MB), Total: 7.42 MB, FLOPs: 193,261,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1723 finished in 0m13s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 27)]\n",
      "Input: 0.115 MB, Params: 1,914,065 (7.302 MB), Total: 7.42 MB, FLOPs: 192,086,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1723 finished in 0m11s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 1,909,500 (7.284 MB), Total: 7.40 MB, FLOPs: 191,881,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1723 finished in 0m12s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 1,906,634 (7.273 MB), Total: 7.39 MB, FLOPs: 191,830,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1723 finished in 0m13s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 1,905,255 (7.268 MB), Total: 7.38 MB, FLOPs: 191,269,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1723 finished in 0m12s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 270)]\n",
      "Input: 0.115 MB, Params: 1,901,230 (7.253 MB), Total: 7.37 MB, FLOPs: 191,197,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1723 finished in 0m10s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 312)]\n",
      "Input: 0.115 MB, Params: 1,897,205 (7.237 MB), Total: 7.35 MB, FLOPs: 191,124,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1723 finished in 0m09s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 150)]\n",
      "Input: 0.115 MB, Params: 1,892,658 (7.220 MB), Total: 7.34 MB, FLOPs: 190,920,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1723 finished in 0m11s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 1,889,810 (7.209 MB), Total: 7.32 MB, FLOPs: 190,869,021\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1723 finished in 0m14s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 1,886,962 (7.198 MB), Total: 7.31 MB, FLOPs: 190,817,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1723 finished in 0m13s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 1,884,114 (7.187 MB), Total: 7.30 MB, FLOPs: 190,766,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1723 finished in 0m13s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 156)]\n",
      "Input: 0.115 MB, Params: 1,880,125 (7.172 MB), Total: 7.29 MB, FLOPs: 190,694,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1723 finished in 0m11s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 1,876,136 (7.157 MB), Total: 7.27 MB, FLOPs: 190,622,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1723 finished in 0m10s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.115 MB, Params: 1,872,147 (7.142 MB), Total: 7.26 MB, FLOPs: 190,551,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1723 finished in 0m10s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 1,867,627 (7.124 MB), Total: 7.24 MB, FLOPs: 190,347,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1723 finished in 0m13s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 1,867,157 (7.123 MB), Total: 7.24 MB, FLOPs: 189,515,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1723 finished in 0m15s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.115 MB, Params: 1,864,336 (7.112 MB), Total: 7.23 MB, FLOPs: 189,464,595\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1723 finished in 0m16s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.115 MB, Params: 1,861,814 (7.102 MB), Total: 7.22 MB, FLOPs: 188,977,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1723 finished in 0m12s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.115 MB, Params: 1,858,993 (7.091 MB), Total: 7.21 MB, FLOPs: 188,926,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1723 finished in 0m14s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 1,854,473 (7.074 MB), Total: 7.19 MB, FLOPs: 188,722,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1723 finished in 0m14s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 23)]\n",
      "Input: 0.115 MB, Params: 1,853,103 (7.069 MB), Total: 7.18 MB, FLOPs: 188,165,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1723 finished in 0m14s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 1,850,282 (7.058 MB), Total: 7.17 MB, FLOPs: 188,114,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1723 finished in 0m16s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.115 MB, Params: 1,846,338 (7.043 MB), Total: 7.16 MB, FLOPs: 188,043,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1723 finished in 0m11s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.115 MB, Params: 1,842,394 (7.028 MB), Total: 7.14 MB, FLOPs: 187,972,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1723 finished in 0m09s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.115 MB, Params: 1,837,892 (7.011 MB), Total: 7.13 MB, FLOPs: 187,769,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1723 finished in 0m13s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.115 MB, Params: 1,833,957 (6.996 MB), Total: 7.11 MB, FLOPs: 187,698,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1723 finished in 0m11s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,831,163 (6.985 MB), Total: 7.10 MB, FLOPs: 187,648,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1723 finished in 0m14s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 1,828,369 (6.975 MB), Total: 7.09 MB, FLOPs: 187,597,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1723 finished in 0m16s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.115 MB, Params: 1,827,899 (6.973 MB), Total: 7.09 MB, FLOPs: 186,765,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.636%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1723 finished in 0m15s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.115 MB, Params: 1,823,406 (6.956 MB), Total: 7.07 MB, FLOPs: 186,562,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1723 finished in 0m15s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 1,819,498 (6.941 MB), Total: 7.06 MB, FLOPs: 186,492,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1723 finished in 0m11s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 287)]\n",
      "Input: 0.115 MB, Params: 1,815,590 (6.926 MB), Total: 7.04 MB, FLOPs: 186,421,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1723 finished in 0m10s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.115 MB, Params: 1,811,682 (6.911 MB), Total: 7.03 MB, FLOPs: 186,351,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1723 finished in 0m10s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 285)]\n",
      "Input: 0.115 MB, Params: 1,807,774 (6.896 MB), Total: 7.01 MB, FLOPs: 186,281,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1723 finished in 0m10s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 1,803,866 (6.881 MB), Total: 7.00 MB, FLOPs: 186,210,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1723 finished in 0m10s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 1,799,418 (6.864 MB), Total: 6.98 MB, FLOPs: 186,008,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1723 finished in 0m13s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 1,796,669 (6.854 MB), Total: 6.97 MB, FLOPs: 185,958,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1723 finished in 0m16s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 1,793,920 (6.843 MB), Total: 6.96 MB, FLOPs: 185,909,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1723 finished in 0m16s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 5)]\n",
      "Input: 0.115 MB, Params: 1,792,550 (6.838 MB), Total: 6.95 MB, FLOPs: 185,352,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1723 finished in 0m14s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.115 MB, Params: 1,788,102 (6.821 MB), Total: 6.94 MB, FLOPs: 185,149,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1723 finished in 0m15s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.115 MB, Params: 1,786,732 (6.816 MB), Total: 6.93 MB, FLOPs: 184,592,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1723 finished in 0m14s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 106)]\n",
      "Input: 0.115 MB, Params: 1,784,372 (6.807 MB), Total: 6.92 MB, FLOPs: 184,379,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1723 finished in 0m11s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.115 MB, Params: 1,781,886 (6.797 MB), Total: 6.91 MB, FLOPs: 183,904,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1723 finished in 0m10s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 1,779,137 (6.787 MB), Total: 6.90 MB, FLOPs: 183,855,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1723 finished in 0m14s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 265)]\n",
      "Input: 0.115 MB, Params: 1,775,274 (6.772 MB), Total: 6.89 MB, FLOPs: 183,785,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1723 finished in 0m11s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 1,770,844 (6.755 MB), Total: 6.87 MB, FLOPs: 183,583,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1723 finished in 0m13s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 1,768,104 (6.745 MB), Total: 6.86 MB, FLOPs: 183,534,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1723 finished in 0m16s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 214)]\n",
      "Input: 0.115 MB, Params: 1,764,259 (6.730 MB), Total: 6.85 MB, FLOPs: 183,465,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1723 finished in 0m11s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.115 MB, Params: 1,761,917 (6.721 MB), Total: 6.84 MB, FLOPs: 183,254,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1723 finished in 0m09s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 1,758,072 (6.707 MB), Total: 6.82 MB, FLOPs: 183,185,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1723 finished in 0m10s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 1,754,227 (6.692 MB), Total: 6.81 MB, FLOPs: 183,116,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1723 finished in 0m10s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 130)]\n",
      "Input: 0.115 MB, Params: 1,749,833 (6.675 MB), Total: 6.79 MB, FLOPs: 182,915,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1723 finished in 0m13s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 122)]\n",
      "Input: 0.115 MB, Params: 1,745,439 (6.658 MB), Total: 6.77 MB, FLOPs: 182,715,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1723 finished in 0m15s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 1,743,115 (6.649 MB), Total: 6.76 MB, FLOPs: 182,506,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1723 finished in 0m11s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 15)]\n",
      "Input: 0.115 MB, Params: 1,743,078 (6.649 MB), Total: 6.76 MB, FLOPs: 182,189,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1723 finished in 0m15s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 140)]\n",
      "Input: 0.115 MB, Params: 1,740,754 (6.640 MB), Total: 6.76 MB, FLOPs: 181,980,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1723 finished in 0m12s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 150)]\n",
      "Input: 0.115 MB, Params: 1,738,430 (6.632 MB), Total: 6.75 MB, FLOPs: 181,771,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1723 finished in 0m10s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 1,734,603 (6.617 MB), Total: 6.73 MB, FLOPs: 181,702,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1723 finished in 0m10s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 1,731,899 (6.607 MB), Total: 6.72 MB, FLOPs: 181,653,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1723 finished in 0m14s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.115 MB, Params: 1,729,575 (6.598 MB), Total: 6.71 MB, FLOPs: 181,444,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1723 finished in 0m11s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 166)]\n",
      "Input: 0.115 MB, Params: 1,727,251 (6.589 MB), Total: 6.70 MB, FLOPs: 181,235,483\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1723 finished in 0m10s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 1,724,547 (6.579 MB), Total: 6.69 MB, FLOPs: 181,186,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1723 finished in 0m14s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 82)]\n",
      "Input: 0.115 MB, Params: 1,720,207 (6.562 MB), Total: 6.68 MB, FLOPs: 180,990,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1723 finished in 0m15s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 157)]\n",
      "Input: 0.115 MB, Params: 1,715,867 (6.546 MB), Total: 6.66 MB, FLOPs: 180,794,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1723 finished in 0m15s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 171)]\n",
      "Input: 0.115 MB, Params: 1,713,561 (6.537 MB), Total: 6.65 MB, FLOPs: 180,587,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1723 finished in 0m11s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 47)]\n",
      "Input: 0.115 MB, Params: 1,712,866 (6.534 MB), Total: 6.65 MB, FLOPs: 179,441,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1723 finished in 0m11s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,710,162 (6.524 MB), Total: 6.64 MB, FLOPs: 179,393,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1723 finished in 0m15s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.115 MB, Params: 1,706,380 (6.509 MB), Total: 6.62 MB, FLOPs: 179,325,227\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1723 finished in 0m11s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.115 MB, Params: 1,702,598 (6.495 MB), Total: 6.61 MB, FLOPs: 179,257,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1723 finished in 0m10s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 70)]\n",
      "Input: 0.115 MB, Params: 1,700,175 (6.486 MB), Total: 6.60 MB, FLOPs: 178,787,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1723 finished in 0m11s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.115 MB, Params: 1,695,862 (6.469 MB), Total: 6.58 MB, FLOPs: 178,592,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1723 finished in 0m13s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 243)]\n",
      "Input: 0.115 MB, Params: 1,693,176 (6.459 MB), Total: 6.57 MB, FLOPs: 178,544,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1723 finished in 0m16s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 1,690,490 (6.449 MB), Total: 6.56 MB, FLOPs: 178,495,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1723 finished in 0m16s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 1,687,804 (6.438 MB), Total: 6.55 MB, FLOPs: 178,447,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1723 finished in 0m16s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 1,685,118 (6.428 MB), Total: 6.54 MB, FLOPs: 178,399,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1723 finished in 0m16s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 233)]\n",
      "Input: 0.115 MB, Params: 1,681,381 (6.414 MB), Total: 6.53 MB, FLOPs: 178,331,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1723 finished in 0m11s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 1,679,093 (6.405 MB), Total: 6.52 MB, FLOPs: 178,126,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1723 finished in 0m10s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 1,674,798 (6.389 MB), Total: 6.50 MB, FLOPs: 177,931,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1723 finished in 0m14s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 1,671,070 (6.375 MB), Total: 6.49 MB, FLOPs: 177,864,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1723 finished in 0m11s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 238)]\n",
      "Input: 0.115 MB, Params: 1,667,342 (6.360 MB), Total: 6.48 MB, FLOPs: 177,797,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1723 finished in 0m10s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 1,663,614 (6.346 MB), Total: 6.46 MB, FLOPs: 177,730,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1723 finished in 0m10s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 161)]\n",
      "Input: 0.115 MB, Params: 1,659,886 (6.332 MB), Total: 6.45 MB, FLOPs: 177,663,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1723 finished in 0m10s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 158)]\n",
      "Input: 0.115 MB, Params: 1,657,607 (6.323 MB), Total: 6.44 MB, FLOPs: 177,458,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1723 finished in 0m10s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 1,653,879 (6.309 MB), Total: 6.42 MB, FLOPs: 177,391,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1723 finished in 0m10s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 60)]\n",
      "Input: 0.115 MB, Params: 1,651,474 (6.300 MB), Total: 6.42 MB, FLOPs: 176,923,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1723 finished in 0m11s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 93)]\n",
      "Input: 0.115 MB, Params: 1,649,069 (6.291 MB), Total: 6.41 MB, FLOPs: 176,455,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
