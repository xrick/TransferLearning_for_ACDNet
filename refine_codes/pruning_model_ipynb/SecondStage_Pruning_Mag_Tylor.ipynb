{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from refine_codes.SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36995275-4419-4d02-a744-3d37ef85e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genDataTimeStr():\n",
    "#     return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([(52,1),(99,2)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/forOneClassModel_alarm/train_test_npz/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=2, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 2 #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        self.opt.device = 'cuda:0'#at home use apple m2\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel();\n",
    "        self.net.load_state_dict(torch.load(\"../retrained_models_after_first_stage_pruning/pruning_time_2024021618_prunratio0.6/retrained_model_after_first_pruning_0.7ratio_acc97.7272720336914_0th_epoch_20240216181902.pt\", map_location=\"cuda:0\")['weight']);\n",
    "        self.net = self.net.to('cuda:0');#at home use apple m2\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        print(f\"pruning algorithm is {self.pruner}\");\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);#in office, use cuda(better) or cpu\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # if self.opt.device == \"mps\":\n",
    "            #     y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                label = label.cpu() #use apple m2, in office use cuda\n",
    "                output = output.cpu() #use apple m2, in office use cuda\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # if self.opt.device == \"mps\":\n",
    "                #     x = torch.tensor(x)\n",
    "                #     x = x.type(torch.FloatTensor) # use apple mp2\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 32;\n",
    "    # opt.LR = 0.01;\n",
    "    # opt.momentum = 0.09;\n",
    "    # opt.weightDecay = 5e-3;\n",
    "    # opt.nEpochs = 1000;#2000;\n",
    "    # opt.schedule = [0.03, 0.06, 0.09]\n",
    "    # opt.warmup = 10;\n",
    "    #set train and validation sets\n",
    "    opt.trainSet = \"../../datasets/CurrentUse/forOneClassModel_alarm/train/trainSet_20240119002902.npz\"\n",
    "    opt.valSet = \"../../datasets/CurrentUse/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz\"\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.83\n",
    "    opt.prune_all = True;\n",
    "    opt.nClasses = 2\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    \n",
    "    # import torch;\n",
    "    # opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use cuda or cpu\n",
    "    opt.device = 'cuda:0' #at home use apple m2\n",
    "    # tlopts.display_info(opt)\n",
    "    save_dir = \"../../th/pruned_models/second_stage_pruned_models/pruning_time_{}_prunratio{}/\".format(getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    model_name = \"model_second_stage_prun_{}.pt\".format(genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:325\n",
      "Start to pruning.....\n",
      "pruning algorithm is <th.resources.pruning_tools.filter_pruning.Taylor object at 0x7fc80a5065f0>\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (2, 2, 4)      1,024        8,192\n",
      " BatchNorm2d-42         (2, 2, 4)         (2, 2, 4)          4            0\n",
      "        ReLu-43         (2, 2, 4)         (2, 2, 4)          0           16\n",
      "   AvgPool2d-44         (2, 2, 4)         (2, 1, 1)          0           16\n",
      "     Flatten-45         (2, 1, 1)            (1, 2)          0            0\n",
      "      Linear-46            (1, 2)            (1, 2)          6            6\n",
      "     Softmax-47            (1, 2)            (1, 2)          0            2\n",
      "==============================================================================\n",
      "Total Params: 4,708,162\n",
      "Total FLOPs : 544,222,072\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2026, Prunable: 2026, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (83%): 1680\n",
      "Total iterations required: 1680\n",
      "\n",
      "Iteration 1 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,708,120 (17.960 MB), Total: 18.08 MB, FLOPs: 483,662,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.364%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1682 finished in 0m07s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,708,078 (17.960 MB), Total: 18.08 MB, FLOPs: 483,296,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.636%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1682 finished in 0m06s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,708,036 (17.960 MB), Total: 18.08 MB, FLOPs: 478,764,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.636%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1682 finished in 0m06s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,994 (17.960 MB), Total: 18.07 MB, FLOPs: 478,399,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1682 finished in 0m06s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,952 (17.959 MB), Total: 18.07 MB, FLOPs: 465,664,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1682 finished in 0m06s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,707,910 (17.959 MB), Total: 18.07 MB, FLOPs: 465,299,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1682 finished in 0m06s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,868 (17.959 MB), Total: 18.07 MB, FLOPs: 460,767,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1682 finished in 0m06s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,826 (17.959 MB), Total: 18.07 MB, FLOPs: 460,401,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1682 finished in 0m06s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,707,784 (17.959 MB), Total: 18.07 MB, FLOPs: 431,723,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1682 finished in 0m06s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,707,742 (17.959 MB), Total: 18.07 MB, FLOPs: 431,357,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1682 finished in 0m06s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,707,700 (17.958 MB), Total: 18.07 MB, FLOPs: 426,825,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1682 finished in 0m06s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 26)]\n",
      "Input: 0.115 MB, Params: 4,707,113 (17.956 MB), Total: 18.07 MB, FLOPs: 425,614,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1682 finished in 0m06s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,700,199 (17.930 MB), Total: 18.05 MB, FLOPs: 425,241,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1682 finished in 0m06s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 4,695,587 (17.912 MB), Total: 18.03 MB, FLOPs: 425,116,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1682 finished in 0m06s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 4,688,673 (17.886 MB), Total: 18.00 MB, FLOPs: 424,743,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1682 finished in 0m06s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 7)]\n",
      "Input: 0.115 MB, Params: 4,687,816 (17.883 MB), Total: 18.00 MB, FLOPs: 423,074,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1682 finished in 0m06s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 4,683,204 (17.865 MB), Total: 17.98 MB, FLOPs: 422,949,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1682 finished in 0m06s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 4,678,592 (17.847 MB), Total: 17.96 MB, FLOPs: 422,825,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1682 finished in 0m06s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.115 MB, Params: 4,671,723 (17.821 MB), Total: 17.94 MB, FLOPs: 422,639,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1682 finished in 0m06s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 292)]\n",
      "Input: 0.115 MB, Params: 4,667,120 (17.804 MB), Total: 17.92 MB, FLOPs: 422,515,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1682 finished in 0m06s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 409)]\n",
      "Input: 0.115 MB, Params: 4,660,260 (17.777 MB), Total: 17.89 MB, FLOPs: 422,330,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1682 finished in 0m07s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 431)]\n",
      "Input: 0.115 MB, Params: 4,653,400 (17.751 MB), Total: 17.87 MB, FLOPs: 422,145,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1682 finished in 0m07s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 230)]\n",
      "Input: 0.115 MB, Params: 4,649,960 (17.738 MB), Total: 17.85 MB, FLOPs: 421,773,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1682 finished in 0m07s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 286)]\n",
      "Input: 0.115 MB, Params: 4,645,375 (17.721 MB), Total: 17.84 MB, FLOPs: 421,650,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1682 finished in 0m07s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 304)]\n",
      "Input: 0.115 MB, Params: 4,640,790 (17.703 MB), Total: 17.82 MB, FLOPs: 421,526,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1682 finished in 0m07s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 4,636,205 (17.686 MB), Total: 17.80 MB, FLOPs: 421,402,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1682 finished in 0m07s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 271)]\n",
      "Input: 0.115 MB, Params: 4,631,620 (17.668 MB), Total: 17.78 MB, FLOPs: 421,278,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1682 finished in 0m07s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 4,627,035 (17.651 MB), Total: 17.77 MB, FLOPs: 421,155,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1682 finished in 0m07s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 316)]\n",
      "Input: 0.115 MB, Params: 4,620,220 (17.625 MB), Total: 17.74 MB, FLOPs: 420,971,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1682 finished in 0m06s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 156)]\n",
      "Input: 0.115 MB, Params: 4,613,405 (17.599 MB), Total: 17.71 MB, FLOPs: 420,787,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1682 finished in 0m06s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.115 MB, Params: 4,606,545 (17.573 MB), Total: 17.69 MB, FLOPs: 420,415,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1682 finished in 0m06s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 298)]\n",
      "Input: 0.115 MB, Params: 4,601,978 (17.555 MB), Total: 17.67 MB, FLOPs: 420,292,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1682 finished in 0m06s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.115 MB, Params: 4,598,529 (17.542 MB), Total: 17.66 MB, FLOPs: 419,489,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1682 finished in 0m06s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 485)]\n",
      "Input: 0.115 MB, Params: 4,593,962 (17.525 MB), Total: 17.64 MB, FLOPs: 419,366,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1682 finished in 0m06s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 4,589,395 (17.507 MB), Total: 17.62 MB, FLOPs: 419,243,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1682 finished in 0m06s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 392)]\n",
      "Input: 0.115 MB, Params: 4,582,616 (17.481 MB), Total: 17.60 MB, FLOPs: 419,060,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1682 finished in 0m06s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.115 MB, Params: 4,578,058 (17.464 MB), Total: 17.58 MB, FLOPs: 418,937,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1682 finished in 0m06s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 4,571,288 (17.438 MB), Total: 17.55 MB, FLOPs: 418,754,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1682 finished in 0m06s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.115 MB, Params: 4,566,739 (17.421 MB), Total: 17.54 MB, FLOPs: 418,631,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1682 finished in 0m06s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.115 MB, Params: 4,562,190 (17.403 MB), Total: 17.52 MB, FLOPs: 418,508,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1682 finished in 0m06s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 94)]\n",
      "Input: 0.115 MB, Params: 4,558,768 (17.390 MB), Total: 17.51 MB, FLOPs: 418,139,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1682 finished in 0m06s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 207)]\n",
      "Input: 0.115 MB, Params: 4,551,935 (17.364 MB), Total: 17.48 MB, FLOPs: 417,769,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1682 finished in 0m06s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 4,547,386 (17.347 MB), Total: 17.46 MB, FLOPs: 417,646,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1682 finished in 0m06s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 224)]\n",
      "Input: 0.115 MB, Params: 4,540,553 (17.321 MB), Total: 17.44 MB, FLOPs: 417,277,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1682 finished in 0m06s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 421)]\n",
      "Input: 0.115 MB, Params: 4,533,828 (17.295 MB), Total: 17.41 MB, FLOPs: 417,095,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1682 finished in 0m06s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 4,529,288 (17.278 MB), Total: 17.39 MB, FLOPs: 416,973,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1682 finished in 0m06s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 397)]\n",
      "Input: 0.115 MB, Params: 4,524,748 (17.261 MB), Total: 17.38 MB, FLOPs: 416,850,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1682 finished in 0m06s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 53)]\n",
      "Input: 0.115 MB, Params: 4,523,891 (17.257 MB), Total: 17.37 MB, FLOPs: 415,181,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1682 finished in 0m06s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 3)]\n",
      "Input: 0.115 MB, Params: 4,523,849 (17.257 MB), Total: 17.37 MB, FLOPs: 414,817,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1682 finished in 0m06s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 4,519,309 (17.240 MB), Total: 17.36 MB, FLOPs: 414,694,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1682 finished in 0m06s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 4,514,769 (17.222 MB), Total: 17.34 MB, FLOPs: 414,572,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1682 finished in 0m06s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 4,510,229 (17.205 MB), Total: 17.32 MB, FLOPs: 414,449,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1682 finished in 0m06s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 377)]\n",
      "Input: 0.115 MB, Params: 4,503,549 (17.180 MB), Total: 17.29 MB, FLOPs: 414,269,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1682 finished in 0m06s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 491)]\n",
      "Input: 0.115 MB, Params: 4,496,869 (17.154 MB), Total: 17.27 MB, FLOPs: 414,089,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1682 finished in 0m07s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 268)]\n",
      "Input: 0.115 MB, Params: 4,492,347 (17.137 MB), Total: 17.25 MB, FLOPs: 413,966,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1682 finished in 0m07s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 167)]\n",
      "Input: 0.115 MB, Params: 4,487,825 (17.120 MB), Total: 17.23 MB, FLOPs: 413,844,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1682 finished in 0m07s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 461)]\n",
      "Input: 0.115 MB, Params: 4,483,303 (17.102 MB), Total: 17.22 MB, FLOPs: 413,722,915\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1682 finished in 0m07s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 402)]\n",
      "Input: 0.115 MB, Params: 4,476,650 (17.077 MB), Total: 17.19 MB, FLOPs: 413,543,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1682 finished in 0m07s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 4,469,997 (17.052 MB), Total: 17.17 MB, FLOPs: 413,363,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1682 finished in 0m07s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 4,465,493 (17.035 MB), Total: 17.15 MB, FLOPs: 413,242,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1682 finished in 0m07s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 4,462,089 (17.022 MB), Total: 17.14 MB, FLOPs: 412,874,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1682 finished in 0m07s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.115 MB, Params: 4,457,585 (17.004 MB), Total: 17.12 MB, FLOPs: 412,753,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1682 finished in 0m07s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 93)]\n",
      "Input: 0.115 MB, Params: 4,454,154 (16.991 MB), Total: 17.11 MB, FLOPs: 411,952,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1682 finished in 0m07s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 212)]\n",
      "Input: 0.115 MB, Params: 4,450,759 (16.978 MB), Total: 17.09 MB, FLOPs: 411,585,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1682 finished in 0m07s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 4,443,989 (16.952 MB), Total: 17.07 MB, FLOPs: 411,218,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1682 finished in 0m07s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 53)]\n",
      "Input: 0.115 MB, Params: 4,440,567 (16.939 MB), Total: 17.05 MB, FLOPs: 410,418,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1682 finished in 0m06s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 4,433,941 (16.914 MB), Total: 17.03 MB, FLOPs: 410,240,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1682 finished in 0m06s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 4,427,315 (16.889 MB), Total: 17.00 MB, FLOPs: 410,061,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1682 finished in 0m06s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.115 MB, Params: 4,422,829 (16.872 MB), Total: 16.99 MB, FLOPs: 409,940,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1682 finished in 0m06s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 4,419,452 (16.859 MB), Total: 16.97 MB, FLOPs: 409,575,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1682 finished in 0m06s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 4,414,966 (16.842 MB), Total: 16.96 MB, FLOPs: 409,454,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1682 finished in 0m06s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 4,408,358 (16.817 MB), Total: 16.93 MB, FLOPs: 409,276,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1682 finished in 0m06s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 4,403,881 (16.799 MB), Total: 16.91 MB, FLOPs: 409,155,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1682 finished in 0m06s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 49)]\n",
      "Input: 0.115 MB, Params: 4,402,169 (16.793 MB), Total: 16.91 MB, FLOPs: 407,509,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1682 finished in 0m07s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 4,397,692 (16.776 MB), Total: 16.89 MB, FLOPs: 407,388,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1682 finished in 0m07s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 366)]\n",
      "Input: 0.115 MB, Params: 4,391,102 (16.751 MB), Total: 16.87 MB, FLOPs: 407,210,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1682 finished in 0m07s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 4,386,634 (16.734 MB), Total: 16.85 MB, FLOPs: 407,089,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1682 finished in 0m07s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 331)]\n",
      "Input: 0.115 MB, Params: 4,380,053 (16.709 MB), Total: 16.82 MB, FLOPs: 406,912,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1682 finished in 0m07s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 208)]\n",
      "Input: 0.115 MB, Params: 4,373,472 (16.683 MB), Total: 16.80 MB, FLOPs: 406,734,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1682 finished in 0m07s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 430)]\n",
      "Input: 0.115 MB, Params: 4,369,022 (16.666 MB), Total: 16.78 MB, FLOPs: 406,614,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1682 finished in 0m07s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 118)]\n",
      "Input: 0.115 MB, Params: 4,362,450 (16.641 MB), Total: 16.76 MB, FLOPs: 406,437,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1682 finished in 0m07s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 379)]\n",
      "Input: 0.115 MB, Params: 4,358,009 (16.624 MB), Total: 16.74 MB, FLOPs: 406,317,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1682 finished in 0m07s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.115 MB, Params: 4,354,632 (16.612 MB), Total: 16.73 MB, FLOPs: 405,952,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1682 finished in 0m07s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 356)]\n",
      "Input: 0.115 MB, Params: 4,348,069 (16.587 MB), Total: 16.70 MB, FLOPs: 405,775,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1682 finished in 0m07s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.115 MB, Params: 4,343,637 (16.570 MB), Total: 16.68 MB, FLOPs: 405,655,801\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1682 finished in 0m07s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 160)]\n",
      "Input: 0.115 MB, Params: 4,336,957 (16.544 MB), Total: 16.66 MB, FLOPs: 405,293,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1682 finished in 0m07s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.115 MB, Params: 4,330,277 (16.519 MB), Total: 16.63 MB, FLOPs: 404,930,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1682 finished in 0m07s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.115 MB, Params: 4,325,845 (16.502 MB), Total: 16.62 MB, FLOPs: 404,810,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1682 finished in 0m07s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.115 MB, Params: 4,324,151 (16.495 MB), Total: 16.61 MB, FLOPs: 403,996,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1682 finished in 0m07s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 4,320,792 (16.483 MB), Total: 16.60 MB, FLOPs: 403,633,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1682 finished in 0m07s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 431)]\n",
      "Input: 0.115 MB, Params: 4,314,265 (16.458 MB), Total: 16.57 MB, FLOPs: 403,457,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1682 finished in 0m07s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.115 MB, Params: 4,309,842 (16.441 MB), Total: 16.56 MB, FLOPs: 403,338,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1682 finished in 0m07s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 4,305,419 (16.424 MB), Total: 16.54 MB, FLOPs: 403,218,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1682 finished in 0m07s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.115 MB, Params: 4,300,996 (16.407 MB), Total: 16.52 MB, FLOPs: 403,099,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1682 finished in 0m07s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 4,296,573 (16.390 MB), Total: 16.51 MB, FLOPs: 402,979,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1682 finished in 0m07s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 4,292,150 (16.373 MB), Total: 16.49 MB, FLOPs: 402,860,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1682 finished in 0m07s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.115 MB, Params: 4,288,791 (16.360 MB), Total: 16.48 MB, FLOPs: 402,497,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1682 finished in 0m07s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 4,285,414 (16.348 MB), Total: 16.46 MB, FLOPs: 401,706,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1682 finished in 0m07s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 373)]\n",
      "Input: 0.115 MB, Params: 4,278,932 (16.323 MB), Total: 16.44 MB, FLOPs: 401,531,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1682 finished in 0m07s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 4,272,450 (16.298 MB), Total: 16.41 MB, FLOPs: 401,356,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1682 finished in 0m07s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.115 MB, Params: 4,269,100 (16.285 MB), Total: 16.40 MB, FLOPs: 400,994,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1682 finished in 0m07s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.115 MB, Params: 4,267,397 (16.279 MB), Total: 16.39 MB, FLOPs: 399,352,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1682 finished in 0m07s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 4,264,047 (16.266 MB), Total: 16.38 MB, FLOPs: 398,991,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1682 finished in 0m07s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 21)]\n",
      "Input: 0.115 MB, Params: 4,263,478 (16.264 MB), Total: 16.38 MB, FLOPs: 397,816,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1682 finished in 0m07s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 485)]\n",
      "Input: 0.115 MB, Params: 4,256,996 (16.239 MB), Total: 16.35 MB, FLOPs: 397,641,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1682 finished in 0m07s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 215)]\n",
      "Input: 0.115 MB, Params: 4,252,600 (16.222 MB), Total: 16.34 MB, FLOPs: 397,523,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1682 finished in 0m07s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 232)]\n",
      "Input: 0.115 MB, Params: 4,248,204 (16.206 MB), Total: 16.32 MB, FLOPs: 397,404,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1682 finished in 0m07s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 4,243,808 (16.189 MB), Total: 16.30 MB, FLOPs: 397,285,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1682 finished in 0m07s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 475)]\n",
      "Input: 0.115 MB, Params: 4,237,353 (16.164 MB), Total: 16.28 MB, FLOPs: 397,111,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1682 finished in 0m07s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 4,232,966 (16.147 MB), Total: 16.26 MB, FLOPs: 396,993,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1682 finished in 0m07s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 4,226,367 (16.122 MB), Total: 16.24 MB, FLOPs: 396,635,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1682 finished in 0m07s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.115 MB, Params: 4,219,768 (16.097 MB), Total: 16.21 MB, FLOPs: 396,277,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1682 finished in 0m07s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 411)]\n",
      "Input: 0.115 MB, Params: 4,215,381 (16.080 MB), Total: 16.20 MB, FLOPs: 396,159,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1682 finished in 0m07s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.115 MB, Params: 4,208,962 (16.056 MB), Total: 16.17 MB, FLOPs: 395,986,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1682 finished in 0m07s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.115 MB, Params: 4,202,543 (16.031 MB), Total: 16.15 MB, FLOPs: 395,812,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1682 finished in 0m07s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 4,198,174 (16.015 MB), Total: 16.13 MB, FLOPs: 395,694,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1682 finished in 0m07s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 270)]\n",
      "Input: 0.115 MB, Params: 4,191,764 (15.990 MB), Total: 16.11 MB, FLOPs: 395,521,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1682 finished in 0m07s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 4,187,404 (15.974 MB), Total: 16.09 MB, FLOPs: 395,404,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1682 finished in 0m07s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 289)]\n",
      "Input: 0.115 MB, Params: 4,183,044 (15.957 MB), Total: 16.07 MB, FLOPs: 395,286,561\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1682 finished in 0m07s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 413)]\n",
      "Input: 0.115 MB, Params: 4,178,684 (15.940 MB), Total: 16.06 MB, FLOPs: 395,168,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1682 finished in 0m07s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.115 MB, Params: 4,174,324 (15.924 MB), Total: 16.04 MB, FLOPs: 395,051,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1682 finished in 0m07s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.115 MB, Params: 4,167,950 (15.899 MB), Total: 16.01 MB, FLOPs: 394,879,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1682 finished in 0m07s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 78)]\n",
      "Input: 0.115 MB, Params: 4,166,274 (15.893 MB), Total: 16.01 MB, FLOPs: 394,073,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1682 finished in 0m07s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 4,161,923 (15.876 MB), Total: 15.99 MB, FLOPs: 393,956,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1682 finished in 0m07s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.115 MB, Params: 4,160,247 (15.870 MB), Total: 15.99 MB, FLOPs: 393,150,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1682 finished in 0m07s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 4,155,896 (15.853 MB), Total: 15.97 MB, FLOPs: 393,032,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1682 finished in 0m07s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 4,151,545 (15.837 MB), Total: 15.95 MB, FLOPs: 392,915,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1682 finished in 0m07s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.115 MB, Params: 4,148,213 (15.824 MB), Total: 15.94 MB, FLOPs: 392,555,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1682 finished in 0m07s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 4,141,659 (15.799 MB), Total: 15.91 MB, FLOPs: 392,200,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1682 finished in 0m07s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 4,137,308 (15.783 MB), Total: 15.90 MB, FLOPs: 392,082,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1682 finished in 0m07s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 119)]\n",
      "Input: 0.115 MB, Params: 4,133,985 (15.770 MB), Total: 15.89 MB, FLOPs: 391,723,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1682 finished in 0m07s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 51)]\n",
      "Input: 0.115 MB, Params: 4,132,309 (15.764 MB), Total: 15.88 MB, FLOPs: 390,918,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1682 finished in 0m07s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 4,127,958 (15.747 MB), Total: 15.86 MB, FLOPs: 390,800,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1682 finished in 0m07s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 4,121,638 (15.723 MB), Total: 15.84 MB, FLOPs: 390,630,177\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1682 finished in 0m07s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 4,117,296 (15.706 MB), Total: 15.82 MB, FLOPs: 390,513,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1682 finished in 0m07s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 164)]\n",
      "Input: 0.115 MB, Params: 4,110,760 (15.681 MB), Total: 15.80 MB, FLOPs: 390,158,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1682 finished in 0m07s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 421)]\n",
      "Input: 0.115 MB, Params: 4,104,458 (15.657 MB), Total: 15.77 MB, FLOPs: 389,988,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1682 finished in 0m07s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 277)]\n",
      "Input: 0.115 MB, Params: 4,100,125 (15.641 MB), Total: 15.76 MB, FLOPs: 389,871,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1682 finished in 0m07s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 4,093,832 (15.617 MB), Total: 15.73 MB, FLOPs: 389,701,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1682 finished in 0m07s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.115 MB, Params: 4,090,518 (15.604 MB), Total: 15.72 MB, FLOPs: 389,343,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1682 finished in 0m07s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 324)]\n",
      "Input: 0.115 MB, Params: 4,086,194 (15.588 MB), Total: 15.70 MB, FLOPs: 389,227,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1682 finished in 0m07s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 278)]\n",
      "Input: 0.115 MB, Params: 4,081,870 (15.571 MB), Total: 15.69 MB, FLOPs: 389,110,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1682 finished in 0m07s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.115 MB, Params: 4,077,546 (15.555 MB), Total: 15.67 MB, FLOPs: 388,993,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1682 finished in 0m07s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 98)]\n",
      "Input: 0.115 MB, Params: 4,075,870 (15.548 MB), Total: 15.66 MB, FLOPs: 388,187,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1682 finished in 0m07s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 4,071,546 (15.532 MB), Total: 15.65 MB, FLOPs: 388,071,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1682 finished in 0m07s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 4,068,232 (15.519 MB), Total: 15.63 MB, FLOPs: 387,713,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1682 finished in 0m07s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.115 MB, Params: 4,066,556 (15.513 MB), Total: 15.63 MB, FLOPs: 386,907,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1682 finished in 0m07s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 473)]\n",
      "Input: 0.115 MB, Params: 4,060,299 (15.489 MB), Total: 15.60 MB, FLOPs: 386,738,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1682 finished in 0m07s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 4,055,984 (15.472 MB), Total: 15.59 MB, FLOPs: 386,622,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1682 finished in 0m07s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 4,049,736 (15.449 MB), Total: 15.56 MB, FLOPs: 386,453,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1682 finished in 0m07s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 4,043,488 (15.425 MB), Total: 15.54 MB, FLOPs: 386,285,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1682 finished in 0m07s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.115 MB, Params: 4,039,191 (15.408 MB), Total: 15.52 MB, FLOPs: 386,169,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1682 finished in 0m07s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 4,034,894 (15.392 MB), Total: 15.51 MB, FLOPs: 386,053,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1682 finished in 0m07s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 4,028,664 (15.368 MB), Total: 15.48 MB, FLOPs: 385,885,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1682 finished in 0m07s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.115 MB, Params: 4,024,376 (15.352 MB), Total: 15.47 MB, FLOPs: 385,769,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1682 finished in 0m07s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.115 MB, Params: 4,020,088 (15.335 MB), Total: 15.45 MB, FLOPs: 385,653,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1682 finished in 0m07s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 360)]\n",
      "Input: 0.115 MB, Params: 4,013,876 (15.312 MB), Total: 15.43 MB, FLOPs: 385,485,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1682 finished in 0m07s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 205)]\n",
      "Input: 0.115 MB, Params: 4,007,664 (15.288 MB), Total: 15.40 MB, FLOPs: 385,318,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1682 finished in 0m07s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 348)]\n",
      "Input: 0.115 MB, Params: 4,003,394 (15.272 MB), Total: 15.39 MB, FLOPs: 385,202,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1682 finished in 0m07s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 364)]\n",
      "Input: 0.115 MB, Params: 3,999,124 (15.255 MB), Total: 15.37 MB, FLOPs: 385,087,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1682 finished in 0m07s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 20)]\n",
      "Input: 0.115 MB, Params: 3,998,555 (15.253 MB), Total: 15.37 MB, FLOPs: 383,913,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1682 finished in 0m07s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 3,992,361 (15.230 MB), Total: 15.34 MB, FLOPs: 383,746,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1682 finished in 0m07s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 3,988,100 (15.213 MB), Total: 15.33 MB, FLOPs: 383,631,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1682 finished in 0m07s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.115 MB, Params: 3,984,786 (15.201 MB), Total: 15.32 MB, FLOPs: 383,273,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1682 finished in 0m07s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 3,980,525 (15.184 MB), Total: 15.30 MB, FLOPs: 383,158,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1682 finished in 0m07s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 3,976,264 (15.168 MB), Total: 15.28 MB, FLOPs: 383,043,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1682 finished in 0m07s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 3,970,097 (15.145 MB), Total: 15.26 MB, FLOPs: 382,876,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1682 finished in 0m07s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 238)]\n",
      "Input: 0.115 MB, Params: 3,963,678 (15.120 MB), Total: 15.24 MB, FLOPs: 382,527,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1682 finished in 0m07s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 3,957,259 (15.096 MB), Total: 15.21 MB, FLOPs: 382,178,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1682 finished in 0m07s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 3,951,110 (15.072 MB), Total: 15.19 MB, FLOPs: 382,012,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1682 finished in 0m07s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 3,946,867 (15.056 MB), Total: 15.17 MB, FLOPs: 381,898,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1682 finished in 0m07s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 455)]\n",
      "Input: 0.115 MB, Params: 3,940,727 (15.033 MB), Total: 15.15 MB, FLOPs: 381,732,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1682 finished in 0m07s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 3,936,493 (15.017 MB), Total: 15.13 MB, FLOPs: 381,617,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1682 finished in 0m07s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 134)]\n",
      "Input: 0.115 MB, Params: 3,933,197 (15.004 MB), Total: 15.12 MB, FLOPs: 381,262,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1682 finished in 0m07s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 232)]\n",
      "Input: 0.115 MB, Params: 3,929,901 (14.991 MB), Total: 15.11 MB, FLOPs: 380,906,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1682 finished in 0m07s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 3,925,667 (14.975 MB), Total: 15.09 MB, FLOPs: 380,792,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1682 finished in 0m07s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 3,919,545 (14.952 MB), Total: 15.07 MB, FLOPs: 380,626,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1682 finished in 0m07s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 349)]\n",
      "Input: 0.115 MB, Params: 3,915,320 (14.936 MB), Total: 15.05 MB, FLOPs: 380,512,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1682 finished in 0m07s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 3,911,095 (14.920 MB), Total: 15.03 MB, FLOPs: 380,398,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1682 finished in 0m07s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 199)]\n",
      "Input: 0.115 MB, Params: 3,906,870 (14.904 MB), Total: 15.02 MB, FLOPs: 380,284,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1682 finished in 0m07s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 110)]\n",
      "Input: 0.115 MB, Params: 3,905,194 (14.897 MB), Total: 15.01 MB, FLOPs: 379,479,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1682 finished in 0m07s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 313)]\n",
      "Input: 0.115 MB, Params: 3,899,099 (14.874 MB), Total: 14.99 MB, FLOPs: 379,314,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1682 finished in 0m07s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 51)]\n",
      "Input: 0.115 MB, Params: 3,893,004 (14.851 MB), Total: 14.97 MB, FLOPs: 379,149,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1682 finished in 0m07s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 3,888,797 (14.835 MB), Total: 14.95 MB, FLOPs: 379,036,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1682 finished in 0m07s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 135)]\n",
      "Input: 0.115 MB, Params: 3,882,441 (14.810 MB), Total: 14.93 MB, FLOPs: 378,690,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1682 finished in 0m07s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.115 MB, Params: 3,876,364 (14.787 MB), Total: 14.90 MB, FLOPs: 378,526,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1682 finished in 0m07s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 3,870,287 (14.764 MB), Total: 14.88 MB, FLOPs: 378,362,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1682 finished in 0m07s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 348)]\n",
      "Input: 0.115 MB, Params: 3,866,098 (14.748 MB), Total: 14.86 MB, FLOPs: 378,249,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1682 finished in 0m07s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 3,861,909 (14.732 MB), Total: 14.85 MB, FLOPs: 378,136,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1682 finished in 0m07s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 143)]\n",
      "Input: 0.115 MB, Params: 3,855,571 (14.708 MB), Total: 14.82 MB, FLOPs: 377,790,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1682 finished in 0m07s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 3,855,002 (14.706 MB), Total: 14.82 MB, FLOPs: 376,616,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1682 finished in 0m07s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 11)]\n",
      "Input: 0.115 MB, Params: 3,853,353 (14.699 MB), Total: 14.81 MB, FLOPs: 375,000,483\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1682 finished in 0m07s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.115 MB, Params: 3,847,015 (14.675 MB), Total: 14.79 MB, FLOPs: 374,654,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1682 finished in 0m07s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 419)]\n",
      "Input: 0.115 MB, Params: 3,840,974 (14.652 MB), Total: 14.77 MB, FLOPs: 374,491,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1682 finished in 0m07s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 76)]\n",
      "Input: 0.115 MB, Params: 3,839,307 (14.646 MB), Total: 14.76 MB, FLOPs: 373,690,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1682 finished in 0m07s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.115 MB, Params: 3,835,127 (14.630 MB), Total: 14.75 MB, FLOPs: 373,577,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1682 finished in 0m07s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 153)]\n",
      "Input: 0.115 MB, Params: 3,828,798 (14.606 MB), Total: 14.72 MB, FLOPs: 373,232,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1682 finished in 0m07s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 3,822,775 (14.583 MB), Total: 14.70 MB, FLOPs: 373,069,865\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1682 finished in 0m07s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 3,818,604 (14.567 MB), Total: 14.68 MB, FLOPs: 372,957,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1682 finished in 0m07s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.115 MB, Params: 3,814,433 (14.551 MB), Total: 14.67 MB, FLOPs: 372,844,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1682 finished in 0m07s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 3,810,262 (14.535 MB), Total: 14.65 MB, FLOPs: 372,732,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1682 finished in 0m07s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.115 MB, Params: 3,806,091 (14.519 MB), Total: 14.63 MB, FLOPs: 372,619,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1682 finished in 0m07s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 3,801,920 (14.503 MB), Total: 14.62 MB, FLOPs: 372,507,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1682 finished in 0m07s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 3,797,749 (14.487 MB), Total: 14.60 MB, FLOPs: 372,394,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1682 finished in 0m07s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 292)]\n",
      "Input: 0.115 MB, Params: 3,791,780 (14.464 MB), Total: 14.58 MB, FLOPs: 372,233,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1682 finished in 0m07s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 132)]\n",
      "Input: 0.115 MB, Params: 3,785,469 (14.440 MB), Total: 14.56 MB, FLOPs: 371,888,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1682 finished in 0m07s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 314)]\n",
      "Input: 0.115 MB, Params: 3,779,509 (14.418 MB), Total: 14.53 MB, FLOPs: 371,727,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1682 finished in 0m07s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 3,778,706 (14.415 MB), Total: 14.53 MB, FLOPs: 370,163,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1682 finished in 0m07s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.115 MB, Params: 3,772,746 (14.392 MB), Total: 14.51 MB, FLOPs: 370,002,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1682 finished in 0m07s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 3,768,602 (14.376 MB), Total: 14.49 MB, FLOPs: 369,891,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1682 finished in 0m07s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 3,762,651 (14.353 MB), Total: 14.47 MB, FLOPs: 369,730,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1682 finished in 0m07s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 3,758,516 (14.338 MB), Total: 14.45 MB, FLOPs: 369,618,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1682 finished in 0m07s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 230)]\n",
      "Input: 0.115 MB, Params: 3,752,232 (14.314 MB), Total: 14.43 MB, FLOPs: 369,274,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1682 finished in 0m07s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 3,748,097 (14.298 MB), Total: 14.41 MB, FLOPs: 369,163,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1682 finished in 0m07s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 226)]\n",
      "Input: 0.115 MB, Params: 3,742,173 (14.275 MB), Total: 14.39 MB, FLOPs: 369,003,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1682 finished in 0m07s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.115 MB, Params: 3,738,931 (14.263 MB), Total: 14.38 MB, FLOPs: 368,653,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1682 finished in 0m07s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 363)]\n",
      "Input: 0.115 MB, Params: 3,734,805 (14.247 MB), Total: 14.36 MB, FLOPs: 368,541,881\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1682 finished in 0m07s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.115 MB, Params: 3,731,563 (14.235 MB), Total: 14.35 MB, FLOPs: 368,191,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1682 finished in 0m07s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 3,727,437 (14.219 MB), Total: 14.33 MB, FLOPs: 368,080,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1682 finished in 0m07s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 177)]\n",
      "Input: 0.115 MB, Params: 3,721,180 (14.195 MB), Total: 14.31 MB, FLOPs: 367,738,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1682 finished in 0m07s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.115 MB, Params: 3,715,283 (14.173 MB), Total: 14.29 MB, FLOPs: 367,579,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1682 finished in 0m07s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 112)]\n",
      "Input: 0.115 MB, Params: 3,712,050 (14.160 MB), Total: 14.28 MB, FLOPs: 367,230,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1682 finished in 0m07s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 3,705,811 (14.137 MB), Total: 14.25 MB, FLOPs: 366,889,727\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1682 finished in 0m07s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.115 MB, Params: 3,702,587 (14.124 MB), Total: 14.24 MB, FLOPs: 366,541,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1682 finished in 0m07s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 441)]\n",
      "Input: 0.115 MB, Params: 3,696,699 (14.102 MB), Total: 14.22 MB, FLOPs: 366,382,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1682 finished in 0m07s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 366)]\n",
      "Input: 0.115 MB, Params: 3,692,591 (14.086 MB), Total: 14.20 MB, FLOPs: 366,271,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1682 finished in 0m07s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 164)]\n",
      "Input: 0.115 MB, Params: 3,686,370 (14.062 MB), Total: 14.18 MB, FLOPs: 365,932,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1682 finished in 0m07s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 157)]\n",
      "Input: 0.115 MB, Params: 3,683,155 (14.050 MB), Total: 14.17 MB, FLOPs: 365,585,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1682 finished in 0m07s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 179)]\n",
      "Input: 0.115 MB, Params: 3,676,943 (14.026 MB), Total: 14.14 MB, FLOPs: 365,246,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1682 finished in 0m07s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.115 MB, Params: 3,675,312 (14.020 MB), Total: 14.14 MB, FLOPs: 363,652,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1682 finished in 0m07s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 123)]\n",
      "Input: 0.115 MB, Params: 3,669,100 (13.997 MB), Total: 14.11 MB, FLOPs: 363,314,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1682 finished in 0m07s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.115 MB, Params: 3,663,248 (13.974 MB), Total: 14.09 MB, FLOPs: 363,156,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1682 finished in 0m07s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 265)]\n",
      "Input: 0.115 MB, Params: 3,659,149 (13.959 MB), Total: 14.07 MB, FLOPs: 363,045,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1682 finished in 0m07s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 384)]\n",
      "Input: 0.115 MB, Params: 3,653,306 (13.936 MB), Total: 14.05 MB, FLOPs: 362,888,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1682 finished in 0m07s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 60)]\n",
      "Input: 0.115 MB, Params: 3,652,512 (13.933 MB), Total: 14.05 MB, FLOPs: 361,341,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1682 finished in 0m07s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 3,649,324 (13.921 MB), Total: 14.04 MB, FLOPs: 360,593,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1682 finished in 0m07s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 318)]\n",
      "Input: 0.115 MB, Params: 3,645,234 (13.905 MB), Total: 14.02 MB, FLOPs: 360,483,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1682 finished in 0m07s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 269)]\n",
      "Input: 0.115 MB, Params: 3,641,144 (13.890 MB), Total: 14.01 MB, FLOPs: 360,373,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1682 finished in 0m07s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 3,637,956 (13.878 MB), Total: 13.99 MB, FLOPs: 360,028,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1682 finished in 0m07s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.115 MB, Params: 3,637,162 (13.875 MB), Total: 13.99 MB, FLOPs: 358,482,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1682 finished in 0m07s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 145)]\n",
      "Input: 0.115 MB, Params: 3,630,977 (13.851 MB), Total: 13.97 MB, FLOPs: 358,145,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1682 finished in 0m07s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.115 MB, Params: 3,629,328 (13.845 MB), Total: 13.96 MB, FLOPs: 357,352,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1682 finished in 0m07s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 318)]\n",
      "Input: 0.115 MB, Params: 3,623,512 (13.823 MB), Total: 13.94 MB, FLOPs: 357,195,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1682 finished in 0m07s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 98)]\n",
      "Input: 0.115 MB, Params: 3,617,696 (13.800 MB), Total: 13.92 MB, FLOPs: 357,038,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1682 finished in 0m07s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 335)]\n",
      "Input: 0.115 MB, Params: 3,613,624 (13.785 MB), Total: 13.90 MB, FLOPs: 356,929,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1682 finished in 0m07s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 112)]\n",
      "Input: 0.115 MB, Params: 3,607,457 (13.761 MB), Total: 13.88 MB, FLOPs: 356,592,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1682 finished in 0m07s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 298)]\n",
      "Input: 0.115 MB, Params: 3,603,385 (13.746 MB), Total: 13.86 MB, FLOPs: 356,482,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1682 finished in 0m07s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 3,597,596 (13.724 MB), Total: 13.84 MB, FLOPs: 356,326,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1682 finished in 0m07s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 3,591,438 (13.700 MB), Total: 13.82 MB, FLOPs: 355,990,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1682 finished in 0m07s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 110)]\n",
      "Input: 0.115 MB, Params: 3,588,277 (13.688 MB), Total: 13.80 MB, FLOPs: 355,648,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1682 finished in 0m07s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.115 MB, Params: 3,582,497 (13.666 MB), Total: 13.78 MB, FLOPs: 355,492,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1682 finished in 0m07s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.115 MB, Params: 3,576,717 (13.644 MB), Total: 13.76 MB, FLOPs: 355,336,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1682 finished in 0m07s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 266)]\n",
      "Input: 0.115 MB, Params: 3,572,672 (13.629 MB), Total: 13.74 MB, FLOPs: 355,227,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1682 finished in 0m07s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 182)]\n",
      "Input: 0.115 MB, Params: 3,566,541 (13.605 MB), Total: 13.72 MB, FLOPs: 354,892,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1682 finished in 0m07s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 3,564,892 (13.599 MB), Total: 13.71 MB, FLOPs: 354,100,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1682 finished in 0m07s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 3,559,130 (13.577 MB), Total: 13.69 MB, FLOPs: 353,944,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1682 finished in 0m07s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 193)]\n",
      "Input: 0.115 MB, Params: 3,555,978 (13.565 MB), Total: 13.68 MB, FLOPs: 353,604,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1682 finished in 0m07s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 3,554,329 (13.559 MB), Total: 13.67 MB, FLOPs: 352,811,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1682 finished in 0m07s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 293)]\n",
      "Input: 0.115 MB, Params: 3,548,567 (13.537 MB), Total: 13.65 MB, FLOPs: 352,655,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1682 finished in 0m07s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 3,544,540 (13.521 MB), Total: 13.64 MB, FLOPs: 352,547,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1682 finished in 0m07s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 3,540,513 (13.506 MB), Total: 13.62 MB, FLOPs: 352,438,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1682 finished in 0m07s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 48)]\n",
      "Input: 0.115 MB, Params: 3,539,719 (13.503 MB), Total: 13.62 MB, FLOPs: 350,892,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1682 finished in 0m07s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 3,533,975 (13.481 MB), Total: 13.60 MB, FLOPs: 350,737,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1682 finished in 0m07s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 9)]\n",
      "Input: 0.115 MB, Params: 3,533,442 (13.479 MB), Total: 13.59 MB, FLOPs: 349,632,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1682 finished in 0m07s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 3,531,793 (13.473 MB), Total: 13.59 MB, FLOPs: 348,840,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1682 finished in 0m07s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 3,527,775 (13.457 MB), Total: 13.57 MB, FLOPs: 348,731,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1682 finished in 0m07s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 3,522,040 (13.436 MB), Total: 13.55 MB, FLOPs: 348,577,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1682 finished in 0m07s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.115 MB, Params: 3,515,954 (13.412 MB), Total: 13.53 MB, FLOPs: 348,244,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1682 finished in 0m07s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 20)]\n",
      "Input: 0.115 MB, Params: 3,515,912 (13.412 MB), Total: 13.53 MB, FLOPs: 337,376,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1682 finished in 0m07s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 346)]\n",
      "Input: 0.115 MB, Params: 3,511,903 (13.397 MB), Total: 13.51 MB, FLOPs: 337,268,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1682 finished in 0m07s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 390)]\n",
      "Input: 0.115 MB, Params: 3,506,186 (13.375 MB), Total: 13.49 MB, FLOPs: 337,113,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1682 finished in 0m07s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 3,502,186 (13.360 MB), Total: 13.48 MB, FLOPs: 337,006,043\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1682 finished in 0m07s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 3,498,186 (13.345 MB), Total: 13.46 MB, FLOPs: 336,898,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1682 finished in 0m07s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 3,492,487 (13.323 MB), Total: 13.44 MB, FLOPs: 336,744,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1682 finished in 0m07s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 3,488,496 (13.308 MB), Total: 13.42 MB, FLOPs: 336,636,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1682 finished in 0m07s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 304)]\n",
      "Input: 0.115 MB, Params: 3,482,806 (13.286 MB), Total: 13.40 MB, FLOPs: 336,482,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1682 finished in 0m07s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 205)]\n",
      "Input: 0.115 MB, Params: 3,476,747 (13.263 MB), Total: 13.38 MB, FLOPs: 336,150,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1682 finished in 0m07s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 335)]\n",
      "Input: 0.115 MB, Params: 3,471,066 (13.241 MB), Total: 13.36 MB, FLOPs: 335,997,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1682 finished in 0m07s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 3,465,385 (13.219 MB), Total: 13.33 MB, FLOPs: 335,844,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1682 finished in 0m07s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.115 MB, Params: 3,462,251 (13.207 MB), Total: 13.32 MB, FLOPs: 335,505,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1682 finished in 0m07s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 372)]\n",
      "Input: 0.115 MB, Params: 3,458,287 (13.192 MB), Total: 13.31 MB, FLOPs: 335,398,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1682 finished in 0m07s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 390)]\n",
      "Input: 0.115 MB, Params: 3,454,323 (13.177 MB), Total: 13.29 MB, FLOPs: 335,291,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1682 finished in 0m07s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.115 MB, Params: 3,450,359 (13.162 MB), Total: 13.28 MB, FLOPs: 335,184,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1682 finished in 0m07s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 3,446,395 (13.147 MB), Total: 13.26 MB, FLOPs: 335,077,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1682 finished in 0m07s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 3,442,431 (13.132 MB), Total: 13.25 MB, FLOPs: 334,970,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1682 finished in 0m07s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 3,436,795 (13.110 MB), Total: 13.23 MB, FLOPs: 334,818,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1682 finished in 0m07s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 53)]\n",
      "Input: 0.115 MB, Params: 3,435,227 (13.104 MB), Total: 13.22 MB, FLOPs: 333,372,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1682 finished in 0m07s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 371)]\n",
      "Input: 0.115 MB, Params: 3,429,591 (13.083 MB), Total: 13.20 MB, FLOPs: 333,220,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1682 finished in 0m07s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 3,423,955 (13.061 MB), Total: 13.18 MB, FLOPs: 333,068,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1682 finished in 0m07s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 245)]\n",
      "Input: 0.115 MB, Params: 3,420,018 (13.046 MB), Total: 13.16 MB, FLOPs: 332,962,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1682 finished in 0m07s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 345)]\n",
      "Input: 0.115 MB, Params: 3,416,081 (13.031 MB), Total: 13.15 MB, FLOPs: 332,856,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1682 finished in 0m07s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 3,410,463 (13.010 MB), Total: 13.13 MB, FLOPs: 332,704,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1682 finished in 0m07s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 3,406,535 (12.995 MB), Total: 13.11 MB, FLOPs: 332,598,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1682 finished in 0m07s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.115 MB, Params: 3,404,967 (12.989 MB), Total: 13.10 MB, FLOPs: 331,152,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1682 finished in 0m07s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 381)]\n",
      "Input: 0.115 MB, Params: 3,401,039 (12.974 MB), Total: 13.09 MB, FLOPs: 331,046,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1682 finished in 0m07s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.115 MB, Params: 3,395,439 (12.953 MB), Total: 13.07 MB, FLOPs: 330,895,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1682 finished in 0m07s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.115 MB, Params: 3,391,520 (12.938 MB), Total: 13.05 MB, FLOPs: 330,789,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1682 finished in 0m07s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 3,385,929 (12.916 MB), Total: 13.03 MB, FLOPs: 330,638,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1682 finished in 0m07s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 3,382,019 (12.901 MB), Total: 13.02 MB, FLOPs: 330,533,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1682 finished in 0m07s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.115 MB, Params: 3,378,109 (12.886 MB), Total: 13.00 MB, FLOPs: 330,427,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1682 finished in 0m07s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 54)]\n",
      "Input: 0.115 MB, Params: 3,377,342 (12.884 MB), Total: 13.00 MB, FLOPs: 328,991,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1682 finished in 0m07s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 351)]\n",
      "Input: 0.115 MB, Params: 3,373,432 (12.869 MB), Total: 12.98 MB, FLOPs: 328,885,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1682 finished in 0m07s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 3,369,522 (12.854 MB), Total: 12.97 MB, FLOPs: 328,780,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1682 finished in 0m07s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 3,363,544 (12.831 MB), Total: 12.95 MB, FLOPs: 328,451,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1682 finished in 0m07s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 3,360,419 (12.819 MB), Total: 12.93 MB, FLOPs: 328,113,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1682 finished in 0m07s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 3,354,873 (12.798 MB), Total: 12.91 MB, FLOPs: 327,963,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1682 finished in 0m07s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 3,349,327 (12.777 MB), Total: 12.89 MB, FLOPs: 327,814,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1682 finished in 0m07s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 3,345,435 (12.762 MB), Total: 12.88 MB, FLOPs: 327,709,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1682 finished in 0m07s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 3,341,543 (12.747 MB), Total: 12.86 MB, FLOPs: 327,604,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1682 finished in 0m07s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 387)]\n",
      "Input: 0.115 MB, Params: 3,337,651 (12.732 MB), Total: 12.85 MB, FLOPs: 327,499,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1682 finished in 0m07s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 84)]\n",
      "Input: 0.115 MB, Params: 3,334,526 (12.720 MB), Total: 12.84 MB, FLOPs: 327,161,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1682 finished in 0m07s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.115 MB, Params: 3,330,634 (12.705 MB), Total: 12.82 MB, FLOPs: 327,056,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1682 finished in 0m07s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 3,325,124 (12.684 MB), Total: 12.80 MB, FLOPs: 326,907,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1682 finished in 0m07s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.115 MB, Params: 3,323,493 (12.678 MB), Total: 12.79 MB, FLOPs: 326,184,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1682 finished in 0m07s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 3,319,610 (12.663 MB), Total: 12.78 MB, FLOPs: 326,079,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1682 finished in 0m07s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 3,314,109 (12.642 MB), Total: 12.76 MB, FLOPs: 325,930,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1682 finished in 0m07s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 3,308,608 (12.621 MB), Total: 12.74 MB, FLOPs: 325,782,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1682 finished in 0m07s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.115 MB, Params: 3,303,107 (12.600 MB), Total: 12.72 MB, FLOPs: 325,633,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1682 finished in 0m07s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 3,297,606 (12.579 MB), Total: 12.69 MB, FLOPs: 325,485,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1682 finished in 0m07s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 58)]\n",
      "Input: 0.115 MB, Params: 3,294,517 (12.568 MB), Total: 12.68 MB, FLOPs: 324,803,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1682 finished in 0m07s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.115 MB, Params: 3,290,670 (12.553 MB), Total: 12.67 MB, FLOPs: 324,699,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1682 finished in 0m07s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 418)]\n",
      "Input: 0.115 MB, Params: 3,285,178 (12.532 MB), Total: 12.65 MB, FLOPs: 324,551,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1682 finished in 0m07s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 3,279,686 (12.511 MB), Total: 12.63 MB, FLOPs: 324,403,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1682 finished in 0m07s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 176)]\n",
      "Input: 0.115 MB, Params: 3,273,807 (12.489 MB), Total: 12.60 MB, FLOPs: 324,077,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1682 finished in 0m07s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 3,269,978 (12.474 MB), Total: 12.59 MB, FLOPs: 323,974,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1682 finished in 0m07s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 3,266,149 (12.459 MB), Total: 12.57 MB, FLOPs: 323,871,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1682 finished in 0m07s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 166)]\n",
      "Input: 0.115 MB, Params: 3,263,042 (12.448 MB), Total: 12.56 MB, FLOPs: 323,535,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1682 finished in 0m07s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 3,259,213 (12.433 MB), Total: 12.55 MB, FLOPs: 323,432,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1682 finished in 0m07s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 3,255,384 (12.418 MB), Total: 12.53 MB, FLOPs: 323,329,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1682 finished in 0m07s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 275)]\n",
      "Input: 0.115 MB, Params: 3,251,555 (12.404 MB), Total: 12.52 MB, FLOPs: 323,225,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1682 finished in 0m07s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 307)]\n",
      "Input: 0.115 MB, Params: 3,247,726 (12.389 MB), Total: 12.50 MB, FLOPs: 323,122,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1682 finished in 0m07s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 3,242,297 (12.368 MB), Total: 12.48 MB, FLOPs: 322,976,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1682 finished in 0m07s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.115 MB, Params: 3,236,436 (12.346 MB), Total: 12.46 MB, FLOPs: 322,652,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1682 finished in 0m07s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.115 MB, Params: 3,232,616 (12.331 MB), Total: 12.45 MB, FLOPs: 322,549,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1682 finished in 0m07s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 148)]\n",
      "Input: 0.115 MB, Params: 3,229,518 (12.320 MB), Total: 12.43 MB, FLOPs: 322,214,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1682 finished in 0m07s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 3,228,994 (12.318 MB), Total: 12.43 MB, FLOPs: 321,168,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1682 finished in 0m07s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 163)]\n",
      "Input: 0.115 MB, Params: 3,223,142 (12.295 MB), Total: 12.41 MB, FLOPs: 320,845,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1682 finished in 0m07s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 338)]\n",
      "Input: 0.115 MB, Params: 3,219,322 (12.281 MB), Total: 12.40 MB, FLOPs: 320,742,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1682 finished in 0m07s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 153)]\n",
      "Input: 0.115 MB, Params: 3,213,470 (12.258 MB), Total: 12.37 MB, FLOPs: 320,419,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1682 finished in 0m07s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 3,210,390 (12.247 MB), Total: 12.36 MB, FLOPs: 320,086,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1682 finished in 0m07s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 3,205,006 (12.226 MB), Total: 12.34 MB, FLOPs: 319,941,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1682 finished in 0m07s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 23)]\n",
      "Input: 0.115 MB, Params: 3,203,384 (12.220 MB), Total: 12.34 MB, FLOPs: 319,221,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1682 finished in 0m07s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 3,199,573 (12.205 MB), Total: 12.32 MB, FLOPs: 319,118,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1682 finished in 0m07s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 327)]\n",
      "Input: 0.115 MB, Params: 3,195,762 (12.191 MB), Total: 12.31 MB, FLOPs: 319,015,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1682 finished in 0m07s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 3,190,396 (12.170 MB), Total: 12.29 MB, FLOPs: 318,871,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1682 finished in 0m07s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 3,187,316 (12.159 MB), Total: 12.27 MB, FLOPs: 318,538,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1682 finished in 0m07s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 348)]\n",
      "Input: 0.115 MB, Params: 3,181,950 (12.138 MB), Total: 12.25 MB, FLOPs: 318,393,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1682 finished in 0m07s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 304)]\n",
      "Input: 0.115 MB, Params: 3,176,584 (12.118 MB), Total: 12.23 MB, FLOPs: 318,248,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1682 finished in 0m07s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 3,171,218 (12.097 MB), Total: 12.21 MB, FLOPs: 318,104,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1682 finished in 0m07s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 367)]\n",
      "Input: 0.115 MB, Params: 3,165,852 (12.077 MB), Total: 12.19 MB, FLOPs: 317,959,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1682 finished in 0m07s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 203)]\n",
      "Input: 0.115 MB, Params: 3,162,086 (12.062 MB), Total: 12.18 MB, FLOPs: 317,857,547\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1682 finished in 0m07s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 356)]\n",
      "Input: 0.115 MB, Params: 3,158,320 (12.048 MB), Total: 12.16 MB, FLOPs: 317,755,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1682 finished in 0m07s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 361)]\n",
      "Input: 0.115 MB, Params: 3,154,554 (12.034 MB), Total: 12.15 MB, FLOPs: 317,654,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1682 finished in 0m07s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 3,150,788 (12.019 MB), Total: 12.13 MB, FLOPs: 317,552,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1682 finished in 0m07s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 317)]\n",
      "Input: 0.115 MB, Params: 3,145,458 (11.999 MB), Total: 12.11 MB, FLOPs: 317,408,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1682 finished in 0m07s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,140,128 (11.979 MB), Total: 12.09 MB, FLOPs: 317,264,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1682 finished in 0m07s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 3,136,380 (11.964 MB), Total: 12.08 MB, FLOPs: 317,163,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1682 finished in 0m07s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.115 MB, Params: 3,133,300 (11.953 MB), Total: 12.07 MB, FLOPs: 316,831,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1682 finished in 0m07s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 361)]\n",
      "Input: 0.115 MB, Params: 3,129,552 (11.938 MB), Total: 12.05 MB, FLOPs: 316,730,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1682 finished in 0m07s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 3,125,804 (11.924 MB), Total: 12.04 MB, FLOPs: 316,628,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1682 finished in 0m07s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.115 MB, Params: 3,120,501 (11.904 MB), Total: 12.02 MB, FLOPs: 316,485,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1682 finished in 0m07s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 366)]\n",
      "Input: 0.115 MB, Params: 3,116,762 (11.890 MB), Total: 12.00 MB, FLOPs: 316,384,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1682 finished in 0m07s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 3,111,468 (11.869 MB), Total: 11.98 MB, FLOPs: 316,241,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1682 finished in 0m07s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.115 MB, Params: 3,105,733 (11.847 MB), Total: 11.96 MB, FLOPs: 315,924,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1682 finished in 0m07s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 3,102,003 (11.833 MB), Total: 11.95 MB, FLOPs: 315,823,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1682 finished in 0m07s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 404)]\n",
      "Input: 0.115 MB, Params: 3,096,727 (11.813 MB), Total: 11.93 MB, FLOPs: 315,681,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1682 finished in 0m07s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.115 MB, Params: 3,093,006 (11.799 MB), Total: 11.91 MB, FLOPs: 315,580,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1682 finished in 0m07s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 197)]\n",
      "Input: 0.115 MB, Params: 3,087,739 (11.779 MB), Total: 11.89 MB, FLOPs: 315,438,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1682 finished in 0m07s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 35)]\n",
      "Input: 0.115 MB, Params: 3,086,117 (11.773 MB), Total: 11.89 MB, FLOPs: 314,719,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1682 finished in 0m07s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 3,082,405 (11.758 MB), Total: 11.87 MB, FLOPs: 314,618,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1682 finished in 0m07s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 322)]\n",
      "Input: 0.115 MB, Params: 3,077,147 (11.738 MB), Total: 11.85 MB, FLOPs: 314,476,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1682 finished in 0m07s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 3,071,439 (11.717 MB), Total: 11.83 MB, FLOPs: 314,160,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1682 finished in 0m07s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 75)]\n",
      "Input: 0.115 MB, Params: 3,069,817 (11.710 MB), Total: 11.83 MB, FLOPs: 313,440,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1682 finished in 0m07s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 3,064,568 (11.690 MB), Total: 11.81 MB, FLOPs: 313,298,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1682 finished in 0m07s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.115 MB, Params: 3,060,874 (11.676 MB), Total: 11.79 MB, FLOPs: 313,198,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1682 finished in 0m07s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 348)]\n",
      "Input: 0.115 MB, Params: 3,057,180 (11.662 MB), Total: 11.78 MB, FLOPs: 313,099,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1682 finished in 0m07s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 126)]\n",
      "Input: 0.115 MB, Params: 3,051,481 (11.640 MB), Total: 11.76 MB, FLOPs: 312,782,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1682 finished in 0m07s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 3,046,259 (11.621 MB), Total: 11.74 MB, FLOPs: 312,641,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1682 finished in 0m07s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 54)]\n",
      "Input: 0.115 MB, Params: 3,045,501 (11.618 MB), Total: 11.73 MB, FLOPs: 311,222,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1682 finished in 0m07s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.115 MB, Params: 3,040,279 (11.598 MB), Total: 11.71 MB, FLOPs: 311,081,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1682 finished in 0m07s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 3,036,603 (11.584 MB), Total: 11.70 MB, FLOPs: 310,982,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1682 finished in 0m07s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 3,032,927 (11.570 MB), Total: 11.68 MB, FLOPs: 310,882,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1682 finished in 0m07s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 3,029,251 (11.556 MB), Total: 11.67 MB, FLOPs: 310,783,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1682 finished in 0m07s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.115 MB, Params: 3,026,198 (11.544 MB), Total: 11.66 MB, FLOPs: 310,454,183\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1682 finished in 0m07s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,021,003 (11.524 MB), Total: 11.64 MB, FLOPs: 310,313,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1682 finished in 0m07s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 3,017,336 (11.510 MB), Total: 11.63 MB, FLOPs: 310,214,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1682 finished in 0m07s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 208)]\n",
      "Input: 0.115 MB, Params: 3,012,150 (11.490 MB), Total: 11.61 MB, FLOPs: 310,074,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1682 finished in 0m07s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 3,006,496 (11.469 MB), Total: 11.58 MB, FLOPs: 309,760,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1682 finished in 0m07s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 330)]\n",
      "Input: 0.115 MB, Params: 3,001,319 (11.449 MB), Total: 11.56 MB, FLOPs: 309,620,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1682 finished in 0m07s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.115 MB, Params: 2,997,670 (11.435 MB), Total: 11.55 MB, FLOPs: 309,522,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1682 finished in 0m07s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 2,994,021 (11.421 MB), Total: 11.54 MB, FLOPs: 309,423,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1682 finished in 0m07s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 125)]\n",
      "Input: 0.115 MB, Params: 2,988,376 (11.400 MB), Total: 11.52 MB, FLOPs: 309,109,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1682 finished in 0m07s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 2,983,226 (11.380 MB), Total: 11.50 MB, FLOPs: 308,970,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1682 finished in 0m07s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 168)]\n",
      "Input: 0.115 MB, Params: 2,977,590 (11.359 MB), Total: 11.47 MB, FLOPs: 308,656,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1682 finished in 0m07s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.115 MB, Params: 2,974,564 (11.347 MB), Total: 11.46 MB, FLOPs: 308,329,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1682 finished in 0m07s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 2,970,924 (11.333 MB), Total: 11.45 MB, FLOPs: 308,231,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1682 finished in 0m07s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 2,967,284 (11.319 MB), Total: 11.43 MB, FLOPs: 308,132,900\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1682 finished in 0m07s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 2,963,644 (11.305 MB), Total: 11.42 MB, FLOPs: 308,034,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1682 finished in 0m07s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 2,960,004 (11.292 MB), Total: 11.41 MB, FLOPs: 307,936,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1682 finished in 0m07s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.115 MB, Params: 2,956,978 (11.280 MB), Total: 11.40 MB, FLOPs: 307,609,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1682 finished in 0m07s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.115 MB, Params: 2,953,338 (11.266 MB), Total: 11.38 MB, FLOPs: 307,511,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1682 finished in 0m07s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 2,949,698 (11.252 MB), Total: 11.37 MB, FLOPs: 307,413,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1682 finished in 0m07s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.115 MB, Params: 2,944,080 (11.231 MB), Total: 11.35 MB, FLOPs: 307,101,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1682 finished in 0m07s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.115 MB, Params: 2,941,063 (11.219 MB), Total: 11.33 MB, FLOPs: 306,775,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1682 finished in 0m07s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.115 MB, Params: 2,935,985 (11.200 MB), Total: 11.32 MB, FLOPs: 306,638,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1682 finished in 0m07s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 2,930,907 (11.181 MB), Total: 11.30 MB, FLOPs: 306,501,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1682 finished in 0m07s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.115 MB, Params: 2,927,285 (11.167 MB), Total: 11.28 MB, FLOPs: 306,403,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1682 finished in 0m07s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.115 MB, Params: 2,922,216 (11.147 MB), Total: 11.26 MB, FLOPs: 306,266,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1682 finished in 0m07s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 2,916,634 (11.126 MB), Total: 11.24 MB, FLOPs: 305,956,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1682 finished in 0m07s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 2,913,021 (11.112 MB), Total: 11.23 MB, FLOPs: 305,858,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1682 finished in 0m07s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 172)]\n",
      "Input: 0.115 MB, Params: 2,910,013 (11.101 MB), Total: 11.22 MB, FLOPs: 305,533,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1682 finished in 0m07s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.115 MB, Params: 2,907,005 (11.089 MB), Total: 11.20 MB, FLOPs: 305,209,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1682 finished in 0m07s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.115 MB, Params: 2,901,441 (11.068 MB), Total: 11.18 MB, FLOPs: 304,900,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1682 finished in 0m07s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 191)]\n",
      "Input: 0.115 MB, Params: 2,898,442 (11.057 MB), Total: 11.17 MB, FLOPs: 304,576,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1682 finished in 0m07s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.115 MB, Params: 2,893,400 (11.037 MB), Total: 11.15 MB, FLOPs: 304,440,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1682 finished in 0m07s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 331)]\n",
      "Input: 0.115 MB, Params: 2,889,796 (11.024 MB), Total: 11.14 MB, FLOPs: 304,343,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1682 finished in 0m07s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 141)]\n",
      "Input: 0.115 MB, Params: 2,884,250 (11.003 MB), Total: 11.12 MB, FLOPs: 304,035,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1682 finished in 0m07s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 354)]\n",
      "Input: 0.115 MB, Params: 2,879,226 (10.983 MB), Total: 11.10 MB, FLOPs: 303,900,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1682 finished in 0m07s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.115 MB, Params: 2,874,202 (10.964 MB), Total: 11.08 MB, FLOPs: 303,764,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1682 finished in 0m07s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 2,869,178 (10.945 MB), Total: 11.06 MB, FLOPs: 303,629,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1682 finished in 0m07s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 88)]\n",
      "Input: 0.115 MB, Params: 2,863,659 (10.924 MB), Total: 11.04 MB, FLOPs: 303,322,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1682 finished in 0m07s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 89)]\n",
      "Input: 0.115 MB, Params: 2,858,140 (10.903 MB), Total: 11.02 MB, FLOPs: 303,015,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1682 finished in 0m07s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 354)]\n",
      "Input: 0.115 MB, Params: 2,853,134 (10.884 MB), Total: 11.00 MB, FLOPs: 302,880,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1682 finished in 0m07s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 2,848,128 (10.865 MB), Total: 10.98 MB, FLOPs: 302,745,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1682 finished in 0m07s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 206)]\n",
      "Input: 0.115 MB, Params: 2,845,156 (10.853 MB), Total: 10.97 MB, FLOPs: 302,424,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1682 finished in 0m07s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.115 MB, Params: 2,843,534 (10.847 MB), Total: 10.96 MB, FLOPs: 301,704,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1682 finished in 0m07s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 2,838,528 (10.828 MB), Total: 10.94 MB, FLOPs: 301,569,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1682 finished in 0m07s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 2,833,522 (10.809 MB), Total: 10.92 MB, FLOPs: 301,434,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1682 finished in 0m07s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 135)]\n",
      "Input: 0.115 MB, Params: 2,828,048 (10.788 MB), Total: 10.90 MB, FLOPs: 301,130,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1682 finished in 0m07s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.115 MB, Params: 2,823,051 (10.769 MB), Total: 10.88 MB, FLOPs: 300,995,135\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1682 finished in 0m07s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 2,819,519 (10.756 MB), Total: 10.87 MB, FLOPs: 300,899,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1682 finished in 0m07s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.115 MB, Params: 2,815,987 (10.742 MB), Total: 10.86 MB, FLOPs: 300,804,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1682 finished in 0m07s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 170)]\n",
      "Input: 0.115 MB, Params: 2,810,522 (10.721 MB), Total: 10.84 MB, FLOPs: 300,500,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1682 finished in 0m07s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 2,805,552 (10.702 MB), Total: 10.82 MB, FLOPs: 300,365,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1682 finished in 0m07s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 41)]\n",
      "Input: 0.115 MB, Params: 2,805,510 (10.702 MB), Total: 10.82 MB, FLOPs: 300,009,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1682 finished in 0m07s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 2,800,540 (10.683 MB), Total: 10.80 MB, FLOPs: 299,875,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1682 finished in 0m07s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 2,798,918 (10.677 MB), Total: 10.79 MB, FLOPs: 299,155,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1682 finished in 0m07s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 93)]\n",
      "Input: 0.115 MB, Params: 2,797,296 (10.671 MB), Total: 10.79 MB, FLOPs: 298,435,812\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1682 finished in 0m07s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 2,793,782 (10.657 MB), Total: 10.77 MB, FLOPs: 298,340,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1682 finished in 0m07s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 2,788,821 (10.639 MB), Total: 10.75 MB, FLOPs: 298,207,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1682 finished in 0m07s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 2,785,316 (10.625 MB), Total: 10.74 MB, FLOPs: 298,112,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1682 finished in 0m07s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 176)]\n",
      "Input: 0.115 MB, Params: 2,779,878 (10.604 MB), Total: 10.72 MB, FLOPs: 297,808,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1682 finished in 0m07s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.115 MB, Params: 2,774,440 (10.584 MB), Total: 10.70 MB, FLOPs: 297,505,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1682 finished in 0m07s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 2,769,002 (10.563 MB), Total: 10.68 MB, FLOPs: 297,201,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1682 finished in 0m07s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 45)]\n",
      "Input: 0.115 MB, Params: 2,768,244 (10.560 MB), Total: 10.68 MB, FLOPs: 295,781,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1682 finished in 0m07s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 2,765,317 (10.549 MB), Total: 10.66 MB, FLOPs: 295,465,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1682 finished in 0m07s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 2,761,812 (10.535 MB), Total: 10.65 MB, FLOPs: 295,371,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1682 finished in 0m07s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 2,758,307 (10.522 MB), Total: 10.64 MB, FLOPs: 295,276,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1682 finished in 0m07s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 2,754,802 (10.509 MB), Total: 10.62 MB, FLOPs: 295,182,207\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1682 finished in 0m07s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 2,751,297 (10.495 MB), Total: 10.61 MB, FLOPs: 295,087,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1682 finished in 0m07s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 203)]\n",
      "Input: 0.115 MB, Params: 2,747,792 (10.482 MB), Total: 10.60 MB, FLOPs: 294,993,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1682 finished in 0m07s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 46)]\n",
      "Input: 0.115 MB, Params: 2,746,314 (10.476 MB), Total: 10.59 MB, FLOPs: 293,625,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1682 finished in 0m07s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 2,741,434 (10.458 MB), Total: 10.57 MB, FLOPs: 293,493,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1682 finished in 0m07s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.115 MB, Params: 2,737,938 (10.444 MB), Total: 10.56 MB, FLOPs: 293,399,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1682 finished in 0m07s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.115 MB, Params: 2,735,029 (10.433 MB), Total: 10.55 MB, FLOPs: 292,755,195\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1682 finished in 0m07s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 2,731,533 (10.420 MB), Total: 10.54 MB, FLOPs: 292,660,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1682 finished in 0m07s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 2,728,037 (10.407 MB), Total: 10.52 MB, FLOPs: 292,566,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1682 finished in 0m07s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 2,723,184 (10.388 MB), Total: 10.50 MB, FLOPs: 292,435,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1682 finished in 0m07s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 2,717,773 (10.367 MB), Total: 10.48 MB, FLOPs: 292,133,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1682 finished in 0m07s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 2,712,362 (10.347 MB), Total: 10.46 MB, FLOPs: 291,830,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1682 finished in 0m07s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 2,708,875 (10.334 MB), Total: 10.45 MB, FLOPs: 291,736,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1682 finished in 0m07s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 2,703,464 (10.313 MB), Total: 10.43 MB, FLOPs: 291,434,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1682 finished in 0m07s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 2,698,647 (10.295 MB), Total: 10.41 MB, FLOPs: 291,304,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1682 finished in 0m07s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.115 MB, Params: 2,695,738 (10.283 MB), Total: 10.40 MB, FLOPs: 290,660,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1682 finished in 0m07s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 59)]\n",
      "Input: 0.115 MB, Params: 2,694,143 (10.277 MB), Total: 10.39 MB, FLOPs: 289,952,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1682 finished in 0m07s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.115 MB, Params: 2,692,548 (10.271 MB), Total: 10.39 MB, FLOPs: 289,244,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1682 finished in 0m07s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 205)]\n",
      "Input: 0.115 MB, Params: 2,689,666 (10.260 MB), Total: 10.38 MB, FLOPs: 288,933,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1682 finished in 0m07s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 2,684,849 (10.242 MB), Total: 10.36 MB, FLOPs: 288,803,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1682 finished in 0m07s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 2,680,032 (10.224 MB), Total: 10.34 MB, FLOPs: 288,673,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1682 finished in 0m07s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.115 MB, Params: 2,676,572 (10.210 MB), Total: 10.33 MB, FLOPs: 288,580,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1682 finished in 0m07s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 2,671,764 (10.192 MB), Total: 10.31 MB, FLOPs: 288,450,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1682 finished in 0m07s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 2,668,882 (10.181 MB), Total: 10.30 MB, FLOPs: 288,139,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1682 finished in 0m07s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 269)]\n",
      "Input: 0.115 MB, Params: 2,664,074 (10.163 MB), Total: 10.28 MB, FLOPs: 288,009,381\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1682 finished in 0m07s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 2,659,266 (10.144 MB), Total: 10.26 MB, FLOPs: 287,879,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1682 finished in 0m07s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 2,655,833 (10.131 MB), Total: 10.25 MB, FLOPs: 287,786,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1682 finished in 0m07s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 2,651,034 (10.113 MB), Total: 10.23 MB, FLOPs: 287,657,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1682 finished in 0m07s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.115 MB, Params: 2,645,704 (10.093 MB), Total: 10.21 MB, FLOPs: 287,358,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1682 finished in 0m07s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 205)]\n",
      "Input: 0.115 MB, Params: 2,640,914 (10.074 MB), Total: 10.19 MB, FLOPs: 287,229,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1682 finished in 0m07s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 2,636,124 (10.056 MB), Total: 10.17 MB, FLOPs: 287,100,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1682 finished in 0m07s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 2,631,334 (10.038 MB), Total: 10.15 MB, FLOPs: 286,970,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1682 finished in 0m07s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 165)]\n",
      "Input: 0.115 MB, Params: 2,626,031 (10.018 MB), Total: 10.13 MB, FLOPs: 286,672,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1682 finished in 0m07s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 2,621,250 (9.999 MB), Total: 10.11 MB, FLOPs: 286,543,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1682 finished in 0m07s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 2,615,956 (9.979 MB), Total: 10.09 MB, FLOPs: 286,246,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1682 finished in 0m07s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 2,611,184 (9.961 MB), Total: 10.08 MB, FLOPs: 286,117,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1682 finished in 0m07s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 292)]\n",
      "Input: 0.115 MB, Params: 2,606,412 (9.943 MB), Total: 10.06 MB, FLOPs: 285,988,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1682 finished in 0m07s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.115 MB, Params: 2,601,640 (9.924 MB), Total: 10.04 MB, FLOPs: 285,859,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1682 finished in 0m07s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 193)]\n",
      "Input: 0.115 MB, Params: 2,598,785 (9.914 MB), Total: 10.03 MB, FLOPs: 285,551,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1682 finished in 0m07s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 102)]\n",
      "Input: 0.115 MB, Params: 2,595,930 (9.903 MB), Total: 10.02 MB, FLOPs: 285,243,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1682 finished in 0m07s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 2,592,569 (9.890 MB), Total: 10.01 MB, FLOPs: 285,152,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1682 finished in 0m07s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 2,587,806 (9.872 MB), Total: 9.99 MB, FLOPs: 285,024,105\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1682 finished in 0m07s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 120)]\n",
      "Input: 0.115 MB, Params: 2,584,951 (9.861 MB), Total: 9.98 MB, FLOPs: 284,715,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1682 finished in 0m07s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 2,580,188 (9.843 MB), Total: 9.96 MB, FLOPs: 284,587,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1682 finished in 0m07s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.115 MB, Params: 2,576,845 (9.830 MB), Total: 9.95 MB, FLOPs: 284,497,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1682 finished in 0m07s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 42)]\n",
      "Input: 0.115 MB, Params: 2,576,803 (9.830 MB), Total: 9.95 MB, FLOPs: 281,043,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1682 finished in 0m07s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 2,573,460 (9.817 MB), Total: 9.93 MB, FLOPs: 280,952,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1682 finished in 0m07s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.115 MB, Params: 2,570,614 (9.806 MB), Total: 9.92 MB, FLOPs: 280,321,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1682 finished in 0m07s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 339)]\n",
      "Input: 0.115 MB, Params: 2,565,869 (9.788 MB), Total: 9.90 MB, FLOPs: 280,193,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1682 finished in 0m06s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 2,563,023 (9.777 MB), Total: 9.89 MB, FLOPs: 279,885,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1682 finished in 0m06s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.115 MB, Params: 2,560,186 (9.766 MB), Total: 9.88 MB, FLOPs: 279,255,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1682 finished in 0m06s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 2,556,852 (9.754 MB), Total: 9.87 MB, FLOPs: 279,165,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1682 finished in 0m06s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.115 MB, Params: 2,553,518 (9.741 MB), Total: 9.86 MB, FLOPs: 279,075,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1682 finished in 0m06s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 2,548,791 (9.723 MB), Total: 9.84 MB, FLOPs: 278,947,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1682 finished in 0m06s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 2,545,954 (9.712 MB), Total: 9.83 MB, FLOPs: 278,641,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1682 finished in 0m06s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 2,543,117 (9.701 MB), Total: 9.82 MB, FLOPs: 278,335,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1682 finished in 0m06s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.115 MB, Params: 2,540,298 (9.690 MB), Total: 9.81 MB, FLOPs: 277,706,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1682 finished in 0m06s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 197)]\n",
      "Input: 0.115 MB, Params: 2,535,571 (9.672 MB), Total: 9.79 MB, FLOPs: 277,578,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1682 finished in 0m06s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 2,532,255 (9.660 MB), Total: 9.78 MB, FLOPs: 277,489,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1682 finished in 0m06s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.115 MB, Params: 2,527,537 (9.642 MB), Total: 9.76 MB, FLOPs: 277,362,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1682 finished in 0m06s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.115 MB, Params: 2,522,819 (9.624 MB), Total: 9.74 MB, FLOPs: 277,234,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1682 finished in 0m06s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.115 MB, Params: 2,518,101 (9.606 MB), Total: 9.72 MB, FLOPs: 277,107,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1682 finished in 0m06s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 2,512,960 (9.586 MB), Total: 9.70 MB, FLOPs: 276,818,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1682 finished in 0m06s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 48)]\n",
      "Input: 0.115 MB, Params: 2,511,500 (9.581 MB), Total: 9.70 MB, FLOPs: 275,496,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1682 finished in 0m06s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.115 MB, Params: 2,506,791 (9.563 MB), Total: 9.68 MB, FLOPs: 275,368,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1682 finished in 0m06s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 2,502,082 (9.545 MB), Total: 9.66 MB, FLOPs: 275,241,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1682 finished in 0m06s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.115 MB, Params: 2,498,811 (9.532 MB), Total: 9.65 MB, FLOPs: 275,153,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1682 finished in 0m06s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 2,494,111 (9.514 MB), Total: 9.63 MB, FLOPs: 275,026,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1682 finished in 0m06s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 341)]\n",
      "Input: 0.115 MB, Params: 2,489,411 (9.496 MB), Total: 9.61 MB, FLOPs: 274,899,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1682 finished in 0m06s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 350)]\n",
      "Input: 0.115 MB, Params: 2,484,711 (9.478 MB), Total: 9.59 MB, FLOPs: 274,772,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1682 finished in 0m06s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 2,481,467 (9.466 MB), Total: 9.58 MB, FLOPs: 274,685,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1682 finished in 0m06s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.115 MB, Params: 2,480,007 (9.460 MB), Total: 9.58 MB, FLOPs: 273,363,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1682 finished in 0m06s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 2,477,188 (9.450 MB), Total: 9.57 MB, FLOPs: 273,058,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1682 finished in 0m06s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 30)]\n",
      "Input: 0.115 MB, Params: 2,476,457 (9.447 MB), Total: 9.56 MB, FLOPs: 271,744,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1682 finished in 0m06s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 77)]\n",
      "Input: 0.115 MB, Params: 2,474,907 (9.441 MB), Total: 9.56 MB, FLOPs: 271,057,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1682 finished in 0m06s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 2,471,663 (9.429 MB), Total: 9.54 MB, FLOPs: 270,969,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1682 finished in 0m06s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 2,468,419 (9.416 MB), Total: 9.53 MB, FLOPs: 270,882,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1682 finished in 0m06s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 2,465,175 (9.404 MB), Total: 9.52 MB, FLOPs: 270,794,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1682 finished in 0m06s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 181)]\n",
      "Input: 0.115 MB, Params: 2,462,356 (9.393 MB), Total: 9.51 MB, FLOPs: 270,490,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1682 finished in 0m06s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 173)]\n",
      "Input: 0.115 MB, Params: 2,459,537 (9.382 MB), Total: 9.50 MB, FLOPs: 270,185,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1682 finished in 0m06s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 2,454,873 (9.365 MB), Total: 9.48 MB, FLOPs: 270,059,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1682 finished in 0m06s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 97)]\n",
      "Input: 0.115 MB, Params: 2,453,323 (9.359 MB), Total: 9.47 MB, FLOPs: 269,372,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1682 finished in 0m06s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 2,450,088 (9.346 MB), Total: 9.46 MB, FLOPs: 269,284,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1682 finished in 0m06s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.115 MB, Params: 2,446,853 (9.334 MB), Total: 9.45 MB, FLOPs: 269,197,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1682 finished in 0m06s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 2,442,207 (9.316 MB), Total: 9.43 MB, FLOPs: 269,072,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1682 finished in 0m06s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.115 MB, Params: 2,438,981 (9.304 MB), Total: 9.42 MB, FLOPs: 268,985,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1682 finished in 0m06s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 2,434,344 (9.286 MB), Total: 9.40 MB, FLOPs: 268,860,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1682 finished in 0m06s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 323)]\n",
      "Input: 0.115 MB, Params: 2,429,707 (9.269 MB), Total: 9.38 MB, FLOPs: 268,734,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1682 finished in 0m06s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 137)]\n",
      "Input: 0.115 MB, Params: 2,424,674 (9.249 MB), Total: 9.36 MB, FLOPs: 268,450,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1682 finished in 0m06s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 2,420,046 (9.232 MB), Total: 9.35 MB, FLOPs: 268,325,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1682 finished in 0m06s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 2,415,418 (9.214 MB), Total: 9.33 MB, FLOPs: 268,200,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1682 finished in 0m06s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 2,412,228 (9.202 MB), Total: 9.32 MB, FLOPs: 268,114,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1682 finished in 0m06s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 2,407,609 (9.184 MB), Total: 9.30 MB, FLOPs: 267,990,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1682 finished in 0m06s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 27)]\n",
      "Input: 0.115 MB, Params: 2,406,878 (9.182 MB), Total: 9.30 MB, FLOPs: 266,676,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1682 finished in 0m06s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.115 MB, Params: 2,405,328 (9.176 MB), Total: 9.29 MB, FLOPs: 265,988,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1682 finished in 0m06s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.115 MB, Params: 2,400,322 (9.157 MB), Total: 9.27 MB, FLOPs: 265,705,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1682 finished in 0m06s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.115 MB, Params: 2,397,521 (9.146 MB), Total: 9.26 MB, FLOPs: 265,402,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1682 finished in 0m06s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 2,392,524 (9.127 MB), Total: 9.24 MB, FLOPs: 265,120,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1682 finished in 0m06s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 159)]\n",
      "Input: 0.115 MB, Params: 2,389,732 (9.116 MB), Total: 9.23 MB, FLOPs: 264,818,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1682 finished in 0m06s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 181)]\n",
      "Input: 0.115 MB, Params: 2,384,744 (9.097 MB), Total: 9.21 MB, FLOPs: 264,537,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1682 finished in 0m06s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 2,380,152 (9.080 MB), Total: 9.19 MB, FLOPs: 264,413,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1682 finished in 0m06s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.115 MB, Params: 2,377,369 (9.069 MB), Total: 9.18 MB, FLOPs: 264,113,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1682 finished in 0m06s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 2,372,777 (9.051 MB), Total: 9.17 MB, FLOPs: 263,989,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1682 finished in 0m06s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 2,369,614 (9.039 MB), Total: 9.15 MB, FLOPs: 263,903,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1682 finished in 0m06s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.115 MB, Params: 2,366,451 (9.027 MB), Total: 9.14 MB, FLOPs: 263,818,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1682 finished in 0m06s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 132)]\n",
      "Input: 0.115 MB, Params: 2,361,490 (9.008 MB), Total: 9.12 MB, FLOPs: 263,538,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1682 finished in 0m06s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 2,358,327 (8.996 MB), Total: 9.11 MB, FLOPs: 263,453,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1682 finished in 0m06s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 2,355,164 (8.984 MB), Total: 9.10 MB, FLOPs: 263,367,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1682 finished in 0m06s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 2,352,001 (8.972 MB), Total: 9.09 MB, FLOPs: 263,282,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1682 finished in 0m06s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 2,348,838 (8.960 MB), Total: 9.08 MB, FLOPs: 263,197,231\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1682 finished in 0m06s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 2,344,309 (8.943 MB), Total: 9.06 MB, FLOPs: 263,074,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1682 finished in 0m06s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.115 MB, Params: 2,341,155 (8.931 MB), Total: 9.05 MB, FLOPs: 262,989,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1682 finished in 0m06s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.115 MB, Params: 2,336,203 (8.912 MB), Total: 9.03 MB, FLOPs: 262,710,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1682 finished in 0m06s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.115 MB, Params: 2,334,788 (8.907 MB), Total: 9.02 MB, FLOPs: 261,432,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1682 finished in 0m06s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.115 MB, Params: 2,329,836 (8.888 MB), Total: 9.00 MB, FLOPs: 261,152,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1682 finished in 0m06s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 2,326,682 (8.876 MB), Total: 8.99 MB, FLOPs: 261,067,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1682 finished in 0m06s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 54)]\n",
      "Input: 0.115 MB, Params: 2,325,141 (8.870 MB), Total: 8.99 MB, FLOPs: 260,383,921\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1682 finished in 0m06s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 2,321,987 (8.858 MB), Total: 8.97 MB, FLOPs: 260,298,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1682 finished in 0m06s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 126)]\n",
      "Input: 0.115 MB, Params: 2,317,035 (8.839 MB), Total: 8.95 MB, FLOPs: 260,019,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1682 finished in 0m06s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.115 MB, Params: 2,312,560 (8.822 MB), Total: 8.94 MB, FLOPs: 259,898,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1682 finished in 0m06s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 2,309,415 (8.810 MB), Total: 8.93 MB, FLOPs: 259,813,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1682 finished in 0m06s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.115 MB, Params: 2,304,949 (8.793 MB), Total: 8.91 MB, FLOPs: 259,692,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1682 finished in 0m06s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 2,301,813 (8.781 MB), Total: 8.90 MB, FLOPs: 259,608,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1682 finished in 0m06s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.115 MB, Params: 2,299,084 (8.770 MB), Total: 8.89 MB, FLOPs: 259,001,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1682 finished in 0m06s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 2,294,627 (8.753 MB), Total: 8.87 MB, FLOPs: 258,881,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1682 finished in 0m06s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 2,294,585 (8.753 MB), Total: 8.87 MB, FLOPs: 258,524,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1682 finished in 0m06s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 191)]\n",
      "Input: 0.115 MB, Params: 2,291,458 (8.741 MB), Total: 8.86 MB, FLOPs: 258,440,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1682 finished in 0m06s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 2,287,010 (8.724 MB), Total: 8.84 MB, FLOPs: 258,320,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1682 finished in 0m06s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 2,283,892 (8.712 MB), Total: 8.83 MB, FLOPs: 258,236,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1682 finished in 0m06s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 2,279,453 (8.695 MB), Total: 8.81 MB, FLOPs: 258,116,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1682 finished in 0m06s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 2,276,344 (8.684 MB), Total: 8.80 MB, FLOPs: 258,032,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1682 finished in 0m06s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 2,273,235 (8.672 MB), Total: 8.79 MB, FLOPs: 257,948,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1682 finished in 0m06s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 4)]\n",
      "Input: 0.115 MB, Params: 2,272,747 (8.670 MB), Total: 8.79 MB, FLOPs: 257,010,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1682 finished in 0m06s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.115 MB, Params: 2,272,034 (8.667 MB), Total: 8.78 MB, FLOPs: 255,728,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1682 finished in 0m06s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 2,270,502 (8.661 MB), Total: 8.78 MB, FLOPs: 255,048,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1682 finished in 0m06s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.115 MB, Params: 2,266,081 (8.644 MB), Total: 8.76 MB, FLOPs: 254,929,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1682 finished in 0m06s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 2,266,039 (8.644 MB), Total: 8.76 MB, FLOPs: 222,437,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1682 finished in 0m06s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 2,262,939 (8.632 MB), Total: 8.75 MB, FLOPs: 222,381,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1682 finished in 0m06s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 306)]\n",
      "Input: 0.115 MB, Params: 2,258,527 (8.616 MB), Total: 8.73 MB, FLOPs: 222,301,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1682 finished in 0m06s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.115 MB, Params: 2,254,115 (8.599 MB), Total: 8.71 MB, FLOPs: 222,222,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1682 finished in 0m06s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 2,249,703 (8.582 MB), Total: 8.70 MB, FLOPs: 222,143,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1682 finished in 0m06s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 2,244,832 (8.563 MB), Total: 8.68 MB, FLOPs: 221,925,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1682 finished in 0m06s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 132)]\n",
      "Input: 0.115 MB, Params: 2,242,103 (8.553 MB), Total: 8.67 MB, FLOPs: 221,680,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1682 finished in 0m06s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 68)]\n",
      "Input: 0.115 MB, Params: 2,239,374 (8.543 MB), Total: 8.66 MB, FLOPs: 221,434,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1682 finished in 0m06s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 76)]\n",
      "Input: 0.115 MB, Params: 2,236,645 (8.532 MB), Total: 8.65 MB, FLOPs: 221,189,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1682 finished in 0m06s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 2,232,242 (8.515 MB), Total: 8.63 MB, FLOPs: 221,110,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1682 finished in 0m06s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 2,229,513 (8.505 MB), Total: 8.62 MB, FLOPs: 220,864,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1682 finished in 0m06s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.115 MB, Params: 2,225,110 (8.488 MB), Total: 8.60 MB, FLOPs: 220,785,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1682 finished in 0m06s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 290)]\n",
      "Input: 0.115 MB, Params: 2,222,055 (8.476 MB), Total: 8.59 MB, FLOPs: 220,730,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1682 finished in 0m06s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 2,217,661 (8.460 MB), Total: 8.58 MB, FLOPs: 220,651,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1682 finished in 0m06s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 2,213,267 (8.443 MB), Total: 8.56 MB, FLOPs: 220,572,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1682 finished in 0m06s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.115 MB, Params: 2,210,538 (8.433 MB), Total: 8.55 MB, FLOPs: 220,326,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1682 finished in 0m06s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 2,210,496 (8.432 MB), Total: 8.55 MB, FLOPs: 219,971,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1682 finished in 0m06s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 262)]\n",
      "Input: 0.115 MB, Params: 2,206,102 (8.416 MB), Total: 8.53 MB, FLOPs: 219,892,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1682 finished in 0m06s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 96)]\n",
      "Input: 0.115 MB, Params: 2,204,570 (8.410 MB), Total: 8.53 MB, FLOPs: 219,269,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1682 finished in 0m06s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.115 MB, Params: 2,200,176 (8.393 MB), Total: 8.51 MB, FLOPs: 219,190,379\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1682 finished in 0m06s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 2,198,644 (8.387 MB), Total: 8.50 MB, FLOPs: 218,567,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1682 finished in 0m06s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 2,194,250 (8.370 MB), Total: 8.49 MB, FLOPs: 218,488,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1682 finished in 0m06s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 2,191,240 (8.359 MB), Total: 8.47 MB, FLOPs: 218,434,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1682 finished in 0m06s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 185)]\n",
      "Input: 0.115 MB, Params: 2,188,230 (8.347 MB), Total: 8.46 MB, FLOPs: 218,379,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1682 finished in 0m06s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 68)]\n",
      "Input: 0.115 MB, Params: 2,185,220 (8.336 MB), Total: 8.45 MB, FLOPs: 218,325,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1682 finished in 0m06s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 317)]\n",
      "Input: 0.115 MB, Params: 2,180,853 (8.319 MB), Total: 8.43 MB, FLOPs: 218,247,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1682 finished in 0m06s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.115 MB, Params: 2,177,852 (8.308 MB), Total: 8.42 MB, FLOPs: 218,193,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1682 finished in 0m06s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 49)]\n",
      "Input: 0.115 MB, Params: 2,173,098 (8.290 MB), Total: 8.41 MB, FLOPs: 217,981,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1682 finished in 0m06s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 2,170,097 (8.278 MB), Total: 8.39 MB, FLOPs: 217,927,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1682 finished in 0m06s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 21)]\n",
      "Input: 0.115 MB, Params: 2,169,618 (8.276 MB), Total: 8.39 MB, FLOPs: 217,043,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1682 finished in 0m06s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 2,166,617 (8.265 MB), Total: 8.38 MB, FLOPs: 216,989,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1682 finished in 0m06s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.115 MB, Params: 2,162,286 (8.248 MB), Total: 8.36 MB, FLOPs: 216,911,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1682 finished in 0m06s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 2,159,294 (8.237 MB), Total: 8.35 MB, FLOPs: 216,857,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1682 finished in 0m06s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 2,156,302 (8.226 MB), Total: 8.34 MB, FLOPs: 216,803,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1682 finished in 0m06s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 134)]\n",
      "Input: 0.115 MB, Params: 2,153,582 (8.215 MB), Total: 8.33 MB, FLOPs: 216,559,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1682 finished in 0m06s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 2,149,269 (8.199 MB), Total: 8.31 MB, FLOPs: 216,481,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1682 finished in 0m06s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.115 MB, Params: 2,144,542 (8.181 MB), Total: 8.30 MB, FLOPs: 216,270,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1682 finished in 0m06s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 2,140,238 (8.164 MB), Total: 8.28 MB, FLOPs: 216,193,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1682 finished in 0m06s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 2,137,527 (8.154 MB), Total: 8.27 MB, FLOPs: 215,949,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1682 finished in 0m06s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 2,134,553 (8.143 MB), Total: 8.26 MB, FLOPs: 215,895,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1682 finished in 0m06s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.115 MB, Params: 2,131,579 (8.131 MB), Total: 8.25 MB, FLOPs: 215,842,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1682 finished in 0m06s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 310)]\n",
      "Input: 0.115 MB, Params: 2,127,293 (8.115 MB), Total: 8.23 MB, FLOPs: 215,765,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1682 finished in 0m06s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 2,123,007 (8.099 MB), Total: 8.21 MB, FLOPs: 215,688,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1682 finished in 0m06s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.115 MB, Params: 2,118,721 (8.082 MB), Total: 8.20 MB, FLOPs: 215,610,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1682 finished in 0m06s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 2,115,774 (8.071 MB), Total: 8.19 MB, FLOPs: 215,557,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1682 finished in 0m06s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 2,112,827 (8.060 MB), Total: 8.18 MB, FLOPs: 215,504,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1682 finished in 0m06s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 277)]\n",
      "Input: 0.115 MB, Params: 2,109,880 (8.049 MB), Total: 8.16 MB, FLOPs: 215,451,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1682 finished in 0m06s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 150)]\n",
      "Input: 0.115 MB, Params: 2,105,621 (8.032 MB), Total: 8.15 MB, FLOPs: 215,375,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1682 finished in 0m06s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 305)]\n",
      "Input: 0.115 MB, Params: 2,101,362 (8.016 MB), Total: 8.13 MB, FLOPs: 215,298,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1682 finished in 0m06s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 2,097,103 (8.000 MB), Total: 8.12 MB, FLOPs: 215,221,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1682 finished in 0m06s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.115 MB, Params: 2,095,571 (7.994 MB), Total: 8.11 MB, FLOPs: 214,598,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1682 finished in 0m06s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 44)]\n",
      "Input: 0.115 MB, Params: 2,094,210 (7.989 MB), Total: 8.10 MB, FLOPs: 213,425,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1682 finished in 0m06s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 67)]\n",
      "Input: 0.115 MB, Params: 2,092,687 (7.983 MB), Total: 8.10 MB, FLOPs: 212,806,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1682 finished in 0m06s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 2,089,767 (7.972 MB), Total: 8.09 MB, FLOPs: 212,753,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1682 finished in 0m06s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 88)]\n",
      "Input: 0.115 MB, Params: 2,088,244 (7.966 MB), Total: 8.08 MB, FLOPs: 212,134,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1682 finished in 0m06s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 54)]\n",
      "Input: 0.115 MB, Params: 2,083,994 (7.950 MB), Total: 8.07 MB, FLOPs: 212,057,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1682 finished in 0m06s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.115 MB, Params: 2,081,382 (7.940 MB), Total: 8.06 MB, FLOPs: 211,545,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1682 finished in 0m06s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 285)]\n",
      "Input: 0.115 MB, Params: 2,078,471 (7.929 MB), Total: 8.04 MB, FLOPs: 211,492,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1682 finished in 0m06s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 2,075,769 (7.918 MB), Total: 8.03 MB, FLOPs: 211,249,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1682 finished in 0m06s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 2,071,528 (7.902 MB), Total: 8.02 MB, FLOPs: 211,173,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1682 finished in 0m06s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.115 MB, Params: 2,068,925 (7.892 MB), Total: 8.01 MB, FLOPs: 210,661,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1682 finished in 0m06s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 290)]\n",
      "Input: 0.115 MB, Params: 2,064,684 (7.876 MB), Total: 7.99 MB, FLOPs: 210,585,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1682 finished in 0m06s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 2,060,443 (7.860 MB), Total: 7.98 MB, FLOPs: 210,509,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1682 finished in 0m06s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 30)]\n",
      "Input: 0.115 MB, Params: 2,059,748 (7.857 MB), Total: 7.97 MB, FLOPs: 209,311,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1682 finished in 0m06s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.115 MB, Params: 2,055,138 (7.840 MB), Total: 7.96 MB, FLOPs: 209,104,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1682 finished in 0m06s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 162)]\n",
      "Input: 0.115 MB, Params: 2,052,454 (7.829 MB), Total: 7.94 MB, FLOPs: 208,863,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1682 finished in 0m06s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 125)]\n",
      "Input: 0.115 MB, Params: 2,047,853 (7.812 MB), Total: 7.93 MB, FLOPs: 208,656,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1682 finished in 0m06s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 2,043,630 (7.796 MB), Total: 7.91 MB, FLOPs: 208,580,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1682 finished in 0m06s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.115 MB, Params: 2,040,755 (7.785 MB), Total: 7.90 MB, FLOPs: 208,528,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1682 finished in 0m06s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 2,037,880 (7.774 MB), Total: 7.89 MB, FLOPs: 208,476,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1682 finished in 0m06s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 2,033,675 (7.758 MB), Total: 7.87 MB, FLOPs: 208,401,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1682 finished in 0m06s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 2,029,470 (7.742 MB), Total: 7.86 MB, FLOPs: 208,325,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1682 finished in 0m06s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.115 MB, Params: 2,026,795 (7.732 MB), Total: 7.85 MB, FLOPs: 208,084,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1682 finished in 0m06s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 2,024,120 (7.721 MB), Total: 7.84 MB, FLOPs: 207,844,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1682 finished in 0m06s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 2,019,915 (7.705 MB), Total: 7.82 MB, FLOPs: 207,768,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1682 finished in 0m06s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 2,015,710 (7.689 MB), Total: 7.80 MB, FLOPs: 207,692,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1682 finished in 0m06s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 2,012,871 (7.678 MB), Total: 7.79 MB, FLOPs: 207,641,777\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1682 finished in 0m06s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 2,010,032 (7.668 MB), Total: 7.78 MB, FLOPs: 207,590,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1682 finished in 0m06s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 2)]\n",
      "Input: 0.115 MB, Params: 2,007,456 (7.658 MB), Total: 7.77 MB, FLOPs: 207,081,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1682 finished in 0m06s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 2,004,790 (7.648 MB), Total: 7.76 MB, FLOPs: 206,841,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1682 finished in 0m06s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 175)]\n",
      "Input: 0.115 MB, Params: 2,002,124 (7.637 MB), Total: 7.75 MB, FLOPs: 206,601,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1682 finished in 0m06s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.115 MB, Params: 1,997,937 (7.622 MB), Total: 7.74 MB, FLOPs: 206,526,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1682 finished in 0m06s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 1,993,750 (7.606 MB), Total: 7.72 MB, FLOPs: 206,451,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1682 finished in 0m06s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,990,929 (7.595 MB), Total: 7.71 MB, FLOPs: 206,400,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1682 finished in 0m06s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 1,988,263 (7.585 MB), Total: 7.70 MB, FLOPs: 206,160,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1682 finished in 0m06s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 129)]\n",
      "Input: 0.115 MB, Params: 1,985,597 (7.574 MB), Total: 7.69 MB, FLOPs: 205,920,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1682 finished in 0m06s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 4)]\n",
      "Input: 0.115 MB, Params: 1,983,057 (7.565 MB), Total: 7.68 MB, FLOPs: 205,414,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1682 finished in 0m06s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 145)]\n",
      "Input: 0.115 MB, Params: 1,978,573 (7.548 MB), Total: 7.66 MB, FLOPs: 205,214,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1682 finished in 0m06s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 1,974,404 (7.532 MB), Total: 7.65 MB, FLOPs: 205,139,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1682 finished in 0m06s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.115 MB, Params: 1,971,592 (7.521 MB), Total: 7.64 MB, FLOPs: 205,088,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1682 finished in 0m06s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.115 MB, Params: 1,970,897 (7.518 MB), Total: 7.63 MB, FLOPs: 203,891,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1682 finished in 0m06s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 1,968,085 (7.508 MB), Total: 7.62 MB, FLOPs: 203,840,701\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1682 finished in 0m06s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 295)]\n",
      "Input: 0.115 MB, Params: 1,963,934 (7.492 MB), Total: 7.61 MB, FLOPs: 203,766,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1682 finished in 0m06s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 1,963,473 (7.490 MB), Total: 7.61 MB, FLOPs: 202,913,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1682 finished in 0m06s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 1,960,670 (7.479 MB), Total: 7.59 MB, FLOPs: 202,862,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1682 finished in 0m06s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 1,959,984 (7.477 MB), Total: 7.59 MB, FLOPs: 201,681,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1682 finished in 0m06s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.115 MB, Params: 1,955,842 (7.461 MB), Total: 7.58 MB, FLOPs: 201,606,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1682 finished in 0m06s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 1,953,048 (7.450 MB), Total: 7.57 MB, FLOPs: 201,556,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1682 finished in 0m06s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 1,950,254 (7.440 MB), Total: 7.55 MB, FLOPs: 201,506,280\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1682 finished in 0m06s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 1,945,797 (7.423 MB), Total: 7.54 MB, FLOPs: 201,306,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1682 finished in 0m06s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 1,943,003 (7.412 MB), Total: 7.53 MB, FLOPs: 201,255,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1682 finished in 0m06s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 39)]\n",
      "Input: 0.115 MB, Params: 1,942,317 (7.409 MB), Total: 7.52 MB, FLOPs: 200,074,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1682 finished in 0m06s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 54)]\n",
      "Input: 0.115 MB, Params: 1,939,678 (7.399 MB), Total: 7.51 MB, FLOPs: 199,836,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1682 finished in 0m06s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 1,935,230 (7.382 MB), Total: 7.50 MB, FLOPs: 199,637,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1682 finished in 0m06s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.115 MB, Params: 1,931,133 (7.367 MB), Total: 7.48 MB, FLOPs: 199,563,591\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1682 finished in 0m06s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 139)]\n",
      "Input: 0.115 MB, Params: 1,928,503 (7.357 MB), Total: 7.47 MB, FLOPs: 199,326,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1682 finished in 0m06s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 1,925,873 (7.347 MB), Total: 7.46 MB, FLOPs: 199,090,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1682 finished in 0m06s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 1,921,776 (7.331 MB), Total: 7.45 MB, FLOPs: 199,016,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1682 finished in 0m06s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.115 MB, Params: 1,917,679 (7.315 MB), Total: 7.43 MB, FLOPs: 198,942,915\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1682 finished in 0m06s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.115 MB, Params: 1,913,582 (7.300 MB), Total: 7.42 MB, FLOPs: 198,869,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1682 finished in 0m06s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 192)]\n",
      "Input: 0.115 MB, Params: 1,910,824 (7.289 MB), Total: 7.40 MB, FLOPs: 198,819,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1682 finished in 0m06s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 1,908,066 (7.279 MB), Total: 7.39 MB, FLOPs: 198,769,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1682 finished in 0m06s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 1,903,987 (7.263 MB), Total: 7.38 MB, FLOPs: 198,696,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1682 finished in 0m06s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 60)]\n",
      "Input: 0.115 MB, Params: 1,901,357 (7.253 MB), Total: 7.37 MB, FLOPs: 198,459,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1682 finished in 0m06s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.115 MB, Params: 1,897,278 (7.238 MB), Total: 7.35 MB, FLOPs: 198,386,541\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1682 finished in 0m06s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 134)]\n",
      "Input: 0.115 MB, Params: 1,892,911 (7.221 MB), Total: 7.34 MB, FLOPs: 198,190,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1682 finished in 0m06s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.115 MB, Params: 1,888,544 (7.204 MB), Total: 7.32 MB, FLOPs: 197,994,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1682 finished in 0m06s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 1,884,483 (7.189 MB), Total: 7.30 MB, FLOPs: 197,921,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1682 finished in 0m06s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.115 MB, Params: 1,880,125 (7.172 MB), Total: 7.29 MB, FLOPs: 197,725,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1682 finished in 0m06s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 1,877,394 (7.162 MB), Total: 7.28 MB, FLOPs: 197,676,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1682 finished in 0m06s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 1,874,663 (7.151 MB), Total: 7.27 MB, FLOPs: 197,627,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1682 finished in 0m06s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 1,870,629 (7.136 MB), Total: 7.25 MB, FLOPs: 197,554,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1682 finished in 0m06s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.115 MB, Params: 1,867,907 (7.125 MB), Total: 7.24 MB, FLOPs: 197,505,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1682 finished in 0m06s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 214)]\n",
      "Input: 0.115 MB, Params: 1,863,882 (7.110 MB), Total: 7.23 MB, FLOPs: 197,433,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1682 finished in 0m06s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 91)]\n",
      "Input: 0.115 MB, Params: 1,862,395 (7.104 MB), Total: 7.22 MB, FLOPs: 196,828,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1682 finished in 0m06s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 1,858,055 (7.088 MB), Total: 7.20 MB, FLOPs: 196,632,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1682 finished in 0m06s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 1,854,039 (7.073 MB), Total: 7.19 MB, FLOPs: 196,560,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1682 finished in 0m06s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 1,850,023 (7.057 MB), Total: 7.17 MB, FLOPs: 196,488,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1682 finished in 0m06s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 17)]\n",
      "Input: 0.115 MB, Params: 1,849,580 (7.056 MB), Total: 7.17 MB, FLOPs: 195,666,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1682 finished in 0m06s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 65)]\n",
      "Input: 0.115 MB, Params: 1,847,085 (7.046 MB), Total: 7.16 MB, FLOPs: 195,167,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1682 finished in 0m06s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 1,844,500 (7.036 MB), Total: 7.15 MB, FLOPs: 194,935,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1682 finished in 0m06s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 1,841,805 (7.026 MB), Total: 7.14 MB, FLOPs: 194,886,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1682 finished in 0m06s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 1,839,110 (7.016 MB), Total: 7.13 MB, FLOPs: 194,838,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1682 finished in 0m06s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.115 MB, Params: 1,836,525 (7.006 MB), Total: 7.12 MB, FLOPs: 194,605,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1682 finished in 0m06s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.115 MB, Params: 1,832,527 (6.991 MB), Total: 7.11 MB, FLOPs: 194,533,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1682 finished in 0m06s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 1,828,529 (6.975 MB), Total: 7.09 MB, FLOPs: 194,461,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1682 finished in 0m06s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 1,824,243 (6.959 MB), Total: 7.07 MB, FLOPs: 194,268,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1682 finished in 0m06s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 1,821,766 (6.949 MB), Total: 7.06 MB, FLOPs: 193,771,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1682 finished in 0m06s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 1,817,777 (6.934 MB), Total: 7.05 MB, FLOPs: 193,699,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1682 finished in 0m06s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 1,816,479 (6.929 MB), Total: 7.04 MB, FLOPs: 192,599,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1682 finished in 0m06s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 1,812,202 (6.913 MB), Total: 7.03 MB, FLOPs: 192,406,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1682 finished in 0m06s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,809,534 (6.903 MB), Total: 7.02 MB, FLOPs: 192,358,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1682 finished in 0m06s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 261)]\n",
      "Input: 0.115 MB, Params: 1,805,563 (6.888 MB), Total: 7.00 MB, FLOPs: 192,286,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1682 finished in 0m06s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.115 MB, Params: 1,802,904 (6.878 MB), Total: 6.99 MB, FLOPs: 192,238,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1682 finished in 0m06s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.115 MB, Params: 1,800,245 (6.867 MB), Total: 6.98 MB, FLOPs: 192,191,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1682 finished in 0m06s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 1,796,292 (6.852 MB), Total: 6.97 MB, FLOPs: 192,119,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1682 finished in 0m06s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 1,792,339 (6.837 MB), Total: 6.95 MB, FLOPs: 192,048,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1682 finished in 0m06s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 162)]\n",
      "Input: 0.115 MB, Params: 1,789,781 (6.827 MB), Total: 6.94 MB, FLOPs: 191,818,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1682 finished in 0m06s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 1,787,140 (6.817 MB), Total: 6.93 MB, FLOPs: 191,771,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1682 finished in 0m06s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 1,783,196 (6.802 MB), Total: 6.92 MB, FLOPs: 191,700,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1682 finished in 0m06s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.115 MB, Params: 1,780,638 (6.793 MB), Total: 6.91 MB, FLOPs: 191,469,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1682 finished in 0m06s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.115 MB, Params: 1,779,970 (6.790 MB), Total: 6.91 MB, FLOPs: 190,319,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1682 finished in 0m06s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 72)]\n",
      "Input: 0.115 MB, Params: 1,778,510 (6.784 MB), Total: 6.90 MB, FLOPs: 189,725,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1682 finished in 0m06s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 1,774,566 (6.769 MB), Total: 6.88 MB, FLOPs: 189,654,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1682 finished in 0m06s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.115 MB, Params: 1,770,352 (6.753 MB), Total: 6.87 MB, FLOPs: 189,463,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1682 finished in 0m06s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 68)]\n",
      "Input: 0.115 MB, Params: 1,767,729 (6.743 MB), Total: 6.86 MB, FLOPs: 189,416,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1682 finished in 0m06s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,765,106 (6.733 MB), Total: 6.85 MB, FLOPs: 189,369,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1682 finished in 0m06s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 48)]\n",
      "Input: 0.115 MB, Params: 1,763,646 (6.728 MB), Total: 6.84 MB, FLOPs: 188,775,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1682 finished in 0m06s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.115 MB, Params: 1,761,023 (6.718 MB), Total: 6.83 MB, FLOPs: 188,728,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1682 finished in 0m06s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 1,758,400 (6.708 MB), Total: 6.82 MB, FLOPs: 188,681,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1682 finished in 0m06s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 1,754,501 (6.693 MB), Total: 6.81 MB, FLOPs: 188,611,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1682 finished in 0m06s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.115 MB, Params: 1,752,060 (6.684 MB), Total: 6.80 MB, FLOPs: 188,122,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1682 finished in 0m06s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 1,747,855 (6.668 MB), Total: 6.78 MB, FLOPs: 187,932,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1682 finished in 0m06s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,745,241 (6.658 MB), Total: 6.77 MB, FLOPs: 187,885,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1682 finished in 0m06s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 1,741,360 (6.643 MB), Total: 6.76 MB, FLOPs: 187,815,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1682 finished in 0m06s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 1,737,479 (6.628 MB), Total: 6.74 MB, FLOPs: 187,745,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1682 finished in 0m06s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 1,733,598 (6.613 MB), Total: 6.73 MB, FLOPs: 187,675,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1682 finished in 0m06s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 1,729,717 (6.598 MB), Total: 6.71 MB, FLOPs: 187,605,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1682 finished in 0m06s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 1,727,186 (6.589 MB), Total: 6.70 MB, FLOPs: 187,378,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1682 finished in 0m06s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 69)]\n",
      "Input: 0.115 MB, Params: 1,724,754 (6.579 MB), Total: 6.69 MB, FLOPs: 186,890,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1682 finished in 0m06s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 1,723,312 (6.574 MB), Total: 6.69 MB, FLOPs: 186,304,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1682 finished in 0m06s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 1)]\n",
      "Input: 0.115 MB, Params: 1,720,889 (6.565 MB), Total: 6.68 MB, FLOPs: 185,820,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1682 finished in 0m06s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 1,718,376 (6.555 MB), Total: 6.67 MB, FLOPs: 185,593,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1682 finished in 0m06s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.115 MB, Params: 1,716,943 (6.550 MB), Total: 6.66 MB, FLOPs: 185,011,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1682 finished in 0m06s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.115 MB, Params: 1,713,062 (6.535 MB), Total: 6.65 MB, FLOPs: 184,941,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1682 finished in 0m06s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 91)]\n",
      "Input: 0.115 MB, Params: 1,708,920 (6.519 MB), Total: 6.63 MB, FLOPs: 184,753,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1682 finished in 0m06s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 1,706,351 (6.509 MB), Total: 6.62 MB, FLOPs: 184,707,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1682 finished in 0m06s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 31)]\n",
      "Input: 0.115 MB, Params: 1,706,309 (6.509 MB), Total: 6.62 MB, FLOPs: 181,994,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1682 finished in 0m06s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 79)]\n",
      "Input: 0.115 MB, Params: 1,704,876 (6.504 MB), Total: 6.62 MB, FLOPs: 181,412,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1682 finished in 0m06s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 1,703,443 (6.498 MB), Total: 6.61 MB, FLOPs: 180,829,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1682 finished in 0m06s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,700,874 (6.488 MB), Total: 6.60 MB, FLOPs: 180,783,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1682 finished in 0m06s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.115 MB, Params: 1,699,441 (6.483 MB), Total: 6.60 MB, FLOPs: 180,200,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1682 finished in 0m06s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 1,695,587 (6.468 MB), Total: 6.58 MB, FLOPs: 180,130,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1682 finished in 0m06s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.115 MB, Params: 1,691,733 (6.453 MB), Total: 6.57 MB, FLOPs: 180,061,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1682 finished in 0m06s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 1,689,229 (6.444 MB), Total: 6.56 MB, FLOPs: 179,836,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1682 finished in 0m06s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 131)]\n",
      "Input: 0.115 MB, Params: 1,686,725 (6.434 MB), Total: 6.55 MB, FLOPs: 179,610,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1682 finished in 0m06s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 1,682,871 (6.420 MB), Total: 6.53 MB, FLOPs: 179,541,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1682 finished in 0m06s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 1,678,774 (6.404 MB), Total: 6.52 MB, FLOPs: 179,355,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1682 finished in 0m06s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 1,676,232 (6.394 MB), Total: 6.51 MB, FLOPs: 179,309,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1682 finished in 0m06s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 41)]\n",
      "Input: 0.115 MB, Params: 1,676,190 (6.394 MB), Total: 6.51 MB, FLOPs: 178,959,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1682 finished in 0m06s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 1,672,354 (6.380 MB), Total: 6.49 MB, FLOPs: 178,890,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1682 finished in 0m06s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 95)]\n",
      "Input: 0.115 MB, Params: 1,669,994 (6.371 MB), Total: 6.49 MB, FLOPs: 178,423,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1682 finished in 0m06s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 146)]\n",
      "Input: 0.115 MB, Params: 1,665,906 (6.355 MB), Total: 6.47 MB, FLOPs: 178,237,731\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1682 finished in 0m06s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 1,663,373 (6.345 MB), Total: 6.46 MB, FLOPs: 178,192,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1682 finished in 0m06s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.115 MB, Params: 1,660,840 (6.336 MB), Total: 6.45 MB, FLOPs: 178,146,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1682 finished in 0m06s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 1,656,752 (6.320 MB), Total: 6.44 MB, FLOPs: 177,960,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1682 finished in 0m06s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.115 MB, Params: 1,654,392 (6.311 MB), Total: 6.43 MB, FLOPs: 177,493,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1682 finished in 0m06s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.115 MB, Params: 1,650,592 (6.297 MB), Total: 6.41 MB, FLOPs: 177,425,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1682 finished in 0m06s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 1,648,068 (6.287 MB), Total: 6.40 MB, FLOPs: 177,380,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1682 finished in 0m06s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 1,644,277 (6.272 MB), Total: 6.39 MB, FLOPs: 177,311,881\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1682 finished in 0m06s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 1,641,762 (6.263 MB), Total: 6.38 MB, FLOPs: 177,266,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1682 finished in 0m06s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 1,639,303 (6.253 MB), Total: 6.37 MB, FLOPs: 177,045,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1682 finished in 0m06s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 1,636,788 (6.244 MB), Total: 6.36 MB, FLOPs: 177,000,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1682 finished in 0m06s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 1,634,329 (6.234 MB), Total: 6.35 MB, FLOPs: 176,778,961\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1682 finished in 0m06s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.115 MB, Params: 1,630,277 (6.219 MB), Total: 6.33 MB, FLOPs: 176,595,091\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1682 finished in 0m06s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 1,627,762 (6.209 MB), Total: 6.32 MB, FLOPs: 176,549,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1682 finished in 0m06s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.115 MB, Params: 1,627,094 (6.207 MB), Total: 6.32 MB, FLOPs: 175,449,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1682 finished in 0m06s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.115 MB, Params: 1,623,042 (6.191 MB), Total: 6.31 MB, FLOPs: 175,265,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1682 finished in 0m06s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 1,620,601 (6.182 MB), Total: 6.30 MB, FLOPs: 175,045,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1682 finished in 0m06s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 1,618,086 (6.173 MB), Total: 6.29 MB, FLOPs: 175,000,591\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1682 finished in 0m06s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 1,614,349 (6.158 MB), Total: 6.27 MB, FLOPs: 174,933,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1682 finished in 0m06s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.115 MB, Params: 1,614,307 (6.158 MB), Total: 6.27 MB, FLOPs: 167,603,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1682 finished in 0m06s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 1,610,570 (6.144 MB), Total: 6.26 MB, FLOPs: 167,536,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1682 finished in 0m06s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 1,606,545 (6.128 MB), Total: 6.24 MB, FLOPs: 167,353,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1682 finished in 0m06s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 1,604,048 (6.119 MB), Total: 6.23 MB, FLOPs: 167,308,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1682 finished in 0m06s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 1,601,551 (6.109 MB), Total: 6.22 MB, FLOPs: 167,263,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1682 finished in 0m06s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.115 MB, Params: 1,599,119 (6.100 MB), Total: 6.22 MB, FLOPs: 167,044,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1682 finished in 0m06s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 1,596,622 (6.091 MB), Total: 6.21 MB, FLOPs: 166,999,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1682 finished in 0m06s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 236)]\n",
      "Input: 0.115 MB, Params: 1,592,921 (6.077 MB), Total: 6.19 MB, FLOPs: 166,933,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1682 finished in 0m06s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 1,589,220 (6.062 MB), Total: 6.18 MB, FLOPs: 166,866,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1682 finished in 0m06s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 1,586,788 (6.053 MB), Total: 6.17 MB, FLOPs: 166,647,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1682 finished in 0m06s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 1,583,087 (6.039 MB), Total: 6.15 MB, FLOPs: 166,581,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1682 finished in 0m06s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 160)]\n",
      "Input: 0.115 MB, Params: 1,580,655 (6.030 MB), Total: 6.15 MB, FLOPs: 166,362,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1682 finished in 0m06s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 64)]\n",
      "Input: 0.115 MB, Params: 1,579,240 (6.024 MB), Total: 6.14 MB, FLOPs: 165,839,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1682 finished in 0m06s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.115 MB, Params: 1,576,943 (6.016 MB), Total: 6.13 MB, FLOPs: 165,410,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1682 finished in 0m06s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 31)]\n",
      "Input: 0.115 MB, Params: 1,576,275 (6.013 MB), Total: 6.13 MB, FLOPs: 164,359,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1682 finished in 0m06s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 1,573,805 (6.004 MB), Total: 6.12 MB, FLOPs: 164,315,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1682 finished in 0m06s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 1,570,113 (5.990 MB), Total: 6.10 MB, FLOPs: 164,248,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1682 finished in 0m06s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 1,566,421 (5.975 MB), Total: 6.09 MB, FLOPs: 164,182,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1682 finished in 0m06s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.115 MB, Params: 1,562,729 (5.961 MB), Total: 6.08 MB, FLOPs: 164,115,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1682 finished in 0m06s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 141)]\n",
      "Input: 0.115 MB, Params: 1,560,306 (5.952 MB), Total: 6.07 MB, FLOPs: 163,897,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1682 finished in 0m06s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 1,557,863 (5.943 MB), Total: 6.06 MB, FLOPs: 163,854,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1682 finished in 0m06s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 1,553,928 (5.928 MB), Total: 6.04 MB, FLOPs: 163,675,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1682 finished in 0m06s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.115 MB, Params: 1,551,485 (5.918 MB), Total: 6.03 MB, FLOPs: 163,631,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1682 finished in 0m06s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.115 MB, Params: 1,547,820 (5.904 MB), Total: 6.02 MB, FLOPs: 163,565,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1682 finished in 0m06s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 1,544,155 (5.890 MB), Total: 6.01 MB, FLOPs: 163,499,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1682 finished in 0m06s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 1,541,741 (5.881 MB), Total: 6.00 MB, FLOPs: 163,282,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1682 finished in 0m06s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.115 MB, Params: 1,540,335 (5.876 MB), Total: 5.99 MB, FLOPs: 162,762,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1682 finished in 0m06s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 1,537,921 (5.867 MB), Total: 5.98 MB, FLOPs: 162,545,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1682 finished in 0m06s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.115 MB, Params: 1,535,496 (5.857 MB), Total: 5.97 MB, FLOPs: 162,501,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1682 finished in 0m06s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.115 MB, Params: 1,534,090 (5.852 MB), Total: 5.97 MB, FLOPs: 161,982,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1682 finished in 0m06s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.115 MB, Params: 1,530,434 (5.838 MB), Total: 5.95 MB, FLOPs: 161,916,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1682 finished in 0m06s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 1,526,544 (5.823 MB), Total: 5.94 MB, FLOPs: 161,739,812\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1682 finished in 0m06s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 123)]\n",
      "Input: 0.115 MB, Params: 1,524,139 (5.814 MB), Total: 5.93 MB, FLOPs: 161,523,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1682 finished in 0m06s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 79)]\n",
      "Input: 0.115 MB, Params: 1,521,896 (5.806 MB), Total: 5.92 MB, FLOPs: 161,104,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1682 finished in 0m06s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 1,518,015 (5.791 MB), Total: 5.91 MB, FLOPs: 160,928,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1682 finished in 0m06s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 250)]\n",
      "Input: 0.115 MB, Params: 1,514,377 (5.777 MB), Total: 5.89 MB, FLOPs: 160,863,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1682 finished in 0m06s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.115 MB, Params: 1,513,709 (5.774 MB), Total: 5.89 MB, FLOPs: 159,812,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1682 finished in 0m06s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 1,510,071 (5.760 MB), Total: 5.88 MB, FLOPs: 159,747,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1682 finished in 0m06s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 1,506,433 (5.747 MB), Total: 5.86 MB, FLOPs: 159,681,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1682 finished in 0m06s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 1,502,795 (5.733 MB), Total: 5.85 MB, FLOPs: 159,616,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1682 finished in 0m06s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 1,499,157 (5.719 MB), Total: 5.83 MB, FLOPs: 159,550,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1682 finished in 0m06s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 227)]\n",
      "Input: 0.115 MB, Params: 1,495,519 (5.705 MB), Total: 5.82 MB, FLOPs: 159,485,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1682 finished in 0m06s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 120)]\n",
      "Input: 0.115 MB, Params: 1,491,692 (5.690 MB), Total: 5.81 MB, FLOPs: 159,310,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1682 finished in 0m06s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 1,488,063 (5.677 MB), Total: 5.79 MB, FLOPs: 159,245,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1682 finished in 0m06s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 1,486,666 (5.671 MB), Total: 5.79 MB, FLOPs: 158,728,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1682 finished in 0m06s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.115 MB, Params: 1,485,503 (5.667 MB), Total: 5.78 MB, FLOPs: 157,819,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1682 finished in 0m06s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.115 MB, Params: 1,484,340 (5.662 MB), Total: 5.78 MB, FLOPs: 156,909,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1682 finished in 0m06s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 1,481,987 (5.653 MB), Total: 5.77 MB, FLOPs: 156,866,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1682 finished in 0m06s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 1,478,169 (5.639 MB), Total: 5.75 MB, FLOPs: 156,692,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1682 finished in 0m06s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 1,474,558 (5.625 MB), Total: 5.74 MB, FLOPs: 156,627,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1682 finished in 0m06s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 154)]\n",
      "Input: 0.115 MB, Params: 1,470,947 (5.611 MB), Total: 5.73 MB, FLOPs: 156,562,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1682 finished in 0m06s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 141)]\n",
      "Input: 0.115 MB, Params: 1,468,578 (5.602 MB), Total: 5.72 MB, FLOPs: 156,349,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1682 finished in 0m06s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.115 MB, Params: 1,466,243 (5.593 MB), Total: 5.71 MB, FLOPs: 156,307,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1682 finished in 0m06s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 1,462,641 (5.580 MB), Total: 5.69 MB, FLOPs: 156,242,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1682 finished in 0m06s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 64)]\n",
      "Input: 0.115 MB, Params: 1,461,262 (5.574 MB), Total: 5.69 MB, FLOPs: 155,732,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1682 finished in 0m06s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 40)]\n",
      "Input: 0.115 MB, Params: 1,459,046 (5.566 MB), Total: 5.68 MB, FLOPs: 155,321,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1682 finished in 0m06s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 1,455,264 (5.551 MB), Total: 5.67 MB, FLOPs: 155,147,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1682 finished in 0m06s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 1,452,938 (5.543 MB), Total: 5.66 MB, FLOPs: 155,106,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1682 finished in 0m06s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 156)]\n",
      "Input: 0.115 MB, Params: 1,450,587 (5.534 MB), Total: 5.65 MB, FLOPs: 154,894,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1682 finished in 0m06s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 1,448,236 (5.525 MB), Total: 5.64 MB, FLOPs: 154,683,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1682 finished in 0m06s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.115 MB, Params: 1,445,910 (5.516 MB), Total: 5.63 MB, FLOPs: 154,641,233\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1682 finished in 0m06s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 1,442,146 (5.501 MB), Total: 5.62 MB, FLOPs: 154,469,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1682 finished in 0m06s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.115 MB, Params: 1,439,804 (5.492 MB), Total: 5.61 MB, FLOPs: 154,258,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1682 finished in 0m06s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 244)]\n",
      "Input: 0.115 MB, Params: 1,436,238 (5.479 MB), Total: 5.59 MB, FLOPs: 154,194,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1682 finished in 0m06s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 1,433,921 (5.470 MB), Total: 5.59 MB, FLOPs: 154,153,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1682 finished in 0m06s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 82)]\n",
      "Input: 0.115 MB, Params: 1,431,732 (5.462 MB), Total: 5.58 MB, FLOPs: 153,743,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1682 finished in 0m06s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 56)]\n",
      "Input: 0.115 MB, Params: 1,429,543 (5.453 MB), Total: 5.57 MB, FLOPs: 153,334,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1682 finished in 0m06s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 19)]\n",
      "Input: 0.115 MB, Params: 1,429,136 (5.452 MB), Total: 5.57 MB, FLOPs: 152,639,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1682 finished in 0m06s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 1,426,812 (5.443 MB), Total: 5.56 MB, FLOPs: 152,430,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1682 finished in 0m06s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 1,423,255 (5.429 MB), Total: 5.54 MB, FLOPs: 152,366,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1682 finished in 0m06s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 1,419,698 (5.416 MB), Total: 5.53 MB, FLOPs: 152,302,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1682 finished in 0m06s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 1,417,518 (5.407 MB), Total: 5.52 MB, FLOPs: 151,894,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1682 finished in 0m06s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.115 MB, Params: 1,413,961 (5.394 MB), Total: 5.51 MB, FLOPs: 151,830,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1682 finished in 0m06s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.115 MB, Params: 1,411,646 (5.385 MB), Total: 5.50 MB, FLOPs: 151,621,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1682 finished in 0m06s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 1,409,356 (5.376 MB), Total: 5.49 MB, FLOPs: 151,580,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1682 finished in 0m06s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 1,407,066 (5.368 MB), Total: 5.48 MB, FLOPs: 151,539,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1682 finished in 0m06s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 1,403,527 (5.354 MB), Total: 5.47 MB, FLOPs: 151,475,881\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1682 finished in 0m06s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.115 MB, Params: 1,401,246 (5.345 MB), Total: 5.46 MB, FLOPs: 151,434,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1682 finished in 0m06s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 1,398,965 (5.337 MB), Total: 5.45 MB, FLOPs: 151,393,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1682 finished in 0m06s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.115 MB, Params: 1,398,324 (5.334 MB), Total: 5.45 MB, FLOPs: 150,385,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1682 finished in 0m06s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 40)]\n",
      "Input: 0.115 MB, Params: 1,396,153 (5.326 MB), Total: 5.44 MB, FLOPs: 149,978,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1682 finished in 0m06s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 1,393,872 (5.317 MB), Total: 5.43 MB, FLOPs: 149,937,177\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1682 finished in 0m06s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.115 MB, Params: 1,391,701 (5.309 MB), Total: 5.42 MB, FLOPs: 149,529,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1682 finished in 0m06s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 1,390,376 (5.304 MB), Total: 5.42 MB, FLOPs: 149,039,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1682 finished in 0m06s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 1,386,864 (5.290 MB), Total: 5.41 MB, FLOPs: 148,976,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1682 finished in 0m06s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 1,384,592 (5.282 MB), Total: 5.40 MB, FLOPs: 148,935,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1682 finished in 0m06s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 1,382,320 (5.273 MB), Total: 5.39 MB, FLOPs: 148,894,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1682 finished in 0m06s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 86)]\n",
      "Input: 0.115 MB, Params: 1,380,158 (5.265 MB), Total: 5.38 MB, FLOPs: 148,490,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1682 finished in 0m06s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 145)]\n",
      "Input: 0.115 MB, Params: 1,377,870 (5.256 MB), Total: 5.37 MB, FLOPs: 148,284,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1682 finished in 0m06s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 1,374,196 (5.242 MB), Total: 5.36 MB, FLOPs: 148,117,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1682 finished in 0m06s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 1,370,711 (5.229 MB), Total: 5.34 MB, FLOPs: 148,054,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1682 finished in 0m06s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.115 MB, Params: 1,368,558 (5.221 MB), Total: 5.34 MB, FLOPs: 147,651,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1682 finished in 0m06s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 1,366,295 (5.212 MB), Total: 5.33 MB, FLOPs: 147,610,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1682 finished in 0m06s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,364,032 (5.203 MB), Total: 5.32 MB, FLOPs: 147,569,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1682 finished in 0m06s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 1,360,565 (5.190 MB), Total: 5.31 MB, FLOPs: 147,507,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1682 finished in 0m06s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.115 MB, Params: 1,358,295 (5.181 MB), Total: 5.30 MB, FLOPs: 147,303,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1682 finished in 0m06s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 1,354,648 (5.168 MB), Total: 5.28 MB, FLOPs: 147,136,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1682 finished in 0m06s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.115 MB, Params: 1,352,394 (5.159 MB), Total: 5.27 MB, FLOPs: 147,096,329\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1682 finished in 0m06s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.115 MB, Params: 1,351,087 (5.154 MB), Total: 5.27 MB, FLOPs: 146,613,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1682 finished in 0m06s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.115 MB, Params: 1,349,960 (5.150 MB), Total: 5.26 MB, FLOPs: 145,727,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1682 finished in 0m06s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 1,347,706 (5.141 MB), Total: 5.26 MB, FLOPs: 145,686,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1682 finished in 0m06s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 1,344,266 (5.128 MB), Total: 5.24 MB, FLOPs: 145,625,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1682 finished in 0m06s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.115 MB, Params: 1,342,021 (5.119 MB), Total: 5.23 MB, FLOPs: 145,584,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1682 finished in 0m06s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 1,338,383 (5.106 MB), Total: 5.22 MB, FLOPs: 145,418,595\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1682 finished in 0m06s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 69)]\n",
      "Input: 0.115 MB, Params: 1,337,085 (5.101 MB), Total: 5.22 MB, FLOPs: 144,938,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1682 finished in 0m06s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 66)]\n",
      "Input: 0.115 MB, Params: 1,335,787 (5.096 MB), Total: 5.21 MB, FLOPs: 144,458,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1682 finished in 0m06s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 1,332,365 (5.083 MB), Total: 5.20 MB, FLOPs: 144,397,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1682 finished in 0m06s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,330,129 (5.074 MB), Total: 5.19 MB, FLOPs: 144,357,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1682 finished in 0m06s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 149)]\n",
      "Input: 0.115 MB, Params: 1,326,716 (5.061 MB), Total: 5.18 MB, FLOPs: 144,295,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1682 finished in 0m06s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 1,323,303 (5.048 MB), Total: 5.16 MB, FLOPs: 144,234,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1682 finished in 0m06s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 1,321,051 (5.039 MB), Total: 5.15 MB, FLOPs: 144,031,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1682 finished in 0m06s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 1,317,449 (5.026 MB), Total: 5.14 MB, FLOPs: 143,866,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1682 finished in 0m06s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.115 MB, Params: 1,315,341 (5.018 MB), Total: 5.13 MB, FLOPs: 143,474,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1682 finished in 0m06s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.115 MB, Params: 1,314,232 (5.013 MB), Total: 5.13 MB, FLOPs: 142,595,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1682 finished in 0m06s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.115 MB, Params: 1,312,124 (5.005 MB), Total: 5.12 MB, FLOPs: 142,204,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1682 finished in 0m06s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 1,310,853 (5.001 MB), Total: 5.12 MB, FLOPs: 141,734,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1682 finished in 0m06s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 204)]\n",
      "Input: 0.115 MB, Params: 1,307,449 (4.988 MB), Total: 5.10 MB, FLOPs: 141,672,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1682 finished in 0m06s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 1,305,240 (4.979 MB), Total: 5.09 MB, FLOPs: 141,633,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1682 finished in 0m06s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 1,303,031 (4.971 MB), Total: 5.09 MB, FLOPs: 141,593,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1682 finished in 0m06s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 1,300,806 (4.962 MB), Total: 5.08 MB, FLOPs: 141,393,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1682 finished in 0m06s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 1,298,597 (4.954 MB), Total: 5.07 MB, FLOPs: 141,353,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1682 finished in 0m06s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 1,295,013 (4.940 MB), Total: 5.06 MB, FLOPs: 141,189,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1682 finished in 0m06s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 52)]\n",
      "Input: 0.115 MB, Params: 1,291,429 (4.926 MB), Total: 5.04 MB, FLOPs: 141,026,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1682 finished in 0m06s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 1,289,220 (4.918 MB), Total: 5.03 MB, FLOPs: 140,986,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1682 finished in 0m06s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.115 MB, Params: 1,285,870 (4.905 MB), Total: 5.02 MB, FLOPs: 140,926,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1682 finished in 0m06s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.115 MB, Params: 1,283,670 (4.897 MB), Total: 5.01 MB, FLOPs: 140,886,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1682 finished in 0m06s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 2)]\n",
      "Input: 0.115 MB, Params: 1,282,399 (4.892 MB), Total: 5.01 MB, FLOPs: 140,416,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1682 finished in 0m06s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 1,280,192 (4.884 MB), Total: 5.00 MB, FLOPs: 140,218,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1682 finished in 0m06s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.115 MB, Params: 1,276,851 (4.871 MB), Total: 4.99 MB, FLOPs: 140,157,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1682 finished in 0m06s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.115 MB, Params: 1,273,294 (4.857 MB), Total: 4.97 MB, FLOPs: 139,995,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1682 finished in 0m06s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 1,271,103 (4.849 MB), Total: 4.96 MB, FLOPs: 139,955,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1682 finished in 0m06s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.115 MB, Params: 1,268,912 (4.841 MB), Total: 4.96 MB, FLOPs: 139,916,441\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1682 finished in 0m06s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 1,265,598 (4.828 MB), Total: 4.94 MB, FLOPs: 139,856,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1682 finished in 0m06s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 1,263,400 (4.819 MB), Total: 4.93 MB, FLOPs: 139,659,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1682 finished in 0m06s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,261,218 (4.811 MB), Total: 4.93 MB, FLOPs: 139,619,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1682 finished in 0m06s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.115 MB, Params: 1,257,913 (4.799 MB), Total: 4.91 MB, FLOPs: 139,560,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1682 finished in 0m06s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 1,255,740 (4.790 MB), Total: 4.91 MB, FLOPs: 139,521,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1682 finished in 0m06s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 53)]\n",
      "Input: 0.115 MB, Params: 1,253,677 (4.782 MB), Total: 4.90 MB, FLOPs: 139,138,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1682 finished in 0m06s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.115 MB, Params: 1,252,586 (4.778 MB), Total: 4.89 MB, FLOPs: 138,266,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1682 finished in 0m06s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 1,249,290 (4.766 MB), Total: 4.88 MB, FLOPs: 138,206,865\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1682 finished in 0m06s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.115 MB, Params: 1,247,227 (4.758 MB), Total: 4.87 MB, FLOPs: 137,824,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1682 finished in 0m06s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 76)]\n",
      "Input: 0.115 MB, Params: 1,245,983 (4.753 MB), Total: 4.87 MB, FLOPs: 137,364,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1682 finished in 0m06s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 1,242,462 (4.740 MB), Total: 4.85 MB, FLOPs: 137,202,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1682 finished in 0m06s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 122)]\n",
      "Input: 0.115 MB, Params: 1,238,941 (4.726 MB), Total: 4.84 MB, FLOPs: 137,041,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1682 finished in 0m06s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.115 MB, Params: 1,235,663 (4.714 MB), Total: 4.83 MB, FLOPs: 136,982,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1682 finished in 0m06s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 1,232,385 (4.701 MB), Total: 4.82 MB, FLOPs: 136,923,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1682 finished in 0m06s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 123)]\n",
      "Input: 0.115 MB, Params: 1,228,882 (4.688 MB), Total: 4.80 MB, FLOPs: 136,762,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1682 finished in 0m06s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.115 MB, Params: 1,228,484 (4.686 MB), Total: 4.80 MB, FLOPs: 136,081,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1682 finished in 0m06s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 110)]\n",
      "Input: 0.115 MB, Params: 1,226,331 (4.678 MB), Total: 4.79 MB, FLOPs: 135,888,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1682 finished in 0m06s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.115 MB, Params: 1,224,286 (4.670 MB), Total: 4.79 MB, FLOPs: 135,509,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1682 finished in 0m06s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.115 MB, Params: 1,222,142 (4.662 MB), Total: 4.78 MB, FLOPs: 135,316,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1682 finished in 0m06s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 1,218,873 (4.650 MB), Total: 4.76 MB, FLOPs: 135,257,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1682 finished in 0m06s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 1,216,736 (4.641 MB), Total: 4.76 MB, FLOPs: 135,219,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1682 finished in 0m06s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 1,213,476 (4.629 MB), Total: 4.74 MB, FLOPs: 135,160,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1682 finished in 0m06s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 1,211,440 (4.621 MB), Total: 4.74 MB, FLOPs: 134,782,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1682 finished in 0m06s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.115 MB, Params: 1,209,312 (4.613 MB), Total: 4.73 MB, FLOPs: 134,744,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1682 finished in 0m06s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.115 MB, Params: 1,207,177 (4.605 MB), Total: 4.72 MB, FLOPs: 134,552,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1682 finished in 0m06s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 1,205,042 (4.597 MB), Total: 4.71 MB, FLOPs: 134,360,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1682 finished in 0m06s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.115 MB, Params: 1,201,593 (4.584 MB), Total: 4.70 MB, FLOPs: 134,202,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1682 finished in 0m06s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 1,199,467 (4.576 MB), Total: 4.69 MB, FLOPs: 134,011,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1682 finished in 0m06s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 1,196,225 (4.563 MB), Total: 4.68 MB, FLOPs: 133,953,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1682 finished in 0m06s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 130)]\n",
      "Input: 0.115 MB, Params: 1,194,099 (4.555 MB), Total: 4.67 MB, FLOPs: 133,762,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1682 finished in 0m06s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 1,190,857 (4.543 MB), Total: 4.66 MB, FLOPs: 133,703,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1682 finished in 0m06s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 141)]\n",
      "Input: 0.115 MB, Params: 1,188,731 (4.535 MB), Total: 4.65 MB, FLOPs: 133,512,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1682 finished in 0m06s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 1,185,489 (4.522 MB), Total: 4.64 MB, FLOPs: 133,454,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1682 finished in 0m06s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.115 MB, Params: 1,183,363 (4.514 MB), Total: 4.63 MB, FLOPs: 133,262,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1682 finished in 0m06s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 1,180,121 (4.502 MB), Total: 4.62 MB, FLOPs: 133,204,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1682 finished in 0m06s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 1,178,029 (4.494 MB), Total: 4.61 MB, FLOPs: 133,166,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1682 finished in 0m06s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 1,175,937 (4.486 MB), Total: 4.60 MB, FLOPs: 133,129,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1682 finished in 0m06s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 204)]\n",
      "Input: 0.115 MB, Params: 1,172,713 (4.474 MB), Total: 4.59 MB, FLOPs: 133,071,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1682 finished in 0m06s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 1,170,587 (4.465 MB), Total: 4.58 MB, FLOPs: 132,880,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1682 finished in 0m06s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 1,167,363 (4.453 MB), Total: 4.57 MB, FLOPs: 132,822,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1682 finished in 0m06s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 1,164,139 (4.441 MB), Total: 4.56 MB, FLOPs: 132,764,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1682 finished in 0m06s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 1,160,915 (4.429 MB), Total: 4.54 MB, FLOPs: 132,706,006\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1682 finished in 0m06s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 1,158,789 (4.420 MB), Total: 4.54 MB, FLOPs: 132,514,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1682 finished in 0m06s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.115 MB, Params: 1,156,733 (4.413 MB), Total: 4.53 MB, FLOPs: 132,477,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1682 finished in 0m06s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 33)]\n",
      "Input: 0.115 MB, Params: 1,156,691 (4.412 MB), Total: 4.53 MB, FLOPs: 132,130,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1682 finished in 0m06s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 1,154,635 (4.405 MB), Total: 4.52 MB, FLOPs: 132,093,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1682 finished in 0m06s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 1,152,579 (4.397 MB), Total: 4.51 MB, FLOPs: 132,056,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1682 finished in 0m06s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 1,149,256 (4.384 MB), Total: 4.50 MB, FLOPs: 131,905,091\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1682 finished in 0m06s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 156)]\n",
      "Input: 0.115 MB, Params: 1,146,068 (4.372 MB), Total: 4.49 MB, FLOPs: 131,847,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1682 finished in 0m06s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 1,142,880 (4.360 MB), Total: 4.48 MB, FLOPs: 131,790,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1682 finished in 0m06s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 1,140,842 (4.352 MB), Total: 4.47 MB, FLOPs: 131,753,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1682 finished in 0m06s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 1,137,663 (4.340 MB), Total: 4.46 MB, FLOPs: 131,696,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1682 finished in 0m06s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.115 MB, Params: 1,135,546 (4.332 MB), Total: 4.45 MB, FLOPs: 131,506,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1682 finished in 0m06s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 1,133,429 (4.324 MB), Total: 4.44 MB, FLOPs: 131,315,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1682 finished in 0m06s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 26)]\n",
      "Input: 0.115 MB, Params: 1,131,312 (4.316 MB), Total: 4.43 MB, FLOPs: 131,125,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1682 finished in 0m06s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 1,128,043 (4.303 MB), Total: 4.42 MB, FLOPs: 130,976,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1682 finished in 0m06s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.115 MB, Params: 1,126,014 (4.295 MB), Total: 4.41 MB, FLOPs: 130,940,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1682 finished in 0m06s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 1,123,985 (4.288 MB), Total: 4.40 MB, FLOPs: 130,903,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1682 finished in 0m06s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 1,123,943 (4.288 MB), Total: 4.40 MB, FLOPs: 128,598,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1682 finished in 0m06s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 7)]\n",
      "Input: 0.115 MB, Params: 1,123,901 (4.287 MB), Total: 4.40 MB, FLOPs: 128,251,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1682 finished in 0m06s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.115 MB, Params: 1,121,872 (4.280 MB), Total: 4.39 MB, FLOPs: 128,215,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1682 finished in 0m06s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 15)]\n",
      "Input: 0.115 MB, Params: 1,121,474 (4.278 MB), Total: 4.39 MB, FLOPs: 127,568,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1682 finished in 0m06s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 1,119,445 (4.270 MB), Total: 4.39 MB, FLOPs: 127,531,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1682 finished in 0m06s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.115 MB, Params: 1,116,311 (4.258 MB), Total: 4.37 MB, FLOPs: 127,475,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1682 finished in 0m06s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 1,114,203 (4.250 MB), Total: 4.37 MB, FLOPs: 127,285,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1682 finished in 0m06s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 1,110,952 (4.238 MB), Total: 4.35 MB, FLOPs: 127,138,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1682 finished in 0m06s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 48)]\n",
      "Input: 0.115 MB, Params: 1,109,726 (4.233 MB), Total: 4.35 MB, FLOPs: 126,684,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1682 finished in 0m06s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 1,106,475 (4.221 MB), Total: 4.34 MB, FLOPs: 126,537,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1682 finished in 0m06s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.115 MB, Params: 1,104,385 (4.213 MB), Total: 4.33 MB, FLOPs: 126,349,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1682 finished in 0m06s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 1,102,365 (4.205 MB), Total: 4.32 MB, FLOPs: 126,313,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1682 finished in 0m06s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 1,099,258 (4.193 MB), Total: 4.31 MB, FLOPs: 126,257,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1682 finished in 0m06s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 1,097,168 (4.185 MB), Total: 4.30 MB, FLOPs: 126,069,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1682 finished in 0m06s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 1,097,126 (4.185 MB), Total: 4.30 MB, FLOPs: 115,255,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 1,095,036 (4.177 MB), Total: 4.29 MB, FLOPs: 115,104,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 1,093,025 (4.170 MB), Total: 4.28 MB, FLOPs: 115,068,488\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.115 MB, Params: 1,091,133 (4.162 MB), Total: 4.28 MB, FLOPs: 114,753,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 54)]\n",
      "Input: 0.115 MB, Params: 1,089,052 (4.154 MB), Total: 4.27 MB, FLOPs: 114,603,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.115 MB, Params: 1,087,169 (4.147 MB), Total: 4.26 MB, FLOPs: 114,288,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 1,085,158 (4.140 MB), Total: 4.25 MB, FLOPs: 114,252,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 1,083,275 (4.132 MB), Total: 4.25 MB, FLOPs: 113,938,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 76)]\n",
      "Input: 0.115 MB, Params: 1,081,212 (4.124 MB), Total: 4.24 MB, FLOPs: 113,789,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 1,078,123 (4.113 MB), Total: 4.23 MB, FLOPs: 113,734,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.115 MB, Params: 1,076,060 (4.105 MB), Total: 4.22 MB, FLOPs: 113,585,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 112)]\n",
      "Input: 0.115 MB, Params: 1,072,881 (4.093 MB), Total: 4.21 MB, FLOPs: 113,464,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.115 MB, Params: 1,070,879 (4.085 MB), Total: 4.20 MB, FLOPs: 113,428,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 1,067,700 (4.073 MB), Total: 4.19 MB, FLOPs: 113,307,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 1,065,655 (4.065 MB), Total: 4.18 MB, FLOPs: 113,160,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.115 MB, Params: 1,063,610 (4.057 MB), Total: 4.17 MB, FLOPs: 113,013,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 63)]\n",
      "Input: 0.115 MB, Params: 1,062,411 (4.053 MB), Total: 4.17 MB, FLOPs: 112,614,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 1,060,409 (4.045 MB), Total: 4.16 MB, FLOPs: 112,578,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 1,058,364 (4.037 MB), Total: 4.15 MB, FLOPs: 112,431,227\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 1,055,212 (4.025 MB), Total: 4.14 MB, FLOPs: 112,312,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 1,053,210 (4.018 MB), Total: 4.13 MB, FLOPs: 112,276,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 1,052,146 (4.014 MB), Total: 4.13 MB, FLOPs: 111,497,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 208)]\n",
      "Input: 0.115 MB, Params: 1,049,111 (4.002 MB), Total: 4.12 MB, FLOPs: 111,442,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 1,047,118 (3.994 MB), Total: 4.11 MB, FLOPs: 111,406,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.115 MB, Params: 1,046,054 (3.990 MB), Total: 4.11 MB, FLOPs: 110,627,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 1,044,873 (3.986 MB), Total: 4.10 MB, FLOPs: 110,234,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 12)]\n",
      "Input: 0.115 MB, Params: 1,044,831 (3.986 MB), Total: 4.10 MB, FLOPs: 109,888,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 1,041,805 (3.974 MB), Total: 4.09 MB, FLOPs: 109,834,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 135)]\n",
      "Input: 0.115 MB, Params: 1,038,671 (3.962 MB), Total: 4.08 MB, FLOPs: 109,715,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 1,035,654 (3.951 MB), Total: 4.07 MB, FLOPs: 109,661,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 1,032,637 (3.939 MB), Total: 4.05 MB, FLOPs: 109,607,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 4)]\n",
      "Input: 0.115 MB, Params: 1,032,059 (3.937 MB), Total: 4.05 MB, FLOPs: 108,784,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 1,030,093 (3.929 MB), Total: 4.04 MB, FLOPs: 108,749,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 1,028,066 (3.922 MB), Total: 4.04 MB, FLOPs: 108,603,637\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 1,026,100 (3.914 MB), Total: 4.03 MB, FLOPs: 108,568,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 1,024,919 (3.910 MB), Total: 4.03 MB, FLOPs: 108,175,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.115 MB, Params: 1,021,920 (3.898 MB), Total: 4.01 MB, FLOPs: 108,121,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 1)]\n",
      "Input: 0.115 MB, Params: 1,021,342 (3.896 MB), Total: 4.01 MB, FLOPs: 107,299,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 1,020,314 (3.892 MB), Total: 4.01 MB, FLOPs: 106,551,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.115 MB, Params: 1,017,315 (3.881 MB), Total: 4.00 MB, FLOPs: 106,497,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 1,014,316 (3.869 MB), Total: 3.98 MB, FLOPs: 106,443,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 1,012,377 (3.862 MB), Total: 3.98 MB, FLOPs: 106,408,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 1,010,350 (3.854 MB), Total: 3.97 MB, FLOPs: 106,263,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 1,008,411 (3.847 MB), Total: 3.96 MB, FLOPs: 106,228,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.115 MB, Params: 1,007,842 (3.845 MB), Total: 3.96 MB, FLOPs: 105,418,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.115 MB, Params: 1,005,815 (3.837 MB), Total: 3.95 MB, FLOPs: 105,272,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 1,003,876 (3.829 MB), Total: 3.94 MB, FLOPs: 105,238,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 1,001,937 (3.822 MB), Total: 3.94 MB, FLOPs: 105,203,227\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 1,000,765 (3.818 MB), Total: 3.93 MB, FLOPs: 104,813,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 71)]\n",
      "Input: 0.115 MB, Params: 998,990 (3.811 MB), Total: 3.93 MB, FLOPs: 104,515,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 40)]\n",
      "Input: 0.115 MB, Params: 995,928 (3.799 MB), Total: 3.91 MB, FLOPs: 104,399,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 995,886 (3.799 MB), Total: 3.91 MB, FLOPs: 102,340,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 992,932 (3.788 MB), Total: 3.90 MB, FLOPs: 102,287,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.115 MB, Params: 989,879 (3.776 MB), Total: 3.89 MB, FLOPs: 102,172,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 987,949 (3.769 MB), Total: 3.88 MB, FLOPs: 102,137,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.115 MB, Params: 985,013 (3.758 MB), Total: 3.87 MB, FLOPs: 102,084,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 982,077 (3.746 MB), Total: 3.86 MB, FLOPs: 102,031,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 980,302 (3.740 MB), Total: 3.85 MB, FLOPs: 101,734,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 978,311 (3.732 MB), Total: 3.85 MB, FLOPs: 101,590,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 976,399 (3.725 MB), Total: 3.84 MB, FLOPs: 101,556,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.115 MB, Params: 973,373 (3.713 MB), Total: 3.83 MB, FLOPs: 101,441,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 4)]\n",
      "Input: 0.115 MB, Params: 973,331 (3.713 MB), Total: 3.83 MB, FLOPs: 101,095,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 971,419 (3.706 MB), Total: 3.82 MB, FLOPs: 101,061,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.115 MB, Params: 969,653 (3.699 MB), Total: 3.81 MB, FLOPs: 100,764,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.115 MB, Params: 966,744 (3.688 MB), Total: 3.80 MB, FLOPs: 100,712,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.115 MB, Params: 965,734 (3.684 MB), Total: 3.80 MB, FLOPs: 100,007,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 130)]\n",
      "Input: 0.115 MB, Params: 962,717 (3.672 MB), Total: 3.79 MB, FLOPs: 99,893,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 126)]\n",
      "Input: 0.115 MB, Params: 959,700 (3.661 MB), Total: 3.78 MB, FLOPs: 99,778,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 956,809 (3.650 MB), Total: 3.77 MB, FLOPs: 99,726,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 953,801 (3.638 MB), Total: 3.75 MB, FLOPs: 99,611,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 951,907 (3.631 MB), Total: 3.75 MB, FLOPs: 99,577,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 948,899 (3.620 MB), Total: 3.74 MB, FLOPs: 99,463,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 946,962 (3.612 MB), Total: 3.73 MB, FLOPs: 99,324,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 945,952 (3.609 MB), Total: 3.72 MB, FLOPs: 98,619,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.115 MB, Params: 943,088 (3.598 MB), Total: 3.71 MB, FLOPs: 98,568,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 940,224 (3.587 MB), Total: 3.70 MB, FLOPs: 98,516,483\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.115 MB, Params: 939,673 (3.585 MB), Total: 3.70 MB, FLOPs: 97,773,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 119)]\n",
      "Input: 0.115 MB, Params: 937,736 (3.577 MB), Total: 3.69 MB, FLOPs: 97,634,591\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 935,860 (3.570 MB), Total: 3.69 MB, FLOPs: 97,600,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.115 MB, Params: 933,984 (3.563 MB), Total: 3.68 MB, FLOPs: 97,567,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 931,138 (3.552 MB), Total: 3.67 MB, FLOPs: 97,515,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 37)]\n",
      "Input: 0.115 MB, Params: 930,137 (3.548 MB), Total: 3.66 MB, FLOPs: 96,823,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.115 MB, Params: 927,291 (3.537 MB), Total: 3.65 MB, FLOPs: 96,772,379\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 925,433 (3.530 MB), Total: 3.65 MB, FLOPs: 96,738,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 922,479 (3.519 MB), Total: 3.63 MB, FLOPs: 96,626,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 919,651 (3.508 MB), Total: 3.62 MB, FLOPs: 96,575,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 917,802 (3.501 MB), Total: 3.62 MB, FLOPs: 96,542,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 915,953 (3.494 MB), Total: 3.61 MB, FLOPs: 96,509,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 914,025 (3.487 MB), Total: 3.60 MB, FLOPs: 96,370,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 182)]\n",
      "Input: 0.115 MB, Params: 911,215 (3.476 MB), Total: 3.59 MB, FLOPs: 96,319,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 69)]\n",
      "Input: 0.115 MB, Params: 910,097 (3.472 MB), Total: 3.59 MB, FLOPs: 95,947,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 907,170 (3.461 MB), Total: 3.58 MB, FLOPs: 95,836,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 907,128 (3.460 MB), Total: 3.58 MB, FLOPs: 90,955,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 905,288 (3.453 MB), Total: 3.57 MB, FLOPs: 90,922,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 902,496 (3.443 MB), Total: 3.56 MB, FLOPs: 90,872,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 899,704 (3.432 MB), Total: 3.55 MB, FLOPs: 90,821,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 45)]\n",
      "Input: 0.115 MB, Params: 898,586 (3.428 MB), Total: 3.54 MB, FLOPs: 90,491,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 896,865 (3.421 MB), Total: 3.54 MB, FLOPs: 90,225,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 895,043 (3.414 MB), Total: 3.53 MB, FLOPs: 90,193,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 893,221 (3.407 MB), Total: 3.52 MB, FLOPs: 90,160,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 890,447 (3.397 MB), Total: 3.51 MB, FLOPs: 90,110,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 887,673 (3.386 MB), Total: 3.50 MB, FLOPs: 90,060,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 884,899 (3.376 MB), Total: 3.49 MB, FLOPs: 90,010,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 129)]\n",
      "Input: 0.115 MB, Params: 882,017 (3.365 MB), Total: 3.48 MB, FLOPs: 89,899,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 7)]\n",
      "Input: 0.115 MB, Params: 881,475 (3.363 MB), Total: 3.48 MB, FLOPs: 89,210,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.115 MB, Params: 878,710 (3.352 MB), Total: 3.47 MB, FLOPs: 89,160,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 875,945 (3.341 MB), Total: 3.46 MB, FLOPs: 89,110,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 874,836 (3.337 MB), Total: 3.45 MB, FLOPs: 88,782,544\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 873,059 (3.330 MB), Total: 3.45 MB, FLOPs: 88,750,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.115 MB, Params: 870,195 (3.320 MB), Total: 3.43 MB, FLOPs: 88,640,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 867,331 (3.309 MB), Total: 3.42 MB, FLOPs: 88,529,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 49)]\n",
      "Input: 0.115 MB, Params: 866,222 (3.304 MB), Total: 3.42 MB, FLOPs: 88,201,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 863,484 (3.294 MB), Total: 3.41 MB, FLOPs: 88,152,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 861,716 (3.287 MB), Total: 3.40 MB, FLOPs: 88,120,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 859,833 (3.280 MB), Total: 3.40 MB, FLOPs: 87,985,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 858,065 (3.273 MB), Total: 3.39 MB, FLOPs: 87,953,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 855,219 (3.262 MB), Total: 3.38 MB, FLOPs: 87,843,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 852,373 (3.252 MB), Total: 3.37 MB, FLOPs: 87,734,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 849,671 (3.241 MB), Total: 3.36 MB, FLOPs: 87,685,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 846,969 (3.231 MB), Total: 3.35 MB, FLOPs: 87,636,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.115 MB, Params: 845,860 (3.227 MB), Total: 3.34 MB, FLOPs: 87,308,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 843,158 (3.216 MB), Total: 3.33 MB, FLOPs: 87,260,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 122)]\n",
      "Input: 0.115 MB, Params: 840,339 (3.206 MB), Total: 3.32 MB, FLOPs: 87,151,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.115 MB, Params: 837,520 (3.195 MB), Total: 3.31 MB, FLOPs: 87,041,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 836,411 (3.191 MB), Total: 3.31 MB, FLOPs: 86,713,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.115 MB, Params: 834,564 (3.184 MB), Total: 3.30 MB, FLOPs: 86,580,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 832,823 (3.177 MB), Total: 3.29 MB, FLOPs: 86,549,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 831,082 (3.170 MB), Total: 3.29 MB, FLOPs: 86,518,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.115 MB, Params: 829,341 (3.164 MB), Total: 3.28 MB, FLOPs: 86,487,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 826,684 (3.154 MB), Total: 3.27 MB, FLOPs: 86,439,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 97)]\n",
      "Input: 0.115 MB, Params: 823,883 (3.143 MB), Total: 3.26 MB, FLOPs: 86,330,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 137)]\n",
      "Input: 0.115 MB, Params: 822,151 (3.136 MB), Total: 3.25 MB, FLOPs: 86,299,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 819,350 (3.126 MB), Total: 3.24 MB, FLOPs: 86,191,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.115 MB, Params: 817,521 (3.119 MB), Total: 3.23 MB, FLOPs: 86,059,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.115 MB, Params: 814,729 (3.108 MB), Total: 3.22 MB, FLOPs: 85,952,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 812,108 (3.098 MB), Total: 3.21 MB, FLOPs: 85,904,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 809,487 (3.088 MB), Total: 3.20 MB, FLOPs: 85,857,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 807,773 (3.081 MB), Total: 3.20 MB, FLOPs: 85,826,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 20)]\n",
      "Input: 0.115 MB, Params: 806,835 (3.078 MB), Total: 3.19 MB, FLOPs: 85,212,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 805,121 (3.071 MB), Total: 3.19 MB, FLOPs: 85,181,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 802,518 (3.061 MB), Total: 3.18 MB, FLOPs: 85,134,917\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 799,915 (3.051 MB), Total: 3.17 MB, FLOPs: 85,088,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 797,159 (3.041 MB), Total: 3.16 MB, FLOPs: 84,981,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.115 MB, Params: 795,348 (3.034 MB), Total: 3.15 MB, FLOPs: 84,850,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.115 MB, Params: 794,410 (3.030 MB), Total: 3.15 MB, FLOPs: 84,236,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 791,816 (3.021 MB), Total: 3.14 MB, FLOPs: 84,189,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 789,222 (3.011 MB), Total: 3.13 MB, FLOPs: 84,143,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 787,544 (3.004 MB), Total: 3.12 MB, FLOPs: 84,112,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 785,866 (2.998 MB), Total: 3.11 MB, FLOPs: 84,082,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 783,290 (2.988 MB), Total: 3.10 MB, FLOPs: 84,036,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.115 MB, Params: 782,937 (2.987 MB), Total: 3.10 MB, FLOPs: 83,542,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.955%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 30)]\n",
      "Input: 0.115 MB, Params: 781,846 (2.983 MB), Total: 3.10 MB, FLOPs: 83,219,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 779,126 (2.972 MB), Total: 3.09 MB, FLOPs: 83,113,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.115 MB, Params: 777,486 (2.966 MB), Total: 3.08 MB, FLOPs: 82,864,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 51)]\n",
      "Input: 0.115 MB, Params: 776,404 (2.962 MB), Total: 3.08 MB, FLOPs: 82,544,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 61)]\n",
      "Input: 0.115 MB, Params: 774,773 (2.956 MB), Total: 3.07 MB, FLOPs: 82,297,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 773,142 (2.949 MB), Total: 3.06 MB, FLOPs: 82,050,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 771,473 (2.943 MB), Total: 3.06 MB, FLOPs: 82,020,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 769,698 (2.936 MB), Total: 3.05 MB, FLOPs: 81,892,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 766,987 (2.926 MB), Total: 3.04 MB, FLOPs: 81,787,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 765,318 (2.919 MB), Total: 3.03 MB, FLOPs: 81,757,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 22)]\n",
      "Input: 0.115 MB, Params: 765,276 (2.919 MB), Total: 3.03 MB, FLOPs: 81,412,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.115 MB, Params: 763,654 (2.913 MB), Total: 3.03 MB, FLOPs: 81,166,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 762,599 (2.909 MB), Total: 3.02 MB, FLOPs: 80,854,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 760,842 (2.902 MB), Total: 3.02 MB, FLOPs: 80,728,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 758,140 (2.892 MB), Total: 3.01 MB, FLOPs: 80,623,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 756,471 (2.886 MB), Total: 3.00 MB, FLOPs: 80,593,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.115 MB, Params: 754,723 (2.879 MB), Total: 2.99 MB, FLOPs: 80,467,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.115 MB, Params: 753,812 (2.876 MB), Total: 2.99 MB, FLOPs: 79,861,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 751,290 (2.866 MB), Total: 2.98 MB, FLOPs: 79,816,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 748,768 (2.856 MB), Total: 2.97 MB, FLOPs: 79,770,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 746,246 (2.847 MB), Total: 2.96 MB, FLOPs: 79,725,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.115 MB, Params: 745,740 (2.845 MB), Total: 2.96 MB, FLOPs: 79,081,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 5)]\n",
      "Input: 0.115 MB, Params: 745,698 (2.845 MB), Total: 2.96 MB, FLOPs: 77,327,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 743,176 (2.835 MB), Total: 2.95 MB, FLOPs: 77,282,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.115 MB, Params: 740,654 (2.825 MB), Total: 2.94 MB, FLOPs: 77,236,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 738,132 (2.816 MB), Total: 2.93 MB, FLOPs: 77,191,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 735,610 (2.806 MB), Total: 2.92 MB, FLOPs: 77,145,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 733,088 (2.797 MB), Total: 2.91 MB, FLOPs: 77,100,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 731,340 (2.790 MB), Total: 2.91 MB, FLOPs: 76,974,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.115 MB, Params: 730,834 (2.788 MB), Total: 2.90 MB, FLOPs: 76,368,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.227%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 729,237 (2.782 MB), Total: 2.90 MB, FLOPs: 76,340,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.115 MB, Params: 726,625 (2.772 MB), Total: 2.89 MB, FLOPs: 76,238,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 725,579 (2.768 MB), Total: 2.88 MB, FLOPs: 75,928,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 84)]\n",
      "Input: 0.115 MB, Params: 722,967 (2.758 MB), Total: 2.87 MB, FLOPs: 75,826,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1184/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1184\n",
      "\n",
      "Iteration 1185 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 721,237 (2.751 MB), Total: 2.87 MB, FLOPs: 75,702,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1185/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1185\n",
      "\n",
      "Iteration 1186 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.115 MB, Params: 720,353 (2.748 MB), Total: 2.86 MB, FLOPs: 75,145,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1186/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1186\n",
      "\n",
      "Iteration 1187 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 717,858 (2.738 MB), Total: 2.85 MB, FLOPs: 75,100,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1187/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1187\n",
      "\n",
      "Iteration 1188 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 716,270 (2.732 MB), Total: 2.85 MB, FLOPs: 75,072,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1188/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1188\n",
      "\n",
      "Iteration 1189 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.115 MB, Params: 714,702 (2.726 MB), Total: 2.84 MB, FLOPs: 74,834,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1189/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1189\n",
      "\n",
      "Iteration 1190 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 9)]\n",
      "Input: 0.115 MB, Params: 712,108 (2.716 MB), Total: 2.83 MB, FLOPs: 74,732,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1190/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1190\n",
      "\n",
      "Iteration 1191 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.115 MB, Params: 709,514 (2.707 MB), Total: 2.82 MB, FLOPs: 74,631,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1191/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1191\n",
      "\n",
      "Iteration 1192 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 707,811 (2.700 MB), Total: 2.82 MB, FLOPs: 74,509,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1192/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1192\n",
      "\n",
      "Iteration 1193 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 705,343 (2.691 MB), Total: 2.81 MB, FLOPs: 74,464,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1193/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1193\n",
      "\n",
      "Iteration 1194 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 703,764 (2.685 MB), Total: 2.80 MB, FLOPs: 74,436,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1194/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1194\n",
      "\n",
      "Iteration 1195 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 702,061 (2.678 MB), Total: 2.79 MB, FLOPs: 74,313,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1195/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1195\n",
      "\n",
      "Iteration 1196 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 699,602 (2.669 MB), Total: 2.78 MB, FLOPs: 74,269,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1196/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1196\n",
      "\n",
      "Iteration 1197 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.115 MB, Params: 698,574 (2.665 MB), Total: 2.78 MB, FLOPs: 73,965,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1197/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1197\n",
      "\n",
      "Iteration 1198 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 697,004 (2.659 MB), Total: 2.77 MB, FLOPs: 73,937,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1198/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1198\n",
      "\n",
      "Iteration 1199 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 694,446 (2.649 MB), Total: 2.76 MB, FLOPs: 73,837,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1199/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1199\n",
      "\n",
      "Iteration 1200 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 70)]\n",
      "Input: 0.115 MB, Params: 692,752 (2.643 MB), Total: 2.76 MB, FLOPs: 73,715,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1200/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1200\n",
      "\n",
      "Iteration 1201 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 691,058 (2.636 MB), Total: 2.75 MB, FLOPs: 73,593,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1201/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1201\n",
      "\n",
      "Iteration 1202 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.115 MB, Params: 689,364 (2.630 MB), Total: 2.75 MB, FLOPs: 73,471,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1202/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1202\n",
      "\n",
      "Iteration 1203 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 686,923 (2.620 MB), Total: 2.74 MB, FLOPs: 73,428,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1203/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1203\n",
      "\n",
      "Iteration 1204 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 684,482 (2.611 MB), Total: 2.73 MB, FLOPs: 73,384,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1204/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1204\n",
      "\n",
      "Iteration 1205 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 8)]\n",
      "Input: 0.115 MB, Params: 683,607 (2.608 MB), Total: 2.72 MB, FLOPs: 72,830,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1205/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1205\n",
      "\n",
      "Iteration 1206 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 682,732 (2.604 MB), Total: 2.72 MB, FLOPs: 72,276,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1206/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1206\n",
      "\n",
      "Iteration 1207 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 681,180 (2.598 MB), Total: 2.71 MB, FLOPs: 72,248,865\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1207/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1207\n",
      "\n",
      "Iteration 1208 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 678,748 (2.589 MB), Total: 2.70 MB, FLOPs: 72,205,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1208/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1208\n",
      "\n",
      "Iteration 1209 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.115 MB, Params: 677,738 (2.585 MB), Total: 2.70 MB, FLOPs: 71,906,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1209/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1209\n",
      "\n",
      "Iteration 1210 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 676,195 (2.579 MB), Total: 2.69 MB, FLOPs: 71,878,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1210/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1210\n",
      "\n",
      "Iteration 1211 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 673,691 (2.570 MB), Total: 2.69 MB, FLOPs: 71,781,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1211/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1211\n",
      "\n",
      "Iteration 1212 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.115 MB, Params: 672,681 (2.566 MB), Total: 2.68 MB, FLOPs: 71,482,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1212/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1212\n",
      "\n",
      "Iteration 1213 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.115 MB, Params: 671,671 (2.562 MB), Total: 2.68 MB, FLOPs: 71,184,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1213/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1213\n",
      "\n",
      "Iteration 1214 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 669,257 (2.553 MB), Total: 2.67 MB, FLOPs: 71,140,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1214/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1214\n",
      "\n",
      "Iteration 1215 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 666,843 (2.544 MB), Total: 2.66 MB, FLOPs: 71,097,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1215/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1215\n",
      "\n",
      "Iteration 1216 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 664,429 (2.535 MB), Total: 2.65 MB, FLOPs: 71,053,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1216/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1216\n",
      "\n",
      "Iteration 1217 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 662,913 (2.529 MB), Total: 2.64 MB, FLOPs: 71,026,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1217/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1217\n",
      "\n",
      "Iteration 1218 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 661,397 (2.523 MB), Total: 2.64 MB, FLOPs: 70,999,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1218/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1218\n",
      "\n",
      "Iteration 1219 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 22)]\n",
      "Input: 0.115 MB, Params: 661,355 (2.523 MB), Total: 2.64 MB, FLOPs: 70,654,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1219/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1219\n",
      "\n",
      "Iteration 1220 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 658,959 (2.514 MB), Total: 2.63 MB, FLOPs: 70,611,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1220/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1220\n",
      "\n",
      "Iteration 1221 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 657,452 (2.508 MB), Total: 2.62 MB, FLOPs: 70,584,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1221/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1221\n",
      "\n",
      "Iteration 1222 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 65)]\n",
      "Input: 0.115 MB, Params: 655,965 (2.502 MB), Total: 2.62 MB, FLOPs: 70,360,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1222/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1222\n",
      "\n",
      "Iteration 1223 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 19)]\n",
      "Input: 0.115 MB, Params: 654,478 (2.497 MB), Total: 2.61 MB, FLOPs: 70,135,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1223/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1223\n",
      "\n",
      "Iteration 1224 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 93)]\n",
      "Input: 0.115 MB, Params: 652,010 (2.487 MB), Total: 2.60 MB, FLOPs: 70,039,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Finished fine tuning.\n",
      "Iteration 1224/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1224\n",
      "\n",
      "Iteration 1225 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 649,632 (2.478 MB), Total: 2.59 MB, FLOPs: 69,996,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1225/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1225\n",
      "\n",
      "Iteration 1226 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 648,134 (2.472 MB), Total: 2.59 MB, FLOPs: 69,969,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1226/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1226\n",
      "\n",
      "Iteration 1227 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 645,765 (2.463 MB), Total: 2.58 MB, FLOPs: 69,927,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1227/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1227\n",
      "\n",
      "Iteration 1228 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.115 MB, Params: 644,107 (2.457 MB), Total: 2.57 MB, FLOPs: 69,807,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1228/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1228\n",
      "\n",
      "Iteration 1229 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 641,738 (2.448 MB), Total: 2.56 MB, FLOPs: 69,765,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1229/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1229\n",
      "\n",
      "Iteration 1230 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 639,369 (2.439 MB), Total: 2.55 MB, FLOPs: 69,722,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Finished fine tuning.\n",
      "Iteration 1230/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1230\n",
      "\n",
      "Iteration 1231 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 637,898 (2.433 MB), Total: 2.55 MB, FLOPs: 69,696,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1231/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1231\n",
      "\n",
      "Iteration 1232 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.115 MB, Params: 635,538 (2.424 MB), Total: 2.54 MB, FLOPs: 69,653,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1232/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1232\n",
      "\n",
      "Iteration 1233 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 633,880 (2.418 MB), Total: 2.53 MB, FLOPs: 69,534,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1233/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1233\n",
      "\n",
      "Iteration 1234 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 632,222 (2.412 MB), Total: 2.53 MB, FLOPs: 69,414,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Finished fine tuning.\n",
      "Iteration 1234/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1234\n",
      "\n",
      "Iteration 1235 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 629,862 (2.403 MB), Total: 2.52 MB, FLOPs: 69,372,488\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1235/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1235\n",
      "\n",
      "Iteration 1236 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 629,014 (2.399 MB), Total: 2.51 MB, FLOPs: 68,826,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1236/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1236\n",
      "\n",
      "Iteration 1237 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 627,561 (2.394 MB), Total: 2.51 MB, FLOPs: 68,800,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.636%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1237/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1237\n",
      "\n",
      "Iteration 1238 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 35)]\n",
      "Input: 0.115 MB, Params: 626,101 (2.388 MB), Total: 2.50 MB, FLOPs: 68,578,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1238/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1238\n",
      "\n",
      "Iteration 1239 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 623,714 (2.379 MB), Total: 2.49 MB, FLOPs: 68,484,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1239/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1239\n",
      "\n",
      "Iteration 1240 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.115 MB, Params: 622,740 (2.376 MB), Total: 2.49 MB, FLOPs: 68,196,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1240/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1240\n",
      "\n",
      "Iteration 1241 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 621,287 (2.370 MB), Total: 2.49 MB, FLOPs: 68,170,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1241/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1241\n",
      "\n",
      "Iteration 1242 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 619,834 (2.364 MB), Total: 2.48 MB, FLOPs: 68,144,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1242/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1242\n",
      "\n",
      "Iteration 1243 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 617,510 (2.356 MB), Total: 2.47 MB, FLOPs: 68,102,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1243/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1243\n",
      "\n",
      "Iteration 1244 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.115 MB, Params: 615,186 (2.347 MB), Total: 2.46 MB, FLOPs: 68,060,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1244/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1244\n",
      "\n",
      "Iteration 1245 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 52)]\n",
      "Input: 0.115 MB, Params: 612,817 (2.338 MB), Total: 2.45 MB, FLOPs: 67,967,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1245/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1245\n",
      "\n",
      "Iteration 1246 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 610,502 (2.329 MB), Total: 2.44 MB, FLOPs: 67,925,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1246/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1246\n",
      "\n",
      "Iteration 1247 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.115 MB, Params: 610,032 (2.327 MB), Total: 2.44 MB, FLOPs: 67,362,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1247/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1247\n",
      "\n",
      "Iteration 1248 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.115 MB, Params: 609,562 (2.325 MB), Total: 2.44 MB, FLOPs: 66,800,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1248/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1248\n",
      "\n",
      "Iteration 1249 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 607,931 (2.319 MB), Total: 2.43 MB, FLOPs: 66,682,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1249/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1249\n",
      "\n",
      "Iteration 1250 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 606,505 (2.314 MB), Total: 2.43 MB, FLOPs: 66,657,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1250/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1250\n",
      "\n",
      "Iteration 1251 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 605,079 (2.308 MB), Total: 2.42 MB, FLOPs: 66,631,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1251/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1251\n",
      "\n",
      "Iteration 1252 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 602,782 (2.299 MB), Total: 2.41 MB, FLOPs: 66,590,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1252/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1252\n",
      "\n",
      "Iteration 1253 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.115 MB, Params: 601,151 (2.293 MB), Total: 2.41 MB, FLOPs: 66,472,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1253/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1253\n",
      "\n",
      "Iteration 1254 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 598,854 (2.284 MB), Total: 2.40 MB, FLOPs: 66,431,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1254/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1254\n",
      "\n",
      "Iteration 1255 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 596,557 (2.276 MB), Total: 2.39 MB, FLOPs: 66,390,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1255/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1255\n",
      "\n",
      "Iteration 1256 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 594,260 (2.267 MB), Total: 2.38 MB, FLOPs: 66,348,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1256/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1256\n",
      "\n",
      "Iteration 1257 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 591,954 (2.258 MB), Total: 2.37 MB, FLOPs: 66,257,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1257/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1257\n",
      "\n",
      "Iteration 1258 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 589,666 (2.249 MB), Total: 2.36 MB, FLOPs: 66,216,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1258/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1258\n",
      "\n",
      "Iteration 1259 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 588,044 (2.243 MB), Total: 2.36 MB, FLOPs: 66,099,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1259/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1259\n",
      "\n",
      "Iteration 1260 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 587,727 (2.242 MB), Total: 2.36 MB, FLOPs: 65,679,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1260/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1260\n",
      "\n",
      "Iteration 1261 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 585,439 (2.233 MB), Total: 2.35 MB, FLOPs: 65,638,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1261/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1261\n",
      "\n",
      "Iteration 1262 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.115 MB, Params: 583,151 (2.225 MB), Total: 2.34 MB, FLOPs: 65,597,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1262/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1262\n",
      "\n",
      "Iteration 1263 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.115 MB, Params: 580,881 (2.216 MB), Total: 2.33 MB, FLOPs: 65,507,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1263/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1263\n",
      "\n",
      "Iteration 1264 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 49)]\n",
      "Input: 0.115 MB, Params: 578,611 (2.207 MB), Total: 2.32 MB, FLOPs: 65,416,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1264/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1264\n",
      "\n",
      "Iteration 1265 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.115 MB, Params: 576,341 (2.199 MB), Total: 2.31 MB, FLOPs: 65,376,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1265/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1265\n",
      "\n",
      "Iteration 1266 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 91)]\n",
      "Input: 0.115 MB, Params: 574,080 (2.190 MB), Total: 2.31 MB, FLOPs: 65,286,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1266/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1266\n",
      "\n",
      "Iteration 1267 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 572,485 (2.184 MB), Total: 2.30 MB, FLOPs: 65,171,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1267/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1267\n",
      "\n",
      "Iteration 1268 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.115 MB, Params: 571,131 (2.179 MB), Total: 2.29 MB, FLOPs: 65,147,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1268/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1268\n",
      "\n",
      "Iteration 1269 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.115 MB, Params: 569,716 (2.173 MB), Total: 2.29 MB, FLOPs: 64,929,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1269/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1269\n",
      "\n",
      "Iteration 1270 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 568,362 (2.168 MB), Total: 2.28 MB, FLOPs: 64,905,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1270/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1270\n",
      "\n",
      "Iteration 1271 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 567,008 (2.163 MB), Total: 2.28 MB, FLOPs: 64,881,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1271/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1271\n",
      "\n",
      "Iteration 1272 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 564,774 (2.154 MB), Total: 2.27 MB, FLOPs: 64,841,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1272/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1272\n",
      "\n",
      "Iteration 1273 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 562,540 (2.146 MB), Total: 2.26 MB, FLOPs: 64,800,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1273/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1273\n",
      "\n",
      "Iteration 1274 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 561,125 (2.141 MB), Total: 2.26 MB, FLOPs: 64,583,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1274/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1274\n",
      "\n",
      "Iteration 1275 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 559,789 (2.135 MB), Total: 2.25 MB, FLOPs: 64,559,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1275/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1275\n",
      "\n",
      "Iteration 1276 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 557,564 (2.127 MB), Total: 2.24 MB, FLOPs: 64,519,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1276/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1276\n",
      "\n",
      "Iteration 1277 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 555,339 (2.118 MB), Total: 2.23 MB, FLOPs: 64,479,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1277/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1277\n",
      "\n",
      "Iteration 1278 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.115 MB, Params: 553,114 (2.110 MB), Total: 2.23 MB, FLOPs: 64,439,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1278/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1278\n",
      "\n",
      "Iteration 1279 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.115 MB, Params: 552,158 (2.106 MB), Total: 2.22 MB, FLOPs: 64,156,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1279/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1279\n",
      "\n",
      "Iteration 1280 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 550,752 (2.101 MB), Total: 2.22 MB, FLOPs: 63,942,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1280/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1280\n",
      "\n",
      "Iteration 1281 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.115 MB, Params: 548,545 (2.093 MB), Total: 2.21 MB, FLOPs: 63,853,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1281/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1281\n",
      "\n",
      "Iteration 1282 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.115 MB, Params: 546,338 (2.084 MB), Total: 2.20 MB, FLOPs: 63,765,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1282/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1282\n",
      "\n",
      "Iteration 1283 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.115 MB, Params: 544,788 (2.078 MB), Total: 2.19 MB, FLOPs: 63,653,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1283/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1283\n",
      "\n",
      "Iteration 1284 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 543,841 (2.075 MB), Total: 2.19 MB, FLOPs: 63,373,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1284/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1284\n",
      "\n",
      "Iteration 1285 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 542,532 (2.070 MB), Total: 2.18 MB, FLOPs: 63,350,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1285/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1285\n",
      "\n",
      "Iteration 1286 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 540,334 (2.061 MB), Total: 2.18 MB, FLOPs: 63,310,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1286/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1286\n",
      "\n",
      "Iteration 1287 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 538,136 (2.053 MB), Total: 2.17 MB, FLOPs: 63,271,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1287/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1287\n",
      "\n",
      "Iteration 1288 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.115 MB, Params: 535,938 (2.044 MB), Total: 2.16 MB, FLOPs: 63,231,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1288/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1288\n",
      "\n",
      "Iteration 1289 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 534,656 (2.040 MB), Total: 2.15 MB, FLOPs: 63,208,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1289/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1289\n",
      "\n",
      "Iteration 1290 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.115 MB, Params: 533,268 (2.034 MB), Total: 2.15 MB, FLOPs: 62,997,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1290/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1290\n",
      "\n",
      "Iteration 1291 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.115 MB, Params: 532,330 (2.031 MB), Total: 2.15 MB, FLOPs: 62,720,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1291/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1291\n",
      "\n",
      "Iteration 1292 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 530,141 (2.022 MB), Total: 2.14 MB, FLOPs: 62,680,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1292/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1292\n",
      "\n",
      "Iteration 1293 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 527,952 (2.014 MB), Total: 2.13 MB, FLOPs: 62,641,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1293/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1293\n",
      "\n",
      "Iteration 1294 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.115 MB, Params: 526,688 (2.009 MB), Total: 2.12 MB, FLOPs: 62,618,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1294/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1294\n",
      "\n",
      "Iteration 1295 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 5)]\n",
      "Input: 0.115 MB, Params: 526,371 (2.008 MB), Total: 2.12 MB, FLOPs: 62,198,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1295/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1295\n",
      "\n",
      "Iteration 1296 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 525,433 (2.004 MB), Total: 2.12 MB, FLOPs: 61,920,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1296/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1296\n",
      "\n",
      "Iteration 1297 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 523,253 (1.996 MB), Total: 2.11 MB, FLOPs: 61,881,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1297/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1297\n",
      "\n",
      "Iteration 1298 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 521,998 (1.991 MB), Total: 2.11 MB, FLOPs: 61,859,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1298/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1298\n",
      "\n",
      "Iteration 1299 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 519,827 (1.983 MB), Total: 2.10 MB, FLOPs: 61,820,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1299/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1299\n",
      "\n",
      "Iteration 1300 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.115 MB, Params: 517,656 (1.975 MB), Total: 2.09 MB, FLOPs: 61,780,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 1300/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1300\n",
      "\n",
      "Iteration 1301 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 516,419 (1.970 MB), Total: 2.09 MB, FLOPs: 61,758,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1301/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1301\n",
      "\n",
      "Iteration 1302 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.115 MB, Params: 515,049 (1.965 MB), Total: 2.08 MB, FLOPs: 61,552,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 1302/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1302\n",
      "\n",
      "Iteration 1303 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.115 MB, Params: 512,923 (1.957 MB), Total: 2.07 MB, FLOPs: 61,466,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1303/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1303\n",
      "\n",
      "Iteration 1304 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.115 MB, Params: 512,471 (1.955 MB), Total: 2.07 MB, FLOPs: 60,925,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 1304/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1304\n",
      "\n",
      "Iteration 1305 of 1680 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 510,318 (1.947 MB), Total: 2.06 MB, FLOPs: 60,886,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1305/1682 finished in 0m06s\n",
      "Total channels prunned so far: 1305\n",
      "\n",
      "Iteration 1306 of 1680 starts..\n",
      "Ranking channels.. \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
