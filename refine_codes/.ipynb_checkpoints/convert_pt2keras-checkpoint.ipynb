{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb5ead3-5abb-4e19-9ebf-298d75e5fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc57599-8e7c-48fc-acf4-d8835f10e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn;\n",
    "import torch.ao.nn.quantized as nnq\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "import torch.ao.quantization.quantize_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e53865-6b27-4444-b4b9-ca91e101196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"));\n",
    "import common.utils as U;\n",
    "import common.opts as opt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564322e0-05fd-488a-b67c-5bd7f3beb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32ad789-96c3-4796-9c77-442981533095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91e71242-8a01-4801-94e2-972206d3634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx2keras import onnx_to_keras\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7eee8d45-16c6-4dc9-970a-7f96f0269aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K;\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Model, load_model;\n",
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1806933a-83c8-4469-ae4c-c00b534c3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U onnx\n",
    "# !pip install -U onnx-tf\n",
    "# !pip install onnx2keras\n",
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca56b414-37f5-42e0-a04b-08be5be4afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current use device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "print(f\"current use device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909a1354-6746-4d0c-b7fe-2262881a8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1555e4e-ff37-4e64-ac5e-14ee2aa4a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;\n",
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=2, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd05a49-3426-468a-a46a-a1f450bbe657",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b775bd7d-8040-420d-b419-6538a40de7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLACDNet:\n",
    "\tdef __init__(self, pretrained_model_path=None,opt=None, num_class=6):\n",
    "\t\tself.opt = opt\n",
    "\t\tself.pretrained_model_path = pretrained_model_path\n",
    "\t\tself.new_model = None\n",
    "\t\tself.num_class = num_class\n",
    "\n",
    "\tdef Create_TLACDNet(self):\n",
    "\t\tmodel = load_model(self.pretrained_model_path)\n",
    "\t\tprint(f\"original model loaded....\")\n",
    "\t\t# for l in model.layers:\n",
    "\t\t# \tprint(f\"layer:{l} trainable weight length is {len(l.wei)}\")\n",
    "\t\ttotal_layers_num = len(model.layers)\n",
    "\t\treplaced_layers_num = 2\n",
    "\t\tfreeze_layers_num = total_layers_num-replaced_layers_num\n",
    "\n",
    "\t\t## freeze layers\n",
    "\t\tfor i in range(freeze_layers_num):\n",
    "\t\t\tmodel.layers[i].trainable = False\n",
    "\n",
    "\t\tfor j in range(freeze_layers_num, total_layers_num):\n",
    "\t\t\tmodel.layers[j].trainable = True\n",
    "\n",
    "\t\tcustom_layers = model.layers[freeze_layers_num-1].output\n",
    "\t\tcustom_layers = L.Dense(self.num_class)(custom_layers)\n",
    "\t\t# custom_layers = Softmax()(custom_layers)\n",
    "\t\tcustom_layers = L.Dense(self.num_class,activation=\"softmax\")(custom_layers)\n",
    "\n",
    "\t\tnew_model = Model(inputs=model.input,outputs=custom_layers)\n",
    "\t\tprint(\"new model info:\\n\")\n",
    "\t\tprint(new_model.summary())\n",
    "\t\tprint(\"\\n\")\n",
    "\t\treturn new_model\n",
    "\n",
    "def GetKerasACDNet(pretrained_model_path=None,opt=None, num_class=2):\n",
    "\ttrainedModelPath = pretrained_model_path\n",
    "\ttlacdnet = TLACDNet(trainedModelPath, opt, num_class)\n",
    "\treturn tlacdnet.Create_TLACDNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab4977f9-9015-40b9-ba0c-9af7a9bc0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n",
      "2024-01-22 15:42:41.572309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.584418: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.584500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.585062: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.585114: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.585154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.589467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.589534: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.589586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-22 15:42:41.590256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12742 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model loaded....\n",
      "new model info:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 30225, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, 15109, 4)       36        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1, 15109, 4)       16        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1, 15109, 4)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1, 7553, 32)       640       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 7553, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 1, 7553, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 151, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " permute (Permute)           (None, 32, 151, 1)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 151, 12)       108       \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 151, 12)       48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32, 151, 12)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 75, 12)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 75, 12)        1296      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16, 75, 12)        48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 16, 75, 12)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 75, 23)        2484      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16, 75, 23)        92        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 16, 75, 23)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 37, 23)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 37, 18)         3726      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8, 37, 18)         72        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 8, 37, 18)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 37, 38)         6156      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 8, 37, 38)         152       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 8, 37, 38)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 18, 38)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 18, 43)         14706     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 4, 18, 43)         172       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 4, 18, 43)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 18, 62)         23994     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 4, 18, 62)         248       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 4, 18, 62)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 9, 62)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 2, 9, 58)          32364     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 2, 9, 58)          232       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 2, 9, 58)          0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 2, 9, 77)          40194     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 2, 9, 77)          308       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 2, 9, 77)          0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 1, 4, 77)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 4, 77)          0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 4, 37)          2849      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 1, 4, 37)          148       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 1, 4, 37)          0         \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 1, 1, 37)          0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 37)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 76        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130299 (508.98 KB)\n",
      "Trainable params: 82 (328.00 Byte)\n",
      "Non-trainable params: 130217 (508.66 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrainedmodelpath = \"../resources/pretrained_models/acdnet20_20khz_fold4.h5\";\n",
    "keras_model = GetKerasACDNet(pretrained_model_path=pretrainedmodelpath);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dea313-0ded-45b9-bb93-39632b36f8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cb5598-69e1-45a1-a08a-6409728c752e",
   "metadata": {},
   "source": [
    "## Convert to onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "012d750a-76d5-424d-aa09-f0ca55cab298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing model structures\n",
    "model = GetCustomedACDNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a02e768-96fc-4f17-af2e-614cc16fa723",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"./trained_models/acdnet_alarm_3rd_20240119100903_acc_96.59091186523438_67th_epoch.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "247bf6b7-0620-4cc0-98cd-288fc7778619",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(weights_path, map_location=device);\n",
    "config = state['config']\n",
    "model.load_state_dict(state['weight']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2834f96-6419-405b-a40d-dd51f7a1260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input.1 : Float(1, 1, 1, 30225, strides=[30225, 30225, 30225, 1], requires_grad=0, device=cpu),\n",
      "      %tfeb.38.weight : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu),\n",
      "      %tfeb.38.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_123 : Float(8, 1, 1, 9, strides=[9, 9, 9, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_124 : Float(8, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_126 : Float(64, 8, 1, 5, strides=[40, 5, 5, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_127 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_129 : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_130 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_132 : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_133 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_135 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_136 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_138 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_139 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_141 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_142 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_144 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_145 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_147 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_148 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_150 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_151 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_153 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_154 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_156 : Float(2, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_157 : Float(2, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %/sfeb/sfeb.0/Conv_output_0 : Float(1, 8, 1, 15109, strides=[120872, 15109, 15109, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 9], pads=[0, 0, 0, 0], strides=[1, 2], onnx_name=\"/sfeb/sfeb.0/Conv\"](%input.1, %onnx::Conv_123, %onnx::Conv_124), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::sfeb/torch.nn.modules.conv.Conv2d::sfeb.0 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/sfeb/sfeb.2/Relu_output_0 : Float(1, 8, 1, 15109, strides=[120872, 15109, 15109, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/sfeb/sfeb.2/Relu\"](%/sfeb/sfeb.0/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::sfeb/torch.nn.modules.activation.ReLU::sfeb.2 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/sfeb/sfeb.3/Conv_output_0 : Float(1, 64, 1, 7553, strides=[483392, 7553, 7553, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 5], pads=[0, 0, 0, 0], strides=[1, 2], onnx_name=\"/sfeb/sfeb.3/Conv\"](%/sfeb/sfeb.2/Relu_output_0, %onnx::Conv_126, %onnx::Conv_127), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::sfeb/torch.nn.modules.conv.Conv2d::sfeb.3 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/sfeb/sfeb.5/Relu_output_0 : Float(1, 64, 1, 7553, strides=[483392, 7553, 7553, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/sfeb/sfeb.5/Relu\"](%/sfeb/sfeb.3/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::sfeb/torch.nn.modules.activation.ReLU::sfeb.5 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/sfeb/sfeb.6/MaxPool_output_0 : Float(1, 64, 1, 151, strides=[9664, 151, 151, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[1, 50], pads=[0, 0, 0, 0], strides=[1, 50], onnx_name=\"/sfeb/sfeb.6/MaxPool\"](%/sfeb/sfeb.5/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::sfeb/torch.nn.modules.pooling.MaxPool2d::sfeb.6 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/Transpose_output_0 : Float(1, 1, 64, 151, strides=[9664, 151, 151, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3], onnx_name=\"/Transpose\"](%/sfeb/sfeb.6/MaxPool_output_0), scope: __main__.Customed_ACDNetV2:: # /tmp/ipykernel_250709/1942818665.py:81:0\n",
      "  %/tfeb/tfeb.0/Conv_output_0 : Float(1, 32, 64, 151, strides=[309248, 9664, 151, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.0/Conv\"](%/Transpose_output_0, %onnx::Conv_129, %onnx::Conv_130), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.0 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.2/Relu_output_0 : Float(1, 32, 64, 151, strides=[309248, 9664, 151, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.2/Relu\"](%/tfeb/tfeb.0/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.2 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.3/MaxPool_output_0 : Float(1, 32, 32, 75, strides=[76800, 2400, 75, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/tfeb/tfeb.3/MaxPool\"](%/tfeb/tfeb.2/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.MaxPool2d::tfeb.3 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/tfeb/tfeb.4/Conv_output_0 : Float(1, 64, 32, 75, strides=[153600, 2400, 75, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.4/Conv\"](%/tfeb/tfeb.3/MaxPool_output_0, %onnx::Conv_132, %onnx::Conv_133), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.4 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.6/Relu_output_0 : Float(1, 64, 32, 75, strides=[153600, 2400, 75, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.6/Relu\"](%/tfeb/tfeb.4/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.6 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.7/Conv_output_0 : Float(1, 64, 32, 75, strides=[153600, 2400, 75, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.7/Conv\"](%/tfeb/tfeb.6/Relu_output_0, %onnx::Conv_135, %onnx::Conv_136), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.7 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.9/Relu_output_0 : Float(1, 64, 32, 75, strides=[153600, 2400, 75, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.9/Relu\"](%/tfeb/tfeb.7/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.9 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.10/MaxPool_output_0 : Float(1, 64, 16, 37, strides=[37888, 592, 37, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/tfeb/tfeb.10/MaxPool\"](%/tfeb/tfeb.9/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.MaxPool2d::tfeb.10 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/tfeb/tfeb.11/Conv_output_0 : Float(1, 128, 16, 37, strides=[75776, 592, 37, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.11/Conv\"](%/tfeb/tfeb.10/MaxPool_output_0, %onnx::Conv_138, %onnx::Conv_139), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.11 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.13/Relu_output_0 : Float(1, 128, 16, 37, strides=[75776, 592, 37, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.13/Relu\"](%/tfeb/tfeb.11/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.13 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.14/Conv_output_0 : Float(1, 128, 16, 37, strides=[75776, 592, 37, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.14/Conv\"](%/tfeb/tfeb.13/Relu_output_0, %onnx::Conv_141, %onnx::Conv_142), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.14 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.16/Relu_output_0 : Float(1, 128, 16, 37, strides=[75776, 592, 37, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.16/Relu\"](%/tfeb/tfeb.14/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.16 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.17/MaxPool_output_0 : Float(1, 128, 8, 18, strides=[18432, 144, 18, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/tfeb/tfeb.17/MaxPool\"](%/tfeb/tfeb.16/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.MaxPool2d::tfeb.17 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/tfeb/tfeb.18/Conv_output_0 : Float(1, 256, 8, 18, strides=[36864, 144, 18, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.18/Conv\"](%/tfeb/tfeb.17/MaxPool_output_0, %onnx::Conv_144, %onnx::Conv_145), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.18 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.20/Relu_output_0 : Float(1, 256, 8, 18, strides=[36864, 144, 18, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.20/Relu\"](%/tfeb/tfeb.18/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.20 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.21/Conv_output_0 : Float(1, 256, 8, 18, strides=[36864, 144, 18, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.21/Conv\"](%/tfeb/tfeb.20/Relu_output_0, %onnx::Conv_147, %onnx::Conv_148), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.21 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.23/Relu_output_0 : Float(1, 256, 8, 18, strides=[36864, 144, 18, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.23/Relu\"](%/tfeb/tfeb.21/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.23 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.24/MaxPool_output_0 : Float(1, 256, 4, 9, strides=[9216, 36, 9, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/tfeb/tfeb.24/MaxPool\"](%/tfeb/tfeb.23/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.MaxPool2d::tfeb.24 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/tfeb/tfeb.25/Conv_output_0 : Float(1, 512, 4, 9, strides=[18432, 36, 9, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.25/Conv\"](%/tfeb/tfeb.24/MaxPool_output_0, %onnx::Conv_150, %onnx::Conv_151), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.25 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.27/Relu_output_0 : Float(1, 512, 4, 9, strides=[18432, 36, 9, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.27/Relu\"](%/tfeb/tfeb.25/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.27 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.28/Conv_output_0 : Float(1, 512, 4, 9, strides=[18432, 36, 9, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/tfeb/tfeb.28/Conv\"](%/tfeb/tfeb.27/Relu_output_0, %onnx::Conv_153, %onnx::Conv_154), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.28 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.30/Relu_output_0 : Float(1, 512, 4, 9, strides=[18432, 36, 9, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.30/Relu\"](%/tfeb/tfeb.28/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.30 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.31/MaxPool_output_0 : Float(1, 512, 2, 4, strides=[4096, 8, 4, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/tfeb/tfeb.31/MaxPool\"](%/tfeb/tfeb.30/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.MaxPool2d::tfeb.31 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/tfeb/tfeb.33/Conv_output_0 : Float(1, 2, 2, 4, strides=[16, 8, 4, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/tfeb/tfeb.33/Conv\"](%/tfeb/tfeb.31/MaxPool_output_0, %onnx::Conv_156, %onnx::Conv_157), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.conv.Conv2d::tfeb.33 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/tfeb/tfeb.35/Relu_output_0 : Float(1, 2, 2, 4, strides=[16, 8, 4, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/tfeb/tfeb.35/Relu\"](%/tfeb/tfeb.33/Conv_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.activation.ReLU::tfeb.35 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/tfeb/tfeb.36/AveragePool_output_0 : Float(1, 2, 1, 1, strides=[2, 1, 1, 1], requires_grad=1, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 4], pads=[0, 0, 0, 0], strides=[2, 4], onnx_name=\"/tfeb/tfeb.36/AveragePool\"](%/tfeb/tfeb.35/Relu_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.pooling.AvgPool2d::tfeb.36 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/tfeb/tfeb.37/Flatten_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/tfeb/tfeb.37/Flatten\"](%/tfeb/tfeb.36/AveragePool_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.flatten.Flatten::tfeb.37 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/flatten.py:47:0\n",
      "  %/tfeb/tfeb.38/Gemm_output_0 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/tfeb/tfeb.38/Gemm\"](%/tfeb/tfeb.37/Flatten_output_0, %tfeb.38.weight, %tfeb.38.bias), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.container.Sequential::tfeb/torch.nn.modules.linear.Linear::tfeb.38 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %121 : Float(1, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=1, onnx_name=\"/output.0/Softmax\"](%/tfeb/tfeb.38/Gemm_output_0), scope: __main__.Customed_ACDNetV2::/torch.nn.modules.activation.Softmax::output.0 # /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/nn/functional.py:1856:0\n",
      "  return (%121)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"config is {config}\")\n",
    "onnx_save_path = \"../th/onnx_models/onnx_3rd_97.7_{}.onnx\".format(genDataTimeStr());\n",
    "rdnary = torch.randn((1, 1, 1, 30225));\n",
    "# torch.onnx.export(model, rdnary, onnx_save_path)\n",
    "torch.onnx.export(model, rdnary, onnx_save_path, verbose=True, input_names = ['input.1'], output_names = ['121'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b445bf7-5151-4cdf-8e00-834d4c182d97",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Convert onnx to keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d821017f-d29d-4d0b-9054-158dbfa8752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_name is input.1, and output name is NodeArg(name='121', type='tensor(float)', shape=[1, 2])\n"
     ]
    }
   ],
   "source": [
    "#first get input name\n",
    "onnx_model_path = \"../th/onnx_models/onnx_3rd_97.7_20240122152249.onnx\"\n",
    "sess = rt.InferenceSession(onnx_model_path)\n",
    "input_name = sess.get_inputs()[0].name;\n",
    "output_name = sess.get_outputs()[0];\n",
    "print(f\"input_name is {input_name}, and output name is {output_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fe53288-0657-4407-bc27-0a08203a7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input.1.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> 121.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight tfeb.38.weight with shape (2, 2).\n",
      "DEBUG:onnx2keras:Found weight tfeb.38.bias with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_123 with shape (8, 1, 1, 9).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_124 with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_126 with shape (64, 8, 1, 5).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_127 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_129 with shape (32, 1, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_130 with shape (32,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_132 with shape (64, 32, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_133 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_135 with shape (64, 64, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_136 with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_138 with shape (128, 64, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_139 with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_141 with shape (128, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_142 with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_144 with shape (256, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_145 with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_147 with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_148 with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_150 with shape (512, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_151 with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_153 with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_154 with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_156 with shape (2, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight onnx::Conv_157 with shape (2,).\n",
      "DEBUG:onnx2keras:Found input input.1 with shape [1, 1, 30225]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: /sfeb/sfeb.0/Conv_output_0\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 9], 'pads': [0, 0, 0, 0], 'strides': [1, 2], 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input.1).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::Conv_123).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name onnx::Conv_124).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'/sfeb/sfeb.0/Conv_output_0/' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(onnx_model_path);\n\u001b[0;32m----> 2\u001b[0m k_model \u001b[38;5;241m=\u001b[39m \u001b[43monnx_to_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/onnx2keras/converter.py:175\u001b[0m, in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    172\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... found all, continue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    174\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_image_data_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[43mAVAILABLE_CONVERTERS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeras_names\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keras_names, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    184\u001b[0m     keras_names \u001b[38;5;241m=\u001b[39m keras_names[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/onnx2keras/convolution_layers.py:177\u001b[0m, in \u001b[0;36mconvert_conv\u001b[0;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[1;32m    162\u001b[0m             weights \u001b[38;5;241m=\u001b[39m [W]\n\u001b[1;32m    164\u001b[0m         conv \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\n\u001b[1;32m    165\u001b[0m             filters\u001b[38;5;241m=\u001b[39mout_channels,\n\u001b[1;32m    166\u001b[0m             kernel_size\u001b[38;5;241m=\u001b[39m(height, width),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m             name\u001b[38;5;241m=\u001b[39mkeras_name\n\u001b[1;32m    175\u001b[0m         )\n\u001b[0;32m--> 177\u001b[0m         layers[node_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# 1D conv\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     W \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: '/sfeb/sfeb.0/Conv_output_0/' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnx_model_path);\n",
    "k_model = onnx_to_keras(onnx_model, ['input.1']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f63447-b4c2-4dee-91d1-e111a5d810ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxscript\n",
      "  Downloading onnxscript-0.1.0.dev20231228-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (1.26.2)\n",
      "Requirement already satisfied: onnx>=1.14 in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (4.8.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnx>=1.14->onnxscript) (4.23.4)\n",
      "Downloading onnxscript-0.1.0.dev20231228-py3-none-any.whl (550 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m\u001b[0m \u001b[32m550.7/550.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: onnxscript\n",
      "Successfully installed onnxscript-0.1.0.dev20231228\n"
     ]
    }
   ],
   "source": [
    "# !pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d421ae89-45af-4c1e-bf07-56d5ca97ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinynn.converter import TFLiteConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3bb12-64f3-4677-81d8-f14e9bdec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    qmodel = copy.deepcopy(mynn)\n",
    "    torch.quantization.convert(qmodel, inplace=False)\n",
    "    #\n",
    "    torch.backends.quantized.engine = 'qnnpack'\n",
    "    converter = TFLiteConverter(qmodel.module,\n",
    "                                torch.randn(1, 64, nn_h, nn_w,\n",
    "                                tflite_path=\"qmodel.tflite\")\n",
    "    converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
