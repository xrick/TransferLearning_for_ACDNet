{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cc9bbe-2fe9-44d4-94d5-ff1e3b393ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffebbf0-fdc4-40ea-83a4-ddeab5fe32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import time;\n",
    "from tensorflow import keras;\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eef15d7-e975-4681-b7b5-d0ea4017b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "sys.path.append(os.path.abspath(\"../common/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f637483a-6163-4957-a389-8f2a745845a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common.utils as U;\n",
    "import common.opts as opts;\n",
    "import resources.models as models;\n",
    "# import resources.train_generator as train_generator;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2242f8e7-8f79-4966-8eec-dd53e37f0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d739af4-bfff-40b9-aa63-2006832e2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f98ee9d3-aa54-48cc-8257-5c8dd4a1bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cc26978-118e-43c4-bf5b-5e58b7b595f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_src_model_path = \"./retrained_models_after_pruned/retrained_model_20240124123209_acc_95.45455169677734_795th_epoch.pt\"\n",
    "config = torch.load(retrain_src_model_path, map_location=device)['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2213c48-f592-4440-87e4-67c327759e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 32, 9, 16, 23, 33, 29, 56, 47, 65, 90, 2]\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce295486-4e08-41e1-9078-3cc76bdce28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_net = models.GetAcdnetModel(input_length=30225, n_class=2, sr=20000, ch_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a33b3c0f-7858-4398-9656-07cde60a6705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 30225, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1, 15109, 5)       45        \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 1, 15109, 5)       20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 1, 15109, 5)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 7553, 32)       800       \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 1, 7553, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 1, 7553, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 1, 151, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " permute_1 (Permute)         (None, 32, 151, 1)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 151, 9)        81        \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 32, 151, 9)        36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 32, 151, 9)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 75, 9)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 75, 16)        1296      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 16, 75, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 16, 75, 16)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 16, 75, 23)        3312      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 16, 75, 23)        92        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_16 (ReLU)             (None, 16, 75, 23)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 8, 37, 23)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 37, 33)         6831      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 8, 37, 33)         132       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_17 (ReLU)             (None, 8, 37, 33)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 37, 29)         8613      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 8, 37, 29)         116       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_18 (ReLU)             (None, 8, 37, 29)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 4, 18, 29)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 18, 56)         14616     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 4, 18, 56)         224       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             (None, 4, 18, 56)         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 18, 47)         23688     \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 4, 18, 47)         188       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 4, 18, 47)         0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 2, 9, 47)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 2, 9, 65)          27495     \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 2, 9, 65)          260       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 2, 9, 65)          0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 2, 9, 90)          52650     \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 2, 9, 90)          360       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 2, 9, 90)          0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 1, 4, 90)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 4, 90)          0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 4, 2)           180       \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 1, 4, 2)           8         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 1, 4, 2)           0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 2)           0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141241 (551.72 KB)\n",
      "Trainable params: 140427 (548.54 KB)\n",
      "Non-trainable params: 814 (3.18 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b3a2a935-4666-44c6-806e-383e50156f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xrickliao/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "tf_net.save(\"./keras_models/retrain_pruned_cp_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34eadc-9247-430e-aa29-4a71cf1025d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695cb76-9693-402e-9487-12b5b553ad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d1f0d-8124-42aa-81d1-36c6fc512936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53080d42-39c3-4ae1-9647-84e5e776b992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02604a92-a1f5-4eb0-af69-5926a1edde78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43919d9-51ad-4043-9786-7dcbc64fcb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc57acd-e163-4125-a17e-a4dd9f891406",
   "metadata": {},
   "source": [
    "## train the tf model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdaf2ae4-e9ac-411b-8f95-9a8c72473709",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '../datasets/forOneClassModel_alarm/train/trainSet_20240119002902.npz'\n",
    "test_data = '../datasets/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e52e973-972c-46fa-9504-078a50ecbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(pad):\n",
    "    def f(sound):\n",
    "        return np.pad(sound, pad, 'constant')\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def random_crop(size):\n",
    "    def f(sound):\n",
    "        org_size = len(sound)\n",
    "        start = random.randint(0, org_size - size)\n",
    "        return sound[start: start + size]\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def normalize(factor):\n",
    "    def f(sound):\n",
    "        return sound / factor\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# For strong data augmentation\n",
    "# def random_scale(max_scale, interpolate='Linear'):\n",
    "def random_scale(max_scale, interpolate='Nearest'):\n",
    "    def f(sound):\n",
    "        scale = np.power(max_scale, random.uniform(-1, 1))\n",
    "        output_size = int(len(sound) * scale)\n",
    "        ref = np.arange(output_size) / scale\n",
    "        print(\"ref:\",ref)\n",
    "        if interpolate == 'Linear':\n",
    "            ref1 = ref.astype(np.int32)\n",
    "            ref2 = np.minimum(ref1 + 1, len(sound) - 1)\n",
    "            r = ref - ref1\n",
    "            scaled_sound = sound[ref1] * (1 - r) + sound[ref2] * r\n",
    "        elif interpolate == 'Nearest':\n",
    "            scaled_sound = sound[ref.astype(np.int32)]\n",
    "        else:\n",
    "            raise Exception('Invalid interpolation mode {}'.format(interpolate))\n",
    "\n",
    "        return scaled_sound\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def random_gain(db):\n",
    "    def f(sound):\n",
    "        return sound * np.power(10, random.uniform(-db, db) / 20.0)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# For testing phase\n",
    "def multi_crop(input_length, n_crops):\n",
    "    def f(sound):\n",
    "        stride = (len(sound) - input_length) // (n_crops - 1)\n",
    "        sounds = [sound[stride * i: stride * i + input_length] for i in range(n_crops)]\n",
    "        return np.array(sounds)\n",
    "\n",
    "    return f\n",
    "\n",
    "def single_crop(input_length, n_crops):\n",
    "    def f(sound):\n",
    "        stride = (len(sound) - input_length) // (n_crops - 1)\n",
    "        sounds = [sound[stride * i: stride * i + input_length] for i in range(n_crops)]\n",
    "        return np.array(sounds)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# For BC learning\n",
    "def a_weight(fs, n_fft, min_db=-80.0):\n",
    "    freq = np.linspace(0, fs // 2, n_fft // 2 + 1)\n",
    "    freq_sq = np.power(freq, 2)\n",
    "    freq_sq[0] = 1.0\n",
    "    weight = 2.0 + 20.0 * (2 * np.log10(12194) + 2 * np.log10(freq_sq)\n",
    "                           - np.log10(freq_sq + 12194 ** 2)\n",
    "                           - np.log10(freq_sq + 20.6 ** 2)\n",
    "                           - 0.5 * np.log10(freq_sq + 107.7 ** 2)\n",
    "                           - 0.5 * np.log10(freq_sq + 737.9 ** 2))\n",
    "    weight = np.maximum(weight, min_db)\n",
    "\n",
    "    return weight\n",
    "\n",
    "\n",
    "def compute_gain(sound, fs, min_db=-80.0, mode='A_weighting'):\n",
    "    if fs == 16000 or fs == 20000:\n",
    "        n_fft = 2048\n",
    "    elif fs == 44100:\n",
    "        n_fft = 4096\n",
    "    else:\n",
    "        raise Exception('Invalid fs {}'.format(fs))\n",
    "    stride = n_fft // 2\n",
    "\n",
    "    gain = []\n",
    "    #no xrange anymore supported\n",
    "    for i in range(0, len(sound) - n_fft + 1, stride):\n",
    "        if mode == 'RMSE':\n",
    "            g = np.mean(sound[i: i + n_fft] ** 2)\n",
    "        elif mode == 'A_weighting':\n",
    "            spec = np.fft.rfft(np.hanning(n_fft + 1)[:-1] * sound[i: i + n_fft])\n",
    "            power_spec = np.abs(spec) ** 2\n",
    "            a_weighted_spec = power_spec * np.power(10, a_weight(fs, n_fft) / 10)\n",
    "            g = np.sum(a_weighted_spec)\n",
    "        else:\n",
    "            raise Exception('Invalid mode {}'.format(mode))\n",
    "        gain.append(g)\n",
    "\n",
    "    gain = np.array(gain)\n",
    "    gain = np.maximum(gain, np.power(10, min_db / 10))\n",
    "    gain_db = 10 * np.log10(gain)\n",
    "\n",
    "    return gain_db\n",
    "\n",
    "\n",
    "def mix(sound1, sound2, r, fs):\n",
    "    gain1 = np.max(compute_gain(sound1, fs))  # Decibel\n",
    "    gain2 = np.max(compute_gain(sound2, fs))\n",
    "    t = 1.0 / (1 + np.power(10, (gain1 - gain2) / 20.) * (1 - r) / r)\n",
    "    sound = ((sound1 * t + sound2 * (1 - t)) / np.sqrt(t ** 2 + (1 - t) ** 2))\n",
    "\n",
    "    return sound\n",
    "\n",
    "# Convert time representation\n",
    "def to_hms(time):\n",
    "    h = int(time // 3600)\n",
    "    m = int((time - h * 3600) // 60)\n",
    "    s = int(time - h * 3600 - m * 60)\n",
    "    if h > 0:\n",
    "        line = '{}h{:02d}m'.format(h, m)\n",
    "    else:\n",
    "        line = '{}m{:02d}s'.format(m, s)\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4a4fa59-8ba9-4aa2-b820-99b3ee920052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples=None, labels=None, options=None, classes_dict=None):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = np.asarray([(samples[i], labels[i]) for i in range (0, len(samples))],dtype=\"object\");\n",
    "        # print(f\"self.data type is {type(self.data)}\")\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = classes_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            print(len(sound1))\n",
    "            sound1 = self.preprocess(np.asarray(sound1))\n",
    "            sound2 = self.preprocess(np.asarray(sound2))\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            # print(f\"nClasses:{self.opt.nClasses}, type of mapdict:{type(self.mapdict)}, type of label1:{type(label1)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    # def preprocess_setup(self):\n",
    "    #     funcs = []\n",
    "    #     if self.opt.strongAugment:\n",
    "    #         funcs += [U.random_scale(1.25)]\n",
    "\n",
    "    #     funcs += [U.padding(self.opt.inputLength // 2),\n",
    "    #               U.random_crop(self.opt.inputLength),\n",
    "    #               U.normalize(32768.0)]\n",
    "    #     return funcs\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [random_scale(1.25)]\n",
    "\n",
    "        funcs += [padding(self.opt.inputLength // 2),\n",
    "                  random_crop(self.opt.inputLength),\n",
    "                  normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eba10fe4-f151-4079-be00-f4dffcf433a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None, classes_dict=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(opt.trainData, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    train_sounds = [list(dataset['fold1'].item()['sounds'][i]) for i in range(len(dataset['fold1'].item()['sounds']))]\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']#[list(dataset['fold1'].item()['labels'][i]) for i in range(len(dataset['fold1'].item()['labels']))]\n",
    "    # print(train_sounds)\n",
    "    # print(train_labels)\n",
    "    # train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    # train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_labels)\n",
    "\n",
    "    # trainGen = TLGenerator(train_sounds, train_labels, opt, classes_dict=classes_dict);\n",
    "    return train_sounds, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d93f9d92-1438-44ce-b071-9a8b07e97e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, net=None, opt=None, classes_dict=None):\n",
    "        self.opt = opt;\n",
    "        # self.trainGen = train_generator.setup(self.opt, self.opt.split);\n",
    "        self.model = net\n",
    "        _x, _y = getTrainGen(opt=opt, split=2,classes_dict=classes_dict)\n",
    "        # self.x, self.y = getTrainGen(opt=opt, split=2,classes_dict=classes_dict)\n",
    "        input_x = []\n",
    "        for i in range(11):\n",
    "            tmp_x = _x[i][:30225]\n",
    "            tmp_x = np.array(tmp_x).astype('float32')\n",
    "            tmp_x = np.expand_dims(tmp_x, axis=1);\n",
    "            tmp_x = np.expand_dims(tmp_x, axis=3);\n",
    "            input_x.append(tf.convert_to_tensor(tmp_x))\n",
    "        \n",
    "        self.x = input_x\n",
    "        self.y = tf.convert_to_tensor(_y[:11])\n",
    "        print(self.x)\n",
    "        print(self.y)\n",
    "        # print(f\"self.x type is {type(self.x[0])}\")\n",
    "        # self.trainGen = getTrainGen(opt=opt, split=2,classes_dict=classes_dict)\n",
    "        \n",
    "    def Train(self):\n",
    "        # model = models.GetAcdnetModel();\n",
    "        # if(self.trainGen != None):\n",
    "        #     print(\"train data generator loaded\")\n",
    "        # else:\n",
    "        #     print(\"train data generator load fail\")\n",
    "        self.model.summary();\n",
    "\n",
    "        loss = 'kullback_leibler_divergence';\n",
    "        optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=self.opt.LR,decay=self.opt.weightDecay)\n",
    "        # optimizer = keras.optimizers.SGD(learning_rate=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True)\n",
    "\n",
    "        self.model.compile(loss=loss, optimizer=optimizer , metrics=['accuracy']);\n",
    "\n",
    "        # learning schedule callback\n",
    "        lrate = keras.callbacks.LearningRateScheduler(self.GetLR);\n",
    "        best_model = keras.callbacks.ModelCheckpoint('./tensorflow_models/retrain_pruned_model_copy_weights/{}_{}.h5'.format(self.opt.model_name, genDataTimeStr()), monitor='val_acc', save_best_only=True, verbose=0);\n",
    "        custom_evaluator = CustomCallback(self.opt);\n",
    "        callbacks_list = [lrate, custom_evaluator, best_model];\n",
    "\n",
    "        # self.model.fit(self.trainGen, epochs=self.opt.nEpochs, steps_per_epoch=len(self.trainGen.data)//self.trainGen.batch_size, callbacks=callbacks_list, verbose=0);\n",
    "        self.model.fit(self.x,self.y, epochs=self.opt.nEpochs, steps_per_epoch=len(self.x)//5, callbacks=callbacks_list, verbose=0);\n",
    "\n",
    "    def GetLR(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.curEpoch = 0;\n",
    "        self.curLr = opt.LR;\n",
    "        self.cur_epoch_start_time = time.time();\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.curEpoch = epoch+1;\n",
    "        self.curLr = Trainer(self.opt).GetLR(epoch+1);\n",
    "        self.cur_epoch_start_time = time.time();\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_time = time.time() - self.cur_epoch_start_time;\n",
    "        self.load_test_data();\n",
    "        val_acc, val_loss = self.validate(self.model);\n",
    "        logs['val_acc'] = val_acc;\n",
    "        logs['val_loss'] = val_loss;\n",
    "        if val_acc > self.bestAcc:\n",
    "            self.bestAcc = val_acc;\n",
    "            self.bestAccEpoch = epoch + 1;\n",
    "        epoch_time = time.time() - self.cur_epoch_start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        # print(logs);\n",
    "        line = 'SP-{}, Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.split, epoch+1, self.opt.nEpochs, to_hms(epoch_time), to_hms(train_time), to_hms(val_time),\n",
    "            self.curLr, logs['loss'], logs['accuracy'] if 'accuracy' in logs else logs['acc'], val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if self.testX is None:\n",
    "            data = np.load(test_data, allow_pickle=True);\n",
    "            self.testX = data['x'];\n",
    "            self.testY = data['y'];\n",
    "\n",
    "    def validate(self, model):\n",
    "        y_pred = None;\n",
    "        y_target = None;\n",
    "        batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "        for batchIndex in range(math.ceil(len(self.testX) / batch_size)):\n",
    "            x = self.testX[batchIndex*batch_size : (batchIndex+1)*batch_size];\n",
    "            y = self.testY[batchIndex*batch_size : (batchIndex+1)*batch_size];\n",
    "            scores = model.predict(x, batch_size=len(y), verbose=0);\n",
    "            y_pred = scores if y_pred is None else np.concatenate((y_pred, scores));\n",
    "            y_target = y if y_target is None else np.concatenate((y_target, y));\n",
    "            #break;\n",
    "\n",
    "        acc, loss = self.compute_accuracy(y_pred, y_target);\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        #Reshape y_pred to shape it like each sample comtains 10 samples.\n",
    "        if self.opt.nCrops > 1:\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(axis=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(axis=1);\n",
    "\n",
    "        loss = keras.losses.KLD(y_target, y_pred).numpy().mean();\n",
    "\n",
    "        #Get the indices that has highest average value for each sample\n",
    "        y_pred = y_pred.argmax(axis=1);\n",
    "        y_target = y_target.argmax(axis=1);\n",
    "        accuracy = (y_pred==y_target).mean()*100;\n",
    "\n",
    "        return accuracy, loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "850b6e98-72d7-4b2b-88fd-8089bcffe06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "    \n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 5;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-2#9e-3;#5e-3;#5e-2;#1e-2;#5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 20;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     opt.device=\"mps\"; #for apple m2 gpu\n",
    "    # elif torch.cuda.is_available():\n",
    "    #     opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    # else:\n",
    "    opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 2#50;\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.TLAcdnetConfig = [8,64,32,64,64,128,128,256,256,512,512,2];\n",
    "    return opt\n",
    "    # opt = parser.parse_args();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57e9ac1f-c731-42aa-adac-1e03da9a3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    map_dict_train = {\n",
    "        52:1, #alarm\n",
    "        99:2, #other_sounds\n",
    "    };\n",
    "    opt = getOpts()\n",
    "    opt.model_name = \"retrain_pruned_tfmodel_cp_weights\"\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    opt.trainData=\"../datasets/forOneClassModel_alarm/train/trainSet_20240119002902.npz\";\n",
    "    opt.testData=\"../datasets/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz\";\n",
    "    trainer = Trainer(net=tf_net, opt=opt,classes_dict=map_dict_train)\n",
    "    trainer.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2cbbbfe4-8671-41f8-ad31-9a9f56824cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Use device:cpu\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 3 is out of bounds for array of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[134], line 13\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39mtrainData\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/forOneClassModel_alarm/train/trainSet_20240119002902.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m;\n\u001b[1;32m     12\u001b[0m opt\u001b[38;5;241m.\u001b[39mtestData\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m;\n\u001b[0;32m---> 13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclasses_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_dict_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mTrain()\n",
      "Cell \u001b[0;32mIn[132], line 13\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, net, opt, classes_dict)\u001b[0m\n\u001b[1;32m     11\u001b[0m     tmp_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tmp_x)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     tmp_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(tmp_x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[0;32m---> 13\u001b[0m     tmp_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     14\u001b[0m     input_x\u001b[38;5;241m.\u001b[39mappend(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(tmp_x))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m input_x\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/numpy/lib/shape_base.py:597\u001b[0m, in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    594\u001b[0m     axis \u001b[38;5;241m=\u001b[39m (axis,)\n\u001b[1;32m    596\u001b[0m out_ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis) \u001b[38;5;241m+\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m--> 597\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_axis_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_ndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m shape_it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    600\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(shape_it) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out_ndim)]\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/numpy/core/numeric.py:1380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001b[39;00m\n\u001b[0;32m-> 1380\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([normalize_axis_index(ax, ndim, argname) \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis])\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(axis)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis):\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argname:\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 3"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534933d-b055-489f-95a4-63c2449d2989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d38846e0-e970-44b9-aff7-28eb6b9d1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.load(train_data, allow_pickle=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd188630-c15a-4f99-a32b-83165856cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dt['fold1'].item()['sounds'])\n",
    "listdt = [list(dt['fold1'].item()['sounds'][i]) for i in range(len(dt['fold1'].item()['sounds']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5862bb59-8505-4300-9778-e78a5b1ae665",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = random_scale(1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a228854b-8e57-42f6-9094-eb44fec034b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: [0.00000000e+00 1.23348739e+00 2.46697479e+00 ... 9.99951225e+04\n",
      " 9.99963560e+04 9.99975895e+04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-100, -177, -185, ...,  134, -239,  243], dtype=int16)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(np.asarray(listdt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682fb9e-e4bd-4762-8497-2b111c04076f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
