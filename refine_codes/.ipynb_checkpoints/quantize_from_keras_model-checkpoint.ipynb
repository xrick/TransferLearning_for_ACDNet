{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eea6844-279b-4304-9bcf-79287652f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a98c06-d390-4260-af3e-fd808278c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../deployment/\"))\n",
    "sys.path.append(os.path.abspath(\"../common/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3de59e-a0db-4ab8-9791-4ba690bfa843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib_home import bytes,constants,quantize\n",
    "from results import *\n",
    "# from  data_loader import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bacca4-5475-4583-b0ec-7b907dd1ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import for data generator\n",
    "import common.utils as U;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d8117-23f9-41f9-914a-3d09497b1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d016f94-c32d-430b-8a97-a0245e0f8aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0556c27-38bb-4e1c-ab98-d5d15ac071fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526e5f2b-2104-40be-a128-83ad2e41c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "    \n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 64;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-2#9e-3;#5e-3;#5e-2;#1e-2;#5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 1000;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 2#50;\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.TLAcdnetConfig = [8,64,32,64,64,128,128,256,256,512,512,2];\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc5165b-2f5f-4815-a45a-7f87a30adc6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: empty expression not allowed (2943723405.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.tflite_path = f'{dest_path}/retrain_pruned_model_{}.tflite'.gen\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: empty expression not allowed\n"
     ]
    }
   ],
   "source": [
    "class KerasConverter():\n",
    "  def __init__(self, model_file, dtype, dest_path, trainer:Trainer):\n",
    "    '''Initialise the Keras model converter'''\n",
    "\n",
    "    self.model_file = model_file\n",
    "    self.dtype = dtype\n",
    "    self.quant_support = quant_support[dtype]\n",
    "    self.tflite_path = f'{dest_path}/retrain_pruned_model_{}.tflite'.gen\n",
    "    self.cc_path = f'{dest_path}/model.cc'\n",
    "    self.h_path = f'{dest_path}/model.h'\n",
    "    self.trainer = trainer    \n",
    "\n",
    "      retrun\n",
    "  def load_model(self):\n",
    "    print(f'Loading model: {self.model_file}')\n",
    "    self.model = keras.models.load_model(self.model_file)\n",
    "  \n",
    "  def get_model_size(self):\n",
    "    '''Returns the input size and output size'''\n",
    "    return self.model.inputs[0].shape[-2], self.model.outputs[0].shape[-1]\n",
    "\n",
    "  def get_tf_summary(self):\n",
    "    '''Displays a model summary'''\n",
    "    stringlist = []\n",
    "    self.model.summary(print_fn=lambda x: stringlist.append(x))\n",
    "    short_model_summary = \"\\n\".join(stringlist)\n",
    "    return short_model_summary\n",
    "\n",
    "  def get_tflite_summary(self):\n",
    "    '''Displays a model summary'''\n",
    "    with tf.io.gfile.GFile(self.tflite_path, 'rb') as f:\n",
    "      model_content = f.read()\n",
    "        \n",
    "    interpreter = tf.lite.Interpreter(model_content = model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    return (interpreter.get_tensor_details(), \\\n",
    "      interpreter._get_ops_details())\n",
    "\n",
    "  def get_arena_size(self):\n",
    "    '''Returns the approx tensor_arena size'''\n",
    "    tensor_details, op_details = self.get_tflite_summary()\n",
    "\n",
    "    get_tensor = lambda index : [t for t in tensor_details if t['index'] == index][0]\n",
    "    get_node_tensors = lambda n : [get_tensor(t) for t in np.concatenate((n['inputs'],n['outputs']), axis= None)]    \n",
    "    get_tensor_size = lambda t : np.prod(t['shape']) * np.dtype(t['dtype']).itemsize\n",
    "    get_node_tensor_sizes = lambda o : np.sum([get_tensor_size(t) for t in get_node_tensors(o)])   \n",
    "    get_max_node_size = lambda : np.max([get_node_tensor_sizes(o) for o in op_details])\n",
    "\n",
    "    return get_max_node_size() \n",
    "\n",
    "  def get_input_data(self):\n",
    "    '''Retrieves the input data set'''\n",
    "    x,y = self.trainer.testX, self.trainer.testY\n",
    "    return x, y\n",
    "\n",
    "  def get_cast_input_data(self, dtype = None):\n",
    "    '''Retrieves the input data set, casting to target dtype'''\n",
    "    x, y = self.get_input_data()\n",
    "\n",
    "    if dtype is None:\n",
    "      print('dtype not provided')\n",
    "      return x,y   \n",
    "    return get_cast(dtype)(x, axis = -2), y\n",
    "  \n",
    "  def get_rep_data(self, dtype = None):\n",
    "    '''Retrieves the reprepresentative data set'''\n",
    "    x, y = self.trainer.trainX, self.trainer.trainY\n",
    "\n",
    "    if dtype is None:\n",
    "      return x,y\n",
    "    return get_cast(dtype)(x, axis=-2), y\n",
    "\n",
    "  def evaluate_accuracy(self, y_pred, y_target, crops = 1):\n",
    "    '''A common accuracy operation which supports multi-crop'''\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0]//crops, crops, y_pred.shape[1])\n",
    "    y_target = y_target.reshape(y_target.shape[0]//crops, crops, y_target.shape[1])\n",
    "\n",
    "    #Calculate the average of class predictions for 10 crops of a sample\n",
    "    y_pred = np.mean(y_pred, axis=1)\n",
    "    y_target = np.mean(y_target,axis=1)\n",
    "\n",
    "    #Get the indices that has highest average value for each sample\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    y_target = y_target.argmax(axis=1)\n",
    "\n",
    "    accuracy = (y_pred==y_target).mean()\n",
    "    return accuracy\n",
    "\n",
    "  def predict_tf(self, x_data):\n",
    "    '''Calculate the output of a single inference of the TF model'''\n",
    "    x = tf.expand_dims(x_data, 0).numpy()\n",
    "    return self.model.predict([x])\n",
    "\n",
    "  def get_tf_accuracy(self, crops = 1):\n",
    "    '''Calculate accuracy of the TF model'''\n",
    "    x_data, y_data = self.get_input_data()\n",
    "\n",
    "    y_pred = self.model.predict([x_data])\n",
    "\n",
    "    accuracy = self.evaluate_accuracy(y_pred, y_data, crops)\n",
    "    return accuracy, y_pred, y_data\n",
    "\n",
    "  def predict_tflite(self, x_data):\n",
    "    '''Calculate output of single inference of the TFLite model'''\n",
    "    with tf.io.gfile.GFile(self.tflite_path, 'rb') as f:\n",
    "      model_content = f.read()\n",
    "        \n",
    "    interpreter = tf.lite.Interpreter(model_content = model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    input_dtype = interpreter.get_input_details()[0]['dtype']\n",
    "    x = get_cast(input_dtype)(x_data, axis=-2)\n",
    "\n",
    "    interpreter.set_tensor(input_index, x)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    return interpreter.get_tensor(output_index)[0]\n",
    "\n",
    "  def get_tflite_accuracy(self, crops = 1):\n",
    "    '''Calculate the accuracy of the TFLite model'''\n",
    "    with tf.io.gfile.GFile(self.tflite_path, 'rb') as f:\n",
    "      model_content = f.read()\n",
    "        \n",
    "    interpreter = tf.lite.Interpreter(model_content = model_content)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    input_dtype = interpreter.get_input_details()[0]['dtype']\n",
    "    print(f'Input dtype {str(input_dtype)}')\n",
    "\n",
    "    x_data, y_data = self.get_cast_input_data(input_dtype)\n",
    "\n",
    "    def predict(x_input):\n",
    "      \n",
    "      x_input = tf.expand_dims(x_input, 0).numpy()\n",
    "      interpreter.set_tensor(input_index, x_input)\n",
    "      # Run inference.\n",
    "      interpreter.invoke()\n",
    "      return interpreter.get_tensor(output_index)[0]\n",
    "    \n",
    "    y_pred = np.array([predict(x) for x in x_data])\n",
    "    print(y_pred.shape)\n",
    "    print(y_data.shape)\n",
    "    accuracy = self.evaluate_accuracy(y_pred, y_data, crops)\n",
    "    return accuracy, y_pred, y_data  \n",
    "\n",
    "  def generate_tflite(self):\n",
    "    '''Generates a TFLite file from a Keras model'''\n",
    "\n",
    "    # Construction of a TFLite converter\n",
    "    tf_converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "    \n",
    "    tf_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    if 'supported_ops' in self.quant_support:\n",
    "      print(f'Targetting Supported Ops {self.quant_support[\"supported_ops\"]}')\n",
    "      tf_converter.target_spec.supported_ops = self.quant_support['supported_ops']\n",
    "\n",
    "    if 'supported_types' in self.quant_support:\n",
    "      print(f'Targetting Supported Types{self.quant_support[\"supported_types\"]}')\n",
    "      tf_converter.target_spec.supported_types = self.quant_support['supported_types']\n",
    "\n",
    "    if 'input_type' in self.quant_support:\n",
    "      print(f'Targetting input type : {self.quant_support[\"input_type\"]}')\n",
    "      tf_converter.inference_input_type = self.quant_support['input_type']\n",
    "\n",
    "    if 'output_type' in self.quant_support:\n",
    "      print(f'Targetting output type : {self.quant_support[\"output_type\"]}')\n",
    "      tf_converter.inference_output_type = self.quant_support['output_type']\n",
    "\n",
    "    # Supplying a representative dataset is required for full integer \n",
    "    # quantization, and also avoids dynamic range quantization\n",
    "\n",
    "    rep_data, _ = self.get_rep_data(None)\n",
    "    print(f'Representative dataset dtype : {rep_data.dtype}')\n",
    "\n",
    "    def representative_dataset_no_padding():\n",
    "      for i in range(len(rep_data)):\n",
    "        if rep_data[i:i+1,:,0,:] != 0 and rep_data[i:i+1,:,-1,:] != 0:\n",
    "          yield([rep_data[i:i+1,:,:,:]])\n",
    "\n",
    "    def representative_dataset():\n",
    "      for i in range(len(rep_data)):\n",
    "        yield([rep_data[i:i+1,:,:,:]])\n",
    "\n",
    "    tf_converter.representative_dataset = representative_dataset\n",
    "\n",
    "    tflite_model = tf_converter.convert()\n",
    "    bytes_written = open(self.tflite_path, 'wb').write(tflite_model)\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    input_type = interpreter.get_input_details()[0]['dtype']\n",
    "    output_type = interpreter.get_output_details()[0]['dtype']\n",
    "\n",
    "    print('TFLite input dtype : ', input_type)\n",
    "    print('TFLite output dtype : ', output_type)\n",
    "    \n",
    "    return bytes_written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a79423d-c859-48b1-a57f-30ea3c894b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, opt=None):\n",
    "        self.opt = opt;\n",
    "        self.trainX = None;\n",
    "        self.trainY = None;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "\n",
    "    def load_training_data(self):\n",
    "        if self.trainX is None:\n",
    "            print('Loading training/calibration data');\n",
    "            #Loading all the 1600 samples to train one epoch at once.\n",
    "            self.opt.sr = 20000;\n",
    "            self.opt.inputLength = 30225;\n",
    "            self.opt.batchSize = len(self.trainX);\n",
    "            trainGen = train_generator.setup(self.opt, self.opt.split);\n",
    "            self.trainX, self.trainY = trainGen.__getitem__(0);\n",
    "            print('Done');\n",
    "\n",
    "            #Revert back the batch size settings to its original state\n",
    "            self.opt.batchSize = 64;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if self.testX is None:\n",
    "            print('Loading test data');\n",
    "            data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_20khz/fold{}_test4000.npz'.format(self.opt.split)), allow_pickle=True);\n",
    "            self.testX = data['x'];\n",
    "            self.testY = data['y'];\n",
    "            print('Done');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9562c0f2-425a-438d-9cd3-7a8180055629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.utils.Sequence):\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;\n",
    "\n",
    "def setup(opt, split):\n",
    "    dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    for i in range(1, opt.nFolds + 1):\n",
    "        sounds = dataset['fold{}'.format(i)].item()['sounds']\n",
    "        labels = dataset['fold{}'.format(i)].item()['labels']\n",
    "        if i != split:\n",
    "            train_sounds.extend(sounds)\n",
    "            train_labels.extend(labels)\n",
    "\n",
    "    trainGen = Generator(train_sounds, train_labels, opt);\n",
    "\n",
    "    return trainGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c2b2b-bdeb-4843-a9cf-7a118f801a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = \"./keras_models/retrain_model.keras\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43035d2d-71f8-4e09-81f6-857655304368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts();\n",
    "    # converter = tf.lite.TFLiteConverter.from_keras_model(\"./keras_models/retrain_model.keras\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f46f9e-6cf5-4d4b-bdaa-1d93cb6b2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"./tensorflow_models/retrain_pruned_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7f2ed0-3dd4-46a2-b364-508b9d1f7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce949c-a5b7-44b8-b732-ada9adfec4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
