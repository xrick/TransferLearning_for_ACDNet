{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d442e42-ec55-4a3c-9680-d92c03c3708e",
   "metadata": {},
   "source": [
    "## 說明：\n",
    "總共要產生三種訓練集\n",
    "- 訓練集\n",
    "- 驗證集\n",
    "- 測試集   \n",
    "其中驗證集及測試集要經二階段建立。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b43e22-a14e-4616-9395-089442614d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "import wavio\n",
    "import time;\n",
    "import random;\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47433362-b1e4-4057-8236-5bd8bb0a06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.tlopts import display_info;\n",
    "import common.utils as U;\n",
    "from Libs.SharedLibs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ba8dc0-57b0-47d0-977a-7ca912373e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a6f93d-6756-4598-a62d-b96a40213ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b13ad-e5ff-40ec-bbe4-76e9e2b90107",
   "metadata": {},
   "source": [
    "## Global Shared Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a480da-6a06-41b4-939b-80769ef1dbe5",
   "metadata": {},
   "source": [
    "### define sounds sources folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dc9e11-f919-4e96-bee6-233091608bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_positive_sounds_src = \"../datasets/forOneClassModel_alarm/train/alarm/\"\n",
    "training_negative_sounds_src = \"../datasets/forOneClassModel_alarm/train/other_sounds/\"\n",
    "val_positive_sounds_src = \"../datasets/forOneClassModel_alarm/test_val/alarm/\"\n",
    "val_negative_sounds_src = \"../datasets/forOneClassModel_alarm/test_val/other_sounds/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973e8de-0a88-44ed-a704-f51a35c96585",
   "metadata": {},
   "source": [
    "### define save pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad3a46b-2b1e-4bd4-bd78-319afb31da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_npz = \"../datasets/forOneClassModel_alarm/train/trainSet_{}.npz\"\n",
    "val_src_npz = \"../datasets/forOneClassModel_alarm/test_val/src_npz/val_src.npz\"\n",
    "final_val_npz = \"../datasets/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_{}.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3de44-0bb6-4b10-8466-b33083ea3f43",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4bd881-4b5f-4e11-8b08-99a3fc41d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolderList(rootDir=None, recursive=False):\n",
    "    if not recursive:\n",
    "        return next(os.walk(rootDir));\n",
    "    else:\n",
    "        return [x[0] for x in os.walk(rootDir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94453b4-50a9-47b0-b755-30e2bc278b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate opt files for data preparation\n",
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "\n",
    "    \"\"\"\n",
    "    current best setting for accuracy: 96.5\n",
    "    opt.batchSize = 32;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-3;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.schedule = [0.3, 0.5, 0.9];\n",
    "    \"\"\"\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 32;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-3;#1e-2;#5e-3;#5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 800;\n",
    "    opt.schedule = [0.3, 0.5, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 2#50;\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.TLAcdnetConfig = [8,64,32,64,64,128,128,256,256,512,512,2];\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33ad2bd-b23b-4704-9426-23b17a18f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f51b349-dbc7-4d35-b8ee-76b51362593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGetSoundsAndLabels(srcDir):\n",
    "    wav_list = getFileList(srcDir)\n",
    "    return wav_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8b71bb-d9cf-47e0-8a72-d73e7f1aaeed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getMp3List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget all wavs in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_positive_sounds_src\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtestGetSoundsAndLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_positive_sounds_src\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mtestGetSoundsAndLabels\u001b[0;34m(srcDir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtestGetSoundsAndLabels\u001b[39m(srcDir):\n\u001b[0;32m----> 2\u001b[0m     wav_list \u001b[38;5;241m=\u001b[39m \u001b[43mgetFileList\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrcDir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wav_list\n",
      "File \u001b[0;32m~/WorkSpaces/Work/Projects/TransferLearning_for_ACDNet/Libs/SharedLibs.py:11\u001b[0m, in \u001b[0;36mgetFileList\u001b[0;34m(srcDir, regex)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(srcDir, file)):\n\u001b[0;32m---> 11\u001b[0m         out_files \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mgetMp3List\u001b[49m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(srcDir, file))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(regex, file,  re\u001b[38;5;241m.\u001b[39mI):  \u001b[38;5;66;03m# file.startswith(startExtension) or file.endswith(\".txt\") or file.endswith(endExtension):\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         out_files\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(srcDir, file))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getMp3List' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"get all wavs in {training_positive_sounds_src}:\\n {testGetSoundsAndLabels(training_positive_sounds_src)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895e211-eff5-4f82-ab58-e4532b962e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(src_path, dst_path, classes_dict):\n",
    "    # print('* {} -> {}'.format(src_path, dst_path))\n",
    "    my_dataset = {};\n",
    "    print(f\"--Start to preparing training dataset...---------------\");\n",
    "    my_dataset['fold1'] = {}\n",
    "    my_sounds = []\n",
    "    my_labels = []\n",
    "    wav_list = None\n",
    "    for k in classes_dict:\n",
    "        if k == 52:\n",
    "            cur_src_dir = os.path.join(src_path,classes_dict[k]);\n",
    "            wav_list = getFileList(cur_src_dir);\n",
    "        elif k == 99:\n",
    "            cur_src_dir = os.path.join(src_path,classes_dict[k]);\n",
    "            wav_list = getFileList(cur_src_dir);\n",
    "        # print(wav_list)\n",
    "        # print(f\"current source directory:{cur_src_dir}\");\n",
    "        for wav_file in wav_list:\n",
    "            sound = wavio.read(wav_file).data.T[0]\n",
    "            start = sound.nonzero()[0].min()\n",
    "            end = sound.nonzero()[0].max()\n",
    "            sound = sound[start: end + 1]  # Remove silent sections\n",
    "            label = int(k);#int(os.path.splitext(wav_file)[0].split('-')[-1])\n",
    "            my_sounds.append(sound)\n",
    "            my_labels.append(k)\n",
    "            print(f\"sound:{os.path.basename(wav_file)} is chopped:\\n   lable:{k}\\n   from {start} to {end} \\n   len:{(end-start)/20000}\\n\");\n",
    "            # print(f\"sound:{wav_file}\\nlabel:{k}\") \n",
    "    print(f\"--End of preparing training dataset-------------------\");\n",
    "\n",
    "    my_dataset['fold1']['sounds'] = my_sounds\n",
    "    my_dataset['fold1']['labels'] = my_labels\n",
    "    npzname = dst_path.format(genDataTimeStr());\n",
    "    np.savez(npzname, **my_dataset)\n",
    "    print(f\"npz file:{npzname}\")a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
