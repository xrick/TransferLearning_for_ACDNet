{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126f46d8-90a4-4912-aa26-5e326147c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecdf211-aa91-458a-8ccb-bcca4b7f6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras;\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b06004-f53a-45a8-9d5a-d9b500d0c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbf4ce8-8ef5-4947-8374-cc77331f7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import time;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1b827ff-643e-4996-8835-128acdb55ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/alibaba/TinyNeuralNetwork.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dd90ce9-9be0-465a-9057-3dfecdf11ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "sys.path.append(os.path.abspath(\"../common/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c68bea9-a8b3-428b-8315-04538943f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from th.resources import calculator as calc\n",
    "from th.resources import models as acdnet_torch_models\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d292f49b-49da-4592-b7b2-26cef8e3b0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tinynn.converter import TFLiteConverter\n",
    "from tinynn.graph.quantization.quantizer import PostQuantizer\n",
    "from tinynn.graph.tracer import model_tracer\n",
    "from tinynn.util.cifar10 import get_dataloader, calibrate\n",
    "from tinynn.util.train_util import DLContext, get_device\n",
    "from tinynn.graph.quantization.algorithm.cross_layer_equalization import cross_layer_equalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63eb9c-31ff-4d3a-abb6-60b6a9c809e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de1d498d-7b8e-42d3-880c-ed662c2b3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "keras_model_path = \"./keras_models/retrain_pruned_cp_weights.h5\"\n",
    "retrain_src_model_path = \"./retrained_models_after_pruned/retrained_model_20240124123209_acc_95.45455169677734_795th_epoch.pt\"\n",
    "quanted_torch_model_path = \"../th/quantized_models/quant_retrained_model_94.3_20240124111811.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2aa665a-9629-4013-a84a-344f639354e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = keras.models.load_model(keras_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5abf5866-e724-4b1c-8a2c-d08673bb3260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 30225, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1, 15109, 5)       45        \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 1, 15109, 5)       20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 1, 15109, 5)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 7553, 32)       800       \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 1, 7553, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 1, 7553, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 1, 151, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " permute_1 (Permute)         (None, 32, 151, 1)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 151, 9)        81        \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 32, 151, 9)        36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 32, 151, 9)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 75, 9)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 75, 16)        1296      \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 16, 75, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_15 (ReLU)             (None, 16, 75, 16)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 16, 75, 23)        3312      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 16, 75, 23)        92        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_16 (ReLU)             (None, 16, 75, 23)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 8, 37, 23)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 37, 33)         6831      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 8, 37, 33)         132       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_17 (ReLU)             (None, 8, 37, 33)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 37, 29)         8613      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 8, 37, 29)         116       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_18 (ReLU)             (None, 8, 37, 29)         0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 4, 18, 29)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 18, 56)         14616     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 4, 18, 56)         224       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             (None, 4, 18, 56)         0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 18, 47)         23688     \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 4, 18, 47)         188       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 4, 18, 47)         0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 2, 9, 47)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 2, 9, 65)          27495     \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 2, 9, 65)          260       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 2, 9, 65)          0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 2, 9, 90)          52650     \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 2, 9, 90)          360       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 2, 9, 90)          0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 1, 4, 90)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 4, 90)          0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 4, 2)           180       \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 1, 4, 2)           8         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 1, 4, 2)           0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 2)           0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141241 (551.72 KB)\n",
      "Trainable params: 140427 (548.54 KB)\n",
      "Non-trainable params: 814 (3.18 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e37f2be-ed1e-423f-82c7-ee7029bf39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn((1, 1, 30225,1));\n",
    "test_input = torch.Tensor.numpy(test_input)\n",
    "test_input = tf.convert_to_tensor(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2b18c14-885b-4014-ac03-8297091f2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "res = keras_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03863c5d-9f69-4fe3-8afc-013a10f0532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045bab5a-22f0-4eb7-b502-7a49780d626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(retrain_src_model_path, map_location=device)\n",
    "config = state['config']\n",
    "torch_weights = state['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf67d946-ddb7-48e6-876e-ac901526e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 32, 9, 16, 23, 33, 29, 56, 47, 65, 90, 2]\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3854f205-a396-4e2f-baf7-89e8823fe415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model = acdnet_torch_models.GetACDNetModel(nclass=2,channel_config=config)\n",
    "quanted_model = acdnet_torch_models.GetACDNetQuantModel(nclass=2,channel_config=config)\n",
    "quanted_model.load_state_dict(state['weight'])\n",
    "pruned_model.load_state_dict(state['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9c54d45-6d4e-40ba-8d84-ad8037e6b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (5, 1, 15109)         45      679,905\n",
      "  BatchNorm2d-2     (5, 1, 15109)     (5, 1, 15109)         10            0\n",
      "         ReLu-3     (5, 1, 15109)     (5, 1, 15109)          0       75,545\n",
      "       Conv2d-4     (5, 1, 15109)     (32, 1, 7553)        800    6,042,400\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)      (9, 32, 151)         81      391,392\n",
      " BatchNorm2d-10      (9, 32, 151)      (9, 32, 151)         18            0\n",
      "        ReLu-11      (9, 32, 151)      (9, 32, 151)          0       43,488\n",
      "   MaxPool2d-12      (9, 32, 151)       (9, 16, 75)          0       43,200\n",
      "      Conv2d-13       (9, 16, 75)      (16, 16, 75)      1,296    1,555,200\n",
      " BatchNorm2d-14      (16, 16, 75)      (16, 16, 75)         32            0\n",
      "        ReLu-15      (16, 16, 75)      (16, 16, 75)          0       19,200\n",
      "      Conv2d-16      (16, 16, 75)      (23, 16, 75)      3,312    3,974,400\n",
      " BatchNorm2d-17      (23, 16, 75)      (23, 16, 75)         46            0\n",
      "        ReLu-18      (23, 16, 75)      (23, 16, 75)          0       27,600\n",
      "   MaxPool2d-19      (23, 16, 75)       (23, 8, 37)          0       27,232\n",
      "      Conv2d-20       (23, 8, 37)       (33, 8, 37)      6,831    2,021,976\n",
      " BatchNorm2d-21       (33, 8, 37)       (33, 8, 37)         66            0\n",
      "        ReLu-22       (33, 8, 37)       (33, 8, 37)          0        9,768\n",
      "      Conv2d-23       (33, 8, 37)       (29, 8, 37)      8,613    2,549,448\n",
      " BatchNorm2d-24       (29, 8, 37)       (29, 8, 37)         58            0\n",
      "        ReLu-25       (29, 8, 37)       (29, 8, 37)          0        8,584\n",
      "   MaxPool2d-26       (29, 8, 37)       (29, 4, 18)          0        8,352\n",
      "      Conv2d-27       (29, 4, 18)       (56, 4, 18)     14,616    1,052,352\n",
      " BatchNorm2d-28       (56, 4, 18)       (56, 4, 18)        112            0\n",
      "        ReLu-29       (56, 4, 18)       (56, 4, 18)          0        4,032\n",
      "      Conv2d-30       (56, 4, 18)       (47, 4, 18)     23,688    1,705,536\n",
      " BatchNorm2d-31       (47, 4, 18)       (47, 4, 18)         94            0\n",
      "        ReLu-32       (47, 4, 18)       (47, 4, 18)          0        3,384\n",
      "   MaxPool2d-33       (47, 4, 18)        (47, 2, 9)          0        3,384\n",
      "      Conv2d-34        (47, 2, 9)        (65, 2, 9)     27,495      494,910\n",
      " BatchNorm2d-35        (65, 2, 9)        (65, 2, 9)        130            0\n",
      "        ReLu-36        (65, 2, 9)        (65, 2, 9)          0        1,170\n",
      "      Conv2d-37        (65, 2, 9)        (90, 2, 9)     52,650      947,700\n",
      " BatchNorm2d-38        (90, 2, 9)        (90, 2, 9)        180            0\n",
      "        ReLu-39        (90, 2, 9)        (90, 2, 9)          0        1,620\n",
      "   MaxPool2d-40        (90, 2, 9)        (90, 1, 4)          0        1,440\n",
      "      Conv2d-41        (90, 1, 4)         (2, 1, 4)        180          720\n",
      " BatchNorm2d-42         (2, 1, 4)         (2, 1, 4)          4            0\n",
      "        ReLu-43         (2, 1, 4)         (2, 1, 4)          0            8\n",
      "   AvgPool2d-44         (2, 1, 4)         (2, 1, 1)          0            8\n",
      "     Flatten-45         (2, 1, 1)            (1, 2)          0            0\n",
      "      Linear-46            (1, 2)            (1, 2)          6            6\n",
      "     Softmax-47            (1, 2)            (1, 2)          0            2\n",
      "==============================================================================\n",
      "Total Params: 140,427\n",
      "Total FLOPs : 22,177,258\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.54\n",
      "Total size (MB) : 0.65\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calc.summary(pruned_model, (1,1,30225));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7898be-8adb-4d46-92d9-286c08b93c97",
   "metadata": {},
   "source": [
    "# TinyNeuralNetwork provides a PostQuantizer class that may rewrite the graph for and perform model fusion for\n",
    "        # quantization. The model returned by the `quantize` function is ready for quantization calibration.\n",
    "        # By default, the rewritten model (in the format of a single file) will be generated in the working directory.\n",
    "        # You may also pass some custom configuration items through the argument `config` in the following line. For\n",
    "        # example, if you have a quantization-rewrite-ready model (e.g models in torchvision.models.quantization),\n",
    "        # then you may use the following line.\n",
    "        #   quantizer = PostQuantizer(model, dummy_input, work_dir='out', config={'rewrite_graph': False})\n",
    "        # Alternatively, if you have modified the generated model description file and want the quantizer to load it\n",
    "        # instead, then use the code below.\n",
    "        #     quantizer = PostQuantizer(\n",
    "        #         model, dummy_input, work_dir='out', config={'force_overwrite': False, 'is_input_quantized': None}\n",
    "        #     )\n",
    "        # The `is_input_quantized` in the previous line is a flag on the input tensors whether they are quantized or\n",
    "        # not, which can be None (False for all inputs) or a list of booleans that corresponds to the inputs.\n",
    "        # Also, we support multiple qschemes for quantization preparation. There are several common choices.\n",
    "        #   a. Asymmetric uint8. (default) config={'asymmetric': True, 'per_tensor': True}\n",
    "        #      The is the most common choice and also conforms to the legacy TFLite quantization spec.\n",
    "        #   b. Asymmetric int8. config={'asymmetric': True, 'per_tensor': False}\n",
    "        #      The conforms to the new TFLite quantization spec. In legacy TF versions, this is usually used in post\n",
    "        #      quantization. Compared with (a), it has support for per-channel quantization in supported kernels\n",
    "        #      (e.g Conv), while (a) does not.\n",
    "        #   c. Symmetric int8. config={'asymmetric': False, 'per_tensor': False}\n",
    "        #      The is same to (b) with no offsets, which may be used on some low-end embedded chips.\n",
    "        #   d. Symmetric uint8. config={'asymmetric': False, 'per_tensor': True}\n",
    "        #      The is same to (a) with no offsets. But it is rarely used, which just serves as a placeholder here.\n",
    "        # In addition, we support additional ptq algorithms including kl-divergence, the usage is shown as below:\n",
    "        #       quantizer = PostQuantizer(model, dummy_input, work_dir='out', config={'algorithm': 'kl'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a151a0f-1cfe-4e26-8f19-a04ffcebefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dummy_input = torch.randn((1, 1, 1, 30225));\n",
    "quant_config = {'asymmetric': True, 'per_tensor': False, 'rewrite_graph': False, 'force_overwrite': False,\n",
    "                'is_input_quantized': None, 'algorithm': 'kl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afe893c3-ba7a-4c69-a3ef-5ec49490ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = PostQuantizer(pruned_model, dummy_input=torch_dummy_input, work_dir=\"../th/quantized_models/\", config=quant_config)\n",
    "        #         model, dummy_input, work_dir='out', config={'force_overwrite': False, 'is_input_quantized': None}\n",
    "        #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45051911-a3c8-433e-8d79-212e590760b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptq_model = quantizer.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6a2854f-ccc9-4b1f-ad17-7b9d750fbc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACDNetV2(\n",
       "  (sfeb): Sequential(\n",
       "    (0): Conv2d(1, 5, kernel_size=(1, 9), stride=(1, 2), bias=False)\n",
       "    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(5, 32, kernel_size=(1, 5), stride=(1, 2), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=(1, 50), stride=(1, 50), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (tfeb): Sequential(\n",
       "    (0): Conv2d(1, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(16, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(23, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (12): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(33, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(29, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (19): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(56, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (22): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU()\n",
       "    (24): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (25): Conv2d(47, 65, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (26): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU()\n",
       "    (28): Conv2d(65, 90, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (29): BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU()\n",
       "    (31): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (32): Dropout(p=0.2, inplace=False)\n",
       "    (33): Conv2d(90, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (34): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU()\n",
       "    (36): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
       "    (37): Flatten(start_dim=1, end_dim=-1)\n",
       "    (38): Linear(in_features=2, out_features=2, bias=True)\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "ptq_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291036ca-193f-4832-a245-de0817a60e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = DLContext()\n",
    "context.device = 'cpu'\n",
    "context.train_loader, context.val_loader = get_dataloader(args.data_path, 224, args.batch_size, args.workers)\n",
    "context.max_iteration = 100\n",
    "\n",
    "# Post quantization calibration\n",
    "calibrate(ptq_model, context)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ptq_model.eval()\n",
    "    ptq_model.cpu()\n",
    "\n",
    "    # The step below converts the model to an actual quantized model, which uses the quantized kernels.\n",
    "    ptq_model = quantizer.convert(ptq_model)\n",
    "\n",
    "    # When converting quantized models, please ensure the quantization backend is set.\n",
    "    torch.backends.quantized.engine = quantizer.backend\n",
    "\n",
    "    # The code section below is used to convert the model to the TFLite format\n",
    "    # If you need a quantized model with a specific data type (e.g. int8)\n",
    "    # you may specify `quantize_target_type='int8'` in the following line.\n",
    "    # If you need a quantized model with strict symmetric quantization check (with pre-defined zero points),\n",
    "    # you may specify `strict_symmetric_check=True` in the following line.\n",
    "    converter = TFLiteConverter(ptq_model, dummy_input, tflite_path='../th/quantized_models/final_quanted_model_{}'.format(gen))\n",
    "    converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bea44c-9d09-429c-a5e7-d215000c947f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb50d65-2b8b-424e-a191-5da9c7fa970d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3715d8b9-b2e4-473d-b923-607119a8030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.quantization.get_default_qconfig('qnnpack')\n",
    "# quanted_torhch_state = torch.jit.load(quanted_torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07ab2339-3264-493f-8b2e-e9b2c33f2a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cac95-8dd2-408d-829f-fcec95532471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
