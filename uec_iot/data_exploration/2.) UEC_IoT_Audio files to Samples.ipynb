{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool converts a folder of samples to a big rectangular matrix with one mono sample per row.\n",
    "\n",
    "Samples should be placed in `data/mydataset/samples/`. They could be `.mp3`, `.wav`, or anything else that ffmpeg can work with. They may be all in one folder, or in nested sub-folders.\n",
    "\n",
    "Change the path below to point to the root directory, e.g., `data/mydataset/`.\n",
    "\n",
    "The samplerate `sr` is not necessarily the native samplerate of the samples, it's the samplerate you want to load them at.\n",
    "\n",
    "The output of this notebook is:\n",
    "* `data/mydataset/durations.txt`\n",
    "* `data/mydataset/filenames.txt`\n",
    "* `data/mydataset/samples.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from utils import *\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "\n",
    "sampleRootDirectory = os.path.expanduser(\"~/Documents/Samples\")\n",
    "\n",
    "#The names of the drum classes\n",
    "drumNames = [\"kick\", \"tom\", \"snare\", \"clap\", \"hi.hat\", \"ride\", \"crash\"]\n",
    "\n",
    "\n",
    "#Collect all of the sample file paths as strings\n",
    "fileNames = []\n",
    "for directory in os.walk(sampleRootDirectory):\n",
    "    for file in directory[2]:\n",
    "        oldPath = directory[0]+\"/\"+file\n",
    "        #shutil.copyfile(oldPath, newPath)\n",
    "        if oldPath[-4:] == '.wav':\n",
    "            fileNames.append(oldPath)\n",
    "\n",
    "            \n",
    "# We assign classes to samples by using regular expressions to see \n",
    "# if the sample file path contains the class name\n",
    "\n",
    "        \n",
    "#From the drum class names, generate the regular expression used to match against sample file paths\n",
    "makeRegex = lambda drumStr : '.*'+\"\".join(map(lambda c : '['+c+c.upper()+']' if c.isalpha() else c, drumStr))+'.*'\n",
    "drumRegex = [makeRegex(drum) for drum in drumNames]\n",
    "\n",
    "\n",
    "#filter filenames into sets by matching vs regex\n",
    "drumFileSets = {}\n",
    "for i in range(len(drumNames)):\n",
    "    drumFileSets[drumNames[i]] = {fileName for fileName in fileNames if re.match(drumRegex[i], fileName)}\n",
    "    \n",
    "\n",
    "#check if any samples end up in more than 1 class\n",
    "intersections = []\n",
    "for i in range(len(drumNames)):\n",
    "    for j in range(i+1, len(drumNames)):\n",
    "        d1 = drumNames[i]\n",
    "        d2 = drumNames[j]\n",
    "        intersectionSet = drumFileSets[d1] & drumFileSets[d2]\n",
    "        if len(intersectionSet) > 0:\n",
    "            intersections.append([d1, d2, intersectionSet])\n",
    "            #print d1, d2, len(drumFileSets[d1]), len(drumFileSets[d2]), len(intersectionSet)\n",
    "\n",
    "#note - for some classes, this siginficantly reduces the number of samples\n",
    "for sect in intersections:\n",
    "    d1 = sect[0]\n",
    "    d2 = sect[1]\n",
    "    sectSet = sect[2]\n",
    "    drumFileSets[d1] = drumFileSets[d1] - sectSet\n",
    "    drumFileSets[d2] = drumFileSets[d2] - sectSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData'\n",
    "sr = 48000\n",
    "max_length = sr*4 # ignore samples longer than 4 seconds\n",
    "fixed_length = sr/4 # trim all samples to 250 milliseconds\n",
    "limit = None # set this to 100 to only load the first 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function to extract audio data from files\n",
    "def load_sample(fn, sr=None,\n",
    "                max_length=None, fixed_length=None, normalize=True):\n",
    "    if fn == '': # ignore empty filenames\n",
    "        return None\n",
    "    audio, _ = ffmpeg_load_audio(fn, sr, mono=True)\n",
    "    duration = len(audio)\n",
    "    if duration == 0: # ignore zero-length samples\n",
    "        return None\n",
    "    if max_length and duration >= max_length: # ignore long samples\n",
    "        return None\n",
    "    if fixed_length:\n",
    "        audio.resize(fixed_length)\n",
    "    max_val = np.abs(audio).max()\n",
    "    if max_val == 0: # ignore completely silent sounds\n",
    "        return None\n",
    "    if normalize:\n",
    "        audio /= max_val\n",
    "    return (fn, audio, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 195 ms, sys: 322 ms, total: 517 ms\n",
      "Wall time: 22.9 s\n",
      " Processed 5395 samples for  kick\n",
      "CPU times: user 18.9 ms, sys: 19.7 ms, total: 38.6 ms\n",
      "Wall time: 3.05 s\n",
      "Processed 529 samples for  tom\n",
      "CPU times: user 117 ms, sys: 135 ms, total: 252 ms\n",
      "Wall time: 12.8 s\n",
      "Processed 2563 samples for  snare\n",
      "CPU times: user 62.1 ms, sys: 53.7 ms, total: 116 ms\n",
      "Wall time: 6.74 s\n",
      "Processed 1332 samples for  clap\n",
      "CPU times: user 9.74 ms, sys: 8.73 ms, total: 18.5 ms\n",
      "Wall time: 880 ms\n",
      "Processed 167 samples for  hi.hat\n",
      "CPU times: user 15.4 ms, sys: 14 ms, total: 29.4 ms\n",
      "Wall time: 1.59 s\n",
      "Processed 250 samples for  ride\n",
      "CPU times: user 54.3 ms, sys: 43.1 ms, total: 97.4 ms\n",
      "Wall time: 7.01 s\n",
      "Processed 998 samples for  crash\n"
     ]
    }
   ],
   "source": [
    "# perform extraction of audio data from files\n",
    "drumSampleSets = {}\n",
    "for drumName in drumNames:\n",
    "    files = list(drumFileSets[drumName])\n",
    "    def job(fn):\n",
    "        return load_sample(fn, sr=sr,\n",
    "                           max_length=max_length, fixed_length=fixed_length)\n",
    "    pool = Pool()\n",
    "    %time drumSampleSets[drumName] = pool.map(job, files[:limit])\n",
    "    print 'Processed', len(drumSampleSets[drumName]), 'samples for ', drumName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.6 ms, sys: 310 ms, total: 320 ms\n",
      "Wall time: 423 ms\n",
      "Saved 5158 samples of kick\n",
      "CPU times: user 1e+03 µs, sys: 23.7 ms, total: 24.7 ms\n",
      "Wall time: 32.5 ms\n",
      "Saved 422 samples of tom\n",
      "CPU times: user 5.28 ms, sys: 146 ms, total: 152 ms\n",
      "Wall time: 196 ms\n",
      "Saved 2546 samples of snare\n",
      "CPU times: user 2.55 ms, sys: 73.9 ms, total: 76.5 ms\n",
      "Wall time: 89.9 ms\n",
      "Saved 1324 samples of clap\n",
      "CPU times: user 419 µs, sys: 7.82 ms, total: 8.24 ms\n",
      "Wall time: 14.7 ms\n",
      "Saved 159 samples of hi.hat\n",
      "CPU times: user 497 µs, sys: 11.4 ms, total: 11.9 ms\n",
      "Wall time: 19 ms\n",
      "Saved 228 samples of ride\n",
      "CPU times: user 1.51 ms, sys: 47.4 ms, total: 48.9 ms\n",
      "Wall time: 75.9 ms\n",
      "Saved 723 samples of crash\n"
     ]
    }
   ],
   "source": [
    "# save audio data as numpy arrays\n",
    "\n",
    "drumLengths = []\n",
    "\n",
    "for drumName in drumNames:\n",
    "    valid = filter(None, drumSampleSets[drumName])\n",
    "    filenames = [x[0] for x in valid]\n",
    "    samples = [x[1] for x in valid]\n",
    "    durations = [x[2] for x in valid]\n",
    "    samples = np.asarray(samples)\n",
    "    drumLengths.append(len(samples))\n",
    "    np.savetxt(join(data_root, drumName+'_filenames.txt'), filenames, fmt='%s')\n",
    "    np.savetxt(join(data_root, drumName+'_durations.txt'), durations, fmt='%i')\n",
    "    %time np.save(join(data_root, drumName+'_samples.npy'), samples)\n",
    "    print 'Saved', len(valid), 'samples of '+drumName\n",
    "\n",
    "pickle.dump(drumNames, open(data_root+\"/drumNames.pickle\", \"w\"))\n",
    "pickle.dump(drumLengths, open(data_root+\"/drumLengths.pickle\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
