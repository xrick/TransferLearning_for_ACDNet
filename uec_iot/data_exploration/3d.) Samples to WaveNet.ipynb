{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book uses the WaveNet autoencoder to encode audio samples into the bottleneck features. We use the open sourced Google Magenta model available for download through http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar. The output dimension per file is (23,16).\n",
    "\n",
    "Engel, Jesse, et al. \"Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders.\" arXiv preprint arXiv:1704.01279 (2017).\n",
    "https://arxiv.org/abs/1704.01279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lamtharnhantrakul/anaconda/envs/klustr/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/masked.py:116: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import umap\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet import fastgen\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_root = './drumData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audio matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 ms, sys: 334 ms, total: 336 ms\n",
      "Wall time: 496 ms\n",
      "CPU times: user 549 µs, sys: 25.7 ms, total: 26.3 ms\n",
      "Wall time: 47.5 ms\n",
      "CPU times: user 1.78 ms, sys: 166 ms, total: 168 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 1.46 ms, sys: 87.5 ms, total: 89 ms\n",
      "Wall time: 128 ms\n",
      "CPU times: user 1.01 ms, sys: 12.8 ms, total: 13.8 ms\n",
      "Wall time: 35.9 ms\n",
      "CPU times: user 1.73 ms, sys: 16.9 ms, total: 18.7 ms\n",
      "Wall time: 34.3 ms\n",
      "CPU times: user 926 µs, sys: 49.7 ms, total: 50.7 ms\n",
      "Wall time: 79.8 ms\n",
      "(5158, 12000)\n",
      "(422, 12000)\n",
      "(2546, 12000)\n",
      "(1324, 12000)\n",
      "(159, 12000)\n",
      "(228, 12000)\n",
      "(723, 12000)\n"
     ]
    }
   ],
   "source": [
    "drumNames = [\"kick\", \"tom\", \"snare\", \"clap\", \"hi.hat\", \"ride\", \"crash\"]\n",
    "drumFingerPrints = {}\n",
    "drumSamples = {}\n",
    "for d in drumNames:\n",
    "    %time drumSamples[d] = np.load(join(data_root, d+'_samples.npy'))\n",
    "for d in drumNames:\n",
    "    print (drumSamples[d].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test function for encoding based on wavenet model\n",
    "**We assume you will not be running the WaveNet model from this notebook**. This is because the encoding process takes over 12 hours for our sample set.\n",
    "\n",
    "The WaveNet model can be downloaded from\n",
    "http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def wavenet_encode(wave_files):\n",
    "  \n",
    "    encoding = fastgen.encode(wave_files, './wavenet-ckpt/model.ckpt-200000', 12000)\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n",
      "(5158, 12000)\n"
     ]
    }
   ],
   "source": [
    "crashes = drumSamples[\"crash\"]\n",
    "kicks = drumSamples[\"kick\"]\n",
    "\n",
    "sample_kick = kicks[0]\n",
    "sample_crash = crashes[0]\n",
    "print(sample_kick.shape)\n",
    "print(kicks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    }
   ],
   "source": [
    "# Encdoe one sample\n",
    "wavenet_kick = wavenet_encode(sample_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23, 16)\n",
      "15.8841\n",
      "-8.46548\n"
     ]
    }
   ],
   "source": [
    "# Check statistics of the embedding space\n",
    "print(wavenet_kick.shape)\n",
    "print(np.max(wavenet_kick))\n",
    "print(np.min(wavenet_kick))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode files using WaveNet\n",
    "The following code block executes the encoding process in parallel. ie, the full (159,12000) matrix is pushed into the model and an output of dimension of (159,23,16) is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('hi.hat', (159, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('ride', (228, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('crash', (723, 23, 16))\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into two groups: files that will take a really long time\n",
    "# to encode, and samples that will take a little shorted amount of time\n",
    "small_drumset = [\"tom\",\"hi.hat\", \"ride\", \"crash\"]\n",
    "large_drumset = [\"kick\", \"snare\", \"clap\"]\n",
    "\n",
    "for drum_name in small_drumset: \n",
    "    wavenet_features = wavenet_encode(drumSamples[drum_name])\n",
    "    print (drum_name, wavenet_features.shape)  \n",
    "    file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "    np.save(file_path, wavenet_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For samples with large numbers (>4000) it is impossible to load all samples in memory and push through the model. Thus, we looked at the magenta source-code and re-wrote the `encode()` function to process an audio file in smaller batches in our `custom_encode()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import Config\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import FastGenerationConfig\n",
    "\n",
    "def custom_encode(wav_data, checkpoint_path, drum_name, sample_length=64000):\n",
    "    batch_size = 1\n",
    "    samples_wavenet = []\n",
    "    num_samples = wav_data.shape[0]\n",
    "    # Load up the model for encoding and find the encoding of \"wav_data\"\n",
    "    session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Graph().as_default(), tf.Session(config=session_config) as sess:\n",
    "        hop_length = Config().ae_hop_length\n",
    "        net = testload_nsynth(batch_size=batch_size, sample_length=11776)  # hardcore to 11776 for samples of length 12000\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        # After the model has been loaded, sequentially load a sample and find encoded output\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            sample = wav_data[i]\n",
    "            sample = np.expand_dims(sample,0)\n",
    "            sample, sample_length = utils.trim_for_encoding(sample, sample_length,hop_length)\n",
    "            encodings = sess.run(net[\"encoding\"], feed_dict={net[\"X\"]: sample})\n",
    "            encodings = encodings.reshape(-1,16)\n",
    "            samples_wavenet.append(encodings)\n",
    "        samples_wavenet = np.asarray(samples_wavenet)\n",
    "        \n",
    "        file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "        np.save(file_path, samples_wavenet)\n",
    "        print (drum_name, samples_wavenet.shape) \n",
    "        \n",
    "def testload_nsynth(batch_size=1, sample_length=64000):\n",
    "    \"\"\"Load the NSynth autoencoder network.\n",
    "    Args:\n",
    "    batch_size: Batch size number of observations to process. [1]\n",
    "    sample_length: Number of samples in the input audio. [64000]\n",
    "    Returns:\n",
    "    graph: The network as a dict with input placeholder in {\"X\"}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        x = tf.placeholder(tf.float32, shape=[batch_size, sample_length])\n",
    "        graph = config.build({\"wav\": x}, is_training=False)\n",
    "        graph.update({\"X\": x})\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clap', (5, 23, 16))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drum_name = \"clap\"\n",
    "custom_encode(drum_name, './wavenet-ckpt/model.ckpt-200000',drum_name, 12000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
