{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a69029-4fb8-4420-9be3-06ea3cf14f0d",
   "metadata": {},
   "source": [
    "## 測試項目\n",
    "1. 訓練集中的alarm聲\n",
    "2. 使用pruned and quantized tflite model\n",
    "4. export to cc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f0a4a7-cc91-44ff-a761-5ec09ce97599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:57:34.885529: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-19 11:57:35.480800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-19 11:57:35.480911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-19 11:57:35.578065: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-19 11:57:35.779569: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 11:57:36.676328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "import zipfile\n",
    "import wavio\n",
    "from common import utils as U\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218705f2-4f93-4cb9-bf6b-84abd01d199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30027b0c-feb4-45ba-aac1-d14089a7516a",
   "metadata": {},
   "source": [
    "### Loading TFlite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff7e097-1237-4564-96dd-678ba95ffd08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provided has model identifier '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tflite_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../refine_codes/trained_models/current_best/acdnet_alarm_3rd_20240119093633_acc_97.7272720336914_190th_epoch.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m;\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load quantized TFLite model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tflite_interpreter_quant \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtflite_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:464\u001b[0m, in \u001b[0;36mInterpreter.__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering)\u001b[0m\n\u001b[1;32m    458\u001b[0m custom_op_registerers_by_name \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    459\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m custom_op_registerers_by_func \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    462\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    463\u001b[0m ]\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43m_interpreter_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateWrapperFromFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_resolver_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_preserve_all_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_disable_delegate_clustering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter:\n\u001b[1;32m    473\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to open \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_path))\n",
      "\u001b[0;31mValueError\u001b[0m: Model provided has model identifier '"
     ]
    }
   ],
   "source": [
    "tflite_model_path = \"../../refine_codes/trained_models/current_best/acdnet_alarm_3rd_20240119093633_acc_97.7272720336914_190th_epoch.pt\";\n",
    "# Load quantized TFLite model\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8031ec-a85c-401f-a714-0579f2a43833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: x.3\n",
      "shape: [    1     1 30225     1]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "name: 185\n",
      "shape: [1 2]\n",
      "type: <class 'numpy.float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# model.summary()\n",
    "input_details = tflite_interpreter_quant.get_input_details()\n",
    "output_details = tflite_interpreter_quant.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "\n",
    "#resize the input and output\n",
    "# tflite_interpreter_quant.resize_tensor_input(input_details[0]['index'], (2, 1, 30225, 1))\n",
    "# tflite_interpreter_quant.resize_tensor_input(output_details[0]['index'], (2, 2))\n",
    "\n",
    "# input_details = tflite_interpreter_quant.get_input_details()\n",
    "# output_details = tflite_interpreter_quant.get_output_details()\n",
    "\n",
    "# print(\"== Input details ==\")\n",
    "# print(\"name:\", input_details[0]['name'])\n",
    "# print(\"shape:\", input_details[0]['shape'])\n",
    "# print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "# print(\"\\n== Output details ==\")\n",
    "# print(\"name:\", output_details[0]['name'])\n",
    "# print(\"shape:\", output_details[0]['shape'])\n",
    "# print(\"type:\", output_details[0]['dtype'])\n",
    "\n",
    "tflite_interpreter_quant.allocate_tensors();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c2bc6-26c8-41a0-908e-0062f48168a1",
   "metadata": {},
   "source": [
    "### loading dataset from npz format\n",
    "1. ACDNet input length is 30225\n",
    "2. sr is 44100 and 20000\n",
    "3. need to convert 16K to 20000\n",
    "### ACDNet Config Setting\n",
    "#### Training Parameters\n",
    "1. opt.batchSize = 64;\n",
    "2. opt.weightDecay = 5e-4;\n",
    "3. opt.momentum = 0.9;\n",
    "4. opt.nEpochs = 2000;\n",
    "5. opt.LR = 0.1;\n",
    "6. opt.schedule = [0.3, 0.6, 0.9];\n",
    "7. opt.warmup = 10; \n",
    "#### Basic Net Configuration\n",
    "- nClasses = 50\n",
    "- nFolds = 5\n",
    "- splits = \\[i for in range(1, nFolds + 1)\\]\n",
    "- sr = 20000\n",
    "- inputLength = 30225\n",
    "<br>ngth = 30225;\n",
    "### How to convert 16K sound to 44.1K with python and sox\n",
    "\n",
    "if using sox the command is as following: <br />\n",
    "    sox old.wav -b 16 new.wav \n",
    "if using python you can do as following: <br />\n",
    "    import soundfile\n",
    "    \n",
    "data, samplerate = soundfile.read('old.wav\n",
    "    <br />)\n",
    "soundfile.write('new.wav', data, samplerate, subtype='PCM_1\n",
    "6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dc6913-7290-414b-a6f1-7172edd43562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4730cca4-ba34-43e0-8c32-13afb77d5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileList(srcDir,regex='.*\\.wav'):\n",
    "    results = os.listdir(srcDir)\n",
    "    out_files = []\n",
    "    cnt_files = 0\n",
    "    for file in results:\n",
    "        if os.path.isdir(os.path.join(srcDir, file)):\n",
    "            out_files += getFileList(os.path.join(srcDir, file))\n",
    "        elif re.match(regex, file,  re.I):  # file.startswith(startExtension) or file.endswith(\".txt\") or file.endswith(endExtension):\n",
    "            out_files.append(os.path.join(srcDir, file))\n",
    "            cnt_files = cnt_files + 1\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a0a0b-2b1a-45c3-9eed-0bf6b10f3f24",
   "metadata": {},
   "source": [
    "## sound preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8156e68-94c4-44b4-af29-166c3533301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputLen = 30225\n",
    "_nCrops = 2\n",
    "def preprocess_setup():\n",
    "    funcs = []\n",
    "    funcs += [U.padding( _inputLen// 2),\n",
    "              U.normalize(32768.0),\n",
    "              U.multi_crop(_inputLen, _nCrops)]\n",
    "              # U.single_crop(_inputLen)]\n",
    "              # \n",
    "\n",
    "    return funcs\n",
    "\n",
    "def preprocess_debug():\n",
    "    debug_funcs = []\n",
    "    debug_funcs += [U.padding( _inputLen// 2),\n",
    "              U.normalize(32768.0),]\n",
    "              # U.multi_crop(_inputLen, _nCrops)]\n",
    "              # U.single_crop(_inputLen)]\n",
    "              # \n",
    "\n",
    "    return debug_funcs\n",
    "\n",
    "def preprocess(sound, funcs):\n",
    "    for f in funcs:\n",
    "        sound = f(sound)\n",
    "\n",
    "    return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d59fc9-c11b-4027-8f53-8ae3b743f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_funcs = preprocess_setup()\n",
    "# _debug_funcs = preprocess_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9dcde-83a3-4b49-9603-27acdb123b72",
   "metadata": {},
   "source": [
    "### Read Test Wav File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b0d4c18-078b-469a-8045-e2c79cb327ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in p_wav_list:\n",
    "#     sound = wavio.read(i).data.T[0]\n",
    "#     start = sound.nonzero()[0].min();\n",
    "#     end = sound.nonzero()[0].max();\n",
    "#     sound = sound[start: end + 1]\n",
    "#     sound_debug = np.array(preprocess(sound,_debug_funcs));\n",
    "#     print(f\"sound content after pad and normalize:\\n{sound_debug}\")\n",
    "#     label = int(p_label);\n",
    "#     print(f\"current sound start:{start} to end:{end}\");\n",
    "#     label = int(p_label);\n",
    "#     if len(sound)> 220500:\n",
    "#         sound = sound[:220500]\n",
    "#     sound = preprocess(sound, _funcs);\n",
    "#     print(f\"label is {label} and sound len is {len(sound)}\");\n",
    "#     sounds.append(sound);\n",
    "#     labels.append(label);\n",
    "    \n",
    "# for j in n_wav_list:\n",
    "#     sound = wavio.read(j).data.T[0]\n",
    "#     start = sound.nonzero()[0].min();\n",
    "#     end = sound.nonzero()[0].max();\n",
    "#     sound = sound[start: end + 1];\n",
    "#     sound_debug = np.array(preprocess(sound,_debug_funcs));\n",
    "#     print(f\"sound content after pad and normalize:\\n{sound_debug}\")\n",
    "#     label = int(n_label);\n",
    "#     print(f\"current sound start:{start} to end:{end}\");\n",
    "    \n",
    "#     sound = np.float32(preprocess(sound, _funcs));\n",
    "#     print(f\"label is {label} and sound len is {len(sound)}\")\n",
    "#     sounds.append(sound);\n",
    "#     labels.append(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06702eca-28ee-4af3-a0d4-3db6d1496f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sounds length: 58\n",
      "labels length: 58\n"
     ]
    }
   ],
   "source": [
    "positive_test_wavs = \"../../../ACDNet_Test/sounds_for_test_from_testset/test_data_p_52/\"\n",
    "negative_test_wavs = \"../../../ACDNet_Test/sounds_for_test_from_testset/test_data_n_99/\"\n",
    "\n",
    "p_wav_list = getFileList(positive_test_wavs);\n",
    "n_wav_list = getFileList(negative_test_wavs);\n",
    "\n",
    "# print(f\"total alarm sounds:{len(p_wav_list)} \");\n",
    "# print(f\"total other sounds:{len(n_wav_list)}\")\n",
    "p_label = 52;\n",
    "n_label = 99;\n",
    "\n",
    "sounds = [];\n",
    "labels = [];\n",
    "## sound = preprocess(sound, _funcs)\n",
    "for i in p_wav_list:\n",
    "    sound = wavio.read(i).data.T[0]\n",
    "    start = sound.nonzero()[0].min();\n",
    "    end = sound.nonzero()[0].max();\n",
    "    sound = sound[start: end + 1]\n",
    "    label = int(p_label);\n",
    "    if len(sound)> 220500:\n",
    "        sound = sound[:220500]\n",
    "    sound = preprocess(sound, _funcs);\n",
    "    sounds.append(sound);\n",
    "    labels.append(label);\n",
    "    \n",
    "for j in n_wav_list:\n",
    "    sound = wavio.read(j).data.T[0]\n",
    "    start = sound.nonzero()[0].min();\n",
    "    end = sound.nonzero()[0].max();\n",
    "    sound = sound[start: end + 1];\n",
    "    label = int(n_label);\n",
    "    sound = np.float32(preprocess(sound, _funcs));\n",
    "    sounds.append(sound);\n",
    "    labels.append(label);\n",
    "\n",
    "print(f\"sounds length: {len(sounds)}\");\n",
    "print(f\"labels length: {len(labels)}\");\n",
    "\n",
    "# sound = wavio.read(test_sound_file).data.T[0]\n",
    "# start = sound.nonzero()[0].min()\n",
    "# end = sound.nonzero()[0].max()\n",
    "# sound = sound[start: end + 1]  # Remove silent sections\n",
    "# label = 18 #int(os.path.splitext(test_sound_file)[0].split('-')[-1])\n",
    "\n",
    "# if len(sound)> 220500:\n",
    "#     sound = sound[:220500]\n",
    "\n",
    "# ec50_sound1 =  wavio.read(ec50_18_sound).data.T[0]\n",
    "# start_ec50 = ec50_sound1.nonzero()[0].min()\n",
    "# end_ec50 = ec50_sound1.nonzero()[0].max()\n",
    "# ec50_sound1 = ec50_sound1[start_ec50:end_ec50+1]\n",
    "# ec50_18_label = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32ee0121-918b-4c85-8514-b82aceae4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sounds)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12e3b08b-bc1b-4dde-bda8-b212fc4352a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30225,)\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(sounds[0][1].shape)\n",
    "print(type(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "992df970-da8d-4c7a-ba72-3f97efe247fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sound = np.expand_dims(sound, axis=1)\n",
    "# sound = np.expand_dims(sound, axis=3)\n",
    "# print(sound.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43e8d6c5-d9ce-461a-9ec9-497a8cef4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result: [[0.94298524 0.05701476]], and true label: 52\n",
      "Prediction result: [[0.98266476 0.0173352 ]], and true label: 52\n",
      "Prediction result: [[9.9938345e-01 6.1656453e-04]], and true label: 52\n",
      "Prediction result: [[0.99280506 0.00719495]], and true label: 52\n",
      "Prediction result: [[0.986761   0.01323901]], and true label: 52\n",
      "Prediction result: [[0.7493076  0.25069234]], and true label: 52\n",
      "Prediction result: [[0.25069234 0.7493076 ]], and true label: 52\n",
      "Prediction result: [[0.9980293  0.00197074]], and true label: 52\n",
      "Prediction result: [[0.8183962  0.18160376]], and true label: 52\n",
      "Prediction result: [[9.9996960e-01 3.0377752e-05]], and true label: 52\n",
      "Prediction result: [[9.999027e-01 9.722223e-05]], and true label: 52\n",
      "Prediction result: [[9.999993e-01 7.046469e-07]], and true label: 52\n",
      "Prediction result: [[0.9351648  0.06483512]], and true label: 52\n",
      "Prediction result: [[0.07364443 0.92635554]], and true label: 52\n",
      "Prediction result: [[0.12829535 0.87170464]], and true label: 52\n",
      "Prediction result: [[0.12083481 0.8791652 ]], and true label: 52\n",
      "Prediction result: [[9.9996519e-01 3.4833225e-05]], and true label: 52\n",
      "Prediction result: [[0.53416306 0.46583694]], and true label: 52\n",
      "Prediction result: [[0.03162612 0.96837384]], and true label: 52\n",
      "Prediction result: [[0.99056107 0.00943898]], and true label: 52\n",
      "Prediction result: [[0.9773303  0.02266964]], and true label: 52\n",
      "Prediction result: [[0.9945186  0.00548147]], and true label: 52\n",
      "Prediction result: [[9.9970943e-01 2.9053644e-04]], and true label: 52\n",
      "Prediction result: [[0.9968221  0.00317792]], and true label: 52\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.36645353 0.6335465 ]], and true label: 99\n",
      "Prediction result: [[0.08354372 0.91645634]], and true label: 99\n",
      "Prediction result: [[0.02769277 0.97230726]], and true label: 99\n",
      "Prediction result: [[0.02423638 0.9757637 ]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.02423638 0.9757637 ]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[9.9999583e-01 4.1753083e-06]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.05701476 0.94298524]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.02959616 0.9704038 ]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[9.9991524e-01 8.4787353e-05]], and true label: 99\n",
      "Prediction result: [[0.12083481 0.8791652 ]], and true label: 99\n",
      "Prediction result: [[0.6335465  0.36645353]], and true label: 99\n",
      "Prediction result: [[0.2637651  0.73623496]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.18160376 0.8183962 ]], and true label: 99\n",
      "Prediction result: [[0.0198274 0.9801726]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.5 0.5]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.32022026 0.6797797 ]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "Prediction result: [[0.01854026 0.98145974]], and true label: 99\n",
      "total sounds result is 84.48275862068965\n",
      "total alarm sounds result is 79.16666666666666\n",
      "total siren sound result is 88.23529411764706\n"
     ]
    }
   ],
   "source": [
    "test_len = len(sounds);\n",
    "p_total_len = len(p_wav_list);\n",
    "n_total_len = len(n_wav_list);\n",
    "correct_num = 0;\n",
    "p_correct_num = 0;\n",
    "n_correct_num = 0;\n",
    "n_correct_siren_num = 0;\n",
    "n_correct_othersounds_num = 0;\n",
    "for w in range(test_len): \n",
    "    s = sounds[w]\n",
    "    l = labels[w]\n",
    "    s_test = np.expand_dims(s[1], axis=0);\n",
    "    s_test = np.expand_dims(s_test, axis=1);\n",
    "    s_test = np.expand_dims(s_test, axis=3);\n",
    "    s_test = np.float32(s_test);\n",
    "    # print(s_test.shape)\n",
    "    # print(f\"the {w+1} item's shape:\\n  {s.shape}\");\n",
    "    # Run inference\n",
    "    # print(f\"s type:{type(s)}, and s shape:{s.shape}\")\n",
    "    tflite_interpreter_quant.set_tensor(input_details[0]['index'], s_test);\n",
    "    tflite_interpreter_quant.invoke()\n",
    "    pred = tflite_interpreter_quant.get_tensor(output_details[0]['index'])\n",
    "    # print(f\"Prediction result shape:{pred.shape}\\n\");\n",
    "    print(f\"Prediction result: {pred}, and true label: {l}\")\n",
    "    if l == 52: #positive\n",
    "        if pred[0][0] > pred[0][1]:\n",
    "            correct_num += 1;\n",
    "            p_correct_num += 1;\n",
    "    if l == 99: #negative\n",
    "        if pred[0][0] < pred[0][1]:\n",
    "            correct_num += 1;\n",
    "            n_correct_num += 1;\n",
    "print(f\"total sounds result is {100*(correct_num/test_len)}\");\n",
    "print(f\"total alarm sounds result is {100*(p_correct_num/p_total_len)}\");\n",
    "print(f\"total siren sound result is {100*(n_correct_num/n_total_len)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "780eb0f5-3acb-4070-8164-00bcf30593c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.predict(sound, batch_size=len(sound), verbose=0);\n",
    "# print(type(scores))\n",
    "# print(scores.shape)\n",
    "\n",
    "# for res in scores:\n",
    "#     max_value = res.max()\n",
    "#     max_index = np.argmax(res)\n",
    "#     print(f\"max value:{max_value:.5f} and index is {max_index}\")\n",
    "#     print('\\n'.join('{}: {:.5f}'.format(*k) for k in enumerate(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024bdc4-6093-4182-ab95-9f3688b6ff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999d37e-c098-4d06-a68c-a436d82a59f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
