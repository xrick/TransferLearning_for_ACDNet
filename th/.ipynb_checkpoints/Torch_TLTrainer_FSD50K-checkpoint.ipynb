{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cc9cb1-7673-4e90-b4c6-a32aba2e4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import glob;\n",
    "import random;\n",
    "import time;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append('../');\n",
    "# sys.path.append(os.path.join(os.getcwd(), 'torch/resources'));\n",
    "import common.utils as U;\n",
    "import common.opts as opts;\n",
    "import resources.models as models;\n",
    "import resources.calculator as calc;\n",
    "import common.tlopts as tlopts\n",
    "# import resources.train_generator as train_generator;\n",
    "import argparse\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0815030-17d2-4406-b087-0409a9863de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f53e33-c3ee-4c51-a448-5ebfc6da731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037be559-e258-4780-9416-dd969489d029",
   "metadata": {},
   "source": [
    "## define TLTraining Generator Class\n",
    "The Class is an python iterator class for generating data for trainer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9850c9d-6a7d-41ed-9244-a802f25b316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = {\n",
    "            17:1, #pouring_water\n",
    "            18:2, #toilet_flushing\n",
    "            21:3, #snezzing\n",
    "            24:4, #coughing\n",
    "            51:5, #kettle_sound\n",
    "            52:6, #alarm\n",
    "            #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "            54:7, #rington\n",
    "            55:8, #shower_water\n",
    "            56:9, #pain_sounds\n",
    "            57:10, #footsteps\n",
    "            98:11, #silence\n",
    "            99:12, #other_sounds\n",
    "        };\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        print(f\"total sounds is {len(sounds)}\")\n",
    "        print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1262f5-e327-4ba4-b8ea-f8570463bcaf",
   "metadata": {},
   "source": [
    "## ACDNetV2 define the acdnet model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5099b20-938b-4841-85d7-fa6ee30ce834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetACDNetModel(input_len=30225, nclass=50, sr=20000, channel_config=None):\n",
    "    net = ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47820f3a-2b2a-4eae-b56f-590433fef0ab",
   "metadata": {},
   "source": [
    "## load pretrained acdnet weights of 20khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbb28af-b51f-409c-ad38-ca8da8879874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acdnet_model = GetACDNetModel()\n",
    "# pretrain_weight= torch.load('./resources/pretrained_models/acdnet_20khz_trained_model_fold4_91.00.pt', map_location=torch.device('cpu'))['weight']\n",
    "\n",
    "# model_state = acdnet_model.state_dict()\n",
    "# model_state.update(pretrain_weight)\n",
    "# acdnet_model.load_state_dict(pretrain_weight, strict=False)\n",
    "\n",
    "# for k, v in pretrain_weight['weight'].items():\n",
    "#     print(\"name:\", k)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# remove the unexpected keys: weight and config\n",
    "# from collections import OrderedDict\n",
    "# new_state_dict = OrderedDict()\n",
    "# for k, v in checkpoint.items():\n",
    "#     name = k.replace(\"weight\", \"\") # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "#     name = k.replace(\"config\", \"\") # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "\n",
    "# model_state = acdnet_model.state_dict()\n",
    "# model_state.update(new_state_dict)\n",
    "# acdnet_model.load_state_dict(new_state_dict, strict=False)\n",
    "\n",
    "# print(\"acdnet_model state_dict:\\n\",acdnet_model.state_dict())\n",
    "# print(\"pretrain_weight: \\n\",pretrain_weight)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc665597-d662-466d-99d7-b32fa9a5afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_38_of_tfeb = list(acdnet_model.tfeb.children())[38]\n",
    "\n",
    "# print(layer_38_of_tfeb)\n",
    "# print(nn.Sequential(*list(acdnet_model.tfeb.children())[:-6]))\n",
    "# print(nn.Sequential(*list(acdnet_model.tfeb.children())))\n",
    "# print(acdnet_model)\n",
    "# for item_v in nn.Sequential(*list(acdnet_model.tfeb.children())):\n",
    "#     for internal_k, internal_v in item_v.named_parameters():\n",
    "#         print(internal_v.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa8d3d7-8658-4b73-a643-e7d68ddeab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(acdnet_model.fc)\n",
    "#acdnet 包含三部份：sfeb, tfeb and output\n",
    "# print(nn.Sequential(*list(acdnet_model.children())))\n",
    "# print(nn.Sequential(*list(acdnet_model.children())[:-1]))\n",
    "# for k, v in acdnet_model.named_parameters():\n",
    "#     print(\"key:\", k)\n",
    "#     v.requires_grad = False\n",
    "\n",
    "# acdnet_model.fcn = nn.Linear(num_ftrs, 10)\n",
    "# print(acdnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e74198-72bd-48f2-90a9-8f4f29b9f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 32;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 10;#2000;\n",
    "    opt.LR = 0.1;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    opt.device = 'cpu';#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 12#50;\n",
    "    opt.nFolds = 5;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 5;\n",
    "    return opt\n",
    "    # opt = parser.parse_args();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82574608-e5c1-47ea-817f-c1bfa8ffba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771ea414-dd74-4897-9f3d-f7566ea543fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_confing_10 = 8 * 64\n",
    "ch_n_class = 12\n",
    "fcn_no_of_inputs = 12\n",
    "# conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "conv12, bn12 = make_layers(in_channels = ch_confing_10, out_channels = ch_n_class, kernel_size = (1, 1));\n",
    "fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f157eff-03da-4e48-9701-606b472663e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNet_TL_Model_Extend(nn.Module):\n",
    "    def __init__(self, PretrainedWeights='./resources/pretrained_models/acdnet_20khz_trained_model_fold4_91.00.pt',opt=None):\n",
    "        super(ACDNet_TL_Model_Extend, self).__init__()\n",
    "        acdnet_model = GetACDNetModel(); # load original acdnet model first\n",
    "        # device = opt#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"device is {opt.device}\")\n",
    "        pretrain_weight= torch.load(PretrainedWeights, map_location=torch.device(opt.device))['weight']\n",
    "        model_state = acdnet_model.state_dict()\n",
    "        model_state.update(pretrain_weight)\n",
    "        acdnet_model.load_state_dict(pretrain_weight, strict=False)\n",
    "        # print(type(acdnet_model))\n",
    "        # count = 0;\n",
    "        for k, v in acdnet_model.named_parameters():\n",
    "            # count += 1;\n",
    "            # print(f\"set {k} required_grade to False\");\n",
    "            v.requires_grad = False\n",
    "        # print(f\"count is {count}\");\n",
    "        self.sfeb = nn.Sequential(*list(acdnet_model.children())[0])\n",
    "        tfeb_modules = []\n",
    "        tfeb_modules.extend([*list(acdnet_model.tfeb.children())[:-6]])\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "        # self.retrained_layers = nn.Sequential(*list(acdnet_model.tfeb.children())[:-1])\n",
    "        # fcn_no_of_inputs = 50, n_class=10\n",
    "        # n_class=6\n",
    "        # fc = nn.Linear(50, n_class);\n",
    "        # fc.requires_grad = True\n",
    "        # tfeb_modules.extend([fc])\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules)\n",
    "        self.output = nn.Sequential(\n",
    "        nn.Softmax(dim=1));\n",
    "        # print(f\"type of self.tfeb is {type(self.tfeb)}\")\n",
    "        # for k2, v2 in self.tfeb:\n",
    "        #     print(f\"k:{k}'s requires_grad is {v2.requires_grad}\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d89596f-04bf-4222-b23f-31ed75cd1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTLACDNet():\n",
    "    model = ACDNet_TL_Model_Extend(opt=getOpts());#ACDNet_TL_Model()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efbc0b0a-28fb-440f-97e3-c59ecb9fa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = GetTLACDNet()\n",
    "# calc.summary(test_model, (1,1,30225))\n",
    "# print(test_model)\n",
    "# print(test_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e62e010-cd9a-42cb-ba31-66bb71ae1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3ca4f4-2d45-488d-ba0f-3466bd397cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "463a7a09-5a89-4097-b4d2-1f8e50f8b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLTrainer:\n",
    "    def __init__(self, opt=None):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(opt, split);\n",
    "        self.opt = opt;\n",
    "        # self.opt.trainer = self;\n",
    "        self.trainGen = getTrainGen(self.opt, self.opt.splits)#train_generator.setup(self.opt, self.opt.split);\n",
    "        # self.pretrainedmodelpath = \"./resources/pretrained_models/acdnet20_20khz_fold4.h5\"\n",
    "\n",
    "    def Train(self):\n",
    "        train_start_time = time.time();\n",
    "        net = GetTLACDNet().to(self.opt.device)#models.GetACDNetModel().to(self.opt.device);\n",
    "        #print networks parameters' require_grade value\n",
    "        for k_, v_ in net.named_parameters():\n",
    "            print(f\"{k_}:{v_.requires_grad}\")\n",
    "        print('ACDNet model has been prepared for training');\n",
    "\n",
    "        calc.summary(net, (1,1,self.opt.inputLength));\n",
    "\n",
    "        # training_text = \"Re-Training\" if self.opt.retrain else \"Training from Scratch\";\n",
    "        # print(\"{} has been started. You will see update after finishing every training epoch and validation\".format(training_text));\n",
    "\n",
    "        lossFunc = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True);\n",
    "\n",
    "        # self.opt.nEpochs = 1957 if self.opt.split == 4 else 2000;\n",
    "        for epochIdx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epochIdx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            for batchIdx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batchIdx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "                y = torch.tensor(y).to(self.opt.device);\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(x);\n",
    "                running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                loss = lossFunc(outputs.log(), y);\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, lossFunc);\n",
    "            #Save best model\n",
    "            self.__save_model(val_acc, epochIdx, net);\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epochIdx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - train_start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        # data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_{}khz/fold{}_test4000.npz'.format(self.opt.sr//1000, self.opt.split)), allow_pickle=True);\n",
    "        data = np.load(\"../../acdnet_trained_data/single_fold/test_data_20K.npz\", allow_pickle=True);\n",
    "        self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "        self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __get_batch(self, index):\n",
    "        x = self.trainX[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        y = self.trainY[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        return x.to(self.opt.device), y.to(self.opt.device);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        if self.testX is None:\n",
    "            self.load_test_data();\n",
    "        net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);#(self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#             for idx in range(len(self.testX)):\n",
    "#             x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "            x = self.testX[:];\n",
    "            scores = net(x);\n",
    "            y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "#         with torch.no_grad():\n",
    "#             y_pred = None;\n",
    "#             batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#                 x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "#                 scores = net(x);\n",
    "#                 y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "#             acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            if self.opt.nCrops == 1:\n",
    "                y_pred = y_pred.argmax(dim=1);\n",
    "                y_target = y_target.argmax(dim=1);\n",
    "            else:\n",
    "                y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        line = 'SP-{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.splits, epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def __save_model(self, acc, epochIdx, net):\n",
    "        print(\"__save_model is called\")\n",
    "        print(f\"current best Acc is {self.bestAcc}\")\n",
    "        print(f\"pass in acc is {acc}\")\n",
    "        if acc > self.bestAcc:\n",
    "            dir = os.getcwd();\n",
    "            save_path = \"./trained_models/{}\".format(opt.model_name);\n",
    "            # fname = \"{}/torch/trained_models/{}_fold{}.pt\";\n",
    "            # fname = \"{}/trained_models/acdnet_torch_20231218.pt\";\n",
    "            # old_model = fname.format(dir, self.opt.model_name.lower(), self.opt.splits);\n",
    "            # if os.path.isfile(old_model):\n",
    "            #     os.remove(old_model);\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            # torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname.format(dir, self.opt.model_name.lower(), self.opt.split));\n",
    "            # torch.save({'weight':net.state_dict()}, fname.format(dir, self.opt.model_name.lower(), self.opt.splits));\n",
    "            torch.save({'weight':net.state_dict()}, save_path);\n",
    "            print(f\"model saved....., acc: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebb03c91-9d87-44bf-86d5-793e2df7fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(\"../../acdnet_trained_data/single_fold/train_fsd50_20K__202401041450.npz\", allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51b05f11-5bf2-438b-bfbb-edb0d48b05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts();\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    # import torch;\n",
    "    \n",
    "    tlopts.display_info(opt)\n",
    "    opt.model_name = \"acdnet_fsd50k_model{}.pt\"\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing TLTrainer Object.....\")\n",
    "    trainer = TLTrainer(opt)\n",
    "    print(\"Start to training.....\")\n",
    "    trainer.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94166430-c5c1-421a-84f9-bdde77ad1c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "| ACDNet_TL_Model_Extend Sound classification\n",
      "+------------------------------+\n",
      "| dataset  : uec_iot\n",
      "| nEpochs  : 10\n",
      "| LRInit   : 0.1\n",
      "| schedule : [0.3, 0.6, 0.9]\n",
      "| warmup   : 10\n",
      "| batchSize: 32\n",
      "| nFolds: 5\n",
      "| Splits: [1, 2, 3, 4, 5]\n",
      "+------------------------------+\n",
      "Initializing TLTrainer Object.....\n",
      "length of samples:332\n",
      "length of samples:332\n",
      "Start to training.....\n",
      "device is cpu\n",
      "sfeb.0.weight:False\n",
      "sfeb.1.weight:False\n",
      "sfeb.1.bias:False\n",
      "sfeb.3.weight:False\n",
      "sfeb.4.weight:False\n",
      "sfeb.4.bias:False\n",
      "tfeb.0.weight:False\n",
      "tfeb.1.weight:False\n",
      "tfeb.1.bias:False\n",
      "tfeb.4.weight:False\n",
      "tfeb.5.weight:False\n",
      "tfeb.5.bias:False\n",
      "tfeb.7.weight:False\n",
      "tfeb.8.weight:False\n",
      "tfeb.8.bias:False\n",
      "tfeb.11.weight:False\n",
      "tfeb.12.weight:False\n",
      "tfeb.12.bias:False\n",
      "tfeb.14.weight:False\n",
      "tfeb.15.weight:False\n",
      "tfeb.15.bias:False\n",
      "tfeb.18.weight:False\n",
      "tfeb.19.weight:False\n",
      "tfeb.19.bias:False\n",
      "tfeb.21.weight:False\n",
      "tfeb.22.weight:False\n",
      "tfeb.22.bias:False\n",
      "tfeb.25.weight:False\n",
      "tfeb.26.weight:False\n",
      "tfeb.26.bias:False\n",
      "tfeb.28.weight:False\n",
      "tfeb.29.weight:False\n",
      "tfeb.29.bias:False\n",
      "tfeb.33.weight:True\n",
      "tfeb.34.weight:True\n",
      "tfeb.34.bias:True\n",
      "tfeb.38.weight:True\n",
      "tfeb.38.bias:True\n",
      "ACDNet model has been prepared for training\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)        (12, 2, 4)      6,144       49,152\n",
      " BatchNorm2d-42        (12, 2, 4)        (12, 2, 4)         24            0\n",
      "        ReLu-43        (12, 2, 4)        (12, 2, 4)          0           96\n",
      "   AvgPool2d-44        (12, 2, 4)        (12, 1, 1)          0           96\n",
      "     Flatten-45        (12, 1, 1)           (1, 12)          0            0\n",
      "      Linear-46           (1, 12)           (1, 12)        156          156\n",
      "     Softmax-47           (1, 12)           (1, 12)          0           12\n",
      "==============================================================================\n",
      "Total Params: 4,713,452\n",
      "Total FLOPs : 544,263,352\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.98\n",
      "Total size (MB) : 18.10\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.2635288  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.73647124]\n",
      " [0.         0.7673391  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23266089 0.         0.        ]\n",
      " [0.         0.         0.         0.41073433 0.         0.\n",
      "  0.         0.         0.         0.5892657  0.         0.        ]\n",
      " [0.95721304 0.         0.04278693 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.7297318  0.         0.         0.         0.2702682\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.42264786 0.         0.         0.         0.57735217\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.38012624 0.         0.         0.61987376 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.06334541 0.         0.         0.93665457\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.98952335 0.         0.         0.\n",
      "  0.         0.         0.         0.01047665 0.         0.        ]\n",
      " [0.         0.         0.         0.1781974  0.         0.\n",
      "  0.         0.         0.         0.8218026  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.6043681  0.3956319\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.7372584  0.         0.         0.\n",
      "  0.         0.2627416  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.24421784\n",
      "  0.         0.         0.         0.         0.         0.7557822 ]\n",
      " [0.         0.         0.38161927 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.6183807 ]\n",
      " [0.         0.         0.         0.31828964 0.         0.\n",
      "  0.         0.         0.         0.68171036 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00324532 0.\n",
      "  0.         0.         0.         0.         0.         0.9967547 ]\n",
      " [0.         0.         0.         0.29844478 0.         0.\n",
      "  0.         0.         0.7015552  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.08150651 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.9184935 ]\n",
      " [0.19322519 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.8067748  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.06921252 0.         0.\n",
      "  0.         0.         0.         0.9307875  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.9643629  0.0356371  0.         0.        ]\n",
      " [0.         0.         0.         0.8996141  0.10038591 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.00719084 0.         0.         0.         0.9928092\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.5141561  0.         0.         0.48584387 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.21538058 0.         0.\n",
      "  0.         0.         0.78461945 0.         0.         0.        ]\n",
      " [0.         0.5329753  0.         0.46702465 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.75134367 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24865633]\n",
      " [0.         0.         0.55686927 0.         0.         0.\n",
      "  0.         0.44313073 0.         0.         0.         0.        ]\n",
      " [0.         0.07363302 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.926367   0.         0.        ]\n",
      " [0.         0.         0.16463712 0.         0.         0.\n",
      "  0.83536285 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.04268236 0.         0.95731765\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4208197  0.5791803  0.         0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.84256727 0.         0.         0.         0.15743273 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.40377554 0.5962244  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.34262684 0.         0.\n",
      "  0.         0.         0.         0.         0.6573732  0.        ]\n",
      " [0.         0.         0.         0.86912173 0.13087828 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00390355 0.\n",
      "  0.         0.99609643 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.24428442 0.         0.\n",
      "  0.         0.         0.         0.7557156  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6539763  0.         0.         0.34602368 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.7355341  0.\n",
      "  0.         0.         0.         0.26446593 0.         0.        ]\n",
      " [0.         0.         0.7964027  0.         0.         0.\n",
      "  0.         0.         0.         0.2035973  0.         0.        ]\n",
      " [0.         0.         0.         0.09229847 0.         0.\n",
      "  0.         0.         0.90770155 0.         0.         0.        ]\n",
      " [0.838418   0.         0.         0.         0.16158198 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9039286  0.         0.         0.09607143 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.3646515\n",
      "  0.         0.         0.         0.         0.         0.6353485 ]\n",
      " [0.78011626 0.         0.         0.         0.         0.21988375\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.8107717  0.         0.         0.         0.         0.18922828]\n",
      " [0.8022351  0.         0.19776486 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8585932  0.14140674 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.601534\n",
      "  0.         0.398466   0.         0.         0.         0.        ]\n",
      " [0.         0.33114988 0.         0.         0.6688501  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.56543624 0.43456376 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.19007878 0.\n",
      "  0.8099212  0.         0.         0.         0.         0.        ]\n",
      " [0.05973688 0.         0.         0.         0.         0.\n",
      "  0.9402631  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8480153  0.         0.15198472\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2956552  0.\n",
      "  0.         0.         0.         0.7043448  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.5939248\n",
      "  0.40607518 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.44178602 0.         0.\n",
      "  0.558214   0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.7162136  0.28378642 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.1934371\n",
      "  0.         0.         0.         0.         0.         0.8065629 ]\n",
      " [0.45541617 0.         0.         0.54458386 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8524287  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14757134]\n",
      " [0.         0.24919827 0.         0.         0.         0.\n",
      "  0.75080174 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.04996039 0.         0.         0.\n",
      "  0.         0.9500396  0.         0.         0.         0.        ]]\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25634456 0.         0.         0.74365544]\n",
      " [0.         0.         0.         0.         0.72540253 0.\n",
      "  0.         0.         0.         0.         0.         0.27459744]\n",
      " [0.         0.         0.         0.8616259  0.13837406 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.41577423 0.5842258  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.14326797\n",
      "  0.856732   0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.853448\n",
      "  0.         0.         0.14655206 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.48822948 0.         0.         0.51177055 0.         0.        ]\n",
      " [0.5326099  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.46739015 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.97289795 0.         0.02710205]\n",
      " [0.         0.         0.45469934 0.         0.         0.\n",
      "  0.         0.54530066 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5296932  0.47030684\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.04025814 0.         0.         0.         0.         0.9597419\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.56396955 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.43603042]\n",
      " [0.         0.         0.         0.11453287 0.         0.8854671\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.6033456  0.         0.         0.39665443 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.8502932  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14970677]\n",
      " [0.         0.37057087 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.6294291  0.         0.        ]\n",
      " [0.03921243 0.         0.         0.         0.         0.9607876\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.7299176  0.         0.         0.\n",
      "  0.         0.27008238 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16926898 0.83073103 0.         0.        ]\n",
      " [0.         0.         0.         0.66360337 0.         0.\n",
      "  0.         0.33639663 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.7203415  0.         0.2796585  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.48857784 0.\n",
      "  0.         0.         0.         0.51142216 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.2942356  0.         0.         0.7057644 ]\n",
      " [0.         0.         0.         0.3437574  0.6562426  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.7694619\n",
      "  0.         0.         0.         0.23053804 0.         0.        ]\n",
      " [0.         0.78361535 0.         0.         0.21638463 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.77251685 0.         0.22748317]\n",
      " [0.29213664 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.70786333 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5212858  0.         0.         0.4787142 ]\n",
      " [0.40070745 0.         0.         0.5992926  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.00608188 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.9939181 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.45051447 0.         0.         0.         0.         0.54948556]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.90076643 0.         0.         0.         0.         0.09923358]\n",
      " [0.         0.         0.         0.44800776 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.55199224]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2881049  0.7118951  0.         0.         0.         0.        ]\n",
      " [0.         0.4102104  0.         0.         0.         0.\n",
      "  0.         0.58978957 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8266312  0.         0.\n",
      "  0.17336884 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.43915346 0.         0.56084657 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08044185 0.91955817\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.41287708 0.\n",
      "  0.5871229  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.4422294  0.\n",
      "  0.         0.         0.         0.         0.         0.5577706 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.65203893 0.         0.         0.         0.         0.34796107]\n",
      " [0.         0.9451935  0.05480646 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.02981527 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.97018474 0.         0.        ]\n",
      " [0.81241745 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18758254 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13101323 0.         0.         0.8689868 ]\n",
      " [0.         0.29021716 0.         0.         0.         0.\n",
      "  0.         0.         0.70978284 0.         0.         0.        ]\n",
      " [0.4614479  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.5385521  0.         0.        ]\n",
      " [0.         0.         0.41549033 0.         0.         0.\n",
      "  0.         0.         0.5845097  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.49175912 0.         0.\n",
      "  0.         0.5082409  0.         0.         0.         0.        ]\n",
      " [0.         0.26717266 0.         0.         0.73282737 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.4465474  0.\n",
      "  0.         0.         0.         0.         0.         0.5534526 ]\n",
      " [0.         0.         0.         0.         0.         0.86960167\n",
      "  0.         0.         0.         0.13039832 0.         0.        ]\n",
      " [0.         0.         0.         0.70522785 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29477212]\n",
      " [0.         0.         0.6680053  0.         0.         0.3319947\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.5900214  0.         0.         0.         0.\n",
      "  0.40997863 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.60251665 0.39748332 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.4879475\n",
      "  0.         0.         0.         0.51205254 0.         0.        ]\n",
      " [0.         0.90962064 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09037933]\n",
      " [0.         0.95400906 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04599097]\n",
      " [0.         0.         0.         0.         0.56592804 0.43407193\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.91282904 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08717098]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46525326 0.         0.         0.         0.53474677]]\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.3610613  0.         0.         0.\n",
      "  0.         0.         0.         0.6389387  0.         0.        ]\n",
      " [0.         0.         0.         0.48320806 0.         0.\n",
      "  0.         0.51679194 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.34177017\n",
      "  0.         0.         0.         0.         0.         0.6582298 ]\n",
      " [0.22425902 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.775741   0.         0.        ]\n",
      " [0.         0.         0.         0.27907163 0.         0.7209284\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.78861046 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21138951]\n",
      " [0.         0.         0.82435995 0.         0.         0.17564008\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.08595105\n",
      "  0.         0.         0.         0.91404897 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.75415146 0.2458485\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.12358873\n",
      "  0.         0.         0.         0.87641126 0.         0.        ]\n",
      " [0.         0.         0.         0.6748366  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32516345]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36459607 0.         0.63540393]\n",
      " [0.         0.         0.         0.         0.9959274  0.\n",
      "  0.00407263 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.41912675 0.         0.\n",
      "  0.         0.         0.         0.58087325 0.         0.        ]\n",
      " [0.         0.         0.03271629 0.         0.         0.\n",
      "  0.9672837  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.35867384 0.         0.6413261\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.7878942  0.         0.21210581 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7928426  0.         0.20715737\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.9875273  0.         0.0124727\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.21001534 0.78998464 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.47391447 0.         0.         0.         0.52608556 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4961613  0.5038387  0.         0.         0.        ]\n",
      " [0.9985868  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00141324 0.         0.        ]\n",
      " [0.         0.67788815 0.         0.         0.         0.\n",
      "  0.32211182 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.53055686 0.         0.46944317 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.12229379 0.         0.         0.         0.         0.8777062 ]\n",
      " [0.         0.         0.         0.3987302  0.         0.\n",
      "  0.60126984 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.68682104 0.\n",
      "  0.31317896 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.05998098 0.         0.         0.         0.\n",
      "  0.940019   0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.13190785\n",
      "  0.         0.         0.         0.8680921  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.15473017 0.\n",
      "  0.         0.         0.         0.         0.         0.8452698 ]\n",
      " [0.         0.5741     0.         0.         0.         0.42589998\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.8294608  0.         0.17053922]\n",
      " [0.         0.         0.00610579 0.         0.9938942  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.7848671\n",
      "  0.         0.         0.         0.21513288 0.         0.        ]\n",
      " [0.         0.         0.40377623 0.         0.         0.5962238\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.5143383  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.48566172]\n",
      " [0.         0.         0.         0.71675354 0.28324646 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05478196 0.945218   0.         0.        ]\n",
      " [0.         0.         0.5026147  0.49738532 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.07207549 0.         0.         0.9279245\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.57339966 0.         0.         0.         0.         0.\n",
      "  0.4266003  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.19867785 0.\n",
      "  0.80132216 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.5995502  0.         0.         0.         0.4004498\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.11402664 0.88597333\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.397601   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.602399  ]\n",
      " [0.         0.75987715 0.24012285 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.3161389  0.         0.6838611 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.49266312 0.5073369  0.         0.         0.         0.        ]\n",
      " [0.38499162 0.         0.         0.         0.         0.\n",
      "  0.         0.6150084  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4497337  0.         0.         0.         0.5502663 ]\n",
      " [0.         0.         0.         0.4505231  0.54947686 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.00901398 0.         0.         0.         0.99098605\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.66163284 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33836713]\n",
      " [0.         0.7480042  0.         0.         0.         0.25199577\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.68976825 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.31023175]\n",
      " [0.         0.         0.6233207  0.         0.         0.3766793\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.36259767 0.         0.         0.\n",
      "  0.         0.         0.         0.63740236 0.         0.        ]\n",
      " [0.         0.         0.         0.15494518 0.         0.8450548\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.03774749 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.9622525  0.         0.        ]\n",
      " [0.         0.         0.278817   0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.721183  ]\n",
      " [0.         0.         0.         0.76599705 0.         0.23400295\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.23056145 0.         0.\n",
      "  0.         0.76943856 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13839853 0.8616015  0.         0.        ]]\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.48833945e-01 0.00000000e+00 0.00000000e+00 8.51166070e-01]\n",
      " [0.00000000e+00 0.00000000e+00 9.17135701e-02 0.00000000e+00\n",
      "  9.08286452e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.26038492e-01 0.00000000e+00 3.73961478e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.49960697e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.50039303e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.41158843e-01 0.00000000e+00 7.58841157e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.51195747e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.48804224e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.52250540e-01 0.00000000e+00\n",
      "  0.00000000e+00 4.77494448e-02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.68045062e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.31954968e-01]\n",
      " [0.00000000e+00 0.00000000e+00 1.87313914e-01 0.00000000e+00\n",
      "  8.12686086e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.45848048e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.54151952e-01 0.00000000e+00 0.00000000e+00]\n",
      " [6.42906129e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.57093871e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.33409590e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.66590381e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.31735861e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.68264139e-01]\n",
      " [0.00000000e+00 8.85790408e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.14209615e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.53290892e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.46709079e-01 0.00000000e+00 0.00000000e+00]\n",
      " [5.63048601e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.36951369e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.32653058e-01 3.67346913e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.54525590e-01 0.00000000e+00 0.00000000e+00\n",
      "  5.45474410e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.66644767e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.33355248e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.25444615e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.74555355e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.59986719e-01 8.40013266e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.33671522e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.66328478e-01]\n",
      " [6.27986610e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.72013390e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.50388324e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.49611646e-01]\n",
      " [0.00000000e+00 0.00000000e+00 7.04037786e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.95962185e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.47173703e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.52826297e-01]\n",
      " [0.00000000e+00 9.35060918e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 6.49390817e-02 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.38507843e-01 0.00000000e+00\n",
      "  3.61492187e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.27722603e-01 5.72277427e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 4.04956052e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99595046e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.76202690e-02 0.00000000e+00\n",
      "  0.00000000e+00 9.72379744e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.32218370e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.67781615e-01 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.838033   0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16196696 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.0788599  0.         0.9211401\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.49742687 0.\n",
      "  0.         0.         0.         0.50257313 0.         0.        ]\n",
      " [0.         0.         0.6623804  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33761957]\n",
      " [0.7891916  0.21080838 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.48294482 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.51705515 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.58437824 0.41562176\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.9753741\n",
      "  0.         0.         0.         0.         0.         0.02462587]\n",
      " [0.         0.         0.         0.         0.         0.26747167\n",
      "  0.         0.         0.         0.7325283  0.         0.        ]\n",
      " [0.7517297  0.24827027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.49826553 0.         0.50173444 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5427694  0.\n",
      "  0.         0.         0.45723063 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.3274794\n",
      "  0.         0.         0.         0.         0.         0.6725206 ]\n",
      " [0.40325406 0.5967459  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.3863488  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.61365116 0.        ]\n",
      " [0.         0.         0.         0.         0.87133664 0.\n",
      "  0.         0.         0.         0.12866339 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.4999221\n",
      "  0.         0.         0.         0.5000779  0.         0.        ]\n",
      " [0.         0.         0.8931317  0.         0.         0.1068683\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.40627533 0.\n",
      "  0.         0.         0.         0.         0.         0.59372467]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10960459 0.8903954  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78290397 0.\n",
      "  0.         0.         0.         0.         0.         0.21709602]\n",
      " [0.         0.         0.         0.27881718 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.7211828 ]\n",
      " [0.         0.         0.8901045  0.         0.         0.10989552\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.61147803 0.\n",
      "  0.38852194 0.         0.         0.         0.         0.        ]\n",
      " [0.478371   0.         0.52162904 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.77198976 0.         0.         0.\n",
      "  0.         0.22801022 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.44191334 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.55808663]\n",
      " [0.         0.         0.         0.28778937 0.         0.\n",
      "  0.         0.         0.7122106  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.70954734\n",
      "  0.         0.         0.         0.29045266 0.         0.        ]\n",
      " [0.         0.21398681 0.         0.         0.         0.7860132\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5868305  0.\n",
      "  0.         0.         0.         0.4131695  0.         0.        ]\n",
      " [0.         0.         0.         0.28264195 0.         0.\n",
      "  0.         0.         0.         0.71735805 0.         0.        ]]\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.5225515  0.         0.47744852 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53515226 0.\n",
      "  0.         0.         0.         0.         0.         0.4648477 ]\n",
      " [0.9971718  0.         0.0028282  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.70160776 0.         0.         0.\n",
      "  0.         0.         0.2983922  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.11074004 0.88925993\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.35171467 0.6482853  0.         0.         0.        ]\n",
      " [0.17549491 0.         0.         0.         0.         0.8245051\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.1847812\n",
      "  0.8152188  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7330057  0.26699433 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.11822484 0.         0.         0.88177514 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.3675439\n",
      "  0.         0.         0.6324561  0.         0.         0.        ]\n",
      " [0.         0.         0.4158456  0.         0.         0.\n",
      "  0.         0.         0.58415437 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7547395  0.         0.24526045 0.         0.        ]\n",
      " [0.         0.11220879 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.8877912  0.         0.        ]\n",
      " [0.         0.         0.         0.5581595  0.         0.\n",
      "  0.         0.         0.44184056 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5465677  0.         0.         0.4534323 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7232801  0.         0.27671993 0.         0.        ]\n",
      " [0.06375992 0.         0.         0.9362401  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.76582766 0.         0.         0.         0.\n",
      "  0.         0.23417231 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6243545  0.         0.         0.         0.         0.37564555]\n",
      " [0.         0.         0.60694134 0.         0.         0.\n",
      "  0.         0.         0.         0.39305863 0.         0.        ]\n",
      " [0.45555466 0.         0.         0.54444534 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.23451006\n",
      "  0.         0.76548994 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.20608163 0.         0.         0.         0.         0.7939184 ]\n",
      " [0.7405411  0.         0.         0.         0.         0.\n",
      "  0.         0.25945893 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.23416151 0.         0.\n",
      "  0.         0.         0.         0.7658385  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.763096   0.\n",
      "  0.         0.         0.         0.         0.         0.23690404]\n",
      " [0.         0.         0.         0.12028611 0.         0.\n",
      "  0.         0.         0.         0.8797139  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.32865748 0.         0.         0.         0.         0.67134255]\n",
      " [0.         0.         0.         0.         0.24096818 0.\n",
      "  0.75903183 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.55728674 0.         0.         0.\n",
      "  0.         0.44271323 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.53563553 0.         0.46436447\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.1881633  0.         0.         0.         0.8118367  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7881922  0.         0.\n",
      "  0.         0.         0.         0.21180777 0.         0.        ]\n",
      " [0.         0.39663205 0.         0.         0.         0.\n",
      "  0.         0.         0.6033679  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.51281655\n",
      "  0.         0.48718345 0.         0.         0.         0.        ]\n",
      " [0.         0.31292203 0.         0.         0.         0.\n",
      "  0.         0.687078   0.         0.         0.         0.        ]\n",
      " [0.         0.         0.27998805 0.72001195 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.25732675 0.         0.7426732\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.8600415  0.         0.         0.13995853]\n",
      " [0.         0.         0.9451881  0.         0.         0.\n",
      "  0.         0.         0.         0.05481189 0.         0.        ]\n",
      " [0.00914146 0.         0.         0.         0.         0.\n",
      "  0.99085855 0.         0.         0.         0.         0.        ]\n",
      " [0.51214564 0.         0.         0.         0.         0.4878544\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.02252065 0.         0.         0.97747934 0.         0.        ]\n",
      " [0.         0.         0.8080679  0.         0.         0.\n",
      "  0.19193205 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5410023  0.45899776\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.0935005  0.9064995  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5001416  0.49985838 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.2297665\n",
      "  0.         0.         0.         0.7702335  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10068835 0.89931166 0.         0.        ]\n",
      " [0.58703613 0.         0.4129639  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.32296503 0.         0.         0.         0.677035\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.94630355 0.         0.         0.05369643\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.9689205  0.         0.         0.         0.03107947\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.44696227 0.\n",
      "  0.         0.         0.         0.         0.         0.5530377 ]\n",
      " [0.         0.         0.7980552  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20194483]\n",
      " [0.         0.31667823 0.         0.         0.6833218  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.18739179 0.         0.         0.         0.81260824 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.4019562  0.         0.         0.         0.\n",
      "  0.5980438  0.         0.         0.         0.         0.        ]\n",
      " [0.09886395 0.         0.         0.         0.         0.90113604\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.26891896 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.731081  ]\n",
      " [0.         0.21733338 0.7826666  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.13548952 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.8645105 ]\n",
      " [0.         0.         0.         0.         0.         0.18452454\n",
      "  0.         0.         0.         0.         0.         0.81547546]]\n",
      "total sounds is 32\n",
      "labels in generate_batch is:\n",
      "[[0.         0.         0.52099025 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.47900975]\n",
      " [0.         0.         0.         0.         0.7575757  0.2424243\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.02691611 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.9730839  0.         0.        ]\n",
      " [0.         0.         0.         0.6729776  0.         0.\n",
      "  0.32702234 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.92603487 0.07396513 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.69170886 0.         0.         0.30829114]\n",
      " [0.         0.         0.         0.         0.         0.65760165\n",
      "  0.         0.         0.         0.34239835 0.         0.        ]\n",
      " [0.9657168  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03428322 0.         0.        ]\n",
      " [0.5805183  0.4194817  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.65503263\n",
      "  0.         0.3449674  0.         0.         0.         0.        ]\n",
      " [0.         0.34832865 0.         0.         0.65167135 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.31890947 0.         0.\n",
      "  0.         0.         0.         0.68109053 0.         0.        ]\n",
      " [0.07007755 0.92992246 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.7681444  0.         0.         0.\n",
      "  0.         0.         0.         0.23185554 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6111642  0.         0.         0.         0.         0.3888358 ]\n",
      " [0.         0.         0.         0.10175205 0.89824796 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.86263657 0.         0.         0.13736345\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.65207535 0.\n",
      "  0.         0.         0.         0.         0.         0.34792465]\n",
      " [0.         0.         0.91524804 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08475197]\n",
      " [0.         0.51082486 0.         0.48917514 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.6934329  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.30656707]\n",
      " [0.         0.         0.8419852  0.         0.         0.\n",
      "  0.         0.         0.         0.15801479 0.         0.        ]\n",
      " [0.49456197 0.         0.         0.         0.         0.505438\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.4346022  0.         0.5653978  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7807402  0.2192598  0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.8232828  0.17671719 0.         0.        ]\n",
      " [0.6536717  0.         0.         0.         0.         0.\n",
      "  0.3463283  0.         0.         0.         0.         0.        ]\n",
      " [0.77563167 0.         0.         0.         0.         0.\n",
      "  0.         0.22436835 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.3838488\n",
      "  0.         0.         0.         0.         0.         0.6161512 ]\n",
      " [0.83162266 0.         0.         0.16837737 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.18481909 0.\n",
      "  0.         0.         0.         0.         0.         0.8151809 ]\n",
      " [0.75032276 0.         0.         0.         0.         0.\n",
      "  0.24967724 0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[70, 5, 12]' is invalid for input of size 4224",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [26], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TLTrainer(opt)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to training.....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [24], line 62\u001b[0m, in \u001b[0;36mTLTrainer.Train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m epoch_train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start_time;\n\u001b[1;32m     61\u001b[0m net\u001b[38;5;241m.\u001b[39meval();\n\u001b[0;32m---> 62\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossFunc\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#Save best model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__save_model(val_acc, epochIdx, net);\n",
      "Cell \u001b[0;32mIn [24], line 105\u001b[0m, in \u001b[0;36mTLTrainer.__validate\u001b[0;34m(self, net, lossFunc)\u001b[0m\n\u001b[1;32m    102\u001b[0m         scores \u001b[38;5;241m=\u001b[39m net(x);\n\u001b[1;32m    103\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m y_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat((y_pred, scores\u001b[38;5;241m.\u001b[39mdata));\n\u001b[0;32m--> 105\u001b[0m     acc, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__compute_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtestY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossFunc\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    106\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain();\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc, loss\n",
      "Cell \u001b[0;32mIn [24], line 117\u001b[0m, in \u001b[0;36mTLTrainer.__compute_accuracy\u001b[0;34m(self, y_pred, y_target, lossFunc)\u001b[0m\n\u001b[1;32m    115\u001b[0m     y_target \u001b[38;5;241m=\u001b[39m y_target\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnCrops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnCrops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[1;32m    118\u001b[0m     y_target \u001b[38;5;241m=\u001b[39m (y_target\u001b[38;5;241m.\u001b[39mreshape(y_target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mnCrops, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mnCrops, y_target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[1;32m    119\u001b[0m acc \u001b[38;5;241m=\u001b[39m (((y_pred\u001b[38;5;241m==\u001b[39my_target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mitem();\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[70, 5, 12]' is invalid for input of size 4224"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e748bbe-3e6b-4bef-9457-c995cac69a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
