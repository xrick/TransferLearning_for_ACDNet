{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eb5ead3-5abb-4e19-9ebf-298d75e5fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.ao.nn.quantized as nnq\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "import torch.ao.quantization.quantize_fx\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e53865-6b27-4444-b4b9-ca91e101196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../\"));\n",
    "import common.utils as U;\n",
    "import common.opts as opt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564322e0-05fd-488a-b67c-5bd7f3beb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1806933a-83c8-4469-ae4c-c00b534c3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U onnx\n",
    "# !pip install -U onnx-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1555e4e-ff37-4e64-ac5e-14ee2aa4a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;\n",
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetQuant, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=6, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4e18e2-24c5-4d3d-a618-21dd148c3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TLGenerator():\n",
    "#     #Generates data for Keras\n",
    "#     def __init__(self, samples, labels, options):\n",
    "#         random.seed(42);\n",
    "#         #Initialization\n",
    "#         print(f\"length of samples:{len(samples)}\")\n",
    "#         self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "#         self.opt = options;\n",
    "#         self.batch_size = options.batchSize;\n",
    "#         self.preprocess_funcs = self.preprocess_setup();\n",
    "#         self.mapdict = dict([(17,1),(18,2),(24,3),\n",
    "#                              (51,4),(52,5),(53,6)])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         #Denotes the number of batches per epoch\n",
    "#         return int(np.floor(len(self.data) / self.batch_size));\n",
    "#         #return len(self.samples);\n",
    "\n",
    "#     def __getitem__(self, batchIndex):\n",
    "#         #Generate one batch of data\n",
    "#         batchX, batchY = self.generate_batch(batchIndex);\n",
    "#         batchX = np.expand_dims(batchX, axis=1);\n",
    "#         batchX = np.expand_dims(batchX, axis=3);\n",
    "#         return batchX, batchY\n",
    "\n",
    "#     def generate_batch(self, batchIndex):\n",
    "#         #Generates data containing batch_size samples\n",
    "#         sounds = [];\n",
    "#         labels = [];\n",
    "#         indexes = None;\n",
    "#         for i in range(self.batch_size):\n",
    "#             # Training phase of BC learning\n",
    "#             # Select two training examples\n",
    "#             while True:\n",
    "#                 sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "#                 sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "#                 if label1 != label2:\n",
    "#                     break\n",
    "#             sound1 = self.preprocess(sound1)\n",
    "#             sound2 = self.preprocess(sound2)\n",
    "\n",
    "#             # Mix two examples\n",
    "#             r = np.array(random.random())\n",
    "#             sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "#             # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "#             eye = np.eye(self.opt.nClasses)\n",
    "#             idx1 = self.mapdict[label1]- 1\n",
    "#             idx2 = self.mapdict[label2] - 1\n",
    "#             label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "#             # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "#             #For stronger augmentation\n",
    "#             sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "#             # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "#             # print(f\"type of sound:{type(sound)}, and type of label:{type(label)}\")\n",
    "#             # print(f\"shape of sound:{sound.shape}\")\n",
    "#             sounds.append(sound);\n",
    "#             labels.append(label);\n",
    "\n",
    "#         sounds = np.asarray(sounds);\n",
    "#         labels = np.asarray(labels);\n",
    "#         # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "#         return sounds, labels;\n",
    "\n",
    "#     def preprocess_setup(self):\n",
    "#         funcs = []\n",
    "#         if self.opt.strongAugment:\n",
    "#             funcs += [U.random_scale(1.25)]\n",
    "\n",
    "#         funcs += [U.padding(self.opt.inputLength // 2),\n",
    "#                   U.random_crop(self.opt.inputLength),\n",
    "#                   U.normalize(32768.0)]\n",
    "#         return funcs\n",
    "\n",
    "#     def preprocess(self, sound):\n",
    "#         for f in self.preprocess_funcs:\n",
    "#             sound = f(sound)\n",
    "\n",
    "#         return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed9ae088-4617-4e06-be39-6ddbddfba1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getOpts():\n",
    "#     parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "#     parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "#     parser.add_argument('--data', default='./datasets/processed/',  required=False);\n",
    "#     parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "#     parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "#     parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "#     #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "#     opt, unknown = parser.parse_known_args()\n",
    "#     #Leqarning settings\n",
    "#     opt.batchSize = 2;\n",
    "#     opt.weightDecay = 5e-4;\n",
    "#     opt.momentum = 0.09;\n",
    "#     opt.nEpochs = 10;#2000;\n",
    "#     opt.LR = 0.01#0.1;\n",
    "#     opt.schedule = [0.03, 0.06, 0.09]#[0.3, 0.6, 0.9];\n",
    "#     opt.warmup = 10;\n",
    "\n",
    "#     #Basic Net Settings\n",
    "#     opt.nClasses = 6#50;\n",
    "#     opt.nFolds = 1;#5;\n",
    "#     opt.split = 1#[i for i in range(1, opt.nFolds + 1)];\n",
    "#     opt.sr = 16000#20000;\n",
    "#     opt.inputLength = 30225;\n",
    "#     #Test data\n",
    "#     opt.nCrops = 5;\n",
    "#     return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c589418b-e041-4292-8c90-333d0b35dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTrainGen(opt=None, split=None):\n",
    "#     # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "#     # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "#     dataset = np.load(\"../datasets/fold1_dataset.npz\", allow_pickle=True);\n",
    "#     train_sounds = []\n",
    "#     train_labels = []\n",
    "#     # print(len(dataset['x']))\n",
    "#     # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "#     # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "#     # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "#     train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "#     train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "#     # print(train_sounds)\n",
    "\n",
    "#     trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "#     return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6690ed56-e042-47f7-8784-0e222fc875ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     opt = getOpts()\n",
    "#     opt.sr = 20000;\n",
    "#     opt.inputLength = 30225;\n",
    "#     dataGen = getTrainGen(opt)\n",
    "#     x,y = dataGen.__getitem__(0);\n",
    "#     print(f\"shape of x:{x.shape}\")\n",
    "#     x  = torch.tensor(np.moveaxis(x, 3, 1)).to('cpu');\n",
    "#     print(f\"shape of x:{x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a19e9363-8aca-463b-80e0-5f96b282adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of samples:65\n",
      "shape of x:(2, 1, 30225, 1)\n",
      "shape of x:torch.Size([2, 1, 1, 30225])\n"
     ]
    }
   ],
   "source": [
    "# length of samples:65\n",
    "# shape of x:(2, 1, 30225, 1)\n",
    "# shape of x:torch.Size([2, 1, 1, 30225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d92fab8b-1c2f-419e-b8ff-050e514035b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pt2keras(pt_model=None):\n",
    "    rdnary = torch.randn(2, 1, 30225, 1);\n",
    "    # quant_model = GetCustomedACDNetModel()\n",
    "    # quant_model.load_state_dict(torch.load(pt_model, map_location='cpu'));\n",
    "    quant_model = torch.jit.load(pt_model)\n",
    "    onnx_program = torch.onnx.dynamo_export(quant_model, rdnary)\n",
    "    onnx_program.save(\"./onnx_models/acdnet_tl_quant_model_202312281348_80.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd5e4146-b76d-46af-b9a2-3106302ca134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OnnxExporterError",
     "evalue": "Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:2547\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2547\u001b[0m     sig \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:2468\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[0;32m-> 2468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_builtin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:2275\u001b[0m, in \u001b[0;36m_signature_from_builtin\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s:\n\u001b[0;32m-> 2275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno signature found for builtin \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func))\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _signature_fromstr(\u001b[38;5;28mcls\u001b[39m, func, s, skip_bound_arg)\n",
      "\u001b[0;31mValueError\u001b[0m: no signature found for builtin <instancemethod __call__ at 0x7f6d1471cd00>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1195\u001b[0m, in \u001b[0;36mdynamo_export\u001b[0;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_export_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:941\u001b[0m, in \u001b[0;36mExporter.export\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdiagnostic_context:\n\u001b[0;32m--> 941\u001b[0m     graph_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx_tracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_fx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    945\u001b[0m     updated_model_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mfx_tracer\u001b[38;5;241m.\u001b[39minput_adapter\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m    947\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/onnx/_internal/fx/dynamo_graph_extractor.py:199\u001b[0m, in \u001b[0;36mDynamoExport.generate_fx\u001b[0;34m(self, options, model, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fake_mode:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     graph_module, graph_guard \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracing_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfx_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m graph_guard  \u001b[38;5;66;03m# Unused\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:1041\u001b[0m, in \u001b[0;36mexport.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m call_to_inspect \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m f\n\u001b[0;32m-> 1041\u001b[0m original_signature \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_to_inspect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3255\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3001\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3003\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/inspect.py:2550\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno signature found for \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj)\n\u001b[0;32m-> 2550\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m   2552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;66;03m# For classes and objects we skip the first parameter of their\u001b[39;00m\n\u001b[1;32m   2554\u001b[0m     \u001b[38;5;66;03m# __call__, __new__, or __init__ methods\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: no signature found for <torch.ScriptMethod object at 0x7f6c3bcead90>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./quantized_models/acdnet_tl_quant_model_202312281348_80.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mconvert_pt2keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m, in \u001b[0;36mconvert_pt2keras\u001b[0;34m(pt_model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# quant_model = GetCustomedACDNetModel()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# quant_model.load_state_dict(torch.load(pt_model, map_location='cpu'));\u001b[39;00m\n\u001b[1;32m      5\u001b[0m quant_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(pt_model)\n\u001b[0;32m----> 6\u001b[0m onnx_program \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamo_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrdnary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m onnx_program\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./onnx_models/acdnet_tl_quant_model_202312281348_80.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1206\u001b[0m, in \u001b[0;36mdynamo_export\u001b[0;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context\u001b[38;5;241m.\u001b[39mdump(sarif_report_path)\n\u001b[1;32m   1199\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to export the model to ONNX. Generating SARIF report at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msarif_report_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSARIF is a standard format for the output of static analysis tools. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease report a bug on PyTorch Github: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_PYTORCH_GITHUB_ISSUES_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1205\u001b[0m )\n\u001b[0;32m-> 1206\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OnnxExporterError(\n\u001b[1;32m   1207\u001b[0m     ExportOutput\u001b[38;5;241m.\u001b[39m_from_failure(e, resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context),\n\u001b[1;32m   1208\u001b[0m     message,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m: Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues"
     ]
    }
   ],
   "source": [
    "model_path = \"./quantized_models/acdnet_tl_quant_model_202312281348_80.pt\"\n",
    "convert_pt2keras(pt_model=model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f63447-b4c2-4dee-91d1-e111a5d810ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxscript\n",
      "  Downloading onnxscript-0.1.0.dev20231228-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (1.26.2)\n",
      "Requirement already satisfied: onnx>=1.14 in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnxscript) (4.8.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages (from onnx>=1.14->onnxscript) (4.23.4)\n",
      "Downloading onnxscript-0.1.0.dev20231228-py3-none-any.whl (550 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m550.7/550.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: onnxscript\n",
      "Successfully installed onnxscript-0.1.0.dev20231228\n"
     ]
    }
   ],
   "source": [
    "# !pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d421ae89-45af-4c1e-bf07-56d5ca97ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinynn.converter import TFLiteConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d3bb12-64f3-4677-81d8-f14e9bdec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    qmodel = copy.deepcopy(mynn)\n",
    "    torch.quantization.convert(qmodel, inplace=False)\n",
    "    #\n",
    "    torch.backends.quantized.engine = 'qnnpack'\n",
    "    converter = TFLiteConverter(qmodel.module,\n",
    "                                torch.randn(1, 64, nn_h, nn_w,\n",
    "                                tflite_path=\"qmodel.tflite\")\n",
    "    converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
