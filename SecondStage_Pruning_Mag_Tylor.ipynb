{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36995275-4419-4d02-a744-3d37ef85e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([(52,1),(99,2)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[label1]- 1\n",
    "            idx2 = self.mapdict[label2] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(\"./datasets/forOneClassModel_alarm/train/trainSet_20240119002902.npz\", allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/forOneClassModel_alarm/train_test_npz/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 32;\n",
    "    opt.weightDecay = 5e-3;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 1000;#2000;\n",
    "    opt.LR = 0.1;\n",
    "    opt.schedule = [0.3, 0.6, 0.9]\n",
    "    opt.warmup = 10;\n",
    "\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 2#50;\n",
    "    opt.nFolds = 1;#5;\n",
    "    opt.split = 1#[i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=2, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 2 #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.opt.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel()\n",
    "        self.net.load_state_dict(torch.load(\"./th/pruned_models/first_stage_pruning/acdne_97.7_purn_20240205093045.pt\", map_location=\"cuda:0\")['weight']);\n",
    "        # self.net = models.GetACDNetModel().to(self.opt.device);\n",
    "        # state = torch.load(self.opt.model_path, map_location=self.opt.device);\n",
    "        # self.net.load_state_dict(state['weight']);\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        print(f\"pruning algorithm is {self.pruner}\");\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(\"./datasets/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz\", allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    # import torch;\n",
    "    opt.device = 'cpu'#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.model_name = \"./th/pruned_models/second_stage_pruned_models/tylor_pruning/acdnet_second_pruning_tylor_pruning_model_from_acc_97.7_85compress_{}.pt\".format(genDataTimeStr());\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:325\n",
      "Start to pruning.....\n",
      "pruning algorithm is <th.resources.pruning_tools.filter_pruning.Taylor object at 0x7f33206e3760>\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (2, 2, 4)      1,024        8,192\n",
      " BatchNorm2d-42         (2, 2, 4)         (2, 2, 4)          4            0\n",
      "        ReLu-43         (2, 2, 4)         (2, 2, 4)          0           16\n",
      "   AvgPool2d-44         (2, 2, 4)         (2, 1, 1)          0           16\n",
      "     Flatten-45         (2, 1, 1)            (1, 2)          0            0\n",
      "      Linear-46            (1, 2)            (1, 2)          6            6\n",
      "     Softmax-47            (1, 2)            (1, 2)          0            2\n",
      "==============================================================================\n",
      "Total Params: 4,708,162\n",
      "Total FLOPs : 544,222,072\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2026, Prunable: 2026, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1721\n",
      "Total iterations required: 1721\n",
      "\n",
      "Iteration 1 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,708,120 (17.960 MB), Total: 18.08 MB, FLOPs: 483,662,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.364%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.500%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,708,078 (17.960 MB), Total: 18.08 MB, FLOPs: 483,296,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1723 finished in 0m16s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,708,036 (17.960 MB), Total: 18.08 MB, FLOPs: 478,764,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1723 finished in 0m16s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,994 (17.960 MB), Total: 18.07 MB, FLOPs: 478,399,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1723 finished in 0m16s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,707,952 (17.959 MB), Total: 18.07 MB, FLOPs: 465,664,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1723 finished in 0m15s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,707,910 (17.959 MB), Total: 18.07 MB, FLOPs: 465,299,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1723 finished in 0m15s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,868 (17.959 MB), Total: 18.07 MB, FLOPs: 460,767,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1723 finished in 0m15s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,707,826 (17.959 MB), Total: 18.07 MB, FLOPs: 460,401,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1723 finished in 0m15s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,707,784 (17.959 MB), Total: 18.07 MB, FLOPs: 431,723,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.773%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1723 finished in 0m15s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,707,742 (17.959 MB), Total: 18.07 MB, FLOPs: 431,357,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1723 finished in 0m14s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,707,700 (17.958 MB), Total: 18.07 MB, FLOPs: 426,825,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1723 finished in 0m14s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 17)]\n",
      "Input: 0.115 MB, Params: 4,707,113 (17.956 MB), Total: 18.07 MB, FLOPs: 425,614,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1723 finished in 0m14s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 25)]\n",
      "Input: 0.115 MB, Params: 4,706,526 (17.954 MB), Total: 18.07 MB, FLOPs: 424,403,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1723 finished in 0m14s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,699,612 (17.928 MB), Total: 18.04 MB, FLOPs: 424,030,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1723 finished in 0m14s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 4,695,000 (17.910 MB), Total: 18.03 MB, FLOPs: 423,905,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1723 finished in 0m14s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 4,690,388 (17.892 MB), Total: 18.01 MB, FLOPs: 423,781,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1723 finished in 0m14s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 338)]\n",
      "Input: 0.115 MB, Params: 4,683,501 (17.866 MB), Total: 17.98 MB, FLOPs: 423,595,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1723 finished in 0m14s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 4,678,898 (17.849 MB), Total: 17.96 MB, FLOPs: 423,471,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1723 finished in 0m14s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.115 MB, Params: 4,674,295 (17.831 MB), Total: 17.95 MB, FLOPs: 423,347,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1723 finished in 0m14s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 172)]\n",
      "Input: 0.115 MB, Params: 4,667,390 (17.805 MB), Total: 17.92 MB, FLOPs: 422,973,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1723 finished in 0m14s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 201)]\n",
      "Input: 0.115 MB, Params: 4,662,787 (17.787 MB), Total: 17.90 MB, FLOPs: 422,849,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1723 finished in 0m14s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 4,658,184 (17.770 MB), Total: 17.88 MB, FLOPs: 422,725,354\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1723 finished in 0m14s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.115 MB, Params: 4,653,581 (17.752 MB), Total: 17.87 MB, FLOPs: 422,601,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1723 finished in 0m14s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 288)]\n",
      "Input: 0.115 MB, Params: 4,648,978 (17.734 MB), Total: 17.85 MB, FLOPs: 422,476,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1723 finished in 0m14s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.115 MB, Params: 4,644,375 (17.717 MB), Total: 17.83 MB, FLOPs: 422,352,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1723 finished in 0m14s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 427)]\n",
      "Input: 0.115 MB, Params: 4,639,772 (17.699 MB), Total: 17.81 MB, FLOPs: 422,228,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1723 finished in 0m14s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.115 MB, Params: 4,636,332 (17.686 MB), Total: 17.80 MB, FLOPs: 421,857,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1723 finished in 0m14s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 4,631,729 (17.669 MB), Total: 17.78 MB, FLOPs: 421,732,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1723 finished in 0m14s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 425)]\n",
      "Input: 0.115 MB, Params: 4,627,126 (17.651 MB), Total: 17.77 MB, FLOPs: 421,608,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1723 finished in 0m14s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 4,622,523 (17.634 MB), Total: 17.75 MB, FLOPs: 421,484,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1723 finished in 0m14s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 4,617,920 (17.616 MB), Total: 17.73 MB, FLOPs: 421,360,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1723 finished in 0m14s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.115 MB, Params: 4,614,480 (17.603 MB), Total: 17.72 MB, FLOPs: 420,988,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1723 finished in 0m14s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 397)]\n",
      "Input: 0.115 MB, Params: 4,609,877 (17.585 MB), Total: 17.70 MB, FLOPs: 420,864,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1723 finished in 0m14s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 404)]\n",
      "Input: 0.115 MB, Params: 4,603,116 (17.559 MB), Total: 17.67 MB, FLOPs: 420,681,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1723 finished in 0m14s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.115 MB, Params: 4,598,522 (17.542 MB), Total: 17.66 MB, FLOPs: 420,558,013\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1723 finished in 0m14s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 4,593,928 (17.524 MB), Total: 17.64 MB, FLOPs: 420,434,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1723 finished in 0m14s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.115 MB, Params: 4,589,334 (17.507 MB), Total: 17.62 MB, FLOPs: 420,310,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1723 finished in 0m14s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 4,582,456 (17.481 MB), Total: 17.60 MB, FLOPs: 419,939,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1723 finished in 0m14s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 356)]\n",
      "Input: 0.115 MB, Params: 4,577,862 (17.463 MB), Total: 17.58 MB, FLOPs: 419,815,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1723 finished in 0m14s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 4,573,268 (17.446 MB), Total: 17.56 MB, FLOPs: 419,691,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1723 finished in 0m14s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 473)]\n",
      "Input: 0.115 MB, Params: 4,568,674 (17.428 MB), Total: 17.54 MB, FLOPs: 419,567,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1723 finished in 0m14s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.115 MB, Params: 4,565,243 (17.415 MB), Total: 17.53 MB, FLOPs: 419,196,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1723 finished in 0m14s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 4,560,649 (17.397 MB), Total: 17.51 MB, FLOPs: 419,072,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1723 finished in 0m14s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 378)]\n",
      "Input: 0.115 MB, Params: 4,556,055 (17.380 MB), Total: 17.50 MB, FLOPs: 418,948,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1723 finished in 0m14s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 323)]\n",
      "Input: 0.115 MB, Params: 4,549,375 (17.354 MB), Total: 17.47 MB, FLOPs: 418,768,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1723 finished in 0m14s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 4,544,790 (17.337 MB), Total: 17.45 MB, FLOPs: 418,644,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1723 finished in 0m14s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 309)]\n",
      "Input: 0.115 MB, Params: 4,540,205 (17.320 MB), Total: 17.43 MB, FLOPs: 418,520,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1723 finished in 0m14s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 472)]\n",
      "Input: 0.115 MB, Params: 4,535,620 (17.302 MB), Total: 17.42 MB, FLOPs: 418,397,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1723 finished in 0m14s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 391)]\n",
      "Input: 0.115 MB, Params: 4,531,035 (17.285 MB), Total: 17.40 MB, FLOPs: 418,273,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1723 finished in 0m14s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 347)]\n",
      "Input: 0.115 MB, Params: 4,526,450 (17.267 MB), Total: 17.38 MB, FLOPs: 418,149,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1723 finished in 0m14s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.115 MB, Params: 4,519,590 (17.241 MB), Total: 17.36 MB, FLOPs: 417,779,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1723 finished in 0m14s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 423)]\n",
      "Input: 0.115 MB, Params: 4,515,005 (17.223 MB), Total: 17.34 MB, FLOPs: 417,656,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1723 finished in 0m14s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.115 MB, Params: 4,510,420 (17.206 MB), Total: 17.32 MB, FLOPs: 417,532,354\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1723 finished in 0m14s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 283)]\n",
      "Input: 0.115 MB, Params: 4,505,835 (17.188 MB), Total: 17.30 MB, FLOPs: 417,408,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1723 finished in 0m14s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.115 MB, Params: 4,502,413 (17.175 MB), Total: 17.29 MB, FLOPs: 417,039,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1723 finished in 0m14s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 4,495,814 (17.150 MB), Total: 17.27 MB, FLOPs: 416,861,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1723 finished in 0m14s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.115 MB, Params: 4,494,084 (17.144 MB), Total: 17.26 MB, FLOPs: 416,029,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1723 finished in 0m14s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.115 MB, Params: 4,490,662 (17.131 MB), Total: 17.25 MB, FLOPs: 415,659,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1723 finished in 0m14s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 4,486,086 (17.113 MB), Total: 17.23 MB, FLOPs: 415,536,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1723 finished in 0m14s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.115 MB, Params: 4,481,510 (17.096 MB), Total: 17.21 MB, FLOPs: 415,412,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1723 finished in 0m14s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 391)]\n",
      "Input: 0.115 MB, Params: 4,476,934 (17.078 MB), Total: 17.19 MB, FLOPs: 415,289,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1723 finished in 0m14s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 422)]\n",
      "Input: 0.115 MB, Params: 4,472,358 (17.061 MB), Total: 17.18 MB, FLOPs: 415,165,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1723 finished in 0m14s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 448)]\n",
      "Input: 0.115 MB, Params: 4,467,782 (17.043 MB), Total: 17.16 MB, FLOPs: 415,042,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1723 finished in 0m14s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 380)]\n",
      "Input: 0.115 MB, Params: 4,463,206 (17.026 MB), Total: 17.14 MB, FLOPs: 414,918,915\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1723 finished in 0m14s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 4,459,802 (17.013 MB), Total: 17.13 MB, FLOPs: 414,124,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1723 finished in 0m14s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 439)]\n",
      "Input: 0.115 MB, Params: 4,453,257 (16.988 MB), Total: 17.10 MB, FLOPs: 413,947,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1723 finished in 0m14s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 4,446,712 (16.963 MB), Total: 17.08 MB, FLOPs: 413,770,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1723 finished in 0m14s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 4,442,154 (16.945 MB), Total: 17.06 MB, FLOPs: 413,647,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1723 finished in 0m14s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 4,437,596 (16.928 MB), Total: 17.04 MB, FLOPs: 413,524,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1723 finished in 0m14s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 350)]\n",
      "Input: 0.115 MB, Params: 4,433,038 (16.911 MB), Total: 17.03 MB, FLOPs: 413,401,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1723 finished in 0m14s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 4,428,480 (16.893 MB), Total: 17.01 MB, FLOPs: 413,278,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1723 finished in 0m14s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 125)]\n",
      "Input: 0.115 MB, Params: 4,425,076 (16.880 MB), Total: 17.00 MB, FLOPs: 412,484,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1723 finished in 0m14s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 282)]\n",
      "Input: 0.115 MB, Params: 4,418,567 (16.855 MB), Total: 16.97 MB, FLOPs: 412,308,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1723 finished in 0m14s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 324)]\n",
      "Input: 0.115 MB, Params: 4,412,058 (16.831 MB), Total: 16.95 MB, FLOPs: 412,132,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1723 finished in 0m14s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 51)]\n",
      "Input: 0.115 MB, Params: 4,410,346 (16.824 MB), Total: 16.94 MB, FLOPs: 411,309,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1723 finished in 0m14s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 4,405,806 (16.807 MB), Total: 16.92 MB, FLOPs: 411,187,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1723 finished in 0m14s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.115 MB, Params: 4,401,266 (16.789 MB), Total: 16.90 MB, FLOPs: 411,064,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1723 finished in 0m14s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 4,396,726 (16.772 MB), Total: 16.89 MB, FLOPs: 410,942,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1723 finished in 0m14s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 4,392,186 (16.755 MB), Total: 16.87 MB, FLOPs: 410,819,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1723 finished in 0m14s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 486)]\n",
      "Input: 0.115 MB, Params: 4,385,713 (16.730 MB), Total: 16.85 MB, FLOPs: 410,644,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1723 finished in 0m14s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.115 MB, Params: 4,381,182 (16.713 MB), Total: 16.83 MB, FLOPs: 410,522,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1723 finished in 0m14s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 439)]\n",
      "Input: 0.115 MB, Params: 4,376,651 (16.696 MB), Total: 16.81 MB, FLOPs: 410,400,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1723 finished in 0m14s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.115 MB, Params: 4,370,196 (16.671 MB), Total: 16.79 MB, FLOPs: 410,226,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1723 finished in 0m14s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 347)]\n",
      "Input: 0.115 MB, Params: 4,363,741 (16.646 MB), Total: 16.76 MB, FLOPs: 410,051,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1723 finished in 0m14s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 122)]\n",
      "Input: 0.115 MB, Params: 4,360,337 (16.633 MB), Total: 16.75 MB, FLOPs: 409,684,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1723 finished in 0m14s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 312)]\n",
      "Input: 0.115 MB, Params: 4,355,824 (16.616 MB), Total: 16.73 MB, FLOPs: 409,562,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1723 finished in 0m14s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 4,349,063 (16.590 MB), Total: 16.71 MB, FLOPs: 409,197,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1723 finished in 0m14s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 213)]\n",
      "Input: 0.115 MB, Params: 4,345,668 (16.577 MB), Total: 16.69 MB, FLOPs: 408,831,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1723 finished in 0m14s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 4,341,155 (16.560 MB), Total: 16.68 MB, FLOPs: 408,709,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1723 finished in 0m14s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 74)]\n",
      "Input: 0.115 MB, Params: 4,334,403 (16.534 MB), Total: 16.65 MB, FLOPs: 408,345,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1723 finished in 0m14s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 132)]\n",
      "Input: 0.115 MB, Params: 4,331,017 (16.522 MB), Total: 16.64 MB, FLOPs: 407,979,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1723 finished in 0m14s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 240)]\n",
      "Input: 0.115 MB, Params: 4,324,274 (16.496 MB), Total: 16.61 MB, FLOPs: 407,616,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1723 finished in 0m14s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 367)]\n",
      "Input: 0.115 MB, Params: 4,319,761 (16.479 MB), Total: 16.59 MB, FLOPs: 407,494,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1723 finished in 0m14s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.115 MB, Params: 4,316,393 (16.466 MB), Total: 16.58 MB, FLOPs: 406,707,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1723 finished in 0m14s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.115 MB, Params: 4,311,880 (16.449 MB), Total: 16.56 MB, FLOPs: 406,585,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1723 finished in 0m14s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.115 MB, Params: 4,307,367 (16.431 MB), Total: 16.55 MB, FLOPs: 406,463,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1723 finished in 0m14s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 4,302,854 (16.414 MB), Total: 16.53 MB, FLOPs: 406,342,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1723 finished in 0m14s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 4,298,341 (16.397 MB), Total: 16.51 MB, FLOPs: 406,220,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1723 finished in 0m14s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 412)]\n",
      "Input: 0.115 MB, Params: 4,293,828 (16.380 MB), Total: 16.49 MB, FLOPs: 406,098,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1723 finished in 0m14s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.115 MB, Params: 4,290,460 (16.367 MB), Total: 16.48 MB, FLOPs: 405,734,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1723 finished in 0m14s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 4,285,947 (16.350 MB), Total: 16.46 MB, FLOPs: 405,613,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1723 finished in 0m14s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 217)]\n",
      "Input: 0.115 MB, Params: 4,279,213 (16.324 MB), Total: 16.44 MB, FLOPs: 405,250,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1723 finished in 0m14s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 4,274,700 (16.307 MB), Total: 16.42 MB, FLOPs: 405,129,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1723 finished in 0m14s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 4,271,341 (16.294 MB), Total: 16.41 MB, FLOPs: 404,342,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1723 finished in 0m14s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 443)]\n",
      "Input: 0.115 MB, Params: 4,266,828 (16.277 MB), Total: 16.39 MB, FLOPs: 404,220,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1723 finished in 0m14s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 4,260,094 (16.251 MB), Total: 16.37 MB, FLOPs: 403,858,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1723 finished in 0m14s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.115 MB, Params: 4,256,753 (16.238 MB), Total: 16.35 MB, FLOPs: 403,498,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1723 finished in 0m14s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.115 MB, Params: 4,255,059 (16.232 MB), Total: 16.35 MB, FLOPs: 402,683,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1723 finished in 0m14s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 4,250,546 (16.215 MB), Total: 16.33 MB, FLOPs: 402,562,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1723 finished in 0m14s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 4,247,205 (16.202 MB), Total: 16.32 MB, FLOPs: 402,201,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1723 finished in 0m14s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 296)]\n",
      "Input: 0.115 MB, Params: 4,242,692 (16.185 MB), Total: 16.30 MB, FLOPs: 402,079,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1723 finished in 0m14s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 4,235,976 (16.159 MB), Total: 16.27 MB, FLOPs: 401,719,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1723 finished in 0m14s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 157)]\n",
      "Input: 0.115 MB, Params: 4,229,260 (16.133 MB), Total: 16.25 MB, FLOPs: 401,359,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1723 finished in 0m14s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 4,224,747 (16.116 MB), Total: 16.23 MB, FLOPs: 401,237,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1723 finished in 0m14s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.115 MB, Params: 4,218,481 (16.092 MB), Total: 16.21 MB, FLOPs: 401,068,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1723 finished in 0m14s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 4,213,977 (16.075 MB), Total: 16.19 MB, FLOPs: 400,946,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1723 finished in 0m14s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 4,209,473 (16.058 MB), Total: 16.17 MB, FLOPs: 400,825,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1723 finished in 0m14s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 272)]\n",
      "Input: 0.115 MB, Params: 4,204,969 (16.041 MB), Total: 16.16 MB, FLOPs: 400,703,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1723 finished in 0m14s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 4,198,730 (16.017 MB), Total: 16.13 MB, FLOPs: 400,535,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1723 finished in 0m14s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.115 MB, Params: 4,194,235 (16.000 MB), Total: 16.12 MB, FLOPs: 400,413,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1723 finished in 0m14s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 81)]\n",
      "Input: 0.115 MB, Params: 4,192,541 (15.993 MB), Total: 16.11 MB, FLOPs: 399,599,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1723 finished in 0m14s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 4,188,046 (15.976 MB), Total: 16.09 MB, FLOPs: 399,478,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1723 finished in 0m14s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.115 MB, Params: 4,181,825 (15.952 MB), Total: 16.07 MB, FLOPs: 399,310,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1723 finished in 0m14s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 4,177,339 (15.935 MB), Total: 16.05 MB, FLOPs: 399,189,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1723 finished in 0m14s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 4,171,127 (15.912 MB), Total: 16.03 MB, FLOPs: 399,021,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1723 finished in 0m14s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.115 MB, Params: 4,170,279 (15.908 MB), Total: 16.02 MB, FLOPs: 397,369,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1723 finished in 0m14s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 4,165,802 (15.891 MB), Total: 16.01 MB, FLOPs: 397,249,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1723 finished in 0m14s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 4,164,117 (15.885 MB), Total: 16.00 MB, FLOPs: 395,602,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1723 finished in 0m14s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 22)]\n",
      "Input: 0.115 MB, Params: 4,160,794 (15.872 MB), Total: 15.99 MB, FLOPs: 394,827,006\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1723 finished in 0m14s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 443)]\n",
      "Input: 0.115 MB, Params: 4,154,591 (15.849 MB), Total: 15.96 MB, FLOPs: 394,659,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1723 finished in 0m14s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.115 MB, Params: 4,152,915 (15.842 MB), Total: 15.96 MB, FLOPs: 393,853,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1723 finished in 0m14s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 4,146,712 (15.818 MB), Total: 15.93 MB, FLOPs: 393,686,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1723 finished in 0m14s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.115 MB, Params: 4,142,253 (15.801 MB), Total: 15.92 MB, FLOPs: 393,566,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1723 finished in 0m19s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 480)]\n",
      "Input: 0.115 MB, Params: 4,136,059 (15.778 MB), Total: 15.89 MB, FLOPs: 393,398,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1723 finished in 0m14s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 4,134,383 (15.771 MB), Total: 15.89 MB, FLOPs: 392,593,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1723 finished in 0m14s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 168)]\n",
      "Input: 0.115 MB, Params: 4,127,730 (15.746 MB), Total: 15.86 MB, FLOPs: 392,234,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1723 finished in 0m14s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 4,121,545 (15.722 MB), Total: 15.84 MB, FLOPs: 392,067,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1723 finished in 0m14s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 54)]\n",
      "Input: 0.115 MB, Params: 4,115,360 (15.699 MB), Total: 15.81 MB, FLOPs: 391,900,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1723 finished in 0m14s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 359)]\n",
      "Input: 0.115 MB, Params: 4,110,928 (15.682 MB), Total: 15.80 MB, FLOPs: 391,781,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1723 finished in 0m14s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 4,104,293 (15.657 MB), Total: 15.77 MB, FLOPs: 391,423,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1723 finished in 0m14s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 4,099,861 (15.640 MB), Total: 15.76 MB, FLOPs: 391,303,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1723 finished in 0m14s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 298)]\n",
      "Input: 0.115 MB, Params: 4,095,429 (15.623 MB), Total: 15.74 MB, FLOPs: 391,184,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1723 finished in 0m14s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 4,089,280 (15.599 MB), Total: 15.71 MB, FLOPs: 391,018,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1723 finished in 0m14s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 4,083,131 (15.576 MB), Total: 15.69 MB, FLOPs: 390,852,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1723 finished in 0m14s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 4,078,717 (15.559 MB), Total: 15.67 MB, FLOPs: 390,733,021\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1723 finished in 0m14s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 4,072,577 (15.536 MB), Total: 15.65 MB, FLOPs: 390,567,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1723 finished in 0m14s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 349)]\n",
      "Input: 0.115 MB, Params: 4,068,172 (15.519 MB), Total: 15.63 MB, FLOPs: 390,448,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1723 finished in 0m14s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 4,063,767 (15.502 MB), Total: 15.62 MB, FLOPs: 390,329,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1723 finished in 0m14s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 343)]\n",
      "Input: 0.115 MB, Params: 4,057,645 (15.479 MB), Total: 15.59 MB, FLOPs: 390,164,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1723 finished in 0m15s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 4,053,249 (15.462 MB), Total: 15.58 MB, FLOPs: 390,045,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1723 finished in 0m14s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 223)]\n",
      "Input: 0.115 MB, Params: 4,049,953 (15.449 MB), Total: 15.56 MB, FLOPs: 389,689,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1723 finished in 0m14s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 4,046,657 (15.437 MB), Total: 15.55 MB, FLOPs: 389,333,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1723 finished in 0m14s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 4,042,261 (15.420 MB), Total: 15.54 MB, FLOPs: 389,215,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1723 finished in 0m15s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 4,037,865 (15.403 MB), Total: 15.52 MB, FLOPs: 389,096,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1723 finished in 0m15s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.115 MB, Params: 4,033,469 (15.386 MB), Total: 15.50 MB, FLOPs: 388,977,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1723 finished in 0m14s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 4,029,073 (15.370 MB), Total: 15.48 MB, FLOPs: 388,859,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1723 finished in 0m14s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.115 MB, Params: 4,024,677 (15.353 MB), Total: 15.47 MB, FLOPs: 388,740,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1723 finished in 0m14s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 287)]\n",
      "Input: 0.115 MB, Params: 4,018,609 (15.330 MB), Total: 15.45 MB, FLOPs: 388,576,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1723 finished in 0m14s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 4,012,037 (15.305 MB), Total: 15.42 MB, FLOPs: 388,222,153\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1723 finished in 0m14s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.115 MB, Params: 4,010,370 (15.298 MB), Total: 15.41 MB, FLOPs: 386,584,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1723 finished in 0m14s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 456)]\n",
      "Input: 0.115 MB, Params: 4,004,311 (15.275 MB), Total: 15.39 MB, FLOPs: 386,420,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1723 finished in 0m15s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 235)]\n",
      "Input: 0.115 MB, Params: 3,997,748 (15.250 MB), Total: 15.37 MB, FLOPs: 386,066,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1723 finished in 0m15s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 109)]\n",
      "Input: 0.115 MB, Params: 3,994,461 (15.238 MB), Total: 15.35 MB, FLOPs: 385,301,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1723 finished in 0m15s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 457)]\n",
      "Input: 0.115 MB, Params: 3,988,411 (15.215 MB), Total: 15.33 MB, FLOPs: 385,137,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1723 finished in 0m15s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 399)]\n",
      "Input: 0.115 MB, Params: 3,984,042 (15.198 MB), Total: 15.31 MB, FLOPs: 385,019,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1723 finished in 0m15s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 437)]\n",
      "Input: 0.115 MB, Params: 3,978,001 (15.175 MB), Total: 15.29 MB, FLOPs: 384,856,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1723 finished in 0m15s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.115 MB, Params: 3,973,641 (15.158 MB), Total: 15.27 MB, FLOPs: 384,739,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1723 finished in 0m14s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.115 MB, Params: 3,969,281 (15.142 MB), Total: 15.26 MB, FLOPs: 384,621,533\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1723 finished in 0m15s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 459)]\n",
      "Input: 0.115 MB, Params: 3,963,258 (15.119 MB), Total: 15.23 MB, FLOPs: 384,458,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1723 finished in 0m14s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.115 MB, Params: 3,957,235 (15.096 MB), Total: 15.21 MB, FLOPs: 384,296,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1723 finished in 0m14s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 376)]\n",
      "Input: 0.115 MB, Params: 3,952,893 (15.079 MB), Total: 15.19 MB, FLOPs: 384,179,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1723 finished in 0m14s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.115 MB, Params: 3,952,063 (15.076 MB), Total: 15.19 MB, FLOPs: 382,562,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1723 finished in 0m14s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 222)]\n",
      "Input: 0.115 MB, Params: 3,948,794 (15.063 MB), Total: 15.18 MB, FLOPs: 382,209,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1723 finished in 0m14s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 3,942,780 (15.041 MB), Total: 15.16 MB, FLOPs: 382,047,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1723 finished in 0m14s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 3,938,447 (15.024 MB), Total: 15.14 MB, FLOPs: 381,930,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1723 finished in 0m18s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.115 MB, Params: 3,934,114 (15.007 MB), Total: 15.12 MB, FLOPs: 381,813,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1723 finished in 0m14s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 3,928,118 (14.985 MB), Total: 15.10 MB, FLOPs: 381,651,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1723 finished in 0m14s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 197)]\n",
      "Input: 0.115 MB, Params: 3,921,618 (14.960 MB), Total: 15.08 MB, FLOPs: 381,299,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1723 finished in 0m14s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 3,917,294 (14.943 MB), Total: 15.06 MB, FLOPs: 381,182,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1723 finished in 0m14s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 103)]\n",
      "Input: 0.115 MB, Params: 3,915,636 (14.937 MB), Total: 15.05 MB, FLOPs: 380,385,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1723 finished in 0m14s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 339)]\n",
      "Input: 0.115 MB, Params: 3,911,312 (14.920 MB), Total: 15.04 MB, FLOPs: 380,269,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1723 finished in 0m14s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 3,906,988 (14.904 MB), Total: 15.02 MB, FLOPs: 380,152,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1723 finished in 0m14s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 3,900,488 (14.879 MB), Total: 14.99 MB, FLOPs: 379,800,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1723 finished in 0m14s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 3,894,537 (14.856 MB), Total: 14.97 MB, FLOPs: 379,639,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1723 finished in 0m14s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.115 MB, Params: 3,890,222 (14.840 MB), Total: 14.96 MB, FLOPs: 379,523,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1723 finished in 0m14s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.115 MB, Params: 3,884,280 (14.817 MB), Total: 14.93 MB, FLOPs: 379,362,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1723 finished in 0m15s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.115 MB, Params: 3,881,029 (14.805 MB), Total: 14.92 MB, FLOPs: 379,011,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1723 finished in 0m15s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 17)]\n",
      "Input: 0.115 MB, Params: 3,880,460 (14.803 MB), Total: 14.92 MB, FLOPs: 377,835,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1723 finished in 0m15s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 3,876,154 (14.786 MB), Total: 14.90 MB, FLOPs: 377,719,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1723 finished in 0m14s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 3,871,848 (14.770 MB), Total: 14.89 MB, FLOPs: 377,603,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1723 finished in 0m14s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 301)]\n",
      "Input: 0.115 MB, Params: 3,867,542 (14.754 MB), Total: 14.87 MB, FLOPs: 377,487,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1723 finished in 0m14s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 3,861,627 (14.731 MB), Total: 14.85 MB, FLOPs: 377,327,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1723 finished in 0m14s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.115 MB, Params: 3,857,330 (14.715 MB), Total: 14.83 MB, FLOPs: 377,211,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1723 finished in 0m14s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 3,854,079 (14.702 MB), Total: 14.82 MB, FLOPs: 376,860,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1723 finished in 0m14s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.115 MB, Params: 3,847,624 (14.678 MB), Total: 14.79 MB, FLOPs: 376,511,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1723 finished in 0m14s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 269)]\n",
      "Input: 0.115 MB, Params: 3,841,727 (14.655 MB), Total: 14.77 MB, FLOPs: 376,352,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1723 finished in 0m14s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 3,838,485 (14.643 MB), Total: 14.76 MB, FLOPs: 376,002,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1723 finished in 0m14s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 3,834,197 (14.626 MB), Total: 14.74 MB, FLOPs: 375,886,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1723 finished in 0m14s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 383)]\n",
      "Input: 0.115 MB, Params: 3,828,309 (14.604 MB), Total: 14.72 MB, FLOPs: 375,727,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1723 finished in 0m14s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 3,824,030 (14.588 MB), Total: 14.70 MB, FLOPs: 375,611,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1723 finished in 0m14s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 3,818,151 (14.565 MB), Total: 14.68 MB, FLOPs: 375,453,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1723 finished in 0m14s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 3,813,881 (14.549 MB), Total: 14.66 MB, FLOPs: 375,337,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1723 finished in 0m14s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 305)]\n",
      "Input: 0.115 MB, Params: 3,808,011 (14.526 MB), Total: 14.64 MB, FLOPs: 375,179,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1723 finished in 0m14s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 3,803,750 (14.510 MB), Total: 14.63 MB, FLOPs: 375,064,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1723 finished in 0m14s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 3,797,889 (14.488 MB), Total: 14.60 MB, FLOPs: 374,906,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1723 finished in 0m18s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.115 MB, Params: 3,794,647 (14.475 MB), Total: 14.59 MB, FLOPs: 374,556,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1723 finished in 0m14s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.115 MB, Params: 3,788,786 (14.453 MB), Total: 14.57 MB, FLOPs: 374,398,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1723 finished in 0m14s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 3,785,544 (14.441 MB), Total: 14.56 MB, FLOPs: 374,047,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1723 finished in 0m14s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.115 MB, Params: 3,779,683 (14.418 MB), Total: 14.53 MB, FLOPs: 373,889,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1723 finished in 0m14s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.115 MB, Params: 3,773,822 (14.396 MB), Total: 14.51 MB, FLOPs: 373,731,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1723 finished in 0m14s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 109)]\n",
      "Input: 0.115 MB, Params: 3,772,164 (14.390 MB), Total: 14.50 MB, FLOPs: 372,934,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1723 finished in 0m14s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 3,767,939 (14.374 MB), Total: 14.49 MB, FLOPs: 372,820,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1723 finished in 0m14s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 337)]\n",
      "Input: 0.115 MB, Params: 3,762,087 (14.351 MB), Total: 14.47 MB, FLOPs: 372,662,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1723 finished in 0m14s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 3,760,429 (14.345 MB), Total: 14.46 MB, FLOPs: 371,865,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1723 finished in 0m14s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 395)]\n",
      "Input: 0.115 MB, Params: 3,756,213 (14.329 MB), Total: 14.44 MB, FLOPs: 371,751,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1723 finished in 0m14s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.115 MB, Params: 3,750,370 (14.307 MB), Total: 14.42 MB, FLOPs: 371,594,013\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1723 finished in 0m14s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 3,747,128 (14.294 MB), Total: 14.41 MB, FLOPs: 371,243,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1723 finished in 0m14s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 199)]\n",
      "Input: 0.115 MB, Params: 3,743,886 (14.282 MB), Total: 14.40 MB, FLOPs: 370,893,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1723 finished in 0m14s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 352)]\n",
      "Input: 0.115 MB, Params: 3,738,043 (14.260 MB), Total: 14.37 MB, FLOPs: 370,736,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1723 finished in 0m14s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 116)]\n",
      "Input: 0.115 MB, Params: 3,734,855 (14.247 MB), Total: 14.36 MB, FLOPs: 369,991,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1723 finished in 0m14s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 3,729,012 (14.225 MB), Total: 14.34 MB, FLOPs: 369,834,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1723 finished in 0m14s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 64)]\n",
      "Input: 0.115 MB, Params: 3,727,363 (14.219 MB), Total: 14.33 MB, FLOPs: 369,041,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1723 finished in 0m14s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 374)]\n",
      "Input: 0.115 MB, Params: 3,721,520 (14.196 MB), Total: 14.31 MB, FLOPs: 368,883,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1723 finished in 0m14s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 369)]\n",
      "Input: 0.115 MB, Params: 3,717,340 (14.181 MB), Total: 14.30 MB, FLOPs: 368,770,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1723 finished in 0m14s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.115 MB, Params: 3,714,107 (14.168 MB), Total: 14.28 MB, FLOPs: 368,421,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1723 finished in 0m14s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.115 MB, Params: 3,707,823 (14.144 MB), Total: 14.26 MB, FLOPs: 368,081,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1723 finished in 0m14s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 270)]\n",
      "Input: 0.115 MB, Params: 3,701,998 (14.122 MB), Total: 14.24 MB, FLOPs: 367,924,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1723 finished in 0m14s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 3,696,173 (14.100 MB), Total: 14.22 MB, FLOPs: 367,766,812\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1723 finished in 0m14s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 3,692,011 (14.084 MB), Total: 14.20 MB, FLOPs: 367,654,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1723 finished in 0m14s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 3,686,195 (14.062 MB), Total: 14.18 MB, FLOPs: 367,497,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1723 finished in 0m14s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 412)]\n",
      "Input: 0.115 MB, Params: 3,680,379 (14.040 MB), Total: 14.15 MB, FLOPs: 367,340,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1723 finished in 0m14s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 3,678,730 (14.033 MB), Total: 14.15 MB, FLOPs: 366,547,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1723 finished in 0m14s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 3,672,914 (14.011 MB), Total: 14.13 MB, FLOPs: 366,390,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1723 finished in 0m14s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 381)]\n",
      "Input: 0.115 MB, Params: 3,667,098 (13.989 MB), Total: 14.10 MB, FLOPs: 366,233,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1723 finished in 0m14s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 3,661,282 (13.967 MB), Total: 14.08 MB, FLOPs: 366,076,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1723 finished in 0m14s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 3,659,669 (13.961 MB), Total: 14.08 MB, FLOPs: 364,478,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1723 finished in 0m14s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 3,653,448 (13.937 MB), Total: 14.05 MB, FLOPs: 364,139,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1723 finished in 0m14s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 3,649,331 (13.921 MB), Total: 14.04 MB, FLOPs: 364,028,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1723 finished in 0m14s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 26)]\n",
      "Input: 0.115 MB, Params: 3,646,116 (13.909 MB), Total: 14.02 MB, FLOPs: 363,681,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1723 finished in 0m14s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 238)]\n",
      "Input: 0.115 MB, Params: 3,640,318 (13.887 MB), Total: 14.00 MB, FLOPs: 363,524,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1723 finished in 0m14s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 3,634,520 (13.865 MB), Total: 13.98 MB, FLOPs: 363,368,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1723 finished in 0m14s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 3,630,421 (13.849 MB), Total: 13.96 MB, FLOPs: 363,257,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1723 finished in 0m14s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.115 MB, Params: 3,626,322 (13.833 MB), Total: 13.95 MB, FLOPs: 363,147,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1723 finished in 0m14s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.115 MB, Params: 3,620,542 (13.811 MB), Total: 13.93 MB, FLOPs: 362,991,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1723 finished in 0m14s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 48)]\n",
      "Input: 0.115 MB, Params: 3,618,902 (13.805 MB), Total: 13.92 MB, FLOPs: 362,202,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1723 finished in 0m14s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 244)]\n",
      "Input: 0.115 MB, Params: 3,614,812 (13.789 MB), Total: 13.90 MB, FLOPs: 362,092,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1723 finished in 0m14s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 3,608,627 (13.766 MB), Total: 13.88 MB, FLOPs: 361,755,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1723 finished in 0m14s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 3,604,537 (13.750 MB), Total: 13.87 MB, FLOPs: 361,644,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1723 finished in 0m14s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 22)]\n",
      "Input: 0.115 MB, Params: 3,603,725 (13.747 MB), Total: 13.86 MB, FLOPs: 360,063,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1723 finished in 0m14s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 3,599,635 (13.732 MB), Total: 13.85 MB, FLOPs: 359,953,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1723 finished in 0m14s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 3,595,545 (13.716 MB), Total: 13.83 MB, FLOPs: 359,842,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1723 finished in 0m14s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.115 MB, Params: 3,594,985 (13.714 MB), Total: 13.83 MB, FLOPs: 358,684,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1723 finished in 0m14s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 3,590,895 (13.698 MB), Total: 13.81 MB, FLOPs: 358,574,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1723 finished in 0m14s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 3,586,805 (13.683 MB), Total: 13.80 MB, FLOPs: 358,463,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1723 finished in 0m14s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.115 MB, Params: 3,580,620 (13.659 MB), Total: 13.77 MB, FLOPs: 358,126,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1723 finished in 0m14s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 339)]\n",
      "Input: 0.115 MB, Params: 3,576,530 (13.643 MB), Total: 13.76 MB, FLOPs: 358,016,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1723 finished in 0m14s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.115 MB, Params: 3,570,831 (13.622 MB), Total: 13.74 MB, FLOPs: 357,862,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1723 finished in 0m14s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.115 MB, Params: 3,565,132 (13.600 MB), Total: 13.72 MB, FLOPs: 357,708,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1723 finished in 0m14s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 3,561,060 (13.584 MB), Total: 13.70 MB, FLOPs: 357,598,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1723 finished in 0m14s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 158)]\n",
      "Input: 0.115 MB, Params: 3,554,893 (13.561 MB), Total: 13.68 MB, FLOPs: 357,262,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1723 finished in 0m14s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.115 MB, Params: 3,550,821 (13.545 MB), Total: 13.66 MB, FLOPs: 357,152,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1723 finished in 0m14s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.115 MB, Params: 3,546,749 (13.530 MB), Total: 13.65 MB, FLOPs: 357,042,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1723 finished in 0m14s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 3,542,677 (13.514 MB), Total: 13.63 MB, FLOPs: 356,932,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1723 finished in 0m14s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.115 MB, Params: 3,537,023 (13.493 MB), Total: 13.61 MB, FLOPs: 356,779,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1723 finished in 0m14s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.115 MB, Params: 3,533,880 (13.481 MB), Total: 13.60 MB, FLOPs: 356,050,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1723 finished in 0m14s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 3,529,817 (13.465 MB), Total: 13.58 MB, FLOPs: 355,940,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1723 finished in 0m14s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 3,525,754 (13.450 MB), Total: 13.56 MB, FLOPs: 355,831,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1723 finished in 0m14s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 429)]\n",
      "Input: 0.115 MB, Params: 3,520,118 (13.428 MB), Total: 13.54 MB, FLOPs: 355,678,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1723 finished in 0m14s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 176)]\n",
      "Input: 0.115 MB, Params: 3,513,969 (13.405 MB), Total: 13.52 MB, FLOPs: 355,342,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1723 finished in 0m14s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 3,509,915 (13.389 MB), Total: 13.50 MB, FLOPs: 355,233,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1723 finished in 0m14s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 3,505,861 (13.374 MB), Total: 13.49 MB, FLOPs: 355,124,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1723 finished in 0m14s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 3,500,252 (13.352 MB), Total: 13.47 MB, FLOPs: 354,972,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1723 finished in 0m14s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 3,494,643 (13.331 MB), Total: 13.45 MB, FLOPs: 354,821,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1723 finished in 0m14s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 150)]\n",
      "Input: 0.115 MB, Params: 3,491,473 (13.319 MB), Total: 13.43 MB, FLOPs: 354,478,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1723 finished in 0m14s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 3,485,864 (13.298 MB), Total: 13.41 MB, FLOPs: 354,327,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1723 finished in 0m14s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 33)]\n",
      "Input: 0.115 MB, Params: 3,482,730 (13.286 MB), Total: 13.40 MB, FLOPs: 353,598,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1723 finished in 0m14s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 162)]\n",
      "Input: 0.115 MB, Params: 3,476,617 (13.262 MB), Total: 13.38 MB, FLOPs: 353,264,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1723 finished in 0m14s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 105)]\n",
      "Input: 0.115 MB, Params: 3,470,504 (13.239 MB), Total: 13.35 MB, FLOPs: 352,930,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1723 finished in 0m14s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 3,466,477 (13.224 MB), Total: 13.34 MB, FLOPs: 352,821,591\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1723 finished in 0m14s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 3,462,450 (13.208 MB), Total: 13.32 MB, FLOPs: 352,712,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1723 finished in 0m14s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 3,462,408 (13.208 MB), Total: 13.32 MB, FLOPs: 352,353,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1723 finished in 0m13s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 18)]\n",
      "Input: 0.115 MB, Params: 3,461,848 (13.206 MB), Total: 13.32 MB, FLOPs: 351,196,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1723 finished in 0m13s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.115 MB, Params: 3,458,714 (13.194 MB), Total: 13.31 MB, FLOPs: 350,467,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1723 finished in 0m13s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 3,453,141 (13.173 MB), Total: 13.29 MB, FLOPs: 350,317,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1723 finished in 0m13s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 3,449,123 (13.157 MB), Total: 13.27 MB, FLOPs: 350,209,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1723 finished in 0m13s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.115 MB, Params: 3,445,989 (13.145 MB), Total: 13.26 MB, FLOPs: 349,870,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1723 finished in 0m13s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 424)]\n",
      "Input: 0.115 MB, Params: 3,440,425 (13.124 MB), Total: 13.24 MB, FLOPs: 349,720,527\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1723 finished in 0m13s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.115 MB, Params: 3,436,416 (13.109 MB), Total: 13.22 MB, FLOPs: 349,612,341\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1723 finished in 0m13s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 3,430,861 (13.088 MB), Total: 13.20 MB, FLOPs: 349,462,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1723 finished in 0m13s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 3,426,861 (13.072 MB), Total: 13.19 MB, FLOPs: 349,354,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1723 finished in 0m13s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 334)]\n",
      "Input: 0.115 MB, Params: 3,422,861 (13.057 MB), Total: 13.17 MB, FLOPs: 349,246,497\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1723 finished in 0m13s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 3,418,861 (13.042 MB), Total: 13.16 MB, FLOPs: 349,138,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1723 finished in 0m13s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 377)]\n",
      "Input: 0.115 MB, Params: 3,414,861 (13.027 MB), Total: 13.14 MB, FLOPs: 349,030,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1723 finished in 0m13s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.115 MB, Params: 3,410,861 (13.011 MB), Total: 13.13 MB, FLOPs: 348,922,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1723 finished in 0m13s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 3,406,861 (12.996 MB), Total: 13.11 MB, FLOPs: 348,814,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1723 finished in 0m13s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 3,401,360 (12.975 MB), Total: 13.09 MB, FLOPs: 348,666,225\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1723 finished in 0m13s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 3,395,292 (12.952 MB), Total: 13.07 MB, FLOPs: 348,333,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1723 finished in 0m13s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 3,389,800 (12.931 MB), Total: 13.05 MB, FLOPs: 348,185,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1723 finished in 0m13s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 3,383,741 (12.908 MB), Total: 13.02 MB, FLOPs: 347,853,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1723 finished in 0m13s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.115 MB, Params: 3,380,616 (12.896 MB), Total: 13.01 MB, FLOPs: 347,125,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1723 finished in 0m13s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 172)]\n",
      "Input: 0.115 MB, Params: 3,376,634 (12.881 MB), Total: 13.00 MB, FLOPs: 347,018,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1723 finished in 0m13s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 163)]\n",
      "Input: 0.115 MB, Params: 3,373,527 (12.869 MB), Total: 12.98 MB, FLOPs: 346,682,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1723 finished in 0m13s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 3,370,411 (12.857 MB), Total: 12.97 MB, FLOPs: 345,956,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1723 finished in 0m13s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.115 MB, Params: 3,367,295 (12.845 MB), Total: 12.96 MB, FLOPs: 345,229,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1723 finished in 0m13s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 3,363,313 (12.830 MB), Total: 12.95 MB, FLOPs: 345,122,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1723 finished in 0m13s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 3,359,331 (12.815 MB), Total: 12.93 MB, FLOPs: 345,014,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1723 finished in 0m13s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 3,353,281 (12.792 MB), Total: 12.91 MB, FLOPs: 344,683,533\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1723 finished in 0m14s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 3,347,834 (12.771 MB), Total: 12.89 MB, FLOPs: 344,536,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1723 finished in 0m13s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.115 MB, Params: 3,341,793 (12.748 MB), Total: 12.86 MB, FLOPs: 344,205,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1723 finished in 0m13s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 225)]\n",
      "Input: 0.115 MB, Params: 3,338,722 (12.736 MB), Total: 12.85 MB, FLOPs: 343,873,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1723 finished in 0m13s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.115 MB, Params: 3,333,284 (12.715 MB), Total: 12.83 MB, FLOPs: 343,727,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1723 finished in 0m13s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 337)]\n",
      "Input: 0.115 MB, Params: 3,327,846 (12.695 MB), Total: 12.81 MB, FLOPs: 343,580,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1723 finished in 0m13s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 3,323,891 (12.680 MB), Total: 12.79 MB, FLOPs: 343,473,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1723 finished in 0m13s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 3,319,936 (12.665 MB), Total: 12.78 MB, FLOPs: 343,366,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1723 finished in 0m14s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 3,315,981 (12.649 MB), Total: 12.76 MB, FLOPs: 343,260,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1723 finished in 0m14s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.115 MB, Params: 3,309,967 (12.627 MB), Total: 12.74 MB, FLOPs: 342,930,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1723 finished in 0m13s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 350)]\n",
      "Input: 0.115 MB, Params: 3,304,565 (12.606 MB), Total: 12.72 MB, FLOPs: 342,784,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1723 finished in 0m13s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.115 MB, Params: 3,301,458 (12.594 MB), Total: 12.71 MB, FLOPs: 342,059,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1723 finished in 0m13s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.115 MB, Params: 3,298,351 (12.582 MB), Total: 12.70 MB, FLOPs: 341,333,572\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1723 finished in 0m14s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 376)]\n",
      "Input: 0.115 MB, Params: 3,292,949 (12.562 MB), Total: 12.68 MB, FLOPs: 341,187,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1723 finished in 0m14s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 3,286,953 (12.539 MB), Total: 12.65 MB, FLOPs: 340,858,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1723 finished in 0m14s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.115 MB, Params: 3,280,957 (12.516 MB), Total: 12.63 MB, FLOPs: 340,529,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1723 finished in 0m14s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.115 MB, Params: 3,277,020 (12.501 MB), Total: 12.62 MB, FLOPs: 340,423,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1723 finished in 0m14s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 3,271,645 (12.480 MB), Total: 12.60 MB, FLOPs: 340,278,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1723 finished in 0m14s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 3,265,658 (12.457 MB), Total: 12.57 MB, FLOPs: 339,949,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1723 finished in 0m14s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 3,261,730 (12.443 MB), Total: 12.56 MB, FLOPs: 339,843,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1723 finished in 0m13s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 241)]\n",
      "Input: 0.115 MB, Params: 3,256,373 (12.422 MB), Total: 12.54 MB, FLOPs: 339,699,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1723 finished in 0m13s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 3,252,454 (12.407 MB), Total: 12.52 MB, FLOPs: 339,593,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1723 finished in 0m24s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.115 MB, Params: 3,248,535 (12.392 MB), Total: 12.51 MB, FLOPs: 339,487,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1723 finished in 0m31s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 238)]\n",
      "Input: 0.115 MB, Params: 3,243,196 (12.372 MB), Total: 12.49 MB, FLOPs: 339,343,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1723 finished in 0m28s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 58)]\n",
      "Input: 0.115 MB, Params: 3,242,402 (12.369 MB), Total: 12.48 MB, FLOPs: 337,797,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1723 finished in 0m28s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 8)]\n",
      "Input: 0.115 MB, Params: 3,241,851 (12.367 MB), Total: 12.48 MB, FLOPs: 336,657,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1723 finished in 0m29s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 3,237,941 (12.352 MB), Total: 12.47 MB, FLOPs: 336,552,231\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1723 finished in 0m30s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.115 MB, Params: 3,236,373 (12.346 MB), Total: 12.46 MB, FLOPs: 335,798,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1723 finished in 0m30s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 242)]\n",
      "Input: 0.115 MB, Params: 3,231,043 (12.325 MB), Total: 12.44 MB, FLOPs: 335,654,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1723 finished in 0m32s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.115 MB, Params: 3,227,142 (12.311 MB), Total: 12.43 MB, FLOPs: 335,549,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1723 finished in 0m30s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.115 MB, Params: 3,221,821 (12.290 MB), Total: 12.41 MB, FLOPs: 335,405,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1723 finished in 0m29s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 3,215,870 (12.268 MB), Total: 12.38 MB, FLOPs: 335,077,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1723 finished in 0m29s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.115 MB, Params: 3,211,978 (12.253 MB), Total: 12.37 MB, FLOPs: 334,972,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1723 finished in 0m26s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 400)]\n",
      "Input: 0.115 MB, Params: 3,206,675 (12.232 MB), Total: 12.35 MB, FLOPs: 334,829,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1723 finished in 0m29s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 3,201,372 (12.212 MB), Total: 12.33 MB, FLOPs: 334,686,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1723 finished in 0m29s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 3,201,330 (12.212 MB), Total: 12.33 MB, FLOPs: 324,108,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1723 finished in 0m29s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 3,196,027 (12.192 MB), Total: 12.31 MB, FLOPs: 323,965,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1723 finished in 0m30s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 3,190,724 (12.172 MB), Total: 12.29 MB, FLOPs: 323,822,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1723 finished in 0m31s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 343)]\n",
      "Input: 0.115 MB, Params: 3,186,868 (12.157 MB), Total: 12.27 MB, FLOPs: 323,718,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1723 finished in 0m31s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.115 MB, Params: 3,181,574 (12.137 MB), Total: 12.25 MB, FLOPs: 323,575,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1723 finished in 0m29s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.115 MB, Params: 3,177,727 (12.122 MB), Total: 12.24 MB, FLOPs: 323,471,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1723 finished in 0m30s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 2)]\n",
      "Input: 0.115 MB, Params: 3,176,159 (12.116 MB), Total: 12.23 MB, FLOPs: 322,776,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1723 finished in 0m29s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 223)]\n",
      "Input: 0.115 MB, Params: 3,173,151 (12.105 MB), Total: 12.22 MB, FLOPs: 322,451,354\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1723 finished in 0m31s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.115 MB, Params: 3,167,866 (12.084 MB), Total: 12.20 MB, FLOPs: 322,308,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1723 finished in 0m26s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 29)]\n",
      "Input: 0.115 MB, Params: 3,167,081 (12.081 MB), Total: 12.20 MB, FLOPs: 320,838,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1723 finished in 0m26s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 3,163,243 (12.067 MB), Total: 12.18 MB, FLOPs: 320,735,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1723 finished in 0m29s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.115 MB, Params: 3,162,458 (12.064 MB), Total: 12.18 MB, FLOPs: 319,265,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1723 finished in 0m28s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 3,157,182 (12.044 MB), Total: 12.16 MB, FLOPs: 319,122,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1723 finished in 0m29s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 3,151,906 (12.024 MB), Total: 12.14 MB, FLOPs: 318,980,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1723 finished in 0m30s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.115 MB, Params: 3,148,086 (12.009 MB), Total: 12.12 MB, FLOPs: 318,877,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1723 finished in 0m29s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 3,142,819 (11.989 MB), Total: 12.10 MB, FLOPs: 318,735,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1723 finished in 0m29s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 3,139,811 (11.977 MB), Total: 12.09 MB, FLOPs: 318,410,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1723 finished in 0m27s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 3,136,000 (11.963 MB), Total: 12.08 MB, FLOPs: 318,307,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1723 finished in 0m29s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.115 MB, Params: 3,132,189 (11.948 MB), Total: 12.06 MB, FLOPs: 318,204,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1723 finished in 0m30s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 3,128,378 (11.934 MB), Total: 12.05 MB, FLOPs: 318,101,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1723 finished in 0m27s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.115 MB, Params: 3,125,370 (11.922 MB), Total: 12.04 MB, FLOPs: 317,776,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1723 finished in 0m30s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.115 MB, Params: 3,119,527 (11.900 MB), Total: 12.02 MB, FLOPs: 317,454,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1723 finished in 0m30s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.115 MB, Params: 3,114,296 (11.880 MB), Total: 12.00 MB, FLOPs: 317,313,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1723 finished in 0m30s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.115 MB, Params: 3,111,234 (11.868 MB), Total: 11.98 MB, FLOPs: 316,636,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1723 finished in 0m27s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 3,107,432 (11.854 MB), Total: 11.97 MB, FLOPs: 316,534,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1723 finished in 0m31s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 3,103,630 (11.839 MB), Total: 11.95 MB, FLOPs: 316,431,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1723 finished in 0m30s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 146)]\n",
      "Input: 0.115 MB, Params: 3,097,796 (11.817 MB), Total: 11.93 MB, FLOPs: 316,109,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1723 finished in 0m28s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.115 MB, Params: 3,092,592 (11.797 MB), Total: 11.91 MB, FLOPs: 315,968,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1723 finished in 0m29s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.115 MB, Params: 3,087,388 (11.777 MB), Total: 11.89 MB, FLOPs: 315,828,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1723 finished in 0m28s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.115 MB, Params: 3,081,572 (11.755 MB), Total: 11.87 MB, FLOPs: 315,506,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1723 finished in 0m28s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 214)]\n",
      "Input: 0.115 MB, Params: 3,075,756 (11.733 MB), Total: 11.85 MB, FLOPs: 315,184,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1723 finished in 0m28s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 3,071,972 (11.719 MB), Total: 11.83 MB, FLOPs: 315,082,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1723 finished in 0m30s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 171)]\n",
      "Input: 0.115 MB, Params: 3,069,009 (11.707 MB), Total: 11.82 MB, FLOPs: 314,762,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1723 finished in 0m28s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 3,063,832 (11.688 MB), Total: 11.80 MB, FLOPs: 314,622,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1723 finished in 0m29s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 225)]\n",
      "Input: 0.115 MB, Params: 3,060,057 (11.673 MB), Total: 11.79 MB, FLOPs: 314,520,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1723 finished in 0m30s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 162)]\n",
      "Input: 0.115 MB, Params: 3,054,889 (11.653 MB), Total: 11.77 MB, FLOPs: 314,381,369\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1723 finished in 0m29s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 3,049,721 (11.634 MB), Total: 11.75 MB, FLOPs: 314,241,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1723 finished in 0m30s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.115 MB, Params: 3,045,964 (11.619 MB), Total: 11.73 MB, FLOPs: 314,140,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1723 finished in 0m27s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 3,042,207 (11.605 MB), Total: 11.72 MB, FLOPs: 314,039,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1723 finished in 0m30s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.115 MB, Params: 3,038,450 (11.591 MB), Total: 11.71 MB, FLOPs: 313,937,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1723 finished in 0m29s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 409)]\n",
      "Input: 0.115 MB, Params: 3,033,309 (11.571 MB), Total: 11.69 MB, FLOPs: 313,798,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1723 finished in 0m27s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 359)]\n",
      "Input: 0.115 MB, Params: 3,028,168 (11.552 MB), Total: 11.67 MB, FLOPs: 313,660,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1723 finished in 0m29s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 13)]\n",
      "Input: 0.115 MB, Params: 3,027,635 (11.550 MB), Total: 11.66 MB, FLOPs: 312,596,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1723 finished in 0m28s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 186)]\n",
      "Input: 0.115 MB, Params: 3,022,494 (11.530 MB), Total: 11.65 MB, FLOPs: 312,458,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1723 finished in 0m28s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 175)]\n",
      "Input: 0.115 MB, Params: 3,019,531 (11.519 MB), Total: 11.63 MB, FLOPs: 312,138,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1723 finished in 0m28s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 3,016,487 (11.507 MB), Total: 11.62 MB, FLOPs: 311,464,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1723 finished in 0m27s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 219)]\n",
      "Input: 0.115 MB, Params: 3,013,533 (11.496 MB), Total: 11.61 MB, FLOPs: 311,145,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1723 finished in 0m30s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 3,009,803 (11.481 MB), Total: 11.60 MB, FLOPs: 311,044,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1723 finished in 0m27s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 3,006,073 (11.467 MB), Total: 11.58 MB, FLOPs: 310,943,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1723 finished in 0m27s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 3,000,338 (11.445 MB), Total: 11.56 MB, FLOPs: 310,626,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1723 finished in 0m30s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 2,998,788 (11.439 MB), Total: 11.55 MB, FLOPs: 309,938,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1723 finished in 0m28s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.115 MB, Params: 2,993,674 (11.420 MB), Total: 11.54 MB, FLOPs: 309,800,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1723 finished in 0m27s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 2,989,953 (11.406 MB), Total: 11.52 MB, FLOPs: 309,700,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1723 finished in 0m28s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.115 MB, Params: 2,986,232 (11.392 MB), Total: 11.51 MB, FLOPs: 309,599,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1723 finished in 0m30s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.115 MB, Params: 2,981,136 (11.372 MB), Total: 11.49 MB, FLOPs: 309,462,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1723 finished in 0m31s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 187)]\n",
      "Input: 0.115 MB, Params: 2,978,191 (11.361 MB), Total: 11.48 MB, FLOPs: 309,144,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1723 finished in 0m30s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.115 MB, Params: 2,973,095 (11.341 MB), Total: 11.46 MB, FLOPs: 309,006,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1723 finished in 0m27s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 2,969,392 (11.327 MB), Total: 11.44 MB, FLOPs: 308,906,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1723 finished in 0m31s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 2,964,305 (11.308 MB), Total: 11.42 MB, FLOPs: 308,769,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1723 finished in 0m29s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 111)]\n",
      "Input: 0.115 MB, Params: 2,961,360 (11.297 MB), Total: 11.41 MB, FLOPs: 308,451,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1723 finished in 0m31s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 397)]\n",
      "Input: 0.115 MB, Params: 2,956,273 (11.277 MB), Total: 11.39 MB, FLOPs: 308,314,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1723 finished in 0m29s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 2,951,186 (11.258 MB), Total: 11.37 MB, FLOPs: 308,176,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1723 finished in 0m32s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 309)]\n",
      "Input: 0.115 MB, Params: 2,946,099 (11.238 MB), Total: 11.35 MB, FLOPs: 308,039,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1723 finished in 0m28s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 181)]\n",
      "Input: 0.115 MB, Params: 2,943,154 (11.227 MB), Total: 11.34 MB, FLOPs: 307,721,441\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1723 finished in 0m29s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 2,938,067 (11.208 MB), Total: 11.32 MB, FLOPs: 307,584,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1723 finished in 0m28s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 305)]\n",
      "Input: 0.115 MB, Params: 2,932,980 (11.188 MB), Total: 11.30 MB, FLOPs: 307,446,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1723 finished in 0m30s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.115 MB, Params: 2,929,981 (11.177 MB), Total: 11.29 MB, FLOPs: 306,780,533\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1723 finished in 0m28s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 2,924,354 (11.156 MB), Total: 11.27 MB, FLOPs: 306,468,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1723 finished in 0m27s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 2,919,276 (11.136 MB), Total: 11.25 MB, FLOPs: 306,330,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1723 finished in 0m27s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 134)]\n",
      "Input: 0.115 MB, Params: 2,913,658 (11.115 MB), Total: 11.23 MB, FLOPs: 306,018,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1723 finished in 0m29s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 2,910,018 (11.101 MB), Total: 11.22 MB, FLOPs: 305,920,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1723 finished in 0m25s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 2,904,958 (11.082 MB), Total: 11.20 MB, FLOPs: 305,783,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1723 finished in 0m27s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 11)]\n",
      "Input: 0.115 MB, Params: 2,903,417 (11.076 MB), Total: 11.19 MB, FLOPs: 304,349,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1723 finished in 0m28s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 334)]\n",
      "Input: 0.115 MB, Params: 2,899,786 (11.062 MB), Total: 11.18 MB, FLOPs: 304,252,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1723 finished in 0m26s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 104)]\n",
      "Input: 0.115 MB, Params: 2,894,177 (11.040 MB), Total: 11.16 MB, FLOPs: 303,940,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1723 finished in 0m27s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 2,891,178 (11.029 MB), Total: 11.14 MB, FLOPs: 303,273,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1723 finished in 0m29s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 2,887,547 (11.015 MB), Total: 11.13 MB, FLOPs: 303,175,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1723 finished in 0m28s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 27)]\n",
      "Input: 0.115 MB, Params: 2,886,780 (11.012 MB), Total: 11.13 MB, FLOPs: 301,739,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1723 finished in 0m28s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 2,883,149 (10.998 MB), Total: 11.11 MB, FLOPs: 301,641,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1723 finished in 0m29s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 2,878,125 (10.979 MB), Total: 11.09 MB, FLOPs: 301,505,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1723 finished in 0m31s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 2,873,101 (10.960 MB), Total: 11.08 MB, FLOPs: 301,370,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1723 finished in 0m29s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.115 MB, Params: 2,867,510 (10.939 MB), Total: 11.05 MB, FLOPs: 301,058,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1723 finished in 0m29s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 2,862,495 (10.920 MB), Total: 11.03 MB, FLOPs: 300,923,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1723 finished in 0m31s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 194)]\n",
      "Input: 0.115 MB, Params: 2,856,913 (10.898 MB), Total: 11.01 MB, FLOPs: 300,612,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1723 finished in 0m29s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 2,854,031 (10.887 MB), Total: 11.00 MB, FLOPs: 300,301,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1723 finished in 0m29s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 2,848,458 (10.866 MB), Total: 10.98 MB, FLOPs: 299,990,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1723 finished in 0m27s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 2,843,461 (10.847 MB), Total: 10.96 MB, FLOPs: 299,855,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1723 finished in 0m29s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 388)]\n",
      "Input: 0.115 MB, Params: 2,838,464 (10.828 MB), Total: 10.94 MB, FLOPs: 299,720,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1723 finished in 0m28s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.115 MB, Params: 2,835,591 (10.817 MB), Total: 10.93 MB, FLOPs: 299,410,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1723 finished in 0m29s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.115 MB, Params: 2,834,824 (10.814 MB), Total: 10.93 MB, FLOPs: 297,974,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1723 finished in 0m31s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 2,829,827 (10.795 MB), Total: 10.91 MB, FLOPs: 297,839,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1723 finished in 0m26s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.115 MB, Params: 2,824,830 (10.776 MB), Total: 10.89 MB, FLOPs: 297,704,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1723 finished in 0m27s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 2,819,302 (10.755 MB), Total: 10.87 MB, FLOPs: 297,396,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1723 finished in 0m29s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 2,815,734 (10.741 MB), Total: 10.86 MB, FLOPs: 297,300,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1723 finished in 0m29s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 2,812,166 (10.728 MB), Total: 10.84 MB, FLOPs: 297,203,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1723 finished in 0m27s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 89)]\n",
      "Input: 0.115 MB, Params: 2,810,643 (10.722 MB), Total: 10.84 MB, FLOPs: 296,528,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1723 finished in 0m30s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 2,805,673 (10.703 MB), Total: 10.82 MB, FLOPs: 296,393,921\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1723 finished in 0m30s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 308)]\n",
      "Input: 0.115 MB, Params: 2,802,114 (10.689 MB), Total: 10.80 MB, FLOPs: 296,297,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1723 finished in 0m29s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 140)]\n",
      "Input: 0.115 MB, Params: 2,796,595 (10.668 MB), Total: 10.78 MB, FLOPs: 295,989,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1723 finished in 0m29s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 2,793,036 (10.655 MB), Total: 10.77 MB, FLOPs: 295,893,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1723 finished in 0m27s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 2,788,093 (10.636 MB), Total: 10.75 MB, FLOPs: 295,760,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1723 finished in 0m27s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 2,785,238 (10.625 MB), Total: 10.74 MB, FLOPs: 295,452,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1723 finished in 0m29s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 2,781,688 (10.611 MB), Total: 10.73 MB, FLOPs: 295,356,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1723 finished in 0m29s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.115 MB, Params: 2,778,138 (10.598 MB), Total: 10.71 MB, FLOPs: 295,260,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1723 finished in 0m28s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 2,772,637 (10.577 MB), Total: 10.69 MB, FLOPs: 294,953,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1723 finished in 0m26s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.115 MB, Params: 2,767,721 (10.558 MB), Total: 10.67 MB, FLOPs: 294,820,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1723 finished in 0m25s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 2,762,805 (10.539 MB), Total: 10.65 MB, FLOPs: 294,688,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1723 finished in 0m28s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 2,757,889 (10.521 MB), Total: 10.64 MB, FLOPs: 294,555,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1723 finished in 0m26s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 196)]\n",
      "Input: 0.115 MB, Params: 2,754,366 (10.507 MB), Total: 10.62 MB, FLOPs: 294,460,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1723 finished in 0m31s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,748,892 (10.486 MB), Total: 10.60 MB, FLOPs: 294,154,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1723 finished in 0m27s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.115 MB, Params: 2,743,994 (10.468 MB), Total: 10.58 MB, FLOPs: 294,022,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1723 finished in 0m26s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 2,739,096 (10.449 MB), Total: 10.56 MB, FLOPs: 293,889,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1723 finished in 0m27s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 2,737,573 (10.443 MB), Total: 10.56 MB, FLOPs: 293,214,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1723 finished in 0m29s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 197)]\n",
      "Input: 0.115 MB, Params: 2,734,068 (10.430 MB), Total: 10.54 MB, FLOPs: 293,119,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1723 finished in 0m28s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.115 MB, Params: 2,732,545 (10.424 MB), Total: 10.54 MB, FLOPs: 292,443,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1723 finished in 0m27s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 2,729,708 (10.413 MB), Total: 10.53 MB, FLOPs: 292,137,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1723 finished in 0m24s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 33)]\n",
      "Input: 0.115 MB, Params: 2,729,666 (10.413 MB), Total: 10.53 MB, FLOPs: 291,782,473\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1723 finished in 0m28s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.115 MB, Params: 2,726,829 (10.402 MB), Total: 10.52 MB, FLOPs: 291,476,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1723 finished in 0m28s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 93)]\n",
      "Input: 0.115 MB, Params: 2,721,391 (10.381 MB), Total: 10.50 MB, FLOPs: 291,172,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1723 finished in 0m26s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 2,717,886 (10.368 MB), Total: 10.48 MB, FLOPs: 291,077,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1723 finished in 0m31s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.115 MB, Params: 2,713,015 (10.349 MB), Total: 10.46 MB, FLOPs: 290,946,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1723 finished in 0m27s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 2,708,144 (10.331 MB), Total: 10.45 MB, FLOPs: 290,814,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1723 finished in 0m28s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 2,703,273 (10.312 MB), Total: 10.43 MB, FLOPs: 290,683,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1723 finished in 0m25s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 2,698,402 (10.294 MB), Total: 10.41 MB, FLOPs: 290,551,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1723 finished in 0m27s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 322)]\n",
      "Input: 0.115 MB, Params: 2,693,531 (10.275 MB), Total: 10.39 MB, FLOPs: 290,420,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1723 finished in 0m28s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 85)]\n",
      "Input: 0.115 MB, Params: 2,690,604 (10.264 MB), Total: 10.38 MB, FLOPs: 289,771,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1723 finished in 0m30s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 2,687,785 (10.253 MB), Total: 10.37 MB, FLOPs: 289,466,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1723 finished in 0m27s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 97)]\n",
      "Input: 0.115 MB, Params: 2,682,401 (10.233 MB), Total: 10.35 MB, FLOPs: 289,165,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1723 finished in 0m27s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 197)]\n",
      "Input: 0.115 MB, Params: 2,678,941 (10.219 MB), Total: 10.33 MB, FLOPs: 289,071,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1723 finished in 0m28s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 355)]\n",
      "Input: 0.115 MB, Params: 2,674,088 (10.201 MB), Total: 10.32 MB, FLOPs: 288,940,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1723 finished in 0m28s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 366)]\n",
      "Input: 0.115 MB, Params: 2,669,235 (10.182 MB), Total: 10.30 MB, FLOPs: 288,809,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1723 finished in 0m27s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 145)]\n",
      "Input: 0.115 MB, Params: 2,665,793 (10.169 MB), Total: 10.28 MB, FLOPs: 288,716,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1723 finished in 0m27s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 378)]\n",
      "Input: 0.115 MB, Params: 2,660,949 (10.151 MB), Total: 10.27 MB, FLOPs: 288,586,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1723 finished in 0m28s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 2,658,139 (10.140 MB), Total: 10.26 MB, FLOPs: 288,282,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1723 finished in 0m29s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 2,654,706 (10.127 MB), Total: 10.24 MB, FLOPs: 288,190,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1723 finished in 0m28s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 2,651,273 (10.114 MB), Total: 10.23 MB, FLOPs: 288,097,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1723 finished in 0m28s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,645,925 (10.093 MB), Total: 10.21 MB, FLOPs: 287,797,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1723 finished in 0m29s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 2,643,124 (10.083 MB), Total: 10.20 MB, FLOPs: 287,495,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1723 finished in 0m31s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.115 MB, Params: 2,638,307 (10.064 MB), Total: 10.18 MB, FLOPs: 287,365,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1723 finished in 0m31s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 2,634,883 (10.051 MB), Total: 10.17 MB, FLOPs: 287,272,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1723 finished in 0m27s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 65)]\n",
      "Input: 0.115 MB, Params: 2,631,983 (10.040 MB), Total: 10.16 MB, FLOPs: 286,626,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1723 finished in 0m30s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.115 MB, Params: 2,631,216 (10.037 MB), Total: 10.15 MB, FLOPs: 285,190,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1723 finished in 0m30s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 133)]\n",
      "Input: 0.115 MB, Params: 2,625,886 (10.017 MB), Total: 10.13 MB, FLOPs: 284,891,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1723 finished in 0m26s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 2,623,103 (10.006 MB), Total: 10.12 MB, FLOPs: 284,591,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1723 finished in 0m30s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 41)]\n",
      "Input: 0.115 MB, Params: 2,620,212 (9.995 MB), Total: 10.11 MB, FLOPs: 283,945,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1723 finished in 0m27s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 2,617,438 (9.985 MB), Total: 10.10 MB, FLOPs: 283,645,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1723 finished in 0m25s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 92)]\n",
      "Input: 0.115 MB, Params: 2,614,556 (9.974 MB), Total: 10.09 MB, FLOPs: 283,001,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1723 finished in 0m28s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 247)]\n",
      "Input: 0.115 MB, Params: 2,609,757 (9.955 MB), Total: 10.07 MB, FLOPs: 282,871,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1723 finished in 0m28s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 2,606,342 (9.942 MB), Total: 10.06 MB, FLOPs: 282,779,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1723 finished in 0m30s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 2,601,552 (9.924 MB), Total: 10.04 MB, FLOPs: 282,650,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1723 finished in 0m28s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 301)]\n",
      "Input: 0.115 MB, Params: 2,596,762 (9.906 MB), Total: 10.02 MB, FLOPs: 282,521,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1723 finished in 0m27s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 184)]\n",
      "Input: 0.115 MB, Params: 2,591,972 (9.888 MB), Total: 10.00 MB, FLOPs: 282,391,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1723 finished in 0m26s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.115 MB, Params: 2,586,696 (9.867 MB), Total: 9.98 MB, FLOPs: 282,096,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1723 finished in 0m30s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.115 MB, Params: 2,583,814 (9.856 MB), Total: 9.97 MB, FLOPs: 281,451,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1723 finished in 0m28s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 2,578,538 (9.836 MB), Total: 9.95 MB, FLOPs: 281,155,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1723 finished in 0m30s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 2,573,766 (9.818 MB), Total: 9.93 MB, FLOPs: 281,027,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1723 finished in 0m30s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.115 MB, Params: 2,568,994 (9.800 MB), Total: 9.92 MB, FLOPs: 280,898,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1723 finished in 0m30s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 2,564,222 (9.782 MB), Total: 9.90 MB, FLOPs: 280,769,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1723 finished in 0m29s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 2,560,861 (9.769 MB), Total: 9.88 MB, FLOPs: 280,678,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1723 finished in 0m30s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 197)]\n",
      "Input: 0.115 MB, Params: 2,557,500 (9.756 MB), Total: 9.87 MB, FLOPs: 280,588,039\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1723 finished in 0m30s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 2,556,013 (9.750 MB), Total: 9.87 MB, FLOPs: 279,216,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1723 finished in 0m30s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.115 MB, Params: 2,551,259 (9.732 MB), Total: 9.85 MB, FLOPs: 279,088,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1723 finished in 0m30s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 2,548,521 (9.722 MB), Total: 9.84 MB, FLOPs: 278,792,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1723 finished in 0m28s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 366)]\n",
      "Input: 0.115 MB, Params: 2,543,767 (9.704 MB), Total: 9.82 MB, FLOPs: 278,664,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1723 finished in 0m26s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 2,540,424 (9.691 MB), Total: 9.81 MB, FLOPs: 278,574,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1723 finished in 0m27s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 2,535,679 (9.673 MB), Total: 9.79 MB, FLOPs: 278,446,153\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1723 finished in 0m28s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 31)]\n",
      "Input: 0.115 MB, Params: 2,534,921 (9.670 MB), Total: 9.79 MB, FLOPs: 277,026,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1723 finished in 0m28s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 312)]\n",
      "Input: 0.115 MB, Params: 2,531,587 (9.657 MB), Total: 9.77 MB, FLOPs: 276,936,817\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1723 finished in 0m28s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 12)]\n",
      "Input: 0.115 MB, Params: 2,530,829 (9.654 MB), Total: 9.77 MB, FLOPs: 275,517,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1723 finished in 0m29s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 2,528,091 (9.644 MB), Total: 9.76 MB, FLOPs: 275,221,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1723 finished in 0m30s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 2,523,355 (9.626 MB), Total: 9.74 MB, FLOPs: 275,094,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1723 finished in 0m30s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 2,520,030 (9.613 MB), Total: 9.73 MB, FLOPs: 275,004,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1723 finished in 0m32s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.115 MB, Params: 2,516,705 (9.600 MB), Total: 9.72 MB, FLOPs: 274,914,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1723 finished in 0m27s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 2,513,841 (9.590 MB), Total: 9.70 MB, FLOPs: 274,271,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1723 finished in 0m27s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 2,509,123 (9.572 MB), Total: 9.69 MB, FLOPs: 274,144,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1723 finished in 0m30s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.115 MB, Params: 2,506,259 (9.561 MB), Total: 9.68 MB, FLOPs: 273,501,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 97.727%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1723 finished in 0m30s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.115 MB, Params: 2,501,073 (9.541 MB), Total: 9.66 MB, FLOPs: 273,210,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1723 finished in 0m26s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 26)]\n",
      "Input: 0.115 MB, Params: 2,500,315 (9.538 MB), Total: 9.65 MB, FLOPs: 271,790,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1723 finished in 0m28s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 333)]\n",
      "Input: 0.115 MB, Params: 2,495,606 (9.520 MB), Total: 9.64 MB, FLOPs: 271,663,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1723 finished in 0m32s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 2,492,299 (9.507 MB), Total: 9.62 MB, FLOPs: 271,574,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1723 finished in 0m29s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 112)]\n",
      "Input: 0.115 MB, Params: 2,487,122 (9.488 MB), Total: 9.60 MB, FLOPs: 271,282,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1723 finished in 0m30s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 2,483,815 (9.475 MB), Total: 9.59 MB, FLOPs: 271,193,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1723 finished in 0m30s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 2,479,133 (9.457 MB), Total: 9.57 MB, FLOPs: 271,067,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1723 finished in 0m33s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 72)]\n",
      "Input: 0.115 MB, Params: 2,477,682 (9.452 MB), Total: 9.57 MB, FLOPs: 270,423,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1723 finished in 0m34s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 2,474,384 (9.439 MB), Total: 9.55 MB, FLOPs: 270,334,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1723 finished in 0m36s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 86)]\n",
      "Input: 0.115 MB, Params: 2,472,933 (9.433 MB), Total: 9.55 MB, FLOPs: 269,690,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1723 finished in 0m32s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 157)]\n",
      "Input: 0.115 MB, Params: 2,470,231 (9.423 MB), Total: 9.54 MB, FLOPs: 269,398,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1723 finished in 0m29s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 2,465,558 (9.405 MB), Total: 9.52 MB, FLOPs: 269,272,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1723 finished in 0m29s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 309)]\n",
      "Input: 0.115 MB, Params: 2,462,269 (9.393 MB), Total: 9.51 MB, FLOPs: 269,184,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1723 finished in 0m28s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 233)]\n",
      "Input: 0.115 MB, Params: 2,457,605 (9.375 MB), Total: 9.49 MB, FLOPs: 269,058,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1723 finished in 0m29s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.115 MB, Params: 2,456,847 (9.372 MB), Total: 9.49 MB, FLOPs: 267,638,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1723 finished in 0m30s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 361)]\n",
      "Input: 0.115 MB, Params: 2,452,183 (9.354 MB), Total: 9.47 MB, FLOPs: 267,512,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1723 finished in 0m27s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.115 MB, Params: 2,449,346 (9.344 MB), Total: 9.46 MB, FLOPs: 266,879,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1723 finished in 0m28s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 57)]\n",
      "Input: 0.115 MB, Params: 2,447,913 (9.338 MB), Total: 9.45 MB, FLOPs: 265,583,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1723 finished in 0m28s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.115 MB, Params: 2,443,249 (9.320 MB), Total: 9.44 MB, FLOPs: 265,457,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1723 finished in 0m29s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 2,440,412 (9.309 MB), Total: 9.42 MB, FLOPs: 264,823,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1723 finished in 0m30s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,437,150 (9.297 MB), Total: 9.41 MB, FLOPs: 264,735,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1723 finished in 0m29s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.115 MB, Params: 2,435,717 (9.292 MB), Total: 9.41 MB, FLOPs: 263,439,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1723 finished in 0m31s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 2,432,455 (9.279 MB), Total: 9.39 MB, FLOPs: 263,351,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1723 finished in 0m31s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 2,429,193 (9.267 MB), Total: 9.38 MB, FLOPs: 263,263,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1723 finished in 0m31s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.115 MB, Params: 2,424,070 (9.247 MB), Total: 9.36 MB, FLOPs: 262,974,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1723 finished in 0m28s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.115 MB, Params: 2,419,442 (9.229 MB), Total: 9.34 MB, FLOPs: 262,849,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1723 finished in 0m27s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 2,416,189 (9.217 MB), Total: 9.33 MB, FLOPs: 262,761,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1723 finished in 0m31s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 2,412,936 (9.205 MB), Total: 9.32 MB, FLOPs: 262,674,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1723 finished in 0m28s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 19)]\n",
      "Input: 0.115 MB, Params: 2,412,894 (9.204 MB), Total: 9.32 MB, FLOPs: 259,480,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1723 finished in 0m27s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 2,408,284 (9.187 MB), Total: 9.30 MB, FLOPs: 259,356,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1723 finished in 0m31s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 2,405,040 (9.174 MB), Total: 9.29 MB, FLOPs: 259,268,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1723 finished in 0m27s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 2,400,439 (9.157 MB), Total: 9.27 MB, FLOPs: 259,144,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1723 finished in 0m27s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.115 MB, Params: 2,397,204 (9.145 MB), Total: 9.26 MB, FLOPs: 259,057,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1723 finished in 0m29s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 2,392,108 (9.125 MB), Total: 9.24 MB, FLOPs: 258,768,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1723 finished in 0m28s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 178)]\n",
      "Input: 0.115 MB, Params: 2,387,525 (9.108 MB), Total: 9.22 MB, FLOPs: 258,644,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1723 finished in 0m31s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 261)]\n",
      "Input: 0.115 MB, Params: 2,382,942 (9.090 MB), Total: 9.21 MB, FLOPs: 258,521,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1723 finished in 0m27s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 306)]\n",
      "Input: 0.115 MB, Params: 2,378,359 (9.073 MB), Total: 9.19 MB, FLOPs: 258,397,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1723 finished in 0m29s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.115 MB, Params: 2,373,290 (9.053 MB), Total: 9.17 MB, FLOPs: 258,109,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1723 finished in 0m29s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 2,368,221 (9.034 MB), Total: 9.15 MB, FLOPs: 257,821,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1723 finished in 0m31s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.115 MB, Params: 2,368,179 (9.034 MB), Total: 9.15 MB, FLOPs: 257,466,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1723 finished in 0m26s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.115 MB, Params: 2,364,971 (9.022 MB), Total: 9.14 MB, FLOPs: 257,380,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1723 finished in 0m26s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.115 MB, Params: 2,361,763 (9.009 MB), Total: 9.12 MB, FLOPs: 257,293,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1723 finished in 0m28s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 2,358,555 (8.997 MB), Total: 9.11 MB, FLOPs: 257,206,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1723 finished in 0m27s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 2,354,017 (8.980 MB), Total: 9.10 MB, FLOPs: 257,084,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1723 finished in 0m26s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 2,349,479 (8.963 MB), Total: 9.08 MB, FLOPs: 256,961,900\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1723 finished in 0m29s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.115 MB, Params: 2,348,046 (8.957 MB), Total: 9.07 MB, FLOPs: 255,700,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1723 finished in 0m27s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 2,343,508 (8.940 MB), Total: 9.06 MB, FLOPs: 255,578,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1723 finished in 0m26s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 60)]\n",
      "Input: 0.115 MB, Params: 2,340,860 (8.930 MB), Total: 9.04 MB, FLOPs: 255,292,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1723 finished in 0m26s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 2,335,827 (8.910 MB), Total: 9.03 MB, FLOPs: 255,005,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1723 finished in 0m27s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.115 MB, Params: 2,331,298 (8.893 MB), Total: 9.01 MB, FLOPs: 254,883,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1723 finished in 0m27s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 318)]\n",
      "Input: 0.115 MB, Params: 2,326,769 (8.876 MB), Total: 8.99 MB, FLOPs: 254,761,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1723 finished in 0m24s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 2,323,606 (8.864 MB), Total: 8.98 MB, FLOPs: 254,676,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1723 finished in 0m25s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 183)]\n",
      "Input: 0.115 MB, Params: 2,318,591 (8.845 MB), Total: 8.96 MB, FLOPs: 254,390,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1723 finished in 0m26s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 2,315,428 (8.833 MB), Total: 8.95 MB, FLOPs: 254,305,013\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1723 finished in 0m27s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 2,310,926 (8.815 MB), Total: 8.93 MB, FLOPs: 254,183,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1723 finished in 0m27s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 165)]\n",
      "Input: 0.115 MB, Params: 2,308,296 (8.805 MB), Total: 8.92 MB, FLOPs: 253,899,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1723 finished in 0m25s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 179)]\n",
      "Input: 0.115 MB, Params: 2,305,666 (8.795 MB), Total: 8.91 MB, FLOPs: 253,615,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1723 finished in 0m27s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 169)]\n",
      "Input: 0.115 MB, Params: 2,303,036 (8.785 MB), Total: 8.90 MB, FLOPs: 253,331,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1723 finished in 0m25s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 2,299,882 (8.773 MB), Total: 8.89 MB, FLOPs: 253,246,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1723 finished in 0m28s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 2,297,081 (8.763 MB), Total: 8.88 MB, FLOPs: 252,616,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1723 finished in 0m28s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 2,292,102 (8.744 MB), Total: 8.86 MB, FLOPs: 252,334,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1723 finished in 0m26s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 23)]\n",
      "Input: 0.115 MB, Params: 2,292,060 (8.744 MB), Total: 8.86 MB, FLOPs: 219,902,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.818%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.909%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1723 finished in 0m28s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 2,288,906 (8.731 MB), Total: 8.85 MB, FLOPs: 219,845,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1723 finished in 0m26s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.115 MB, Params: 2,284,431 (8.714 MB), Total: 8.83 MB, FLOPs: 219,765,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1723 finished in 0m24s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 2,279,956 (8.697 MB), Total: 8.81 MB, FLOPs: 219,684,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1723 finished in 0m25s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 269)]\n",
      "Input: 0.115 MB, Params: 2,276,820 (8.685 MB), Total: 8.80 MB, FLOPs: 219,628,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1723 finished in 0m23s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 2,271,859 (8.666 MB), Total: 8.78 MB, FLOPs: 219,407,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1723 finished in 0m28s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 146)]\n",
      "Input: 0.115 MB, Params: 2,266,898 (8.648 MB), Total: 8.76 MB, FLOPs: 219,186,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1723 finished in 0m25s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 203)]\n",
      "Input: 0.115 MB, Params: 2,263,762 (8.636 MB), Total: 8.75 MB, FLOPs: 219,130,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1723 finished in 0m28s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 2,259,323 (8.619 MB), Total: 8.73 MB, FLOPs: 219,050,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1723 finished in 0m26s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.115 MB, Params: 2,254,884 (8.602 MB), Total: 8.72 MB, FLOPs: 218,970,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1723 finished in 0m27s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.115 MB, Params: 2,251,766 (8.590 MB), Total: 8.71 MB, FLOPs: 218,914,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1723 finished in 0m28s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 45)]\n",
      "Input: 0.115 MB, Params: 2,251,035 (8.587 MB), Total: 8.70 MB, FLOPs: 217,655,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1723 finished in 0m25s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 2,247,917 (8.575 MB), Total: 8.69 MB, FLOPs: 217,598,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1723 finished in 0m24s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 2,244,799 (8.563 MB), Total: 8.68 MB, FLOPs: 217,542,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1723 finished in 0m24s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 2,243,375 (8.558 MB), Total: 8.67 MB, FLOPs: 216,367,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1723 finished in 0m25s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 323)]\n",
      "Input: 0.115 MB, Params: 2,238,963 (8.541 MB), Total: 8.66 MB, FLOPs: 216,288,225\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1723 finished in 0m25s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 2,234,551 (8.524 MB), Total: 8.64 MB, FLOPs: 216,208,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1723 finished in 0m26s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 2,230,139 (8.507 MB), Total: 8.62 MB, FLOPs: 216,129,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1723 finished in 0m23s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.115 MB, Params: 2,225,727 (8.490 MB), Total: 8.61 MB, FLOPs: 216,050,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1723 finished in 0m26s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 2,221,315 (8.474 MB), Total: 8.59 MB, FLOPs: 215,970,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1723 finished in 0m24s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 2,218,242 (8.462 MB), Total: 8.58 MB, FLOPs: 215,915,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1723 finished in 0m26s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 2,213,839 (8.445 MB), Total: 8.56 MB, FLOPs: 215,836,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1723 finished in 0m26s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 2,209,436 (8.428 MB), Total: 8.54 MB, FLOPs: 215,756,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.591%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.045%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1723 finished in 0m27s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 2,208,048 (8.423 MB), Total: 8.54 MB, FLOPs: 215,192,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.455%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.182%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1723 finished in 0m29s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 2,205,256 (8.412 MB), Total: 8.53 MB, FLOPs: 214,635,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.318%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
